services:
  neurosurfer:
    build:
      context: .
      dockerfile: Dockerfile
    image: neurosurfer:V1.0.0
    container_name: neurosurfer
    env_file:
      - .env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - NEUROSURFER_BACKEND_APP=neurosurfer.examples.quickstart_app_agent:ns
      - NEUROSURFER_BACKEND_HOST=0.0.0.0
      - NEUROSURFER_UI_HOST=0.0.0.0
      - NEUROSURFER_BACKEND_PORT=8081
      - NEUROSURFER_UI_PORT=5173
      - NEUROSURFER_UI_OPEN=false
      - CHAT_ANSWER_LANGUAGE=english
      - CHAT_ANSWER_LENGTH=detailed
      - NEUROSURFER_MODEL_PATH=/models/Qwen3-8B-unsloth-bnb-4bit
      - MODEL_MAX_SEQ_LEN=8000
      - LOG_TRACES=false
      - ENABLE_RAG=true
      - ENABLE_CODE_AGENT=true
    ports:
      - "8081:8081"
      - "5173:5173"
    volumes:
      - /home/nomi/workspace/Model_Weights:/models:ro
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia
    # command is already set via CMD in Dockerfile, so usually you don't need this:
    # command: ["python3", "-m", "neurosurfer.cli.main", "serve"]
