{
  "node_id": "research",
  "mode": "auto",
  "started_at": 1763463487.713657,
  "duration_ms": 2015,
  "error": null,
  "type": "tool_call",
  "selected_tool": "web_search",
  "inputs": {
    "query": "The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models"
  },
  "returns": {
    "query": "The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models",
    "summary": "Top 3 results out of ~70,300 results for: 'The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models'\n1. The Invisible Layer That Unlocks the Real Potential of AI ‚Äî https://skooloflife.medium.com/the-invisible-layer-that-unlocks-the-real-potential-of-ai-acdce54ff266\n2. A Short Primer on LLM Routing ‚Äî https://kleiber.me/blog/2025/08/10/llm-router-primer/\n3. Found in the Middle: How Language Models Use Long ... ‚Äî https://arxiv.org/html/2403.04797v1",
    "provider": "serpapi",
    "elapsed_ms": 814,
    "rag_content": "Source: 56d472196d75d0fd:cc35f490\nires neither additional fine-tuning nor increased memory usage. Instead, it involves a simple remapping of the position embedding depicted in Figure 2 , which enables the important information in the middle to be detected effectively (brown bars). For more details, see Section 4.2 and Figure 5 . Nevertheless, emerging research reveals the constrained efficacy of LLMs in managing tasks requiring long contextual understanding. Particularly, Liu et al. ( 2023 ) ... end, to fit the position-biased nature of RoPE. Chen et al. ( 2023d ) conducted parallel runs of LLMs with different RoPE angles, thereby mitigating the risk of overlooking crucial information through a weighted sum of the outputs. These approaches usually require additional memory or multiple inference runs, which can be expensive for LLMs. In this paper, we aim to address the ‚Äúlost-in-the-middle‚Äù problem by reintroducing the concept of multi-scale features from computer vision into the context of Transformer-based LLMs. Multi\n\n---\n\nSource: 3a3088c4c0eb7037:cc35f490\nContext Utilization Current LLMs tend to neglect information located in the middle of the context, despite its potential relevance. This ‚Äúlost in the middle‚Äù phenomenon likely arises from two contributing factors: (i) Casual Attention, where preceding tokens undergo a higher number of attention ... average accuracy when placing the key document in various positions. The bottom curve indicates the gap between the best and worst accuracy. Results. Figure 3 demonstrates that the gap accuracy can be alleviated via appropriate positional re-scaling. Particularly, we see that the Gap between the best and the worst accuracy is greatly reduced when increasing the re-scaling ratio. An enhanced average accuracy can be observed with a scaling ratio equals near 1.5 1.5 1.5 1.5 . Additionally, changing the scaling ratio also affects the favored zone of LLMs. With a small scaling ratio (e.g., 0.5 0.5 0.5 0.5 ), LLMs ... query within two different attention heads. Top: Results of the 12th attention h\n\n---\n\nSource: ee4e82f8edbd3230:cc35f490\nr. üß† Beyond Intelligence: Architecture as the Missing Piece As Reid Hoffman writes in Superagency : Developers will continue to write more efficient algorithms‚Ä¶ they‚Äôll come up with new architectures and techniques, and incorporate different approaches like multimodal learning and neurosymbolic AI systems that integrate neural networks with symbolic reasoning based on explicit, human-defined rules and logic. This reinforces the the idea that LLMs are limited not by intelligence ‚Äî but by incomplete architecture. To fix that, the infrastructure of Superagency requires three ... language intent and immediately transform it into structured, actionable behavior ‚Äî without scripting, hardcoding, or manual orchestration. In systems built for semantic execution: Memory is composable Tools are callable Logic is embedded in structure ‚Äî not buried in code or wrapped in prompt engineering This collapses the boundary between thinking and doing.The result is execution at the speed of thought ‚Äî where\n\n---\n\nSource: 371a60a368903236:cc35f490\nto action ‚Äî you stop managing the ... emerges from architecture and systems that connect memory, logic, execution, and reasoning ‚Äî with a human operator in the loop. That‚Äôs the shift this system embodies. You‚Äôre not getting smarter outputs from smarter models. You‚Äôre getting smarter workflows from connected components. Memory is no longer a static archive . It‚Äôs a dynamic, routable asset ‚Äî something that can be reused, acted upon, queried, and transformed in real time. Tools aren‚Äôt just interfaces . They‚Äôre execution layers ‚Äî endpoints that make reasoning actionable. The model itself becomes just one part of a broader cognitive circuit. Pair that with memory, route it ... is a natural language operating system that transforms text into real actions across your tools ‚Äî like creating documents, moving files, sending messages, and chaining entire workflows. It connects to any external API ‚Äî from tools like Notion, Dropbox, and Gmail to document editors like Outline ‚Äî and automatically int\n\n---\n\nSource: 142ed1229175e45b:cc35f490\nabout the generative inference process of Large Language Models ... (Zhang et al., 2024 ) . These approaches have successfully expanded the contextual window with minimal or no additional training overhead. Despite the extended context window, LLMs still face a significant challenge in long-context inference due to the uneven utilization of lengthy inputs. Liu et al. ( 2023 ) conducted a pivotal investigation, revealing that LLMs tend to overlook the middle portion of the input. This bias compromises the practical application of LLMs, as critical information may be located in the middle part of the input, leading to unreliable outputs. To tackle this issue, Peysakhovich & Lerer ( 2023 ) ... italic_T end_POSTSUPERSCRIPT italic_f ( bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_n ) = italic_g ( bold_q start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_m - italic_n ) Here, f ùëì f italic_f is the positional encodin\n\n---\n\nSource: b38485ad1c38f6c4:cc35f490\necifically to tackle the ‚Äúlost-in-the-middle‚Äù problem, we include it in our comparison for its ... 61.0 57.4 58.4 64.8 61.12 PI 65.2 62.4 60.0 60.4 64.0 62.40 Self-Extend 64.7 63.7 61.4 59.8 62.0 62.32 Ms-PoE 65.6 64.2 63.0 65.2 67.2 65.04 Models Methods Key-Value Retrival 1 15 30 40 50 Average Vicuna-7B Baseline 92.0 25.8 8.0 25.4 30.0 36.24 PI 96.4 76.4 61.4 64.6 57.8 67.60 Self-Extend 88.6 63.8 76.2 59.4 42.0 66.00 Ms-PoE 97.0 83.4 75.0 86.6 57.8 79.96 Outperform other competitive methods. We conduct a thorough comparison between Ms-PoE and other competitive methods, including Positional Interpolation (PI) (Chen et al., 2023c ) and Self-Extend (Jin et al., 2024 ) , both of which ... the accuracy of the generated context. All results are averaged across 500 samples. The Gap accuracy metric is employed to assess the context utilization ability of LLMs, defined as the gap between the best and worst accuracy when varying the position of important information. Main Results. As depicted i\n\n---\n\nSource: 38e83f6f12d9e3d4:cc35f490\ned in Table 4 , indicate that adjusting the scaling ratio between 0.5 0.5 0.5 0.5 and 2.5 2.5 2.5 2.5 can significantly enhance generative performance and mitigate the ‚Äùlost-in-the-middle‚Äù ... guidelines to ensure that the applications of LLM advancements contribute positively to society. 7 Acknowledgements We thank Dr. Yuandong Tian for interesting discussions on this work. References Chen et al. (2023a) Chen, G., Li, X., Meng, Z., Liang, S., and Bing, L. Clex: Continuous length extrapolation for large language models. arXiv preprint arXiv:2310.16450 , 2023a. Chen et al. (2023b) Chen, H., Pasunuru, R., Weston, J., and Celikyilmaz, A. Walking down the memory maze: Beyond context limit through interactive reading. arXiv preprint arXiv:2310.05029 , 2023b. Chen et al. (2023c) Chen, S., Wong, S., Chen, L., and Tian, Y. Extending context window ... Jacobs, S. A., Tanaka, M., Zhang, C., Zhang, M., Song, S. L., Rajbhandari, S., and He, Y. Deepspeed ulysses: System optimizations for enabling t\n\n---\n\nSource: de1fc7972617aa65:cc35f490\nf LLMs. With a small scaling ratio (e.g., 0.5 0.5 0.5 0.5 ), LLMs ... query within two different attention heads. Top: Results of the 12th attention head in the 15th layer. Bottom: Results of the 8th attention head in the 15th layer. The most recent query remains unchanged while varying the position of the crucial document. More examples are reported in Figure 6 in the appendix. Observation. We observe the presence of ‚Äúposition-aware‚Äù attention heads capable of capturing relevant information even when its position is shifted. As an example, we select the eighth attention head in the fifteenth layer, depicted in the bottom of Figure 4 , while consistent observations can be drawn across ... using Œ± = 3 ùõº 3 \\alpha=3 italic_Œ± = 3 , and the corresponding important tokens are highlighted in Figure 4 , which are shown in red. In the spirit of numerous studies that investigate the outlier properties in LLMs (Xiao et al., 2023 ; Lin et al., 2023 ; Yin et al., 2023 ) , we utilize ùíÆ P subscript ùíÆ\n\n---\n\nSource: c965c36ef6c6f4fe:cc35f490\nbility of LLMs, defined as the gap between the best and worst accuracy when varying the position of important information. Main Results. As depicted in Figure 5 and 1 , Ms-PoE demonstrates consistent improvement across different models, tasks and critical positions. Even when the important information exists in the sweet region (beginning and end) of the input, Ms-PoE achieves significant performance improvements ranging from 3% to 6%, highlighting its efficacy in enhancing generation quality. Moreover, the ... 61.0 2.5 59.5 57.5 57.0 58.0 0.8 ‚Üí ‚Üí \\to ‚Üí 2.2 53.5 59.5 67.5 60.2 1 ‚Üí ‚Üí \\to ‚Üí 2 61.0 57.0 63.0 60.3 1.2 ‚Üí ‚Üí \\to ‚Üí 1.8 65.6 63.0 67.2 65.3 1.4 ‚Üí ‚Üí \\to ‚Üí 1.6 65.5 59.0 63.0 62.5 A2: Ablation study of the scaling ratios. We first examined the effect of uniform scaling ratios across all heads on model performance. Our findings, outlined in Table 4 , indicate that adjusting the scaling ratio between 0.5 0.5 0.5 0.5 and 2.5 2.5 2.5 2.5 can significantly enhance generative performance\n\n---\n\nSource: 9082a45da31dbc9e:cc35f490\nost-in-the-middle‚Äù problem by reintroducing the concept of multi-scale features from computer vision into the context of Transformer-based LLMs. Multi-scale features, well-established in Inception-style models (Szegedy et al., 2015 , 2016 ; Guo et al., 2022 ) , utilize ... acquired during the pre-training phase. The efficacy of Ms-PoE is substantiated through extensive experiments. By simply re-scaling the indices of positional encoding, Ms-PoE consistently enhances the performance of various LLMs including Llama-2 (Touvron et al., 2023 ) , StableBeluga ( Mahan et al., ) and Vicuna (Chiang et al., 2023 ) on the ZeroSCROLLS benchmark (Shaham et al., 2023 ) , achieving a notable average accuracy gain of up to 3.8. 2 Background and Related Works In this section, we provide a concise overview of the background knowledge and recent literature about the generative inference process of Large Language Models ... (Zhang et al., 2024 ) . These approaches have successfully expanded the contextual"
  },
  "final": false,
  "extras": {}
}