{
  "node_id": "research",
  "mode": "auto",
  "started_at": 1763446662.6447718,
  "duration_ms": 1356,
  "error": null,
  "type": "tool_call",
  "selected_tool": "web_search",
  "inputs": {
    "query": "Using tool-augmented LLM agents to build reliable workflows",
    "hl": "en"
  },
  "returns": {
    "query": "Using tool-augmented LLM agents to build reliable workflows",
    "summary": "Top 2 results out of ~612,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\n1. Building Effective AI Agents — https://www.anthropic.com/research/building-effective-agents\n2. Fundamentals of Building Autonomous LLM Agents † — https://arxiv.org/html/2510.09244v1",
    "results": [
      {
        "title": "Building Effective AI Agents",
        "url": "https://www.anthropic.com/research/building-effective-agents",
        "snippet": "The basic building block of agentic systems is an LLM enhanced with augmentations such as retrieval, tools, and memory. Our current models can ...",
        "score": null,
        "content": null,
        "content_length": null,
        "error": null
      },
      {
        "title": "Fundamentals of Building Autonomous LLM Agents †",
        "url": "https://arxiv.org/html/2510.09244v1",
        "snippet": "Many people confuse workflows with agents ... LLM-based agents can significantly enhance their perception capabilities through tool augmentation.",
        "score": null,
        "content": "Fundamentals of Building Autonomous LLM Agents This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. 1 1 institutetext: Universitat Politècnica de Catalunya, Barcelona, Spain 1 1 email: victor.de.lamo@estudiantat.upc.edu 2 2 institutetext: Technische Universität München, München, Germany 2 2 email: {habtom.gidey, alex.lenz, knoll}@tum.de Fundamentals of Building Autonomous LLM Agents † † thanks: This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. Victor de Lamo Castrillo Habtom Kahsay Gidey Alexander Lenz Alois ... of tasks, including natural language processing (NLP), machine translation, vision applications, and question-answering. 2.2 From LLMs to LLM Agents LLMs in their standard form have significant limitations due to their chatbot nature. This restricts their effectiveness in real-world tasks. These models lack long-term memory, cannot autonomously interact with external tools, and struggle to pursue goals in dynamic environments. Such shortcomings hinder their performance in scenarios requiring sustained reasoning or multi-step workflows [ 61 ] . To overcome these constraints, LLMs are guided to follow a reasoning path and are provided with tools to interact with the environment that enables them ... paper “VCoder: Versatile Vision Encoders for Multimodal Large Language Models” by Jain et al. (2023) [ 28 ] , traditional MM-LLM systems often face limitations in fundamental visual perception, such as accurately identifying or counting objects, and a tendency to hallucinate non-existent entities. A faster and more cost-effective way to enhance perception (rather than improving each individual component of an MM-LLM) is to use visual encoders. These encoders, which can be separate models, extract relevant information from images to help the MM-LLM interpret them more effectively. While this approach doesn’t match the performance gains of directly improving each component of ... . • Data Collection: Training robust perception systems, particularly for multimodal or specialized domains, often requires large volumes of high-quality, annotated data. The collection of this data can be costly and time-consuming. • Computational Resources: High-fidelity perception, especially with multimodal inputs, requires high computational resources for both training and inference. This can be a barrier for execution in resource-constrained environments or for widespread adoption. Ultimately, the quality and fidelity of an LLM agent’s perception system directly affects the reasoning and planning modules. Therefore, continuous advancements in perception technologies are not merely improvements to one component, but fundamental enablers for building ... reasoning, and outcomes, and then use these insights to improve its future performance. This allows agents to learn from their mistakes or inefficiencies without human intervention. Key characteristics of reflection include: • Self-Evaluation: The agent examines its completed (or ongoing) task, its generated plans, and the results of its actions. This often involves comparing actual and expected outcomes. • Error Detection and Analysis: Identifying where things went wrong, why a plan failed, or where the reasoning failed. This can be due to misunderstandings of the prompt, incorrect tool usage, logical inconsistencies, or environmental changes. Papers like [ 49 ] and ... and roles” [ 51 ] of your expert. This involves: • Clear Specialization: What specific task, domain, or reasoning capability will this expert excel at? (e.g., planning, code generation, error handling). • Input and Output: What kind of information does this expert take as input, and what kind of output does it produce? • Boundaries: What are the limitations of its expertise? When should other experts be consulted or take over? [ 33 ] . 4.6.1 Equip with Knowledge An expert’s effectiveness hinges on its specialized knowledge. This can be achieved by: • Targeted Prompting: Crafting precise and detailed prompts ... Experiences: It is beneficial to store records of both successful and failed tasks. Research has indicated that even failed experiences, when appropriately logged and distinguished as such, can be valuable. By explicitly noting a “failed experience,” LLMs can learn to avoid repeating similar mistakes in the future. This continuous learning from past interactions, including the identification of “invalid action filtering,” contributes to the agent’s robust development and ability to adapt [ 1 , 22 ] . To store an experience, you capture a task’s natural language instruction (e.g., “Who ordered order 0130?” ) and the sequence of steps taken to ... approach is especially valuable for data manipulation tasks, complex calculations, file processing, and integration between different systems. Agents can write Python scripts for data analysis, generate SQL queries for database operations, create shell scripts for system administration, or produce HTML/CSS/JavaScript for web-based solutions [ 10 , 42 ] . 6.2.3 Robotic and Physical System Control: In robotics applications, LLM agents can control physical systems through appropriate APIs and sensor integrations [ 61 ] . They process sensor data (cameras, force sensors, temperature sensors) to understand the physical environment, generate motion plans and control commands, coordinate multiple actuators and subsystems, and ... https://arxiv.org/abs/2305.14992 [25] Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems 43 (2) (2025). doi: 10.1145/3703155 , http://dx.doi.org/10.1145/3703155 [26] Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint (2024), https://arxiv.org/abs/2402.02716 [27] Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills in humanoid robots: A deep learning approach. ... Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH [69] Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large language models with long-term memory. arXiv preprint (2023), https://arxiv.org/abs/2305.10250 [70] Zhou, S., Xu, F.F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T., Bisk, Y., Fried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building autonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854 [71] Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist agents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.07972 [72] Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced",
        "content_length": 6990,
        "error": null
      }
    ],
    "provider": "serpapi",
    "elapsed_ms": 275
  },
  "final": false,
  "extras": {}
}