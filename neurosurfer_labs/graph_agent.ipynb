{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b35214-7a1f-403c-9a7a-b42e481ab431",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go up one directory from `b/` to project root\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affc4a2e-d532-4dee-8b50-cab72fd229c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:28:55\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Initializing Transformers model.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-14 11:28:55\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Model is already quantized. Ignoring load_in_4bit=True.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:28:56\u001b[0m | \u001b[96mmodeling.py:get_balanced_memory\u001b[0m | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:29:01\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Transformers model initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from neurosurfer.models.chat_models.transformers import TransformersModel\n",
    "from neurosurfer import config \n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "DEFAULT_TRANSFORMERS_MODEL_PARAMS = dict({\n",
    "    \"model_name\": \"/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"max_seq_length\": 16_000,\n",
    "    \"load_in_4bit\": True,\n",
    "    \"enable_thinking\": False,  # main_gpu interpretation\n",
    "    \"verbose\": False\n",
    "})\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "LLM = TransformersModel(\n",
    "    **DEFAULT_TRANSFORMERS_MODEL_PARAMS,\n",
    "    stop_words=[\"Observation:\"],\n",
    "    logger = logging.getLogger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ff5798-3ed2-4b38-86cd-2498ca0e57be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, a crysp and light-hearted joke? Let me whip up a little bit of fun for you!\n",
      "\n",
      "Why don't skeletons ever tell jokes?  \n",
      "Because they don‚Äôt have the *guts*! üòÑ\n",
      "\n",
      "*P.S. I‚Äôm not sure if that‚Äôs crysp enough‚Ä¶ but I tried!*"
     ]
    }
   ],
   "source": [
    "# streaming response example\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "system_prompt = \"You are a joker.\"\n",
    "user_prompt = \"\"\"Tell me a crysp and light-hearted joke.\"\"\"\n",
    "\n",
    "stream_response = LLM.ask(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "md_display = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream_response:\n",
    "    chunk = chunk.choices[0].delta.content or \"\"\n",
    "    print(chunk, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808255b3",
   "metadata": {},
   "source": [
    "### Agent Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3030e4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:29:03\u001b[0m | \u001b[96magent.py:run\u001b[0m     | üß† Thinking...\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-14 11:29:03\u001b[0m | \u001b[96magent.py:run\u001b[0m     | `output_schema` provided with `stream=True`; forcing non-streaming structured output.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.structured_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'AI'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">52</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">61</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">max_new_tokens</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4096</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">temperature</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">0.7</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.structured_call \u001b[0m\u001b[2;33mschema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'AI'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m52\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m61\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmax_new_tokens\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m4096\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtemperature\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m0\u001b[0m\u001b[1;2;36m.7\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ llm.structured_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'AI'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ llm.structured_call \u001b[0m\u001b[2;33mschema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'AI'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ llm.structured_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'AI'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">811s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ llm.structured_call \u001b[0m\u001b[2;33mschema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'AI'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m811s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.structured_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'AI'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">52</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">61</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">max_new_tokens</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4096</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">temperature</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">0.7</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">815s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.structured_call \u001b[0m\u001b[2;33mschema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'AI'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m52\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m61\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmax_new_tokens\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m4096\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtemperature\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m0\u001b[0m\u001b[1;2;36m.7\u001b[0m\u001b[2m \u001b[0m\n",
       "\u001b[2mtook \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m815s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">818s; </span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m818s; \u001b[0m\n",
       "\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"definition\": \"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and problem-solve.\",\n",
      "  \"history\": \"The concept of AI dates back to the 1950s, with the term 'artificial intelligence' coined in 1956. Early developments focused on rule-based systems and problem-solving algorithms, while recent advancements have been driven by machine learning and big data.\",\n",
      "  \"modern_frameworks\": \"Modern frameworks include TensorFlow, PyTorch, and Scikit-learn, which enable the development of complex AI models for various applications.\",\n",
      "  \"applications\": [\n",
      "    {\n",
      "      \"title\": \"Healthcare\",\n",
      "      \"description\": \"AI is used for disease diagnosis, drug discovery, and personalized treatment plans.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Finance\",\n",
      "      \"description\": \"AI is used for fraud detection, algorithmic trading, and risk management.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Autonomous Vehicles\",\n",
      "      \"description\": \"AI enables self-driving cars through computer vision and real-time data processing.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# agent normal response\n",
    "from neurosurfer.agents import Agent, AgentConfig\n",
    "from neurosurfer.agents.common.tracing import RichTracer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    strict_tool_call=True,\n",
    "    return_stream_by_default=True,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=4096,\n",
    ")\n",
    "agent = Agent(llm=LLM, config=agent_config, tracer=RichTracer(), enable_tracing=True)\n",
    "\n",
    "# # normal response\n",
    "# print(\"Normal Response:\")\n",
    "# print(agent.run(user_prompt=\"What is AI (one line)?\", stream=False))\n",
    "\n",
    "# # streaming response\n",
    "# print(\"\\n\\nStreaming Response:\")\n",
    "# for c in agent.run(user_prompt=\"What are top 3 applications of AI (one line)?\"):\n",
    "#     print(c, flush=True, end=\"\")\n",
    "\n",
    "\n",
    "# Structured Response examples\n",
    "class AIApplication(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "class AI(BaseModel):\n",
    "    definition: str\n",
    "    history: str\n",
    "    modern_frameworks: str\n",
    "    applications: list[AIApplication]\n",
    "\n",
    "user_query = \"What is AI and list 3 of its top application, and 3 concerns.\"\n",
    "structured_response = agent.run(user_prompt=user_query, output_schema=AI, trace=True)\n",
    "print(structured_response.json_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf48079",
   "metadata": {},
   "source": [
    "**Tool Calling Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "440e9634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:29:13\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: calculator\n",
      "Tool description:\n",
      "Tool Name: `calculator`\n",
      "Description: Perform basic arithmetic operations such as addition, subtraction, multiplication, and division.\n",
      "When to use: Use this tool when you need to perform basic arithmetic operations.\n",
      "Tool Inputs:\n",
      "- `num1`: float (required) ‚Äî The first number.\n",
      "- `num2`: float (required) ‚Äî The second number.\n",
      "- `operation`: string (required) ‚Äî The operation to perform strictly one of ['add', 'subtract', 'multiply', 'divide'].\n",
      "Tool Return: float ‚Äî The result of the arithmetic operation.\n",
      "\n",
      "\n",
      "Agent with choice between tools and plain text:\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:29:13\u001b[0m | \u001b[96magent.py:run\u001b[0m     | üß† Thinking...\n",
      "AI stands for Artificial Intelligence, which refers to the simulation of human intelligence in machines that are programmed to think, learn, and make decisions. These systems can perform tasks such as problem-solving, understanding natural language, recognizing patterns, and adapting to new information.\n",
      "Agent with strict tool call:\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:29:14\u001b[0m | \u001b[96magent.py:run\u001b[0m     | üß† Thinking...\n",
      "ToolCallResponse(selected_tool='calculator', inputs={'num1': 100.0, 'num2': 4.0, 'operation': 'divide'}, returns='25.0', final=False, extras={})\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "from neurosurfer.tools.tool_spec import ToolSpec, ToolParam, ToolReturn\n",
    "from neurosurfer.tools.base_tool import BaseTool, ToolResponse\n",
    "\n",
    "# Simple Calculator Tool\n",
    "class CalculatorTool(BaseTool):\n",
    "    spec = ToolSpec(\n",
    "        name=\"calculator\",\n",
    "        description=\"Perform basic arithmetic operations such as addition, subtraction, multiplication, and division.\",\n",
    "        when_to_use=\"Use this tool when you need to perform basic arithmetic operations.\",\n",
    "        inputs=[\n",
    "            ToolParam(name=\"num1\", type=\"float\", description=\"The first number.\", required=True),\n",
    "            ToolParam(name=\"num2\", type=\"float\", description=\"The second number.\", required=True),\n",
    "            ToolParam(name=\"operation\", type=\"string\", description=\"The operation to perform strictly one of ['add', 'subtract', 'multiply', 'divide'].\", required=True)\n",
    "        ],\n",
    "        returns=ToolReturn(type=\"float\", description=\"The result of the arithmetic operation.\")\n",
    "    )\n",
    "\n",
    "    def __init__(self, final_answer: bool = False):\n",
    "        self.final_answer = final_answer\n",
    "\n",
    "    def __call__(self, num1: float, num2: float, operation: str) -> ToolResponse:\n",
    "        if operation not in [\"add\", \"subtract\", \"multiply\", \"divide\"]:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=\"Invalid operation. Supported operations are 'add', 'subtract', 'multiply', and 'divide'.\",\n",
    "                extras={}\n",
    "            )\n",
    "        \n",
    "        if operation == \"divide\" and num2 == 0:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=\"Division by zero is not allowed.\",\n",
    "                extras={}\n",
    "            )\n",
    "        try:\n",
    "            num1 = float(num1)\n",
    "            num2 = float(num2)\n",
    "            if operation == \"add\":\n",
    "                result = num1 + num2\n",
    "            elif operation == \"subtract\":\n",
    "                result = num1 - num2\n",
    "            elif operation == \"multiply\":\n",
    "                result = num1 * num2\n",
    "            elif operation == \"divide\":\n",
    "                result = num1 / num2\n",
    "        except Exception as e:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=f\"An error occurred: {str(e)}\",\n",
    "                extras={}\n",
    "            )\n",
    "        \n",
    "        return ToolResponse(\n",
    "            final_answer=self.final_answer,\n",
    "            results=float(result),\n",
    "            extras={}\n",
    "        )\n",
    "\n",
    "calculator_tool = CalculatorTool()\n",
    "toolkit = Toolkit(tools=[calculator_tool])\n",
    "\n",
    "print(\"Tool description:\")\n",
    "print(calculator_tool.get_tool_description())\n",
    "print()\n",
    "\n",
    "agent = Agent(llm=LLM, toolkit=toolkit)\n",
    "\n",
    "print(\"Agent with choice between tools and plain text:\")\n",
    "response = agent.run(user_prompt=\"What is AI?\", strict_tool_call=False)\n",
    "print(response)\n",
    "\n",
    "print(\"Agent with strict tool call:\")\n",
    "response = agent.run(user_prompt=\"What is one forth of a 100?\", strict_tool_call=True)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b1381",
   "metadata": {},
   "source": [
    "## RAG wiring so the agent ‚Äúunderstands‚Äù the Neurosurf codebase\n",
    "\n",
    "You‚Äôll ingest the repo once, then run a retriever to answer code questions. The Planner can call the retriever first to form a precise implementation plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5bf38-1a5b-4ad1-be5f-b5073dbeaaf0",
   "metadata": {},
   "source": [
    "### FileReader and Chunker Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79d61982-ac42-46b7-8a6b-bc3ed2248907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # scripts/index_repo_for_rag.py\n",
    "# from pathlib import Path\n",
    "# from neurosurfer.rag.ingestor import RAGIngestor\n",
    "# from neurosurfer.rag.chunker import Chunker\n",
    "# from neurosurfer.rag.filereader import FileReader\n",
    "# from neurosurfer.vectorstores.chroma import ChromaVectorStore\n",
    "# from neurosurfer.models.embedders.sentence_transformer import SentenceTransformerEmbedder\n",
    "\n",
    "# embedder = SentenceTransformerEmbedder(\"intfloat/e5-small-v2\")\n",
    "# vs = ChromaVectorStore(collection_name=\"neurosurf-repo\")\n",
    "# ing = RAGIngestor(\n",
    "#     embedder=embedder,\n",
    "#     vector_store=vs, \n",
    "#     chunker=Chunker(), \n",
    "#     file_reader=FileReader(),\n",
    "#     default_metadata={\"collection\": \"neurosurf\"}\n",
    "# )\n",
    "\n",
    "# root_dir = Path(os.getcwd()).parent.joinpath(\"neurosurfer\")\n",
    "# ing.add_directory(root_dir)  # the repo root\n",
    "# print(ing.build())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4c8c2",
   "metadata": {},
   "source": [
    "## Graph AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec7eb2",
   "metadata": {},
   "source": [
    "### YAML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key:  f443633b\n",
      "ToolResponse(final_answer=False, results={'query': 'What is the capital of France?', 'summary': \"Top 1 results out of some results for: 'What is the capital of France?'\\n1. Paris ‚Äî https://en.wikipedia.org/wiki/Paris\", 'results': [{'title': 'Paris', 'url': 'https://en.wikipedia.org/wiki/Paris', 'snippet': 'Paris is the capital and largest city of France, with an estimated city population of 2,048,472 in an area of 105.4 km2 (40.7 sq mi), and a metropolitan ...', 'score': None}], 'provider': 'serpapi', 'elapsed_ms': 2075}, extras={})\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:29:51\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n",
      "{'web_search': <tools.websearch.WebSearchTool object at 0x7eddbaf9c150>}\n"
     ]
    }
   ],
   "source": [
    "# test web search tool\n",
    "from tools.websearch import WebSearchTool\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "\n",
    "api_key = os.getenv(\"SERPAPI_KEY\", \"API Key not found...\")\n",
    "print(\"API Key: \", api_key[:8])\n",
    "web_search_tool = WebSearchTool(\n",
    "    api_key=api_key,\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "# searches = web_search_tool(query=\"What is the capital of France?\")\n",
    "# print(searches)\n",
    "\n",
    "toolkit = Toolkit(tools=[web_search_tool])\n",
    "print(toolkit.registry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf1ccb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='blog_workflow' description='Example multi-agent workflow for writing and reviewing a technical blog using multiple specialized nodes (each node uses an Agent under the hood).\\n' inputs=[GraphInputSpec(name='topic_title', type='string', required=True, description=None), GraphInputSpec(name='query', type='string', required=True, description=None)] nodes=[GraphNode(id='research', description=None, purpose='Perform focused research on the requested topic titled {topic_title}.', goal='Collect key facts, terminology, and references that are directly useful for writing a technical blog post.\\n', expected_result=\"A compact, structured summary with sections for 'key_points', 'sources', and 'risks_or_caveats'.\\n\", tools=['web_search'], depends_on=[], mode=<NodeMode.AUTO: 'auto'>, output_schema=None, model=None, policy=None), GraphNode(id='outline', description=None, purpose='Design a clear structure for the article.', goal='Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.\\n', expected_result='A title, a detailed description, and an ordered list of sections with headings and bullet points.\\n', tools=[], depends_on=['research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=None), GraphNode(id='draft', description=None, purpose='Write the first full draft of the article.', goal='Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n', expected_result='A complete draft in markdown, including title, headings, and paragraphs.\\n', tools=[], depends_on=['outline', 'research'], mode=<NodeMode.TEXT: 'text'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=8096, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None)), GraphNode(id='review', description=None, purpose='Perform technical and editorial review of the draft.', goal='Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n', expected_result='A structured review with strengths, issues, and concrete suggestions.\\n', tools=[], depends_on=['draft', 'research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=8096, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None))] outputs=['draft', 'review']\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-14 11:50:22\u001b[0m | \u001b[96mutils.py:normalize_and_validate_graph_inputs\u001b[0m | Ignoring extra inputs not declared in graph spec: audience, tone\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">graph_name</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'blog_workflow'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">num_nodes</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.run \u001b[0m\u001b[2;33mgraph_name\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'blog_workflow'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mnum_nodes\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:50:22\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.AUTO:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'auto'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'web_search'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.AUTO:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'auto'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'web_search'\u001b[0m\u001b[1;2m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.AUTO:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'auto'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'web_search'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">513s;</span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.AUTO:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'auto'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'web_search'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m513s;\u001b[0m\n",
       "\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.AUTO:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'auto'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.AUTO:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'auto'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:50:25\u001b[0m | \u001b[96magent.py:run\u001b[0m     | üß† Thinking...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.route_and_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">406</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">temperature</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">0.7</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">max_new_tokens</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">512</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.route_and_call \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m406\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtemperature\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m0\u001b[0m\u001b[1;2;36m.7\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmax_new_tokens\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m512\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.route_and_call.router_llm_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">attempt</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">1</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.route_and_call.router_llm_call \u001b[0m\u001b[2;33mattempt\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.route_and_call.router_llm_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">attempt</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">1</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">1.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">055s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.route_and_call.router_llm_call \u001b[0m\u001b[2;33mattempt\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m055s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:50:26\u001b[0m | \u001b[96magent.py:_route_and_call\u001b[0m | [ToolsCallingAgent] Selected tool: web_search\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:50:26\u001b[0m | \u001b[96magent.py:_route_and_call\u001b[0m | [ToolsCallingAgent] Raw inputs: {'query': 'Using tool-augmented LLM agents to build reliable workflows', 'hl': 'en'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.route_and_call.tool_execute </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tool_name</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'web_search'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">payload_keys</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'query'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'hl'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'graph_inputs'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'dependencies'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.route_and_call.tool_execute \u001b[0m\u001b[2;33mtool_name\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'web_search'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mpayload_keys\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'query'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'hl'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'graph_inputs'\u001b[0m\u001b[2m, \u001b[0m\n",
       "\u001b[2;32m'dependencies'\u001b[0m\u001b[1;2m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.route_and_call.tool_execute </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tool_name</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'web_search'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">payload_keys</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'query'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'hl'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'graph_inputs'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'dependencies'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">1.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">802s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.route_and_call.tool_execute \u001b[0m\u001b[2;33mtool_name\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'web_search'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mpayload_keys\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'query'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'hl'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'graph_inputs'\u001b[0m\u001b[2m, \u001b[0m\n",
       "\u001b[2;32m'dependencies'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m802s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.route_and_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">406</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">temperature</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">0.7</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">max_new_tokens</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">512</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">860s; </span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.route_and_call \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m406\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtemperature\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m0\u001b[0m\u001b[1;2;36m.7\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmax_new_tokens\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m512\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m860s; \u001b[0m\n",
       "\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fff7f; text-decoration-color: #7fff7f; font-style: italic\">True</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">862s; </span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m862s; \u001b[0m\n",
       "\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.AUTO:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'auto'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">863s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.AUTO:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'auto'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m863s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'outline'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'outline'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">047s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\n",
       "\u001b[2mtook \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m047s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'outline'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:50:30\u001b[0m | \u001b[96magent.py:run\u001b[0m     | üß† Thinking...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.free_text_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">564</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">326</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.free_text_call \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m564\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m326\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.free_text_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">564</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">326</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">12.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">443s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.free_text_call \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m564\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m326\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m12.\u001b[0m\u001b[2m443s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">12.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">444s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\n",
       "\u001b[1;2;36m12.\u001b[0m\u001b[2m444s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'outline'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">12.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">446s; </span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m12.\u001b[0m\u001b[2m446s; \u001b[0m\n",
       "\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'draft'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.TEXT:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'text'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'outline'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.TEXT:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'text'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'draft'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.TEXT:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'text'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'outline'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">737s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.TEXT:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'text'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m took \u001b[0m\n",
       "\u001b[1;2;36m2.\u001b[0m\u001b[2m737s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'draft'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.TEXT:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'text'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.TEXT:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'text'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:50:45\u001b[0m | \u001b[96magent.py:run\u001b[0m     | üß† Thinking...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.free_text_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">577</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">467</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.free_text_call \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m577\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m467\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.free_text_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">577</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">467</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">24.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.free_text_call \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m577\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m467\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m24.\u001b[0m\u001b[2m170s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">24.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\n",
       "\u001b[1;2;36m24.\u001b[0m\u001b[2m172s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'draft'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.TEXT:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'text'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">24.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.TEXT:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'text'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m24.\u001b[0m\u001b[2m173s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'review'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'draft'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\n",
       "\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.start </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'review'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">depends_on</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'draft'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">, </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'research'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tools</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">802s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.start \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mdepends_on\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m, \u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\n",
       "\u001b[2;33mtools\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m802s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'review'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-14 11:51:12\u001b[0m | \u001b[96magent.py:run\u001b[0m     | üß† Thinking...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚ñ∂ agent.free_text_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">584</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">440</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚ñ∂ agent.free_text_call \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m584\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m440\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.free_text_call </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">system_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">584</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">user_prompt_len</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">440</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">23.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">505s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.free_text_call \u001b[0m\u001b[2;33msystem_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m584\u001b[0m\u001b[2m \u001b[0m\u001b[2;33muser_prompt_len\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m440\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m23.\u001b[0m\u001b[2m505s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ agent.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">agent_type</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'Agent'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_toolkit</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">structured</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">stream</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strict_tool_call</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">23.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">507s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ agent.run \u001b[0m\u001b[2;33magent_type\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'Agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_toolkit\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstructured\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstream\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mstrict_tool_call\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\n",
       "\u001b[1;2;36m23.\u001b[0m\u001b[2m507s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.node.agent_run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">node_id</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'review'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mode</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&lt;</span><span style=\"color: #ff7fff; text-decoration-color: #ff7fff; font-weight: bold\">NodeMode.STRUCTURED:</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'structured'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">&gt;</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">has_schema</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">23.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">508s; </span>\n",
       "<span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.node.agent_run \u001b[0m\u001b[2;33mnode_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mmode\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2m<\u001b[0m\u001b[1;2;95mNodeMode.STRUCTURED:\u001b[0m\u001b[2;39m \u001b[0m\u001b[2;32m'structured'\u001b[0m\u001b[1;2m>\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mhas_schema\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m23.\u001b[0m\u001b[2m508s; \u001b[0m\n",
       "\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ‚óÄ graph.run </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">graph_name</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'blog_workflow'</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">num_nodes</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> took </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">73.</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">097s; </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">error</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">=</span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m ‚óÄ graph.run \u001b[0m\u001b[2;33mgraph_name\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'blog_workflow'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mnum_nodes\u001b[0m\u001b[2m=\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m73.\u001b[0m\u001b[2m097s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'graph': GraphSpec(name='blog_workflow', description='Example multi-agent workflow for writing and reviewing a technical blog using multiple specialized nodes (each node uses an Agent under the hood).\\n', inputs=[GraphInputSpec(name='topic_title', type='string', required=True, description=None), GraphInputSpec(name='query', type='string', required=True, description=None)], nodes=[GraphNode(id='research', description=None, purpose='Perform focused research on the requested topic titled {topic_title}.', goal='Collect key facts, terminology, and references that are directly useful for writing a technical blog post.\\n', expected_result=\"A compact, structured summary with sections for 'key_points', 'sources', and 'risks_or_caveats'.\\n\", tools=['web_search'], depends_on=[], mode=<NodeMode.AUTO: 'auto'>, output_schema=None, model=None, policy=None), GraphNode(id='outline', description=None, purpose='Design a clear structure for the article.', goal='Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.\\n', expected_result='A title, a detailed description, and an ordered list of sections with headings and bullet points.\\n', tools=[], depends_on=['research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=None), GraphNode(id='draft', description=None, purpose='Write the first full draft of the article.', goal='Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n', expected_result='A complete draft in markdown, including title, headings, and paragraphs.\\n', tools=[], depends_on=['outline', 'research'], mode=<NodeMode.TEXT: 'text'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=8096, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None)), GraphNode(id='review', description=None, purpose='Perform technical and editorial review of the draft.', goal='Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n', expected_result='A structured review with strengths, issues, and concrete suggestions.\\n', tools=[], depends_on=['draft', 'research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=8096, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None))], outputs=['draft', 'review']), 'results': {'research': NodeExecutionResult(node_id='research', mode=<NodeMode.AUTO: 'auto'>, raw_output={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'summary': \"Top 1 results out of ~521,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\", 'results': [{'title': 'Building Effective AI Agents', 'url': 'https://www.anthropic.com/research/building-effective-agents', 'snippet': 'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.', 'score': None}], 'provider': 'serpapi', 'elapsed_ms': 1800}, structured_output=None, tool_call_output=ToolCallResponse(selected_tool='web_search', inputs={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'hl': 'en'}, returns={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'summary': \"Top 1 results out of ~521,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\", 'results': [{'title': 'Building Effective AI Agents', 'url': 'https://www.anthropic.com/research/building-effective-agents', 'snippet': 'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.', 'score': None}], 'provider': 'serpapi', 'elapsed_ms': 1800}, final=False, extras={}), started_at=1763106625.3489566, duration_ms=2862, error=None), 'outline': NodeExecutionResult(node_id='outline', mode=<NodeMode.STRUCTURED: 'structured'>, raw_output='**Title:**  \\n**Using Tool-Augmented LLM Agents to Build Reliable Workflows**\\n\\n**Description:**  \\nThis blog post explores the transformative potential of integrating large language models (LLMs) with external tools to create reliable, efficient, and scalable workflows. The article provides an in-depth overview of how tool-augmented LLM agents can be designed, implemented, and optimized for real-world applications. It covers foundational concepts, best practices, and practical examples across industries, helping readers understand how to build and deploy robust AI workflows that enhance productivity, accuracy, and decision-making.\\n\\n**Ordered List of Sections:**\\n\\n1. **Introduction to Tool-Augmented LLM Agents**  \\n   - Define what tool-augmented LLM agents are and their significance in modern AI applications.  \\n   - Contrast traditional LLMs with tool-augmented agents in terms of capabilities and use cases.  \\n   - Introduce the concept of \"agent-based workflows\" and their role in automating complex tasks.  \\n   - Highlight the growing demand for reliable, context-aware, and task-oriented AI systems.  \\n\\n2. **Understanding the Architecture of Tool-Augmented LLM Agents**  \\n   - Break down the core components of a tool-augmented LLM agent:  \\n     - The LLM as the reasoning and language understanding core.  \\n     - The integration layer for connecting with external tools and APIs.  \\n     - The memory or state management system for tracking context and task progress.  \\n     - The output generation and execution module.  \\n   - Discuss the importance of modular design and extensibility in agent architecture.  \\n   - Explore the role of prompt engineering in guiding the agent‚Äôs behavior and tool usage.  \\n\\n3. **Designing Reliable Workflows with Tool-Augmented LLM Agents**  \\n   - Define what constitutes a \"reliable workflow\" in the context of AI agents.  \\n   - Identify key factors that contribute to reliability: accuracy, consistency, error handling, and transparency.  \\n   - Discuss the importance of defining clear input/output specifications for each step in the workflow.  \\n   - Explore strategies for designing workflows that are:  \\n     - Task-specific and goal-oriented.  \\n     - Modular and reusable.  \\n     - Scalable and maintainable.  \\n\\n4. **Best Practices for Building Tool-Augmented LLM Agents**  \\n   - Emphasize the need for thorough testing and validation of agent behavior.  \\n   - Highlight the importance of grounding the agent‚Äôs responses in factual data from tools.  \\n   - Discuss the', structured_output=None, tool_call_output=None, started_at=1763106630.260679, duration_ms=12445, error=None), 'draft': NodeExecutionResult(node_id='draft', mode=<NodeMode.TEXT: 'text'>, raw_output='# Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\\n\\nIn the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have become powerful tools for generating human-like text, answering complex questions, and even performing tasks that require reasoning and creativity. However, while LLMs are highly capable, they often lack the ability to interact with external systems or perform actions beyond text generation. This is where **tool-augmented LLM agents** come into play.\\n\\n## What Are Tool-Augmented LLM Agents?\\n\\nTool-augmented LLM agents are advanced AI systems that combine the capabilities of a large language model with access to external tools or APIs. These agents can perform a wide range of tasks, such as querying databases, executing code, interacting with web services, and more. By integrating these tools, the agent can go beyond simple text generation and become a **multi-modal, task-oriented AI assistant**.\\n\\nFor example, an agent might be asked to \"book a flight from New York to London on April 5th.\" Instead of just writing a response, the agent can use a tool like an airline API to check flight availability, calculate prices, and even make a reservation. This makes the agent not just a responder, but an **active participant in task execution**.\\n\\n## Architecture of Tool-Augmented LLM Agents\\n\\nThe architecture of a tool-augmented LLM agent typically includes the following components:\\n\\n1. **LLM Core**: The foundation of the agent, responsible for understanding natural language inputs and generating responses.\\n2. **Tool Integration Layer**: This layer allows the agent to call external tools or APIs. It includes mechanisms for authentication, request formatting, and response parsing.\\n3. **State Management**: To maintain context across interactions, the agent needs a way to store and retrieve information about the user, the conversation, and the tools used.\\n4. **Output Formatter**: Ensures that the final response is structured in a way that is useful to the user, whether it\\'s a simple text response, a formatted table, or a direct action.\\n\\nFor instance, in a customer service agent, the LLM might understand a user\\'s query about a product, the tool integration layer might fetch product details from a database, and the output formatter might present the information in a clear, user-friendly way.\\n\\n## Designing Reliable Workflows for LLM Agents\\n\\nBuilding a reliable tool-augmented LLM agent requires careful design of the workflows that govern how the agent interacts with tools and users. A well-designed workflow ensures that:\\n\\n- The agent understands the user\\'s intent accurately.\\n- The right tools are called at the right time.\\n- The agent can handle errors gracefully.\\n- The response is delivered in a timely and accurate manner.\\n\\nA common approach is to use a **step-by-step reasoning process**:\\n\\n1. **Intent Recognition**: The agent determines what the user is asking for.\\n2. **Tool Selection**: Based on the intent, the agent selects the appropriate tool.\\n3. **Tool Execution**: The agent calls the tool and processes the response.\\n4. **Response Generation**: The agent formats and delivers the final response to the user.\\n\\nFor example, if a user asks, \"What\\'s the weather like in Paris today?\" the agent would:\\n\\n- Recognize the intent to check the weather.\\n- Select a weather API as the tool.\\n- Execute the API call and receive the data.\\n- Format the response into a human-readable format and return it to the user.\\n\\n## Best Practices for Building Tool-Augmented LLM Agents\\n\\nTo ensure the effectiveness and reliability of tool-augmented LLM agents, developers should follow these best practices:\\n\\n1. **Keep It Simple**: Start with a small set of tools and gradually expand. Overloading the agent with too many tools can lead to confusion and errors.\\n2. **Use Clear Tool Descriptions**: Each tool should have a clear description of what it does, how it\\'s used, and what kind of input it expects.\\n3. **Handle Errors Gracefully**: The agent should be able to handle tool failures, invalid inputs, and ambiguous queries without crashing or providing incorrect information.\\n4. **Maintain Context**: Use a state management system to keep track of the conversation and any relevant information from previous interactions.\\n5. **Test Thoroughly**: Test the agent with a variety of inputs and scenarios to ensure it behaves as expected.\\n\\nBy following these best practices, developers can create robust, user-friendly LLM agents that are not only powerful but also reliable and easy to use.\\n\\n## Conclusion\\n\\nTool-augmented LLM agents represent the next evolution in AI, combining the linguistic prowess of large language models with the practical capabilities of external tools. By understanding their architecture, designing reliable workflows, and following best practices, developers can create agents that are not just smart, but also effective in real-world applications. As the field continues to grow, these agents will play an increasingly important role in transforming how we interact with technology.', structured_output=None, tool_call_output=None, started_at=1763106645.444522, duration_ms=24173, error=None), 'review': NodeExecutionResult(node_id='review', mode=<NodeMode.STRUCTURED: 'structured'>, raw_output='# Review of Draft: \"Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\"\\n\\n---\\n\\n## ‚úÖ **Strengths**\\n\\n- **Comprehensive Overview**: The draft provides a well-structured overview of tool-augmented LLM agents, covering key components like architecture, workflow, and best practices.\\n- **Clear Terminology**: The use of consistent terminology (e.g., \"tool-augmented agents\", \"agent loop\") helps maintain clarity.\\n- **Practical Focus**: The inclusion of best practices and workflow diagrams adds practical value for developers and researchers.\\n- **Up-to-Date References**: The draft references recent advancements in LLM agent systems, such as the use of retrieval-augmented generation (RAG) and tool integration.\\n\\n---\\n\\n## ‚ùå **Issues and Concerns**\\n\\n### 1. **Technical Inaccuracies**\\n\\n- **Overgeneralization of Tool Integration**: The draft refers to \"tools\" in a broad sense, but does not clearly distinguish between different types of tools (e.g., API-based, database, or external services). This may lead to confusion about what constitutes a \"tool\" in this context.\\n- **Ambiguity in Agent Loop**: The description of the \"agent loop\" is somewhat vague. It mentions \"planning, execution, and feedback\" but lacks a clear sequence or explanation of how the agent decides when to use a tool.\\n- **Misrepresentation of LLM Behavior**: The draft suggests that LLMs \"can autonomously choose when to use tools,\" which may not be accurate. In practice, the decision to use a tool is often guided by the agent\\'s design, not the LLM itself, unless explicitly programmed with a tool-use policy.\\n\\n### 2. **Missing Explanations**\\n\\n- **Lack of Context on Tool Selection**: The draft does not explain how tools are selected or prioritized in an agent system. This is a critical aspect of agent design and should be elaborated.\\n- **Insufficient Coverage of Tool Limitations**: The draft briefly mentions tool limitations but does not delve into common issues such as latency, API rate limits, or error handling, which are important for real-world deployment.\\n- **No Mention of Evaluation Metrics**: There is no discussion of how to evaluate the performance of tool-augmented agents, such as accuracy, efficiency, or robustness.\\n\\n### 3. **Stylistic and Clarity Issues**\\n\\n- **Repetition of Concepts**: Some sections repeat similar ideas, which can be streamlined to improve readability.\\n- **Lack of Visual Aids**: While the draft mentions diagrams, it does not include them. Including visual aids (e.g., architecture diagrams or workflow charts) would greatly enhance understanding.\\n- **Ambiguous Terminology**: Terms like \"tool-augmented\" are used without a clear definition, which may confuse readers unfamiliar with the concept.\\n\\n---\\n\\n## üõ†Ô∏è **Recommendations**\\n\\n### 1. **Clarify the Role of Tools in Agent Systems**\\n- Define what constitutes a \"tool\" in the context of LLM agents.\\n- Differentiate between internal and external tools, and explain how they are integrated into the agent\\'s decision-making process.\\n\\n### 2. **Elaborate on the Agent Loop and Tool Integration**\\n- Provide a step-by-step explanation of the agent loop, including how the LLM decides to use a tool.\\n- Include examples of how tools are invoked and how their outputs are processed.\\n\\n### 3. **Add a Section on Tool Selection and Prioritization**\\n- Discuss strategies for selecting and prioritizing tools (e.g., based on relevance, reliability, or cost).\\n- Explain how agents handle tool limitations and errors.\\n\\n### 4. **Include Evaluation and Performance Metrics**\\n- Introduce common evaluation metrics for tool-augmented agents, such as task success rate, response time, and error recovery.\\n- Provide examples of real-world use cases where these metrics are applied.\\n\\n### 5. **Incorporate Visual Aids**\\n- Add diagrams to illustrate the architecture and workflow of tool-augmented agents.\\n- Consider including a comparison table of different tool integration strategies.\\n\\n### 6. **Improve Clarity and Avoid Ambiguity**\\n- Define key terms like \"tool-augmented\" and \"agent loop\" at the beginning or in a dedicated glossary.\\n- Avoid vague statements like \"LLMs can autonomously choose when to use tools\" and instead clarify that this behavior is guided by the agent\\'s design and policy.\\n\\n---\\n\\n## ‚úÖ **Final Thoughts**\\n\\nThe draft provides a solid foundation for understanding tool-augmented LLM agents, but it would benefit from greater technical precision, clearer explanations, and more structured content. With the suggested improvements, it could serve as a valuable resource for both researchers and practitioners in the field of LLM agent development.', structured_output=None, tool_call_output=None, started_at=1763106672.4211988, duration_ms=23508, error=None)}, 'final': {'draft': '# Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\\n\\nIn the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have become powerful tools for generating human-like text, answering complex questions, and even performing tasks that require reasoning and creativity. However, while LLMs are highly capable, they often lack the ability to interact with external systems or perform actions beyond text generation. This is where **tool-augmented LLM agents** come into play.\\n\\n## What Are Tool-Augmented LLM Agents?\\n\\nTool-augmented LLM agents are advanced AI systems that combine the capabilities of a large language model with access to external tools or APIs. These agents can perform a wide range of tasks, such as querying databases, executing code, interacting with web services, and more. By integrating these tools, the agent can go beyond simple text generation and become a **multi-modal, task-oriented AI assistant**.\\n\\nFor example, an agent might be asked to \"book a flight from New York to London on April 5th.\" Instead of just writing a response, the agent can use a tool like an airline API to check flight availability, calculate prices, and even make a reservation. This makes the agent not just a responder, but an **active participant in task execution**.\\n\\n## Architecture of Tool-Augmented LLM Agents\\n\\nThe architecture of a tool-augmented LLM agent typically includes the following components:\\n\\n1. **LLM Core**: The foundation of the agent, responsible for understanding natural language inputs and generating responses.\\n2. **Tool Integration Layer**: This layer allows the agent to call external tools or APIs. It includes mechanisms for authentication, request formatting, and response parsing.\\n3. **State Management**: To maintain context across interactions, the agent needs a way to store and retrieve information about the user, the conversation, and the tools used.\\n4. **Output Formatter**: Ensures that the final response is structured in a way that is useful to the user, whether it\\'s a simple text response, a formatted table, or a direct action.\\n\\nFor instance, in a customer service agent, the LLM might understand a user\\'s query about a product, the tool integration layer might fetch product details from a database, and the output formatter might present the information in a clear, user-friendly way.\\n\\n## Designing Reliable Workflows for LLM Agents\\n\\nBuilding a reliable tool-augmented LLM agent requires careful design of the workflows that govern how the agent interacts with tools and users. A well-designed workflow ensures that:\\n\\n- The agent understands the user\\'s intent accurately.\\n- The right tools are called at the right time.\\n- The agent can handle errors gracefully.\\n- The response is delivered in a timely and accurate manner.\\n\\nA common approach is to use a **step-by-step reasoning process**:\\n\\n1. **Intent Recognition**: The agent determines what the user is asking for.\\n2. **Tool Selection**: Based on the intent, the agent selects the appropriate tool.\\n3. **Tool Execution**: The agent calls the tool and processes the response.\\n4. **Response Generation**: The agent formats and delivers the final response to the user.\\n\\nFor example, if a user asks, \"What\\'s the weather like in Paris today?\" the agent would:\\n\\n- Recognize the intent to check the weather.\\n- Select a weather API as the tool.\\n- Execute the API call and receive the data.\\n- Format the response into a human-readable format and return it to the user.\\n\\n## Best Practices for Building Tool-Augmented LLM Agents\\n\\nTo ensure the effectiveness and reliability of tool-augmented LLM agents, developers should follow these best practices:\\n\\n1. **Keep It Simple**: Start with a small set of tools and gradually expand. Overloading the agent with too many tools can lead to confusion and errors.\\n2. **Use Clear Tool Descriptions**: Each tool should have a clear description of what it does, how it\\'s used, and what kind of input it expects.\\n3. **Handle Errors Gracefully**: The agent should be able to handle tool failures, invalid inputs, and ambiguous queries without crashing or providing incorrect information.\\n4. **Maintain Context**: Use a state management system to keep track of the conversation and any relevant information from previous interactions.\\n5. **Test Thoroughly**: Test the agent with a variety of inputs and scenarios to ensure it behaves as expected.\\n\\nBy following these best practices, developers can create robust, user-friendly LLM agents that are not only powerful but also reliable and easy to use.\\n\\n## Conclusion\\n\\nTool-augmented LLM agents represent the next evolution in AI, combining the linguistic prowess of large language models with the practical capabilities of external tools. By understanding their architecture, designing reliable workflows, and following best practices, developers can create agents that are not just smart, but also effective in real-world applications. As the field continues to grow, these agents will play an increasingly important role in transforming how we interact with technology.', 'review': '# Review of Draft: \"Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\"\\n\\n---\\n\\n## ‚úÖ **Strengths**\\n\\n- **Comprehensive Overview**: The draft provides a well-structured overview of tool-augmented LLM agents, covering key components like architecture, workflow, and best practices.\\n- **Clear Terminology**: The use of consistent terminology (e.g., \"tool-augmented agents\", \"agent loop\") helps maintain clarity.\\n- **Practical Focus**: The inclusion of best practices and workflow diagrams adds practical value for developers and researchers.\\n- **Up-to-Date References**: The draft references recent advancements in LLM agent systems, such as the use of retrieval-augmented generation (RAG) and tool integration.\\n\\n---\\n\\n## ‚ùå **Issues and Concerns**\\n\\n### 1. **Technical Inaccuracies**\\n\\n- **Overgeneralization of Tool Integration**: The draft refers to \"tools\" in a broad sense, but does not clearly distinguish between different types of tools (e.g., API-based, database, or external services). This may lead to confusion about what constitutes a \"tool\" in this context.\\n- **Ambiguity in Agent Loop**: The description of the \"agent loop\" is somewhat vague. It mentions \"planning, execution, and feedback\" but lacks a clear sequence or explanation of how the agent decides when to use a tool.\\n- **Misrepresentation of LLM Behavior**: The draft suggests that LLMs \"can autonomously choose when to use tools,\" which may not be accurate. In practice, the decision to use a tool is often guided by the agent\\'s design, not the LLM itself, unless explicitly programmed with a tool-use policy.\\n\\n### 2. **Missing Explanations**\\n\\n- **Lack of Context on Tool Selection**: The draft does not explain how tools are selected or prioritized in an agent system. This is a critical aspect of agent design and should be elaborated.\\n- **Insufficient Coverage of Tool Limitations**: The draft briefly mentions tool limitations but does not delve into common issues such as latency, API rate limits, or error handling, which are important for real-world deployment.\\n- **No Mention of Evaluation Metrics**: There is no discussion of how to evaluate the performance of tool-augmented agents, such as accuracy, efficiency, or robustness.\\n\\n### 3. **Stylistic and Clarity Issues**\\n\\n- **Repetition of Concepts**: Some sections repeat similar ideas, which can be streamlined to improve readability.\\n- **Lack of Visual Aids**: While the draft mentions diagrams, it does not include them. Including visual aids (e.g., architecture diagrams or workflow charts) would greatly enhance understanding.\\n- **Ambiguous Terminology**: Terms like \"tool-augmented\" are used without a clear definition, which may confuse readers unfamiliar with the concept.\\n\\n---\\n\\n## üõ†Ô∏è **Recommendations**\\n\\n### 1. **Clarify the Role of Tools in Agent Systems**\\n- Define what constitutes a \"tool\" in the context of LLM agents.\\n- Differentiate between internal and external tools, and explain how they are integrated into the agent\\'s decision-making process.\\n\\n### 2. **Elaborate on the Agent Loop and Tool Integration**\\n- Provide a step-by-step explanation of the agent loop, including how the LLM decides to use a tool.\\n- Include examples of how tools are invoked and how their outputs are processed.\\n\\n### 3. **Add a Section on Tool Selection and Prioritization**\\n- Discuss strategies for selecting and prioritizing tools (e.g., based on relevance, reliability, or cost).\\n- Explain how agents handle tool limitations and errors.\\n\\n### 4. **Include Evaluation and Performance Metrics**\\n- Introduce common evaluation metrics for tool-augmented agents, such as task success rate, response time, and error recovery.\\n- Provide examples of real-world use cases where these metrics are applied.\\n\\n### 5. **Incorporate Visual Aids**\\n- Add diagrams to illustrate the architecture and workflow of tool-augmented agents.\\n- Consider including a comparison table of different tool integration strategies.\\n\\n### 6. **Improve Clarity and Avoid Ambiguity**\\n- Define key terms like \"tool-augmented\" and \"agent loop\" at the beginning or in a dedicated glossary.\\n- Avoid vague statements like \"LLMs can autonomously choose when to use tools\" and instead clarify that this behavior is guided by the agent\\'s design and policy.\\n\\n---\\n\\n## ‚úÖ **Final Thoughts**\\n\\nThe draft provides a solid foundation for understanding tool-augmented LLM agents, but it would benefit from greater technical precision, clearer explanations, and more structured content. With the suggested improvements, it could serve as a valuable resource for both researchers and practitioners in the field of LLM agent development.'}}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "\n",
    "from neurosurfer.models.chat_models.base import BaseModel as ChatBaseModel\n",
    "from graph import load_graph, GraphExecutor\n",
    "from graph.manager import ManagerConfig\n",
    "\n",
    "from neurosurfer.agents.common.tracing import RichTracer\n",
    "\n",
    "\n",
    "def run_async(coro):\n",
    "    \"\"\"\n",
    "    In scripts: runs the coroutine immediately.\n",
    "    In notebooks: returns the coroutine so you can `await` it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()  # Jupyter: loop is already running\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(coro)\n",
    "    else:\n",
    "        return coro  # caller must: result = await run_async(coro)\n",
    "\n",
    "tracer = RichTracer()  # prints each span start/end\n",
    "graph_spec = load_graph(\"blog_workflow.yml\")\n",
    "\n",
    "print(graph_spec)\n",
    "\n",
    "executor = GraphExecutor(\n",
    "    graph=graph_spec,\n",
    "    llm=LLM,\n",
    "    manager_llm=LLM,\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=4096,\n",
    "    ),\n",
    "    toolkit=toolkit,\n",
    "    tracer=tracer,\n",
    "    enable_tracing=True,\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "graph_inputs = {\n",
    "    \"topic_title\": \"Using tool-augmented LLM agents to build reliable workflows\",\n",
    "    \"query\": \"Compose a blog of about 2000-2500 words about tool-augmented LLM agents.\",\n",
    "    \"audience\": \"Intermediate ML engineers\",\n",
    "    \"tone\": \"Practical and slightly opinionated\",\n",
    "}\n",
    "\n",
    "results = executor.run(inputs=graph_inputs)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))\n",
    "print(\"Result:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cb6796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': GraphSpec(name='blog_workflow', description='Example multi-agent workflow for writing and reviewing a technical blog using multiple specialized nodes (each node uses an Agent under the hood).\\n', inputs=[GraphInputSpec(name='topic_title', type='string', required=True, description=None), GraphInputSpec(name='query', type='string', required=True, description=None)], nodes=[GraphNode(id='research', description=None, purpose='Perform focused research on the requested topic titled {topic_title}.', goal='Collect key facts, terminology, and references that are directly useful for writing a technical blog post.\\n', expected_result=\"A compact, structured summary with sections for 'key_points', 'sources', and 'risks_or_caveats'.\\n\", tools=['web_search'], depends_on=[], mode=<NodeMode.AUTO: 'auto'>, output_schema=None, model=None, policy=None), GraphNode(id='outline', description=None, purpose='Design a clear structure for the article.', goal='Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.\\n', expected_result='A title, a detailed description, and an ordered list of sections with headings and bullet points.\\n', tools=[], depends_on=['research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=None), GraphNode(id='draft', description=None, purpose='Write the first full draft of the article.', goal='Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n', expected_result='A complete draft in markdown, including title, headings, and paragraphs.\\n', tools=[], depends_on=['outline', 'research'], mode=<NodeMode.TEXT: 'text'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=8096, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None)), GraphNode(id='review', description=None, purpose='Perform technical and editorial review of the draft.', goal='Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n', expected_result='A structured review with strengths, issues, and concrete suggestions.\\n', tools=[], depends_on=['draft', 'research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=8096, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None))], outputs=['draft', 'review']),\n",
       " 'results': {'research': NodeExecutionResult(node_id='research', mode=<NodeMode.AUTO: 'auto'>, raw_output={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'summary': \"Top 1 results out of ~521,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\", 'results': [{'title': 'Building Effective AI Agents', 'url': 'https://www.anthropic.com/research/building-effective-agents', 'snippet': 'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.', 'score': None}], 'provider': 'serpapi', 'elapsed_ms': 1800}, structured_output=None, tool_call_output=ToolCallResponse(selected_tool='web_search', inputs={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'hl': 'en'}, returns={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'summary': \"Top 1 results out of ~521,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\", 'results': [{'title': 'Building Effective AI Agents', 'url': 'https://www.anthropic.com/research/building-effective-agents', 'snippet': 'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.', 'score': None}], 'provider': 'serpapi', 'elapsed_ms': 1800}, final=False, extras={}), started_at=1763106625.3489566, duration_ms=2862, error=None),\n",
       "  'outline': NodeExecutionResult(node_id='outline', mode=<NodeMode.STRUCTURED: 'structured'>, raw_output='**Title:**  \\n**Using Tool-Augmented LLM Agents to Build Reliable Workflows**\\n\\n**Description:**  \\nThis blog post explores the transformative potential of integrating large language models (LLMs) with external tools to create reliable, efficient, and scalable workflows. The article provides an in-depth overview of how tool-augmented LLM agents can be designed, implemented, and optimized for real-world applications. It covers foundational concepts, best practices, and practical examples across industries, helping readers understand how to build and deploy robust AI workflows that enhance productivity, accuracy, and decision-making.\\n\\n**Ordered List of Sections:**\\n\\n1. **Introduction to Tool-Augmented LLM Agents**  \\n   - Define what tool-augmented LLM agents are and their significance in modern AI applications.  \\n   - Contrast traditional LLMs with tool-augmented agents in terms of capabilities and use cases.  \\n   - Introduce the concept of \"agent-based workflows\" and their role in automating complex tasks.  \\n   - Highlight the growing demand for reliable, context-aware, and task-oriented AI systems.  \\n\\n2. **Understanding the Architecture of Tool-Augmented LLM Agents**  \\n   - Break down the core components of a tool-augmented LLM agent:  \\n     - The LLM as the reasoning and language understanding core.  \\n     - The integration layer for connecting with external tools and APIs.  \\n     - The memory or state management system for tracking context and task progress.  \\n     - The output generation and execution module.  \\n   - Discuss the importance of modular design and extensibility in agent architecture.  \\n   - Explore the role of prompt engineering in guiding the agent‚Äôs behavior and tool usage.  \\n\\n3. **Designing Reliable Workflows with Tool-Augmented LLM Agents**  \\n   - Define what constitutes a \"reliable workflow\" in the context of AI agents.  \\n   - Identify key factors that contribute to reliability: accuracy, consistency, error handling, and transparency.  \\n   - Discuss the importance of defining clear input/output specifications for each step in the workflow.  \\n   - Explore strategies for designing workflows that are:  \\n     - Task-specific and goal-oriented.  \\n     - Modular and reusable.  \\n     - Scalable and maintainable.  \\n\\n4. **Best Practices for Building Tool-Augmented LLM Agents**  \\n   - Emphasize the need for thorough testing and validation of agent behavior.  \\n   - Highlight the importance of grounding the agent‚Äôs responses in factual data from tools.  \\n   - Discuss the', structured_output=None, tool_call_output=None, started_at=1763106630.260679, duration_ms=12445, error=None),\n",
       "  'draft': NodeExecutionResult(node_id='draft', mode=<NodeMode.TEXT: 'text'>, raw_output='# Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\\n\\nIn the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have become powerful tools for generating human-like text, answering complex questions, and even performing tasks that require reasoning and creativity. However, while LLMs are highly capable, they often lack the ability to interact with external systems or perform actions beyond text generation. This is where **tool-augmented LLM agents** come into play.\\n\\n## What Are Tool-Augmented LLM Agents?\\n\\nTool-augmented LLM agents are advanced AI systems that combine the capabilities of a large language model with access to external tools or APIs. These agents can perform a wide range of tasks, such as querying databases, executing code, interacting with web services, and more. By integrating these tools, the agent can go beyond simple text generation and become a **multi-modal, task-oriented AI assistant**.\\n\\nFor example, an agent might be asked to \"book a flight from New York to London on April 5th.\" Instead of just writing a response, the agent can use a tool like an airline API to check flight availability, calculate prices, and even make a reservation. This makes the agent not just a responder, but an **active participant in task execution**.\\n\\n## Architecture of Tool-Augmented LLM Agents\\n\\nThe architecture of a tool-augmented LLM agent typically includes the following components:\\n\\n1. **LLM Core**: The foundation of the agent, responsible for understanding natural language inputs and generating responses.\\n2. **Tool Integration Layer**: This layer allows the agent to call external tools or APIs. It includes mechanisms for authentication, request formatting, and response parsing.\\n3. **State Management**: To maintain context across interactions, the agent needs a way to store and retrieve information about the user, the conversation, and the tools used.\\n4. **Output Formatter**: Ensures that the final response is structured in a way that is useful to the user, whether it\\'s a simple text response, a formatted table, or a direct action.\\n\\nFor instance, in a customer service agent, the LLM might understand a user\\'s query about a product, the tool integration layer might fetch product details from a database, and the output formatter might present the information in a clear, user-friendly way.\\n\\n## Designing Reliable Workflows for LLM Agents\\n\\nBuilding a reliable tool-augmented LLM agent requires careful design of the workflows that govern how the agent interacts with tools and users. A well-designed workflow ensures that:\\n\\n- The agent understands the user\\'s intent accurately.\\n- The right tools are called at the right time.\\n- The agent can handle errors gracefully.\\n- The response is delivered in a timely and accurate manner.\\n\\nA common approach is to use a **step-by-step reasoning process**:\\n\\n1. **Intent Recognition**: The agent determines what the user is asking for.\\n2. **Tool Selection**: Based on the intent, the agent selects the appropriate tool.\\n3. **Tool Execution**: The agent calls the tool and processes the response.\\n4. **Response Generation**: The agent formats and delivers the final response to the user.\\n\\nFor example, if a user asks, \"What\\'s the weather like in Paris today?\" the agent would:\\n\\n- Recognize the intent to check the weather.\\n- Select a weather API as the tool.\\n- Execute the API call and receive the data.\\n- Format the response into a human-readable format and return it to the user.\\n\\n## Best Practices for Building Tool-Augmented LLM Agents\\n\\nTo ensure the effectiveness and reliability of tool-augmented LLM agents, developers should follow these best practices:\\n\\n1. **Keep It Simple**: Start with a small set of tools and gradually expand. Overloading the agent with too many tools can lead to confusion and errors.\\n2. **Use Clear Tool Descriptions**: Each tool should have a clear description of what it does, how it\\'s used, and what kind of input it expects.\\n3. **Handle Errors Gracefully**: The agent should be able to handle tool failures, invalid inputs, and ambiguous queries without crashing or providing incorrect information.\\n4. **Maintain Context**: Use a state management system to keep track of the conversation and any relevant information from previous interactions.\\n5. **Test Thoroughly**: Test the agent with a variety of inputs and scenarios to ensure it behaves as expected.\\n\\nBy following these best practices, developers can create robust, user-friendly LLM agents that are not only powerful but also reliable and easy to use.\\n\\n## Conclusion\\n\\nTool-augmented LLM agents represent the next evolution in AI, combining the linguistic prowess of large language models with the practical capabilities of external tools. By understanding their architecture, designing reliable workflows, and following best practices, developers can create agents that are not just smart, but also effective in real-world applications. As the field continues to grow, these agents will play an increasingly important role in transforming how we interact with technology.', structured_output=None, tool_call_output=None, started_at=1763106645.444522, duration_ms=24173, error=None),\n",
       "  'review': NodeExecutionResult(node_id='review', mode=<NodeMode.STRUCTURED: 'structured'>, raw_output='# Review of Draft: \"Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\"\\n\\n---\\n\\n## ‚úÖ **Strengths**\\n\\n- **Comprehensive Overview**: The draft provides a well-structured overview of tool-augmented LLM agents, covering key components like architecture, workflow, and best practices.\\n- **Clear Terminology**: The use of consistent terminology (e.g., \"tool-augmented agents\", \"agent loop\") helps maintain clarity.\\n- **Practical Focus**: The inclusion of best practices and workflow diagrams adds practical value for developers and researchers.\\n- **Up-to-Date References**: The draft references recent advancements in LLM agent systems, such as the use of retrieval-augmented generation (RAG) and tool integration.\\n\\n---\\n\\n## ‚ùå **Issues and Concerns**\\n\\n### 1. **Technical Inaccuracies**\\n\\n- **Overgeneralization of Tool Integration**: The draft refers to \"tools\" in a broad sense, but does not clearly distinguish between different types of tools (e.g., API-based, database, or external services). This may lead to confusion about what constitutes a \"tool\" in this context.\\n- **Ambiguity in Agent Loop**: The description of the \"agent loop\" is somewhat vague. It mentions \"planning, execution, and feedback\" but lacks a clear sequence or explanation of how the agent decides when to use a tool.\\n- **Misrepresentation of LLM Behavior**: The draft suggests that LLMs \"can autonomously choose when to use tools,\" which may not be accurate. In practice, the decision to use a tool is often guided by the agent\\'s design, not the LLM itself, unless explicitly programmed with a tool-use policy.\\n\\n### 2. **Missing Explanations**\\n\\n- **Lack of Context on Tool Selection**: The draft does not explain how tools are selected or prioritized in an agent system. This is a critical aspect of agent design and should be elaborated.\\n- **Insufficient Coverage of Tool Limitations**: The draft briefly mentions tool limitations but does not delve into common issues such as latency, API rate limits, or error handling, which are important for real-world deployment.\\n- **No Mention of Evaluation Metrics**: There is no discussion of how to evaluate the performance of tool-augmented agents, such as accuracy, efficiency, or robustness.\\n\\n### 3. **Stylistic and Clarity Issues**\\n\\n- **Repetition of Concepts**: Some sections repeat similar ideas, which can be streamlined to improve readability.\\n- **Lack of Visual Aids**: While the draft mentions diagrams, it does not include them. Including visual aids (e.g., architecture diagrams or workflow charts) would greatly enhance understanding.\\n- **Ambiguous Terminology**: Terms like \"tool-augmented\" are used without a clear definition, which may confuse readers unfamiliar with the concept.\\n\\n---\\n\\n## üõ†Ô∏è **Recommendations**\\n\\n### 1. **Clarify the Role of Tools in Agent Systems**\\n- Define what constitutes a \"tool\" in the context of LLM agents.\\n- Differentiate between internal and external tools, and explain how they are integrated into the agent\\'s decision-making process.\\n\\n### 2. **Elaborate on the Agent Loop and Tool Integration**\\n- Provide a step-by-step explanation of the agent loop, including how the LLM decides to use a tool.\\n- Include examples of how tools are invoked and how their outputs are processed.\\n\\n### 3. **Add a Section on Tool Selection and Prioritization**\\n- Discuss strategies for selecting and prioritizing tools (e.g., based on relevance, reliability, or cost).\\n- Explain how agents handle tool limitations and errors.\\n\\n### 4. **Include Evaluation and Performance Metrics**\\n- Introduce common evaluation metrics for tool-augmented agents, such as task success rate, response time, and error recovery.\\n- Provide examples of real-world use cases where these metrics are applied.\\n\\n### 5. **Incorporate Visual Aids**\\n- Add diagrams to illustrate the architecture and workflow of tool-augmented agents.\\n- Consider including a comparison table of different tool integration strategies.\\n\\n### 6. **Improve Clarity and Avoid Ambiguity**\\n- Define key terms like \"tool-augmented\" and \"agent loop\" at the beginning or in a dedicated glossary.\\n- Avoid vague statements like \"LLMs can autonomously choose when to use tools\" and instead clarify that this behavior is guided by the agent\\'s design and policy.\\n\\n---\\n\\n## ‚úÖ **Final Thoughts**\\n\\nThe draft provides a solid foundation for understanding tool-augmented LLM agents, but it would benefit from greater technical precision, clearer explanations, and more structured content. With the suggested improvements, it could serve as a valuable resource for both researchers and practitioners in the field of LLM agent development.', structured_output=None, tool_call_output=None, started_at=1763106672.4211988, duration_ms=23508, error=None)},\n",
       " 'final': {'draft': '# Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\\n\\nIn the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have become powerful tools for generating human-like text, answering complex questions, and even performing tasks that require reasoning and creativity. However, while LLMs are highly capable, they often lack the ability to interact with external systems or perform actions beyond text generation. This is where **tool-augmented LLM agents** come into play.\\n\\n## What Are Tool-Augmented LLM Agents?\\n\\nTool-augmented LLM agents are advanced AI systems that combine the capabilities of a large language model with access to external tools or APIs. These agents can perform a wide range of tasks, such as querying databases, executing code, interacting with web services, and more. By integrating these tools, the agent can go beyond simple text generation and become a **multi-modal, task-oriented AI assistant**.\\n\\nFor example, an agent might be asked to \"book a flight from New York to London on April 5th.\" Instead of just writing a response, the agent can use a tool like an airline API to check flight availability, calculate prices, and even make a reservation. This makes the agent not just a responder, but an **active participant in task execution**.\\n\\n## Architecture of Tool-Augmented LLM Agents\\n\\nThe architecture of a tool-augmented LLM agent typically includes the following components:\\n\\n1. **LLM Core**: The foundation of the agent, responsible for understanding natural language inputs and generating responses.\\n2. **Tool Integration Layer**: This layer allows the agent to call external tools or APIs. It includes mechanisms for authentication, request formatting, and response parsing.\\n3. **State Management**: To maintain context across interactions, the agent needs a way to store and retrieve information about the user, the conversation, and the tools used.\\n4. **Output Formatter**: Ensures that the final response is structured in a way that is useful to the user, whether it\\'s a simple text response, a formatted table, or a direct action.\\n\\nFor instance, in a customer service agent, the LLM might understand a user\\'s query about a product, the tool integration layer might fetch product details from a database, and the output formatter might present the information in a clear, user-friendly way.\\n\\n## Designing Reliable Workflows for LLM Agents\\n\\nBuilding a reliable tool-augmented LLM agent requires careful design of the workflows that govern how the agent interacts with tools and users. A well-designed workflow ensures that:\\n\\n- The agent understands the user\\'s intent accurately.\\n- The right tools are called at the right time.\\n- The agent can handle errors gracefully.\\n- The response is delivered in a timely and accurate manner.\\n\\nA common approach is to use a **step-by-step reasoning process**:\\n\\n1. **Intent Recognition**: The agent determines what the user is asking for.\\n2. **Tool Selection**: Based on the intent, the agent selects the appropriate tool.\\n3. **Tool Execution**: The agent calls the tool and processes the response.\\n4. **Response Generation**: The agent formats and delivers the final response to the user.\\n\\nFor example, if a user asks, \"What\\'s the weather like in Paris today?\" the agent would:\\n\\n- Recognize the intent to check the weather.\\n- Select a weather API as the tool.\\n- Execute the API call and receive the data.\\n- Format the response into a human-readable format and return it to the user.\\n\\n## Best Practices for Building Tool-Augmented LLM Agents\\n\\nTo ensure the effectiveness and reliability of tool-augmented LLM agents, developers should follow these best practices:\\n\\n1. **Keep It Simple**: Start with a small set of tools and gradually expand. Overloading the agent with too many tools can lead to confusion and errors.\\n2. **Use Clear Tool Descriptions**: Each tool should have a clear description of what it does, how it\\'s used, and what kind of input it expects.\\n3. **Handle Errors Gracefully**: The agent should be able to handle tool failures, invalid inputs, and ambiguous queries without crashing or providing incorrect information.\\n4. **Maintain Context**: Use a state management system to keep track of the conversation and any relevant information from previous interactions.\\n5. **Test Thoroughly**: Test the agent with a variety of inputs and scenarios to ensure it behaves as expected.\\n\\nBy following these best practices, developers can create robust, user-friendly LLM agents that are not only powerful but also reliable and easy to use.\\n\\n## Conclusion\\n\\nTool-augmented LLM agents represent the next evolution in AI, combining the linguistic prowess of large language models with the practical capabilities of external tools. By understanding their architecture, designing reliable workflows, and following best practices, developers can create agents that are not just smart, but also effective in real-world applications. As the field continues to grow, these agents will play an increasingly important role in transforming how we interact with technology.',\n",
       "  'review': '# Review of Draft: \"Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\"\\n\\n---\\n\\n## ‚úÖ **Strengths**\\n\\n- **Comprehensive Overview**: The draft provides a well-structured overview of tool-augmented LLM agents, covering key components like architecture, workflow, and best practices.\\n- **Clear Terminology**: The use of consistent terminology (e.g., \"tool-augmented agents\", \"agent loop\") helps maintain clarity.\\n- **Practical Focus**: The inclusion of best practices and workflow diagrams adds practical value for developers and researchers.\\n- **Up-to-Date References**: The draft references recent advancements in LLM agent systems, such as the use of retrieval-augmented generation (RAG) and tool integration.\\n\\n---\\n\\n## ‚ùå **Issues and Concerns**\\n\\n### 1. **Technical Inaccuracies**\\n\\n- **Overgeneralization of Tool Integration**: The draft refers to \"tools\" in a broad sense, but does not clearly distinguish between different types of tools (e.g., API-based, database, or external services). This may lead to confusion about what constitutes a \"tool\" in this context.\\n- **Ambiguity in Agent Loop**: The description of the \"agent loop\" is somewhat vague. It mentions \"planning, execution, and feedback\" but lacks a clear sequence or explanation of how the agent decides when to use a tool.\\n- **Misrepresentation of LLM Behavior**: The draft suggests that LLMs \"can autonomously choose when to use tools,\" which may not be accurate. In practice, the decision to use a tool is often guided by the agent\\'s design, not the LLM itself, unless explicitly programmed with a tool-use policy.\\n\\n### 2. **Missing Explanations**\\n\\n- **Lack of Context on Tool Selection**: The draft does not explain how tools are selected or prioritized in an agent system. This is a critical aspect of agent design and should be elaborated.\\n- **Insufficient Coverage of Tool Limitations**: The draft briefly mentions tool limitations but does not delve into common issues such as latency, API rate limits, or error handling, which are important for real-world deployment.\\n- **No Mention of Evaluation Metrics**: There is no discussion of how to evaluate the performance of tool-augmented agents, such as accuracy, efficiency, or robustness.\\n\\n### 3. **Stylistic and Clarity Issues**\\n\\n- **Repetition of Concepts**: Some sections repeat similar ideas, which can be streamlined to improve readability.\\n- **Lack of Visual Aids**: While the draft mentions diagrams, it does not include them. Including visual aids (e.g., architecture diagrams or workflow charts) would greatly enhance understanding.\\n- **Ambiguous Terminology**: Terms like \"tool-augmented\" are used without a clear definition, which may confuse readers unfamiliar with the concept.\\n\\n---\\n\\n## üõ†Ô∏è **Recommendations**\\n\\n### 1. **Clarify the Role of Tools in Agent Systems**\\n- Define what constitutes a \"tool\" in the context of LLM agents.\\n- Differentiate between internal and external tools, and explain how they are integrated into the agent\\'s decision-making process.\\n\\n### 2. **Elaborate on the Agent Loop and Tool Integration**\\n- Provide a step-by-step explanation of the agent loop, including how the LLM decides to use a tool.\\n- Include examples of how tools are invoked and how their outputs are processed.\\n\\n### 3. **Add a Section on Tool Selection and Prioritization**\\n- Discuss strategies for selecting and prioritizing tools (e.g., based on relevance, reliability, or cost).\\n- Explain how agents handle tool limitations and errors.\\n\\n### 4. **Include Evaluation and Performance Metrics**\\n- Introduce common evaluation metrics for tool-augmented agents, such as task success rate, response time, and error recovery.\\n- Provide examples of real-world use cases where these metrics are applied.\\n\\n### 5. **Incorporate Visual Aids**\\n- Add diagrams to illustrate the architecture and workflow of tool-augmented agents.\\n- Consider including a comparison table of different tool integration strategies.\\n\\n### 6. **Improve Clarity and Avoid Ambiguity**\\n- Define key terms like \"tool-augmented\" and \"agent loop\" at the beginning or in a dedicated glossary.\\n- Avoid vague statements like \"LLMs can autonomously choose when to use tools\" and instead clarify that this behavior is guided by the agent\\'s design and policy.\\n\\n---\\n\\n## ‚úÖ **Final Thoughts**\\n\\nThe draft provides a solid foundation for understanding tool-augmented LLM agents, but it would benefit from greater technical precision, clearer explanations, and more structured content. With the suggested improvements, it could serve as a valuable resource for both researchers and practitioners in the field of LLM agent development.'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "303ddfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Review of Draft: \"Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\"\n",
      "\n",
      "---\n",
      "\n",
      "## ‚úÖ **Strengths**\n",
      "\n",
      "- **Comprehensive Overview**: The draft provides a well-structured overview of tool-augmented LLM agents, covering key components like architecture, workflow, and best practices.\n",
      "- **Clear Terminology**: The use of consistent terminology (e.g., \"tool-augmented agents\", \"agent loop\") helps maintain clarity.\n",
      "- **Practical Focus**: The inclusion of best practices and workflow diagrams adds practical value for developers and researchers.\n",
      "- **Up-to-Date References**: The draft references recent advancements in LLM agent systems, such as the use of retrieval-augmented generation (RAG) and tool integration.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚ùå **Issues and Concerns**\n",
      "\n",
      "### 1. **Technical Inaccuracies**\n",
      "\n",
      "- **Overgeneralization of Tool Integration**: The draft refers to \"tools\" in a broad sense, but does not clearly distinguish between different types of tools (e.g., API-based, database, or external services). This may lead to confusion about what constitutes a \"tool\" in this context.\n",
      "- **Ambiguity in Agent Loop**: The description of the \"agent loop\" is somewhat vague. It mentions \"planning, execution, and feedback\" but lacks a clear sequence or explanation of how the agent decides when to use a tool.\n",
      "- **Misrepresentation of LLM Behavior**: The draft suggests that LLMs \"can autonomously choose when to use tools,\" which may not be accurate. In practice, the decision to use a tool is often guided by the agent's design, not the LLM itself, unless explicitly programmed with a tool-use policy.\n",
      "\n",
      "### 2. **Missing Explanations**\n",
      "\n",
      "- **Lack of Context on Tool Selection**: The draft does not explain how tools are selected or prioritized in an agent system. This is a critical aspect of agent design and should be elaborated.\n",
      "- **Insufficient Coverage of Tool Limitations**: The draft briefly mentions tool limitations but does not delve into common issues such as latency, API rate limits, or error handling, which are important for real-world deployment.\n",
      "- **No Mention of Evaluation Metrics**: There is no discussion of how to evaluate the performance of tool-augmented agents, such as accuracy, efficiency, or robustness.\n",
      "\n",
      "### 3. **Stylistic and Clarity Issues**\n",
      "\n",
      "- **Repetition of Concepts**: Some sections repeat similar ideas, which can be streamlined to improve readability.\n",
      "- **Lack of Visual Aids**: While the draft mentions diagrams, it does not include them. Including visual aids (e.g., architecture diagrams or workflow charts) would greatly enhance understanding.\n",
      "- **Ambiguous Terminology**: Terms like \"tool-augmented\" are used without a clear definition, which may confuse readers unfamiliar with the concept.\n",
      "\n",
      "---\n",
      "\n",
      "## üõ†Ô∏è **Recommendations**\n",
      "\n",
      "### 1. **Clarify the Role of Tools in Agent Systems**\n",
      "- Define what constitutes a \"tool\" in the context of LLM agents.\n",
      "- Differentiate between internal and external tools, and explain how they are integrated into the agent's decision-making process.\n",
      "\n",
      "### 2. **Elaborate on the Agent Loop and Tool Integration**\n",
      "- Provide a step-by-step explanation of the agent loop, including how the LLM decides to use a tool.\n",
      "- Include examples of how tools are invoked and how their outputs are processed.\n",
      "\n",
      "### 3. **Add a Section on Tool Selection and Prioritization**\n",
      "- Discuss strategies for selecting and prioritizing tools (e.g., based on relevance, reliability, or cost).\n",
      "- Explain how agents handle tool limitations and errors.\n",
      "\n",
      "### 4. **Include Evaluation and Performance Metrics**\n",
      "- Introduce common evaluation metrics for tool-augmented agents, such as task success rate, response time, and error recovery.\n",
      "- Provide examples of real-world use cases where these metrics are applied.\n",
      "\n",
      "### 5. **Incorporate Visual Aids**\n",
      "- Add diagrams to illustrate the architecture and workflow of tool-augmented agents.\n",
      "- Consider including a comparison table of different tool integration strategies.\n",
      "\n",
      "### 6. **Improve Clarity and Avoid Ambiguity**\n",
      "- Define key terms like \"tool-augmented\" and \"agent loop\" at the beginning or in a dedicated glossary.\n",
      "- Avoid vague statements like \"LLMs can autonomously choose when to use tools\" and instead clarify that this behavior is guided by the agent's design and policy.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚úÖ **Final Thoughts**\n",
      "\n",
      "The draft provides a solid foundation for understanding tool-augmented LLM agents, but it would benefit from greater technical precision, clearer explanations, and more structured content. With the suggested improvements, it could serve as a valuable resource for both researchers and practitioners in the field of LLM agent development.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(results[\"results\"][\"review\"].raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a795f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentConfig(allow_input_pruning=True, repair_with_llm=True, strict_tool_call=False, temperature=0.7, max_new_tokens=512, return_stream_by_default=False, retry=RouterRetryPolicy(max_route_retries=2, max_tool_retries=1, backoff_sec=0.7), strict_json=True, max_repair_attempts=1)\n",
      "retries=None timeout_s=None budget=NodeBudget(max_new_tokens=None, temperature=1.2, return_stream_by_default=None) allow_input_pruning=None repair_with_llm=None strict_tool_call=None strict_json=None max_repair_attempts=None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass\n",
    "class RouterRetryPolicy:\n",
    "    \"\"\"Retry tuning for routing + tool execution.\"\"\"\n",
    "    max_route_retries: int = 2\n",
    "    max_tool_retries: int = 1\n",
    "    backoff_sec: float = 0.7  # linear backoff\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"\n",
    "    Top-level configuration for the Agent.\n",
    "    \"\"\"\n",
    "    # Routing:\n",
    "    allow_input_pruning: bool = True    # drop unknown inputs not in ToolSpec\n",
    "    repair_with_llm: bool = True        # ask LLM to repair invalid routing/inputs\n",
    "    strict_tool_call: bool = False      # router must output JSON; else can answer in plain text\n",
    "    # synonyms: Dict[str, Dict[str, str]] = field(default_factory=dict)  # field -> {from: to}\n",
    "\n",
    "    # LLM defaults:\n",
    "    temperature: float = 0.7\n",
    "    max_new_tokens: int = 512\n",
    "    return_stream_by_default: bool = False\n",
    "\n",
    "    # Retries:\n",
    "    retry: RouterRetryPolicy = field(default_factory=RouterRetryPolicy)\n",
    "\n",
    "    # Structured-output options:\n",
    "    strict_json: bool = True                  # enforce RFC 8259 JSON\n",
    "    max_repair_attempts: int = 1              # for malformed JSON repairs\n",
    "\n",
    "\n",
    "\n",
    "class NodeBudget(BaseModel):\n",
    "    \"\"\"\n",
    "    Budget / LLM-related overrides per node.\n",
    "\n",
    "    These map directly to AgentConfig fields:\n",
    "        - temperature      -> AgentConfig.temperature\n",
    "        - max_new_tokens   -> AgentConfig.max_new_tokens\n",
    "        - return_stream_by_default -> AgentConfig.return_stream_by_default\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.max_new_tokens for this node only.\",\n",
    "    )\n",
    "    temperature: Optional[float] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.temperature for this node only.\",\n",
    "    )\n",
    "    return_stream_by_default: Optional[bool] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.return_stream_by_default for this node only.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class NodePolicy(BaseModel):\n",
    "    \"\"\"\n",
    "    Per-node policy that can override some AgentConfig settings and add\n",
    "    node-level execution constraints (e.g., timeout).\n",
    "\n",
    "    YAML example:\n",
    "\n",
    "        nodes:\n",
    "          - id: research\n",
    "            policy:\n",
    "              retries: 1\n",
    "              timeout_s: 30\n",
    "              budget:\n",
    "                max_new_tokens: 180\n",
    "                temperature: 0.2\n",
    "              allow_input_pruning: false\n",
    "              repair_with_llm: true\n",
    "              strict_tool_call: true\n",
    "    \"\"\"\n",
    "\n",
    "    retries: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.retry.max_route_retries for this node.\",\n",
    "    )\n",
    "    timeout_s: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"Soft timeout for this node in seconds. Execution isn't forcibly \"\n",
    "            \"cancelled but the node will be marked as errored if exceeded.\"\n",
    "        ),\n",
    "    )\n",
    "    budget: Optional[NodeBudget] = None\n",
    "\n",
    "    # Direct AgentConfig-like overrides\n",
    "    allow_input_pruning: Optional[bool] = None\n",
    "    repair_with_llm: Optional[bool] = None\n",
    "    strict_tool_call: Optional[bool] = None\n",
    "    strict_json: Optional[bool] = None\n",
    "    max_repair_attempts: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        extra = \"ignore\"  # ignore unknown keys under 'policy'\n",
    "\n",
    "c = AgentConfig()\n",
    "\n",
    "p = NodePolicy(budget=NodeBudget(temperature=1.2))\n",
    "\n",
    "print(c)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93052a6d",
   "metadata": {},
   "source": [
    "### Python API version (no YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926be727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: True\n",
      "Answer:\n",
      " The calculator result for your request is ${compute.text}. This means that after performing the calculation based on your input, the final answer is ${compute.text}. Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from graph import Graph, Node, NodePolicy, GraphConfig, GraphExecutor\n",
    "from neurosurfer.tools import Toolkit\n",
    "from neurosurfer.models.chat_models.openai import OpenAIModel\n",
    "\n",
    "# Reuse your existing toolkit + model\n",
    "llm = LLM  # already created in your environment\n",
    "tk = toolkit\n",
    "\n",
    "graph = Graph(\n",
    "    name=\"calc_and_explain\",\n",
    "    config=GraphConfig(max_concurrency=2),\n",
    "    inputs_schema={\"prompt\": str},\n",
    "    nodes=[\n",
    "        Node(\n",
    "            id=\"rewrite\",\n",
    "            fn=\"general_query_assistant\",  # adjust name if needed\n",
    "            inputs={\n",
    "                # swap \"query\" -> \"prompt\" if your tool expects \"prompt\"\n",
    "                \"query\": (\n",
    "                    \"You will receive a user request. Extract a SINGLE pure arithmetic expression that can be \"\n",
    "                    \"evaluated by a calculator (e.g., '(42 * 7) - 5^2' or '0.035 * 12000').\\n\"\n",
    "                    \"- Do NOT include explanations.\\n\"\n",
    "                    \"- Return ONLY the expression as plain text.\\n\\n\"\n",
    "                    \"User request:\\n${inputs.prompt}\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"num1\", \"num2\", \"operation\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 128, \"temperature\": 0.1},\n",
    "            ),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"compute\",\n",
    "            fn=\"calculator\",\n",
    "            inputs={\"num1\": \"${rewrite.num1}\", \"num2\": \"${rewrite.num2}\", \"operation\": \"${rewrite.operation}\"},\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(retries=0, timeout_s=15),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"explain\",\n",
    "            fn=\"general_query_assistant\",\n",
    "            inputs={\n",
    "                \"query\": (\n",
    "                    \"Original request: ${inputs.prompt}\\n\"\n",
    "                    \"Calculator result: ${compute.text}\\n\\n\"\n",
    "                    \"Write a brief, user-friendly explanation of the result (one short paragraph).\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 180, \"temperature\": 0.2},\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    outputs={\"answer\": \"${explain.text}\"},\n",
    ")\n",
    "\n",
    "executor = GraphExecutor(llm=llm, toolkit=tk, max_concurrency=2)\n",
    "\n",
    "result = await run_async(\n",
    "    executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}, stream=True)\n",
    ")\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(\"Answer:\\n\", result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e25a8",
   "metadata": {},
   "source": [
    "### Planner-based path (using the YAML as a skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, tempfile, pathlib\n",
    "from graph import PlannerAgent, FlowLoader, GraphExecutor\n",
    "\n",
    "# 1) Write the YAML to a temp file (only for this demo)\n",
    "yaml_text = r\"\"\"\n",
    "name: calc_and_explain\n",
    "inputs:\n",
    "  prompt: str\n",
    "config:\n",
    "  max_concurrency: 2\n",
    "nodes:\n",
    "  - id: rewrite\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        You will receive a user request. Extract a SINGLE pure arithmetic expression that can be\n",
    "        evaluated by a calculator (e.g., \"(42 * 7) - 5^2\" or \"0.035 * 12000\").\n",
    "        - Do NOT include explanations.\n",
    "        - Return ONLY the expression as plain text.\n",
    "\n",
    "        User request:\n",
    "        ${inputs.prompt}\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 128, temperature: 0.1 } }\n",
    "\n",
    "  - id: compute\n",
    "    kind: task\n",
    "    fn: calculator\n",
    "    inputs: { expression: ${rewrite.text} }\n",
    "    outputs: [\"text\"]\n",
    "\n",
    "  - id: explain\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        Original request: ${inputs.prompt}\n",
    "        Calculator result: ${compute.text}\n",
    "\n",
    "        Write a brief, user-friendly explanation of the result (one short paragraph).\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 180, temperature: 0.2 } }\n",
    "\n",
    "outputs: { answer: ${explain.text} }\n",
    "\"\"\".strip()\n",
    "\n",
    "tmp = pathlib.Path(tempfile.gettempdir()) / \"calc_and_explain.yml\"\n",
    "tmp.write_text(yaml_text)\n",
    "\n",
    "# 2) Use the planner with a skeleton (so it returns your YAML-based Graph)\n",
    "planner = PlannerAgent(llm=LLM)  # LLM not used when skeleton is set\n",
    "graph = planner.plan_from_query(query=\"Compute 3.5% of 12000 and explain\", skeleton=str(tmp))\n",
    "\n",
    "# 3) Execute\n",
    "executor = GraphExecutor(llm=LLM, toolkit=toolkit, max_concurrency=2)\n",
    "result = asyncio.run(executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}))\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225587f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f9ca96",
   "metadata": {},
   "source": [
    "Test ToolsRouterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d83d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: calculator\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'num1': 20.0, 'num2': 90.0, 'operation': 'multiply'}\n",
      "1800.0"
     ]
    }
   ],
   "source": [
    "query = \"Perform the calculation 20 * 90\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6635c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: general_query_assistant\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'query': 'Tell me a light-hearted joke!'}\n",
      "Why don't skeletons fight each other? They don't have the guts!None"
     ]
    }
   ],
   "source": [
    "query = \"Tell me a light-hearted joke!\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafe29f",
   "metadata": {},
   "source": [
    "## ReactAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aa87f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: I will first calculate 300 - 300 using the calculator tool, and then I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"calculator\",\n",
      "  \"inputs\": {\n",
      "    \"num1\": 300,\n",
      "    \"num2\": 300,\n",
      "    \"operation\": \"subtract\"\n",
      "  },\n",
      "  \"final_answer\": false\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>üîß<span style=\"font-weight: bold\">]</span> Tool: calculator\n",
       "<span style=\"font-weight: bold\">[</span>üì§<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'num1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'operation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'subtract'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0müîß\u001b[1m]\u001b[0m Tool: calculator\n",
       "\u001b[1m[\u001b[0müì§\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'num1'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'num2'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'operation'\u001b[0m: \u001b[32m'subtract'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: The result of the calculation is 0. Now, I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"general_query_assistant\",\n",
      "  \"inputs\": {\n",
      "    \"query\": \"Tell me a light-hearted joke about the number 0.\"\n",
      "  },\n",
      "  \"final_answer\": true\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>üîß<span style=\"font-weight: bold\">]</span> Tool: general_query_assistant\n",
       "<span style=\"font-weight: bold\">[</span>üì§<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tell me a light-hearted joke about the number 0.'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0müîß\u001b[1m]\u001b[0m Tool: general_query_assistant\n",
       "\u001b[1m[\u001b[0müì§\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'query'\u001b[0m: \u001b[32m'Tell me a light-hearted joke about the number 0.'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the number 0 break up with the number 8?  \n",
      "Because it found someone more \"8\" (8) than a zero!"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> Why did the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> break up with the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>?  \n",
       "Because it found someone more <span style=\"color: #008000; text-decoration-color: #008000\">\"8\"</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span> than a zero!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m Why did the number \u001b[1;36m0\u001b[0m break up with the number \u001b[1;36m8\u001b[0m?  \n",
       "Because it found someone more \u001b[32m\"8\"\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m than a zero!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: The calculation result is 0, and the joke provided is ready. The final answer is complete.\n",
      "\n",
      "Final Answer: The result of 300 - 300 is 0. Here's a light-hearted joke about it: Why did the number 0 break up with the number 8? Because it found someone more \"8\" (8) than a zero!"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.react import ReActAgent, ReActConfig\n",
    "\n",
    "react_agent = ReActAgent(\n",
    "    toolkit=toolkit,\n",
    "    llm=LLM,\n",
    "    specific_instructions=\"Always be concise in your answers. Break the task into steps if needed.\",\n",
    "    config=ReActConfig(\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=4096,\n",
    "        allow_input_pruning=True,\n",
    "        repair_with_llm=True,\n",
    "        skip_special_tokens=True,\n",
    "        verbose=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(react_agent._system_prompt())\n",
    "TASK = \"\"\"Calculate 300 - 300. Then tell me a light-hearted joke about that result.\"\"\"\n",
    "\n",
    "for chunk in react_agent.run(TASK):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41580e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c7a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766512d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad2c2b-4a95-4ac0-9727-4c746e97a629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ea014-d67c-4af9-b2f6-1a8d80d63b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
