{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9cbd0d5",
   "metadata": {},
   "source": [
    "### ğŸ”§ Notebook Setup â€” Auto-Reload & Project Path\n",
    "\n",
    "Before we start exploring different agent types and execution modes, we need to set up\n",
    "our Jupyter environment so that it can import the Neurosurfer project cleanly and \n",
    "pick up code changes automatically.\n",
    "\n",
    "### ğŸ“Œ What this cell does\n",
    "\n",
    "1. **Enables autoreload**  \n",
    "   This makes Jupyter reload modules automatically whenever you modify the source code.  \n",
    "   No need to restart the kernel each time you edit a Python file.\n",
    "\n",
    "2. **Adds your project root to `sys.path`**  \n",
    "   Your notebook likely lives inside a subfolder such as `b/` or `notebooks/`.  \n",
    "   By moving one directory up and appending it to `sys.path`, Python can import your\n",
    "   local Neurosurfer modules as if they were installed packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ae728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go up one directory from `b/` to project root\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584b75a",
   "metadata": {},
   "source": [
    "## ğŸ¤– Initializing the Local LLM (Qwen3-8B-Unsloth)\n",
    "\n",
    "This cell prepares the language model that all agents in this notebook will use.  \n",
    "We load a locally stored Qwen3-8B model, quantized in 4-bit mode for efficient GPU usage.\n",
    "\n",
    "### ğŸ”§ What happens in this step\n",
    "- **GPU memory is cleared** to avoid leftover allocations from earlier runs.\n",
    "- **Model configuration parameters** are defined (model path, max sequence length, quantization mode, stop words, verbosity).\n",
    "- **The TransformersModel wrapper is created**, which handles:\n",
    "  - GPU/CPU device selection  \n",
    "  - automatic dtype (bfloat16 on CUDA)\n",
    "  - thread-safe generation\n",
    "  - streaming support and stop-token detection\n",
    "  - integration with all Neurosurfer agents\n",
    "\n",
    "### ğŸ“Œ Why this matters\n",
    "All subsequent components â€” ReActAgent, CodeAgent, RAG workflows, and the Main Workflow â€”\n",
    "reuse this single `LLM` instance.  \n",
    "It ensures consistent generation behavior, reduced memory footprint, and faster warm-up.\n",
    "\n",
    "### âš™ï¸ Key configuration highlights\n",
    "- **model_name**: filesystem path to your local 4-bit Qwen3-8B model  \n",
    "- **max_seq_length**: extended context window for longer agent chains  \n",
    "- **load_in_4bit=True**: enables efficient inference on mid-range GPUs  \n",
    "- **enable_thinking=False**: disables structured â€œthinking modeâ€ tokens  \n",
    "- **stop_words**: early-stop hints for streaming (e.g., â€œObservation:â€)\n",
    "\n",
    "After running this cell, the model is ready for use by all agents in the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affc4a2e-d532-4dee-8b50-cab72fd229c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                                                                  â•‘\n",
      "â•‘ â–“â–“â–“â–“â–“   â–“â–“â–“â–“                                  â–“â–“â–“                â•‘\n",
      "â•‘  â–“â–“ â–“â–“   â–“â–“  â–“â–“â–“â–“ â–“  â–“ â–“ â–“ â–“â–“â–“â–“ â–“â–“â–“ â–“  â–“ â–“ â–“  â–“   â–“â–“â–“â–“ â–“ â–“       â•‘\n",
      "â•‘  â–“â–“  â–“â–“  â–“â–“  â–“â–â–â–“ â–“  â–“ â–“â–“â– â–“  â–“ â–“â–  â–“  â–“ â–“â–“â– â–“â–“â–“  â–“â–â–â–“ â–“â–“        â•‘\n",
      "â•‘  â–“â–“   â–“â–“ â–“â–“  â–“    â–“  â–“ â–“   â–“  â–“   â–“ â–“  â–“ â–“    â–“   â–“    â–“         â•‘\n",
      "â•‘ â–“â–“â–“â–“   â–“â–“â–“â–“â–“ â–“â–“â–“â–“ â–“â–“â–“â–“ â–“   â–“â–“â–“â–“ â–“â–“â–“ â–“â–“â–“â–“ â–“    â–“   â–“â–“â–“â–“ â–“         â•‘\n",
      "â•‘ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ â•‘\n",
      "â•‘ Orchestrate Agents - RAG - SQL Tools - Multi-LLM - FastAPI Ready â•‘\n",
      "â•‘ Faster builds, clearer flows, production-first                   â•‘\n",
      "â•‘                                                                  â•‘\n",
      "â•‘ Version: 0.1.0 | Python: 3.12.12                                 â•‘\n",
      "â•‘ OS: Linux 6.17.0-8-generic (x86_64)                              â•‘\n",
      "â•‘ Torch: 2.9.0+cu130   CUDA: yes (13.0)                            â•‘\n",
      "â•‘ MPS: no (built: False)                                           â•‘\n",
      "â•‘ Transformers: 4.56.2   SentEmb: 5.1.1                            â•‘\n",
      "â•‘ Accelerate: 1.10.1   bnb: 0.48.1                                 â•‘\n",
      "â•‘ Unsloth: 2025.10.5                                               â•‘\n",
      "â•‘                                                                  â•‘\n",
      "â•‘ Detected CUDA devices: NVIDIA GeForce RTX 5080                   â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2026-01-04 11:10:11\u001b[0m | \u001b[96m__init__.py:<module>\u001b[0m | Skipping import of cpp extensions due to incompatible torch version 2.9.0+cu130 for torchao version 0.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomi/micromamba/envs/LLMs/lib/python3.12/importlib/__init__.py:90: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "#### Unsloth: `hf_xet==1.1.10` and `ipykernel>6.30.1` breaks progress bars. Disabling for now in XET.\n",
      "#### Unsloth: To re-enable progress bars, please downgrade to `ipykernel==6.30.1` or wait for a fix to\n",
      "https://github.com/huggingface/xet-core/issues/526\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2026-01-04 11:10:18\u001b[0m | \u001b[96m_cpp_lib.py:<module>\u001b[0m | WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.8.0+cu128 with CUDA 1208 (you have 2.9.0+cu130)\n",
      "    Python  3.9.23 (you have 3.12.12)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Unsloth: Xformers does not work in RTX 50X, Blackwell GPUs as of yet. Please build from source via\n",
      "```\n",
      "pip install ninja\n",
      "pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers\n",
      "```\n",
      "\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:10:18\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Initializing Transformers model.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2026-01-04 11:10:18\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Model is already quantized. Ignoring load_in_4bit=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomi/workspace/neurosurfer/neurosurfer/__init__.py:46: UserWarning: Some optional LLM dependencies are not installed: unsloth.\n",
      "      Neurosurfer core will load, but LLM features (model loading, HF/Unsloth, BnB quant, etc.)\n",
      "      will be unavailable until you install them.\n",
      "\n",
      "      To install everything with one extra:\n",
      "        - pip install 'neurosurfer[torch]'\n",
      "\n",
      "      Or use one of these commands:\n",
      "\n",
      "- pip install -U 'neurosurfer[torch]'\n",
      "- pip install -U accelerate sentence-transformers transformers unsloth\n",
      "- pip install -U torch --index-url https://download.pytorch.org/whl/cpu\n",
      "- pip install -U torch --index-url https://download.pytorch.org/whl/cu124\n",
      "  warn_optional_llm_stack()\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:10:19\u001b[0m | \u001b[96mmodeling.py:get_balanced_memory\u001b[0m | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8066d44c02a463085c7d15d0d943138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:10:23\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Transformers model initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from neurosurfer.models.chat_models.transformers import TransformersModel\n",
    "from neurosurfer.models.chat_models.openai import OpenAIModel\n",
    "from neurosurfer import config \n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "\n",
    "DEFAULT_TRANSFORMERS_MODEL_PARAMS = dict({\n",
    "    \"model_name\": \"/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"max_seq_length\": 12000,\n",
    "    \"load_in_4bit\": True,\n",
    "    \"enable_thinking\": False,  # main_gpu interpretation\n",
    "    \"verbose\": False\n",
    "})\n",
    "\n",
    "LLM = TransformersModel(\n",
    "    **DEFAULT_TRANSFORMERS_MODEL_PARAMS,\n",
    "    stop_words=[\"Observation:\"],\n",
    "    logger = logging.getLogger(),\n",
    ")\n",
    "\n",
    "# LLM = OpenAIModel(\n",
    "#     model_name=\"qwen3-8b\",\n",
    "#     base_url=\"http://localhost:9999/v1\",\n",
    "#     api_key=\"abc\",\n",
    "#     strip_reasoning=True,\n",
    "#     stop_words=[],\n",
    "#     logger=LOGGER,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e7831",
   "metadata": {},
   "source": [
    "##### ğŸ“ Streaming a Simple LLM Response\n",
    "\n",
    "This cell demonstrates how to stream tokens directly from the model in real time.  \n",
    "We send a system prompt and user message, enable `stream=True`, and print each token as it arrives.  \n",
    "Streaming is useful for interactive agent outputs, debugging, and understanding how the model generates text step by step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ff5798-3ed2-4b38-86cd-2498ca0e57be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?  \n",
      "Because they don't have the *guts*! ğŸ˜„"
     ]
    }
   ],
   "source": [
    "# streaming response example\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "system_prompt = \"/nothink You are a joker.\"\n",
    "user_prompt = \"\"\"Tell me a short and light-hearted joke.\"\"\"\n",
    "\n",
    "stream_response = LLM.ask(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "md_display = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream_response:\n",
    "    chunk = chunk.choices[0].delta.content or \"\"\n",
    "    print(chunk, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808255b3",
   "metadata": {},
   "source": [
    "## ğŸ¤– Using the Generic Agent (LLM-Only Mode)\n",
    "\n",
    "This section introduces the basic `Agent` class, which provides a lightweight wrapper around an LLM without invoking tools or complex workflows. It supports both normal (non-streaming) responses and streaming output.\n",
    "\n",
    "### ğŸ”§ What this cell demonstrates\n",
    "- Creating an `Agent` with a simple configuration (temperature, token limit, streaming defaults).\n",
    "- Sending a plain natural-language query and receiving a direct response.\n",
    "- Showing how the agent integrates tracing, routing logic, and output handling behind the scenes.\n",
    "\n",
    "### ğŸ“Œ When to use this agent\n",
    "Use the generic `Agent` whenever you want:\n",
    "- a straightforward LLM response,\n",
    "- optional structured JSON outputs,\n",
    "- optional tool routing if a Toolkit is attached,\n",
    "- lightweight experimentation without the full MainWorkflow.\n",
    "\n",
    "This provides the foundation before moving on to more advanced agents like ReAct, CodeAgent, or RAGAgent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3030e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m708s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m711s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "\n",
      "Normal Response:\n",
      "AI, or Artificial Intelligence, is the simulation of human intelligence in machines that are programmed to think, learn, and perform tasks typically requiring human cognition.\n"
     ]
    }
   ],
   "source": [
    "# agent normal response\n",
    "from neurosurfer.agents import Agent, AgentConfig\n",
    "# from neurosurfer.tracing import RichTracer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    strict_tool_call=True,\n",
    "    return_stream_by_default=True,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=4096,\n",
    ")\n",
    "agent = Agent(llm=LLM, config=agent_config, log_traces=True)\n",
    "\n",
    "# normal response\n",
    "agent_response = agent.run(user_prompt=\"What is AI (one line)?\", stream=False)\n",
    "print(\"\\nNormal Response:\")\n",
    "print(agent_response.response)\n",
    "\n",
    "# # streaming response\n",
    "# print(\"\\n\\nStreaming Response:\")\n",
    "# for c in agent.run(user_prompt=\"What are top 3 applications of AI (one line)?\").response:\n",
    "#     print(c, flush=True, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d91b3b",
   "metadata": {},
   "source": [
    "### ğŸ“¦ Structured Responses with Pydantic Models\n",
    "\n",
    "This example shows how the Agent can produce **validated, structured outputs** instead of free-form text. By providing a Pydantic schema, the Agent is prompted to return JSON that matches the required fields, and any malformed output is automatically repaired or retried.\n",
    "\n",
    "### ğŸ”§ What this cell demonstrates\n",
    "- Defining custom Pydantic models to shape the LLMâ€™s output.\n",
    "- Asking the Agent a natural-language query while enforcing a specific schema.\n",
    "- Receiving a clean `json_obj` back, already parsed and validated.\n",
    "\n",
    "### ğŸ“Œ Why structured responses matter\n",
    "Structured outputs make downstream processing far easier â€” especially for:\n",
    "- pipelines,\n",
    "- UI rendering,\n",
    "- database inserts,\n",
    "- chaining multiple agents,\n",
    "- or building tool-driven reasoning graphs.\n",
    "\n",
    "This is one of the core benefits of Neurosurferâ€™s generic Agent abstraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344ffe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "    \u001b[1;33mWARNING: `output_schema` provided with `\u001b[0m\u001b[1;33mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;3;33mTrue\u001b[0m\u001b[1;33m`; forcing non-streaming structured output.\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m472s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m479s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "\n",
      "Structured Response:\n",
      "{\n",
      "  \"definition\": \"Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding.\",\n",
      "  \"history\": \"The concept of AI dates back to the 1950s, with the term 'artificial intelligence' coined in 1956. Early developments focused on rule-based systems and symbolic reasoning, while recent advancements have been driven by machine learning and big data.\",\n",
      "  \"modern_frameworks\": \"Modern frameworks for AI include TensorFlow, PyTorch, and Keras, which provide tools for building and training machine learning models efficiently.\",\n",
      "  \"applications\": [\n",
      "    {\n",
      "      \"title\": \"Healthcare\",\n",
      "      \"description\": \"AI is used in medical diagnosis, drug discovery, and personalized treatment plans.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Finance\",\n",
      "      \"description\": \"AI is applied in fraud detection, algorithmic trading, and risk management.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Autonomous Vehicles\",\n",
      "      \"description\": \"AI enables self-driving cars through computer vision and real-time data processing.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Structured Response examples\n",
    "class AIApplication(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "class AI(BaseModel):\n",
    "    definition: str\n",
    "    history: str\n",
    "    modern_frameworks: str\n",
    "    applications: list[AIApplication]\n",
    "\n",
    "user_query = \"What is AI and list 3 of its top application, and 3 concerns.\"\n",
    "agent_response = agent.run(user_prompt=user_query, output_schema=AI)\n",
    "\n",
    "print(\"\\nStructured Response:\")\n",
    "print(agent_response.response.json_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e93c3b",
   "metadata": {},
   "source": [
    "#### ğŸ” Inspecting Agent Traces\n",
    "\n",
    "Each agent call produces a detailed trace that captures how the model processed the request.  \n",
    "By inspecting a specific trace step, you can see metadata such as timing, inputs, whether tools were used, and whether the step succeeded.\n",
    "\n",
    "**ğŸ”§ What this cell demonstrates**\n",
    "- Accessing `agent_response.traces.steps`\n",
    "- Viewing the internal details of the `agent.run` execution step\n",
    "- Understanding inputs (streaming, schema enforcement, toolkit availability)\n",
    "- Checking timing (`duration_ms`) and success state (`ok=True`)\n",
    "\n",
    "\n",
    "This becomes even more valuable once we begin chaining agents or using RAG and code-execution modes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fe4f0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_id': 2,\n",
       " 'kind': 'llm.call',\n",
       " 'label': 'agent.structured_call.first_pass',\n",
       " 'node_id': None,\n",
       " 'agent_id': 'main_agent',\n",
       " 'started_at': 1767437502.18619,\n",
       " 'duration_ms': 7738,\n",
       " 'inputs': {'schema': 'AI',\n",
       "  'system_prompt_len': 52,\n",
       "  'user_prompt_len': 61,\n",
       "  'user_prompt': 'What is AI and list 3 of its top application, and 3 concerns.',\n",
       "  'system_prompt': \"You are a precise and rule-abiding assistant.  \\nYour task is to produce only a single valid JSON object following the schema below.\\n\\nStructured Output Contract:\\n- Output only JSON â€” no markdown, code fences, or explanations.  \\n- JSON must be strictly valid (RFC 8259): use double quotes for all keys and string values.  \\n- Do not include extra keys or any text outside the JSON object.  \\n- All required fields must be present, even if empty.  \\n- Arrays must contain at least one object when applicable.  \\n- The JSON must be a single complete object (not pretty-printed, no trailing commas).  \\n- Failure to comply with this structure means your response is invalid.\\n\\nExpected JSON Structure:\\n{'$defs': {'AIApplication': {'properties': {'title': {'title': 'Title', 'type': 'string'}, 'description': {'title': 'Description', 'type': 'string'}}, 'required': ['title', 'description'], 'title': 'AIApplication', 'type': 'object'}}, 'properties': {'definition': {'title': 'Definition', 'type': 'string'}, 'history': {'title': 'History', 'type': 'string'}, 'modern_frameworks': {'title': 'Modern Frameworks', 'type': 'string'}, 'applications': {'items': {'$ref': '#/$defs/AIApplication'}, 'title': 'Applications', 'type': 'array'}}, 'required': ['definition', 'history', 'modern_frameworks', 'applications'], 'title': 'AI', 'type': 'object'}\\n\\nNow generate your response strictly following this contract.\\n\",\n",
       "  'temperature': 0.7,\n",
       "  'max_new_tokens': 4096,\n",
       "  'stream': False},\n",
       " 'outputs': {'model_response': '{\\n  \"definition\": \"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to perform tasks requiring cognition, such as learning, reasoning, problem-solving, perception, and language understanding. It encompasses techniques like machine learning, neural networks, and natural language processing.\",\\n  \"history\": \"AI research began in the 1950s with foundational concepts. Early progress was hindered by computational limitations and unmet expectations, leading to \\'AI winters.\\' Modern advancements since the 2010s, driven by big data, increased computing power, and improved algorithms, have revitalized AI applications.\",\\n  \"modern_frameworks\": \"TensorFlow, PyTorch, and Keras are leading frameworks enabling scalable AI model development.\",\\n  \"applications\": [\\n    {\"title\": \"Healthcare Diagnostics\", \"description\": \"AI analyzes medical data for disease detection, imaging interpretation, and personalized treatment recommendations.\"},\\n    {\"title\": \"Autonomous Vehicles\", \"description\": \"Self-driving cars use AI for real-time object recognition, path planning, and decision-making in dynamic environments.\"},\\n    {\"title\": \"Customer Service Chatbots\", \"description\": \"AI-powered virtual assistants provide 24/7 support, handling inquiries and troubleshooting across industries.\"}\\n  ]\\n}',\n",
       "  'model_response_len': 1333},\n",
       " 'meta': {},\n",
       " 'ok': True,\n",
       " 'error': None,\n",
       " 'logs': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_response.traces.steps[1].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf48079",
   "metadata": {},
   "source": [
    "### ğŸ”§ Using Tools with the Generic Agent\n",
    "\n",
    "This section shows how to extend an Agent with custom tools.  \n",
    "We define a simple calculator tool, register it inside a Toolkit, and attach that Toolkit to the Agent.\n",
    "\n",
    "### ğŸ”§ What this cell demonstrates\n",
    "- Creating a custom tool by subclassing `BaseTool`\n",
    "- Defining tool inputs, outputs, and descriptions using `ToolSpec`\n",
    "- Registering the tool inside a `Toolkit`\n",
    "- Allowing the Agent to decide whether to answer directly or call a tool (`strict_tool_call=False`)\n",
    "- Viewing full execution traces showing the router LLM selecting the tool and executing it\n",
    "\n",
    "### ğŸ“Œ Why this is useful\n",
    "Tools allow Agents to go beyond text generation and perform real actions:\n",
    "- mathematical operations  \n",
    "- data processing  \n",
    "- API queries  \n",
    "- database lookups  \n",
    "- code execution  \n",
    "- any custom operation your application needs\n",
    "\n",
    "This example demonstrates the full tool-calling pipeline:\n",
    "1. The router LLM interprets the request.\n",
    "2. It selects the calculator tool.\n",
    "3. The tool executes and returns the result.\n",
    "4. The Agent wraps the result in a clean `ToolCallResponse`.\n",
    "\n",
    "This pattern is the foundation for building more advanced multi-tool assistants.\n",
    "\n",
    "Additionally, using `agent_response.traces`, we can see the complete execution trace for the agent call â€” including routing, the selected tool, LLM inputs/outputs, and the toolâ€™s final return value. Itâ€™s useful for debugging and understanding exactly how the agent reached its decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440e9634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:12:52\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: calculator\n",
      "Agent with choice between tools and plain text:\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: calculator\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'num1'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'num2'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'operation'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'add'\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m721s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting tool.execute\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'calculator'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m2.0\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m002s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed tool.execute!\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m728s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "ToolCallResponse(selected_tool='calculator', inputs={'num1': 1.0, 'num2': 1.0, 'operation': 'add'}, returns='2.0', final=False, extras={})\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.agent import Agent\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "from neurosurfer.tools.tool_spec import ToolSpec, ToolParam, ToolReturn\n",
    "from neurosurfer.tools.base_tool import BaseTool, ToolResponse\n",
    "\n",
    "# Simple Calculator Tool\n",
    "class CalculatorTool(BaseTool):\n",
    "    spec = ToolSpec(\n",
    "        name=\"calculator\",\n",
    "        description=\"Perform basic arithmetic operations such as addition, subtraction, multiplication, and division.\",\n",
    "        when_to_use=\"Use this tool when you need to perform basic arithmetic operations.\",\n",
    "        inputs=[\n",
    "            ToolParam(name=\"num1\", type=\"float\", description=\"The first number.\", required=True),\n",
    "            ToolParam(name=\"num2\", type=\"float\", description=\"The second number.\", required=True),\n",
    "            ToolParam(name=\"operation\", type=\"string\", description=\"The operation to perform strictly one of ['add', 'subtract', 'multiply', 'divide'].\", required=True)\n",
    "        ],\n",
    "        returns=ToolReturn(type=\"float\", description=\"The result of the arithmetic operation.\")\n",
    "    )\n",
    "\n",
    "    def __init__(self, final_answer: bool = False):\n",
    "        self.final_answer = final_answer\n",
    "\n",
    "    def __call__(self, num1: float, num2: float, operation: str, **kwargs) -> ToolResponse:\n",
    "        if operation not in [\"add\", \"subtract\", \"multiply\", \"divide\"]:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=\"Invalid operation. Supported operations are 'add', 'subtract', 'multiply', and 'divide'.\",\n",
    "                extras={}\n",
    "            )\n",
    "        \n",
    "        if operation == \"divide\" and num2 == 0:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=\"Division by zero is not allowed.\",\n",
    "                extras={}\n",
    "            )\n",
    "        try:\n",
    "            num1 = float(num1)\n",
    "            num2 = float(num2)\n",
    "            if operation == \"add\":\n",
    "                result = num1 + num2\n",
    "            elif operation == \"subtract\":\n",
    "                result = num1 - num2\n",
    "            elif operation == \"multiply\":\n",
    "                result = num1 * num2\n",
    "            elif operation == \"divide\":\n",
    "                result = num1 / num2\n",
    "        except Exception as e:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=f\"An error occurred: {str(e)}\",\n",
    "                extras={}\n",
    "            )\n",
    "        \n",
    "        return ToolResponse(\n",
    "            final_answer=self.final_answer,\n",
    "            results=float(result),\n",
    "            extras={}\n",
    "        )\n",
    "\n",
    "calculator_tool = CalculatorTool()\n",
    "toolkit = Toolkit(tools=[calculator_tool])\n",
    "\n",
    "# print(\"Tool description:\")\n",
    "# print(calculator_tool.get_tool_description())\n",
    "# print()\n",
    "\n",
    "agent = Agent(llm=LLM, toolkit=toolkit)\n",
    "\n",
    "print(\"Agent with choice between tools and plain text:\")\n",
    "agent_response = agent.run(user_prompt=\"What is 1 + 1?\", strict_tool_call=False, stream=False)\n",
    "print(agent_response.response)\n",
    "\n",
    "# print(\"\\n\\nAgent with strict tool call:\")\n",
    "# agent_response = agent.run(user_prompt=\"What is one forth of a 100?\", strict_tool_call=True)\n",
    "# print(agent_response.response)\n",
    "\n",
    "# for chunk in agent_response.response.returns:\n",
    "#     print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e587eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_response.traces.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3778857",
   "metadata": {},
   "source": [
    "## ğŸ¤– ReAct Agent with Multiple Tools\n",
    "\n",
    "This section demonstrates how the ReActAgent combines *reasoning*, *tool usage*, and *final natural-language responses* in a multi-step workflow. We register both the calculator and city-info tools, configure the ReAct agent, and ask it to perform a multi-tool reasoning task.\n",
    "\n",
    "### ğŸ”§ What this cell demonstrates\n",
    "- Initializing the ReAct agent with a toolkit containing multiple tools  \n",
    "- Using the agentâ€™s reasoning loop to:\n",
    "  1. look up information via tools,\n",
    "  2. perform intermediate calculations,\n",
    "  3. then produce a final user-facing answer\n",
    "- Inspecting the agentâ€™s step-by-step reasoning through trace logs\n",
    "\n",
    "### ğŸ§­ Why the ReAct pattern matters\n",
    "ReAct (Reason + Act) provides a powerful mechanism enabling the model to:\n",
    "- think step-by-step,\n",
    "- decide which tool to use and when,\n",
    "- execute tools with structured inputs,\n",
    "- incorporate the results into its next reasoning step,\n",
    "- and finally delegate the output to the configured final-answer generator.\n",
    "\n",
    "### ğŸŒ Language + Length control\n",
    "The configuration in this example instructs the agent to:\n",
    "- output the final answer in **Urdu**,  \n",
    "- using a **detailed** explanation style.  \n",
    "\n",
    "This showcases how ReAct can seamlessly combine:\n",
    "tool execution â†’ internal reasoning â†’ controlled natural-language output.\n",
    "\n",
    "### ğŸ“Œ What youâ€™ll see in the output\n",
    "The trace log shows:\n",
    "- the agent thinking about the task,\n",
    "- selecting the correct tool,\n",
    "- performing the arithmetic with the calculator,\n",
    "- switching into final-answer mode,\n",
    "- and producing a polished, human-readable result in Urdu.\n",
    "\n",
    "This example completes the picture of a full ReAct loop with multi-tool support and controlled final messaging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e4e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:13:14\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: calculator\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:13:14\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: city_info\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from typing import Dict, Any\n",
    "from neurosurfer.tools import BaseTool, ToolSpec, ToolParam, ToolReturn, ToolResponse\n",
    "\n",
    "# CityInfoTool\n",
    "class CityInfoTool(BaseTool):\n",
    "    \"\"\"\n",
    "    Simple read-only city info DB so the ReAct agent has something non-trivial to reason about.\n",
    "    \"\"\"\n",
    "    spec = ToolSpec(\n",
    "        name=\"city_info\",\n",
    "        description=\"Look up basic information about a city (population and timezone).\",\n",
    "        when_to_use=\"Use this tool when you need factual info about a city such as population or timezone.\",\n",
    "        inputs=[\n",
    "            ToolParam(name=\"city\", type=\"string\", description=\"City name, e.g. 'Paris', 'Tokyo'.\", required=True),\n",
    "        ],\n",
    "        returns=ToolReturn(type=\"string\", description=\"A short JSON-formatted string with fields like population_millions and timezone.\"),\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # tiny in-memory DB\n",
    "        self._db = {\n",
    "            \"paris\": {\n",
    "                \"population_millions\": 2.1,\n",
    "                \"timezone\": \"Europe/Paris\",\n",
    "            },\n",
    "            \"tokyo\": {\n",
    "                \"population_millions\": 13.9,\n",
    "                \"timezone\": \"Asia/Tokyo\",\n",
    "            },\n",
    "            \"dubai\": {\n",
    "                \"population_millions\": 3.6,\n",
    "                \"timezone\": \"Asia/Dubai\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def __call__(self, city: str, **kwargs: Dict[str, Any]) -> ToolResponse:\n",
    "        city_key = city.strip().lower()\n",
    "        info = self._db.get(city_key)\n",
    "        if not info:\n",
    "            result = f'{{\"city\": \"{city}\", \"error\": \"unknown city\"}}'\n",
    "        else:\n",
    "            result = json.dumps({\"city\": city_key, **info})\n",
    "\n",
    "        return ToolResponse(\n",
    "            results=result,\n",
    "            final_answer=False,  # ReAct can decide what to do next\n",
    "            extras={},          # you can stash anything here into memory if you want\n",
    "        )\n",
    "\n",
    "\n",
    "calculator_tool = CalculatorTool()\n",
    "city_info_tool = CityInfoTool()\n",
    "\n",
    "toolkit = Toolkit(tools=[calculator_tool, city_info_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c099e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mğŸ§  Thinking\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting react_agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "    \u001b[3;90mThought: \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mlook \u001b[0m\u001b[3;90mup \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mParis \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mfirst. \u001b[0m\u001b[3;90mI'll \u001b[0m\u001b[3;90mstart \u001b[0m\u001b[3;90mby \u001b[0m\u001b[3;90mretrieving \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90minformation \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mParis.\u001b[0m\n",
      "    \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"city_info\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"city\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Paris\"\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[3;90m\"city_info_Paris\"\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "    \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: city_info\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting tool.execute\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: city_info, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'city'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Paris'\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \n",
      "            \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m\"city\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"paris\"\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"population_millions\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m2.1\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"timezone\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"Europe/Paris\"\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m005s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed tool.execute!\u001b[0m\n",
      "    \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m939s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "    \u001b[3;90mThought: \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mlook \u001b[0m\u001b[3;90mup \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mnext. \u001b[0m\u001b[3;90mI'll \u001b[0m\u001b[3;90mretrieve \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90minformation \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mTokyo.\u001b[0m\n",
      "    \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"city_info\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"city\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Tokyo\"\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[3;90m\"city_info_Tokyo\"\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "    \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: city_info\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting tool.execute\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: city_info, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'city'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Tokyo'\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \n",
      "            \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m\"city\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"tokyo\"\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"population_millions\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m13.9\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"timezone\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"Asia/Tokyo\"\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m005s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed tool.execute!\u001b[0m\n",
      "    \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m928s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "    \u001b[3;90mThought: \u001b[0m\u001b[3;90mNow \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mhave \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mboth \u001b[0m\u001b[3;90mcities, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mcalculate \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdifference \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mbetween \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mParis \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mdetermine \u001b[0m\u001b[3;90mhow \u001b[0m\u001b[3;90mmany \u001b[0m\u001b[3;90mmillions \u001b[0m\u001b[3;90mmore \u001b[0m\u001b[3;90mpeople \u001b[0m\u001b[3;90mlive \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mthan \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90mParis.\u001b[0m\n",
      "    \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"calculator\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"num1\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m13.9\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"num2\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m2.1\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"operation\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"subtract\"\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "    \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: calculator\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting tool.execute\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: calculator, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'num1'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m13.9\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'num2'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m2.1\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'operation'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'subtract'\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \n",
      "            \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: \u001b[0m\u001b[1;32m11.8\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m005s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed tool.execute!\u001b[0m\n",
      "    \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m668s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "    \u001b[3;90mThought: \u001b[0m\u001b[3;90mNow \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mhave \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mdifference \u001b[0m\u001b[3;90mbetween \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mParis, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mcan \u001b[0m\u001b[3;90mprovide \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mfinal \u001b[0m\u001b[3;90mrecommendation \u001b[0m\u001b[3;90mbased \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mthis \u001b[0m\u001b[3;90mnumber.\u001b[0m\n",
      "    \u001b[3;90mAction: \u001b[0m\u001b[3;90mNone\u001b[0m        \u001b[1;32mINFO: Generating final answer with \u001b[0m\u001b[1;32mlanguage\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mlength\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mhistory_len\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m7\u001b[0m\n",
      "\n",
      "    \u001b[1;32mFinal Response:\u001b[0m\n",
      "    \u001b[1;37mÙ¹ÙˆÚ©ÛŒÙˆ \u001b[0m\u001b[1;37mÙ…ÛŒÚº \u001b[0m\u001b[1;37mØ±ÛÙ†Û’ \u001b[0m\u001b[1;37mÙˆØ§Ù„ÛŒ \u001b[0m\u001b[1;37mØ¢Ø¨Ø§Ø¯ÛŒ \u001b[0m\u001b[1;37mÙ¾Ø§Ø±Ø³ \u001b[0m\u001b[1;37mÚ©ÛŒ \u001b[0m\u001b[1;37mØ¢Ø¨Ø§Ø¯ÛŒ \u001b[0m\u001b[1;37mØ³Û’ \u001b[0m\u001b[1;37m11.8\u001b[0m\u001b[1;37m \u001b[0m\u001b[1;37mÙ…Ù„ÛŒÙ† \u001b[0m\u001b[1;37mØ²ÛŒØ§Ø¯Û \u001b[0m\u001b[1;37mÛÛ’Û” \u001b[0m\u001b[1;37mÛŒÛ \u001b[0m\u001b[1;37mØ§Ø¹Ø¯Ø§Ø¯ \u001b[0m\u001b[1;37mÙˆ \u001b[0m\u001b[1;37mØ´Ù…Ø§Ø± \u001b[0m\u001b[1;37mØ¨ØªØ§ØªÛ’ \u001b[0m\u001b[1;37mÛÛŒÚº \u001b[0m\u001b[1;37mÚ©Û \u001b[0m\u001b[1;37mÙ¹ÙˆÚ©ÛŒÙˆ \u001b[0m\u001b[1;37mØ§ÛŒÚ© \u001b[0m\u001b[1;37mØ¨ÛØª \u001b[0m\u001b[1;37mØ¨Ú‘Ø§ \u001b[0m\u001b[1;37mØ´ÛØ± \u001b[0m\u001b[1;37mÛÛ’ \u001b[0m\u001b[1;37mØ¬Ø³ \u001b[0m\u001b[1;37mÙ…ÛŒÚº \u001b[0m\u001b[1;37mØ¨ÛØª \u001b[0m\u001b[1;37mØ²ÛŒØ§Ø¯Û \u001b[0m\u001b[1;37mØ¢Ø¨Ø§Ø¯ÛŒ \u001b[0m\u001b[1;37mØ±ÛØªÛŒ \u001b[0m\u001b[1;37mÛÛ’Û” \u001b[0m\u001b[1;37mØ§Ú¯Ø± \u001b[0m\u001b[1;37mØ¢Ù¾ \u001b[0m\u001b[1;37mÚ©Ùˆ \u001b[0m\u001b[1;37mØ¨Ú‘ÛŒ \u001b[0m\u001b[1;37mØ¢Ø¨Ø§Ø¯ÛŒ \u001b[0m\u001b[1;37mÙˆØ§Ù„Û’ \u001b[0m\u001b[1;37mØ´ÛØ± \u001b[0m\u001b[1;37mÚ©Ø§ \u001b[0m\u001b[1;37mØ³ÙØ± \u001b[0m\u001b[1;37mÚ©Ø±Ù†Û’ \u001b[0m\u001b[1;37mÚ©Ø§ \u001b[0m\u001b[1;37mØ§Ù†ØªØ®Ø§Ø¨ \u001b[0m\u001b[1;37mÚ©Ø±Ù†Û’ \u001b[0m\u001b[1;37mÚ©ÛŒ \u001b[0m\u001b[1;37mØ¶Ø±ÙˆØ±Øª \u001b[0m\u001b[1;37mÛÛ’ØŒ \u001b[0m\u001b[1;37mØªÙˆ \u001b[0m\u001b[1;37mÙ¹ÙˆÚ©ÛŒÙˆ \u001b[0m\u001b[1;37mØ§ÛŒÚ© \u001b[0m\u001b[1;37mØ§Ú†Ú¾Ø§ \u001b[0m\u001b[1;37mØ§Ù†ØªØ®Ø§Ø¨ \u001b[0m\u001b[1;37mÛÙˆÚ¯Ø§Û” \u001b[0m\u001b[1;37mÙ„ÛŒÚ©Ù† \u001b[0m\u001b[1;37mØ§Ú¯Ø± \u001b[0m\u001b[1;37mØ¢Ù¾ \u001b[0m\u001b[1;37mÚ©Ùˆ \u001b[0m\u001b[1;37mÚ©Ù… \u001b[0m\u001b[1;37mØ¢Ø¨Ø§Ø¯ÛŒ \u001b[0m\u001b[1;37mÙˆØ§Ù„Û’ \u001b[0m\u001b[1;37mØ´ÛØ± \u001b[0m\u001b[1;37mÚ©Ø§ \u001b[0m\u001b[1;37mØ³ÙØ± \u001b[0m\u001b[1;37mÚ©Ø±Ù†Û’ \u001b[0m\u001b[1;37mÚ©Ø§ \u001b[0m\u001b[1;37mØ§Ù†ØªØ®Ø§Ø¨ \u001b[0m\u001b[1;37mÚ©Ø±Ù†Û’ \u001b[0m\u001b[1;37mÚ©ÛŒ \u001b[0m\u001b[1;37mØ¶Ø±ÙˆØ±Øª \u001b[0m\u001b[1;37mÛÛ’ØŒ \u001b[0m\u001b[1;37mØªÙˆ \u001b[0m\u001b[1;37mÙ¾Ø§Ø±Ø³ \u001b[0m\u001b[1;37mØ§ÛŒÚ© \u001b[0m\u001b[1;37mØ§Ú†Ú¾Ø§ \u001b[0m\u001b[1;37mØ§Ù†ØªØ®Ø§Ø¨ \u001b[0m\u001b[1;37mÛÙˆÚ¯Ø§Û”\u001b[0m    \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m6.\u001b[0m\u001b[2m802s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m13.\u001b[0m\u001b[2m348s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mreact_agent_main\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed react_agent!\u001b[0m\n",
      "\n",
      "\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.react.agent import ReActAgent, ReActConfig\n",
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "\n",
    "\n",
    "react_config = ReActConfig(\n",
    "    mode=\"delegate_final\",\n",
    "    skip_special_tokens=True,\n",
    "    max_new_tokens=4096,\n",
    "    temperature=0.7,\n",
    "    log_internal_thoughts=True,\n",
    "    final_answer_language=\"Urdu\",\n",
    "    final_answer_length=\"detailed\",\n",
    ")\n",
    "\n",
    "react_agent = ReActAgent(\n",
    "    id=\"react_agent_main\",\n",
    "    llm=LLM,\n",
    "    toolkit=toolkit,\n",
    "    config=react_config,\n",
    "    log_traces=True,\n",
    ")\n",
    "\n",
    "query = (\n",
    "    \"/nothink\"\n",
    "    \"I'm deciding between visiting Paris or Tokyo. \"\n",
    "    \"Use your tools to: \"\n",
    "    \"1) look up the population of each city in millions, \"\n",
    "    \"2) compute how many millions more people live in Tokyo than in Paris, \"\n",
    "    \"3) then give me a final recommendation in natural language using that number.\"\n",
    ")\n",
    "\n",
    "res = react_agent.run(query=query, stream=False)\n",
    "\n",
    "\n",
    "# # For streaming Response\n",
    "# res = react_agent.run(query=query, stream=True)\n",
    "# for chunk in res.response: \n",
    "#     # print(chunk, end=\"\", flush=True)\n",
    "#     pass\n",
    "\n",
    "# traces\n",
    "# trace_dict = res.traces.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5383323",
   "metadata": {},
   "source": [
    "## ğŸ§ª CodeAgent â€” Python Execution via ReAct\n",
    "\n",
    "This example shows how the `CodeAgent` can analyze a user request, plan the required steps, and then execute real Python code through the built-in `python_execute` tool. The task here is to generate synthetic Lorenz-attractor data and produce a 3D plot.\n",
    "\n",
    "### ğŸ”§ What this cell demonstrates\n",
    "- Initializing the `CodeAgent` with analysis-first mode (`analysis_only`)\n",
    "- Allowing the agent to think step-by-step before calling the Python execution tool\n",
    "- Automatically generating Python code, running it, and retrieving the results\n",
    "- Viewing the generated plot file in the working directory\n",
    "- Inspecting detailed traces showing:\n",
    "  - reasoning thoughts,\n",
    "  - tool selection,\n",
    "  - executed Python code,\n",
    "  - generated artifacts,\n",
    "  - and the final explanatory output\n",
    "\n",
    "### ğŸ§­ Why the CodeAgent is useful\n",
    "The CodeAgent is designed for tasks that require:\n",
    "- data analysis,\n",
    "- mathematical simulations,\n",
    "- plotting and visualization,\n",
    "- execution of multi-step logic,\n",
    "- or any workflow where Python code is needed.\n",
    "\n",
    "It combines ReAct reasoning with safe, sandboxed code execution, making it ideal for scientific, analytical, or exploratory notebooks.\n",
    "\n",
    "### ğŸ“Œ Outcome\n",
    "You will see:\n",
    "- the generated Python code,\n",
    "- the saved `lorenz_attractor_3d.png` plot,\n",
    "- and a final descriptive summary of what the code produced.\n",
    "\n",
    "This marks the transition from pure LLM reasoning into full programmatic capabilities within the agent framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4eb609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Agent Cofig:\n",
      "CodeAgentConfig(mode='analysis_only', temperature=0.7, max_new_tokens=4096, allow_input_pruning=True, repair_with_llm=True, retry=RetryPolicy(max_parse_retries=2, max_tool_errors=2, backoff_sec=0.8), skip_special_tokens=True, return_stream_by_default=False, log_internal_thoughts=True, return_internal_thoughts=False, max_loop_iterations=5, final_answer_language='english', final_answer_length='detailed', final_answer_max_history_chars=12000, forced_memory_keys={'python_execute': ['python_last_result_summary', 'python_last_error']}, agent_name='CodeAgent', enable_post_processing=False, default_workdir='.', encourage_multistep_planning=True, default_return_raw=False)\n",
      "\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:13:48\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: python_code_generate_and_execute\n",
      "\u001b[1;33mğŸ§  Thinking\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting react_agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "    \u001b[3;90mThought: \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mgenerate \u001b[0m\u001b[3;90msynthetic \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mLorenz \u001b[0m\u001b[3;90mattractor \u001b[0m\u001b[3;90musing \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mgiven \u001b[0m\u001b[3;90mparameters \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mthen \u001b[0m\u001b[3;90mcreate \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90m3D \u001b[0m\u001b[3;90mplot. \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mwill \u001b[0m\u001b[3;90mfirst \u001b[0m\u001b[3;90mgenerate \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mthen \u001b[0m\u001b[3;90mplot \u001b[0m\u001b[3;90mit.\u001b[0m\n",
      "    \n",
      "    \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"python_code_generate_and_execute\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"task\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Generate \u001b[0m\u001b[3;90msynthetic \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mLorenz \u001b[0m\u001b[3;90mattractor \u001b[0m\u001b[3;90mwith \u001b[0m\u001b[3;90mparameters \u001b[0m\u001b[3;90mÏƒ\u001b[0m\u001b[3;90m=\u001b[0m\u001b[1;3;90m10\u001b[0m\u001b[3;90m, \u001b[0m\u001b[3;90mÏ\u001b[0m\u001b[3;90m=\u001b[0m\u001b[1;3;90m28\u001b[0m\u001b[3;90m, \u001b[0m\u001b[3;90mÎ²\u001b[0m\u001b[3;90m=\u001b[0m\u001b[1;3;90m8\u001b[0m\u001b[3;90m/\u001b[0m\u001b[1;3;90m3\u001b[0m\u001b[3;90m. \u001b[0m\u001b[3;90mUse \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mtime \u001b[0m\u001b[3;90mstep \u001b[0m\u001b[3;90mof \u001b[0m\u001b[1;3;90m0.01\u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90msimulate \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[1;3;90m10000\u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90msteps. \u001b[0m\u001b[3;90mStore \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mresults \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mDataFrame \u001b[0m\u001b[3;90mwith \u001b[0m\u001b[3;90mcolumns \u001b[0m\u001b[3;90mx, \u001b[0m\u001b[3;90my, \u001b[0m\u001b[3;90mz.\"\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "    \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: python_code_generate_and_execute\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting tool.execute\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: python_code_generate_and_execute, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'task'\u001b[0m\u001b[1;32m: 'Generate synthetic data for the Lorenz attractor with parameters \u001b[0m\u001b[1;32mÏƒ\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m10\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mÏ\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m28\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mÎ²\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m8\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m3\u001b[0m\u001b[1;32m. Use a time step of \u001b[0m\u001b[1;32m0.01\u001b[0m\u001b[1;32m and simulate for \u001b[0m\u001b[1;32m10000\u001b[0m\u001b[1;32m steps. Store the results in a DataFrame with columns x, y, \u001b[0m\n",
      "\u001b[1;32m...\u001b[0m\n",
      "            \n",
      "            \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: Here are the results from executing Python code for your task:\u001b[0m\n",
      "            \n",
      "            \u001b[1;32m|        x |        y |         z |\u001b[0m\n",
      "            \u001b[1;32m|---------:|---------:|----------:|\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.1\u001b[0m\u001b[1;32m      | \u001b[0m\u001b[1;32m0.1269\u001b[0m\u001b[1;32m   | \u001b[0m\u001b[1;32m0.0974333\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.10269\u001b[0m\u001b[1;32m  | \u001b[0m\u001b[1;32m0.153534\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.094962\u001b[0m\u001b[1;32m  |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.107774\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.180654\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0925874\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.115062\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.208924\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0903131\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.124449\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.238949\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0881451\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.135899\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.271295\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0860919\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.149438\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.306517\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0841648\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.165146\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.345168\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0823785\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.183148\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.387822\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0807518\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.203616\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.435077\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0793087\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.226762\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.487577\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0780797\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.252843\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.546018\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0771032\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.282161\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.611159\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0764277\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.315061\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.683836\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.076114\u001b[0m\u001b[1;32m  |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.351938\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.764975\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.0762388\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.393242\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.8556\u001b[0m\u001b[1;32m   | \u001b[0m\u001b[1;32m0.076898\u001b[0m\u001b[1;32m  |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.439478\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.956849\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m0.078212\u001b[0m\u001b[1;32m  |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.491215\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m1.06999\u001b[0m\u001b[1;32m  | \u001b[0m\u001b[1;32m0.0803315\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.549092\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m1.19644\u001b[0m\u001b[1;32m  | \u001b[0m\u001b[1;32m0.0834453\u001b[0m\u001b[1;32m |\u001b[0m\n",
      "            \u001b[1;32m| \u001b[0m\u001b[1;32m0.613827\u001b[0m\u001b[1;32m | \u001b[0m\u001b[1;32m1.33776\u001b[0m\u001b[1;32m  | \u001b[0m\u001b[1;32m0.0877896\u001b[0m\u001b[1;32m |\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m932s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed tool.execute!\u001b[0m\n",
      "    \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m8.\u001b[0m\u001b[2m642s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "    \u001b[3;90mThought: \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mnow \u001b[0m\u001b[3;90mhave \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90msynthetic \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mLorenz \u001b[0m\u001b[3;90mattractor. \u001b[0m\u001b[3;90mThe \u001b[0m\u001b[3;90mnext \u001b[0m\u001b[3;90mstep \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mcreate \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90m3D \u001b[0m\u001b[3;90mplot \u001b[0m\u001b[3;90musing \u001b[0m\u001b[3;90mthis \u001b[0m\u001b[3;90mdata. \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mwill \u001b[0m\u001b[3;90muse \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90m`plotly` \u001b[0m\u001b[3;90mlibrary \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mgenerate \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90m3D \u001b[0m\u001b[3;90mplot.\u001b[0m\n",
      "    \n",
      "    \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"python_code_generate_and_execute\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "    \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"task\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Create \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90m3D \u001b[0m\u001b[3;90mplot \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mLorenz \u001b[0m\u001b[3;90mattractor \u001b[0m\u001b[3;90musing \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mgenerated \u001b[0m\u001b[3;90mx, \u001b[0m\u001b[3;90my, \u001b[0m\u001b[3;90mz \u001b[0m\u001b[3;90mdata.\"\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[3;90m\"python_last_result_summary\"\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "    \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mtrue\u001b[0m\n",
      "    \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: python_code_generate_and_execute\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting tool.execute\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: python_code_generate_and_execute, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mğŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'task'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Create a 3D plot of the Lorenz attractor using the generated x, y, z data.'\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \n",
      "            \u001b[1;32m[\u001b[0m\u001b[1;32mğŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: Here are the results from executing Python code for your task:\u001b[0m\n",
      "            \n",
      "            \u001b[1;32m[\u001b[0m\n",
      "            \u001b[1;32m  \u001b[0m\u001b[1;32m\"lorenz_attractor_3d_plot.png\"\u001b[0m\n",
      "            \u001b[1;32m]\u001b[0m\n",
      "            \n",
      "            \u001b[1;32mGenerated plots \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32msaved in this session's working directory\u001b[0m\u001b[1;32m)\u001b[0m\u001b[1;32m:\u001b[0m\n",
      "            \u001b[1;32m- lorenz_attractor_3d_plot.png\u001b[0m\n",
      "            \u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m8.\u001b[0m\u001b[2m421s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed tool.execute!\u001b[0m\n",
      "    \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m11.\u001b[0m\u001b[2m623s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "    \u001b[3;90mThought: \u001b[0m\u001b[3;90mThe \u001b[0m\u001b[3;90m3D \u001b[0m\u001b[3;90mplot \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mLorenz \u001b[0m\u001b[3;90mattractor \u001b[0m\u001b[3;90mhas \u001b[0m\u001b[3;90mbeen \u001b[0m\u001b[3;90mgenerated \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90msaved \u001b[0m\u001b[3;90mas \u001b[0m\u001b[3;90man \u001b[0m\u001b[3;90mimage \u001b[0m\u001b[3;90mfile. \u001b[0m\u001b[3;90mSince \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90muser \u001b[0m\u001b[3;90mrequested \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mplot, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mwill \u001b[0m\u001b[3;90mnow \u001b[0m\u001b[3;90mprovide \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfinal \u001b[0m\u001b[3;90manswer \u001b[0m\u001b[3;90mwith \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mplot \u001b[0m\u001b[3;90mfile \u001b[0m\u001b[3;90mname \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mbrief \u001b[0m\u001b[3;90mexplanation.\u001b[0m\n",
      "    \n",
      "    \u001b[3;90mAction: \u001b[0m\u001b[3;90mNone\u001b[0m\u001b[1;32m No further tool selected; returning control to parent agent.\u001b[0m\n",
      "    \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m736s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m22.\u001b[0m\u001b[2m007s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed react_agent!\u001b[0m\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mCodeAgent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neurosurfer.agents.code import CodeAgent, CodeAgentConfig\n",
    "\n",
    "code_agent = CodeAgent(\n",
    "    llm=LLM,\n",
    "    config=CodeAgentConfig(\n",
    "        mode=\"analysis_only\",\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=4096,\n",
    "        log_internal_thoughts=True,\n",
    "        default_workdir=\".\",\n",
    "    ),\n",
    "    log_traces=True,\n",
    ")\n",
    "\n",
    "user_query = \"\"\"Generate a 3D plot of the Lorenz attractor using synthetic data with the classic (Ïƒ=10, Ï=28, Î²=8/3) parameters.\"\"\"\n",
    "agent_restuls = code_agent.run(query=user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89dcfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(agent_restuls.tool_calls[0].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b1381",
   "metadata": {},
   "source": [
    "## ğŸ“š Retrieval-Augmented Generation (RAG) â€” Indexing & Querying a Document\n",
    "\n",
    "This example demonstrates how to use the RAGAgent to ingest documents, build a searchable vector store, and answer queries using retrieved context. It showcases the full RAG pipeline: file reading â†’ chunking â†’ embedding â†’ storage â†’ retrieval â†’ generation.\n",
    "\n",
    "### ğŸ”§ What this cell sets up\n",
    "- A **Chunker** to split large documents into semantically meaningful segments.\n",
    "- A **FileReader** capable of loading DOCX, PDF, text files, and more.\n",
    "- A **SentenceTransformerEmbedder** to generate vector embeddings (`e5-small-v2`).\n",
    "- A **RAGAgent** configured with:\n",
    "  - persistent vector storage,\n",
    "  - configurable retrieval depth,\n",
    "  - deduplication,\n",
    "  - multi-worker ingestion for speed.\n",
    "\n",
    "### ğŸ“ Ingesting a document\n",
    "The agent reads the target file, chunks it, computes embeddings, and stores them on disk.  \n",
    "A summary of ingestion statisticsâ€”chunk count, file size, processing timeâ€”is printed afterward.\n",
    "\n",
    "### ğŸ” Querying with RAG\n",
    "We then pose a natural-language question and enable `stream=True` to visualize the answer as itâ€™s generated.  \n",
    "Under the hood, the RAGAgent:\n",
    "1. retrieves the most relevant chunks,\n",
    "2. injects them into the model as context,\n",
    "3. produces a grounded, reference-aware answer.\n",
    "\n",
    "### ğŸ“Œ Why this matters\n",
    "RAG is essential when working with:\n",
    "- proprietary documents,\n",
    "- long technical files,\n",
    "- research papers,\n",
    "- project documentation,\n",
    "- meeting notes and knowledge bases.\n",
    "\n",
    "This example demonstrates a complete retrieval-augmented workflow integrated directly with the Neurosurfer agent framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a35db287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:20:53\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:20:53\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2026-01-04 11:20:53\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175728d5b2ec4459aafa623a9777c9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of ingestion:\n",
      "status: ok\n",
      "sources: 1\n",
      "chunks: 9\n",
      "unique_chunks: 9\n",
      "added: 9\n",
      "finished_at: 1767511253.6746953\n",
      "accepted_sources: 1\n",
      "total_docs_in_collection: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scripts/index_repo_for_rag.py\n",
    "from pathlib import Path\n",
    "from neurosurfer.models.embedders.sentence_transformer import SentenceTransformerEmbedder\n",
    "from neurosurfer.agents.rag.chunker import Chunker\n",
    "from neurosurfer.agents.rag.filereader import FileReader\n",
    "from neurosurfer.agents.rag import RAGAgent, RAGAgentConfig, RAGIngestorConfig\n",
    "\n",
    "chunker = Chunker()\n",
    "file_reader = FileReader()\n",
    "\n",
    "embedder = SentenceTransformerEmbedder(\"intfloat/e5-small-v2\")\n",
    "rag_agent = RAGAgent(\n",
    "    llm=LLM,\n",
    "    embedder=embedder,\n",
    "    file_reader=file_reader,\n",
    "    chunker=chunker,\n",
    "    config=RAGAgentConfig(\n",
    "        top_k=5,\n",
    "        fixed_max_new_tokens=2048,\n",
    "        clear_collection_on_init=True,\n",
    "        persist_directory=\"/home/nomi/rag-storage\",\n",
    "    ),\n",
    "    ingestor_config=RAGIngestorConfig(\n",
    "        batch_size=64,\n",
    "        max_workers=4,\n",
    "        deduplicate=True,\n",
    "        normalize_embeddings=True,\n",
    "        default_metadata=None,\n",
    "        tmp_dir=\"/home/nomi/rag-storage\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "dir_path = \"./temp/AI Demonstration Proposal_Final_Draft.docx\"\n",
    "summary = rag_agent.ingest(sources=dir_path)\n",
    "\n",
    "print(\"\\nSummary of ingestion:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print()\n",
    "\n",
    "# retrival_results = rag_agent.retrieve(user_query=\"Explain how graph agent is initialized\", top_k=10)\n",
    "# print(\"max_new_tokens\", retrival_results.max_new_tokens)\n",
    "# print()\n",
    "# print(retrival_results.context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebe5c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'rag_agent.run'\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting RAGAgent retrieve\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "    \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'full'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'summary'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'summary of the entire document'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m50\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac00cc6e2b7842abb2b5142c8f9e4c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m9\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "    \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m15423\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "    \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m15423\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m841s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed RAGAgent retrieve!\u001b[0m\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m001s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m002s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'rag_agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m849s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed agent!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The document provides an overview of three AI demonstration projects designed for enterprise and government systems. These projects focus on integrating AI for enhanced productivity, automation, and knowledge management. \n",
       "\n",
       "1. **AI Demonstration for eOffice**: This project uses vector-based storage and retrieval of notings for automated summarization and draft generation, improving efficiency in document handling and decision-making.\n",
       "\n",
       "2. **RAG System Demonstration**: This project presents a Retrieval-Augmented Generation (RAG) framework that transforms unstructured organizational documents into searchable, intelligent knowledge domains. It uses custom models for specific domains like Law, Healthcare, and Finance to provide accurate and explainable answers.\n",
       "\n",
       "3. **MOM LLM Project**: This project automates meeting documentation by combining speech recognition and language understanding. It transcribes audio inputs and generates structured Minutes of Meeting (MOMs), reducing manual effort and improving accuracy in meeting reporting.\n",
       "\n",
       "All projects emphasize on-premise deployment for data sovereignty, privacy, cost-efficiency, and scalability. They highlight the use of advanced AI models, vector databases, and modular architectures to deliver context-aware, intelligent solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# streaming response example\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "user_query = \"\"\"Give me brief summary of the document.\"\"\"\n",
    "streaming_response = rag_agent.run(\n",
    "    user_query, \n",
    "    retrieval_mode=\"smart\", \n",
    "    stream=True\n",
    ")\n",
    "\n",
    "md_display = display(Markdown(\"\"), display_id=True)\n",
    "response = \"\"\n",
    "for chunk in streaming_response.agent_response.response:\n",
    "    md_display.update(Markdown(response))\n",
    "    response += chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4c8c2",
   "metadata": {},
   "source": [
    "## ğŸ§© GraphAgent â€” Multi-Node Workflow with Web Search, Outlining, Drafting, and Review\n",
    "\n",
    "This section demonstrates how to use the `GraphAgent` to run a complete multi-stage writing workflow.  \n",
    "A YAML graph defines the nodes (â€œresearchâ€, â€œoutlineâ€, â€œdraftâ€, â€œreviewâ€), their tool access, dependencies, and output modes.  \n",
    "The agent then orchestrates all nodes in sequence using the same LLM, Toolkit, and tracing system.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ What this cell sets up\n",
    "- **WebSearchTool** configured with SerpAPI and optional crawling.\n",
    "- A **Toolkit** containing web search, enabling the research node to gather external information.\n",
    "- A **GraphAgent** configured with:\n",
    "  - a YAML workflow (`blog_workflow.yml`),\n",
    "  - per-node policies (temperature, max tokens, structured/text modes),\n",
    "  - a manager LLM that composes prompts and coordinates all nodes,\n",
    "  - full tracing for transparency.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§­ What happens during execution\n",
    "The workflow runs node-by-node:\n",
    "\n",
    "1. **research**  \n",
    "   - Uses the web search tool to gather key information.  \n",
    "   - Produces a structured summary exported as JSON.\n",
    "\n",
    "2. **outline**  \n",
    "   - Reads the research output.  \n",
    "   - Generates a structured blog outline in markdown.  \n",
    "   - Exported as an `.md` file.\n",
    "\n",
    "3. **draft**  \n",
    "   - Consumes both the outline and research data.  \n",
    "   - Produces a long-form article draft (~3000 words).  \n",
    "   - Exported as markdown.\n",
    "\n",
    "4. **review**  \n",
    "   - Reads the draft + research.  \n",
    "   - Produces a structured technical/editorial review.  \n",
    "   - Exported as markdown.\n",
    "\n",
    "The manager LLM composes prompts for each node, ensuring that every tool, dependency, and policy is correctly applied.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Why GraphAgent is powerful\n",
    "- It allows you to define entire multi-step, multi-agent workflows declaratively via YAML.  \n",
    "- Each node can have different modes: free-text, structured, tool-enabled, or special policies.  \n",
    "- Tools are selectively available only to nodes that require them.  \n",
    "- Every step is traced, logged, and exportable for inspection or reuse.  \n",
    "- Output artifacts (research, outline, draft, review) are automatically saved to the `exports/` folder.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ What you see in the console\n",
    "- Detailed traces for each node  \n",
    "- Web search execution logs  \n",
    "- LLM calls and tool routing decisions  \n",
    "- Final responses for each stage  \n",
    "- Automatic export notifications\n",
    "\n",
    "This example showcases how to build full production-grade, multi-agent pipelines using Neurosurferâ€™s GraphAgent system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec7eb2",
   "metadata": {},
   "source": [
    "### YAML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e3d42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key:  f443633b...\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2026-01-04 11:41:18\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:41:18\u001b[0m | \u001b[96mposthog.py:__init__\u001b[0m | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:41:19\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:41:19\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 11:41:19\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n",
      "{'web_search': <neurosurfer.tools.websearch.tool.WebSearchTool object at 0x7f5750b668a0>}\n"
     ]
    }
   ],
   "source": [
    "# test web search tool\n",
    "from neurosurfer.tools.websearch import WebSearchTool, WebSearchConfig\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "\n",
    "api_key = os.getenv(\"SERPAPI_KEY\", \"API Key not found...\")\n",
    "print(\"API Key: \", f\"{api_key[:8]}...\")\n",
    "\n",
    "web_search_tool = WebSearchTool(\n",
    "    config=WebSearchConfig(\n",
    "        engine=\"serpapi\",\n",
    "        engine_kwargs={\"api_key\": api_key},\n",
    "        max_results=3,\n",
    "        enable_crawl=True,\n",
    "        max_crawl_results=2,\n",
    "        content_words_limit=2000,\n",
    "        content_limit_strategy=\"distributive\",\n",
    "        summarize=False,\n",
    "        top_k=10,\n",
    "    ),\n",
    "    llm=LLM,\n",
    ")\n",
    "\n",
    "toolkit = Toolkit(tools=[web_search_tool])\n",
    "print(toolkit.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ccb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:14:38\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m441s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;33mğŸ§  Thinking\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mresearch\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: web_search\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Stop Treating LMs as Black Boxes: The Case for Observability-First AI Systems'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'hl'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'en'\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m945s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-12-11 21:14:48\u001b[0m | \u001b[96mingestor.py:ingest\u001b[0m | Some sources were skipped as unsupported: [None, None]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ee1be9bfc346c7adf4522422ed8a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:14:48\u001b[0m | \u001b[96magent.py:retrieve\u001b[0m | [RAGAgent.retrieve] Retrieval plan: RetrievalPlan(mode='classic', scope=None, answer_breadth=None, top_k=10, notes=None, extra=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c769ec64da514b4c9f513849a1112d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:14:48\u001b[0m | \u001b[96magent.py:retrieve\u001b[0m | [RAGAgent.retrieve] Retrieved 10 documents\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:14:48\u001b[0m | \u001b[96magent.py:retrieve\u001b[0m | [RAGAgent.retrieve] Untrimmed context: 10397 chars\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:14:48\u001b[0m | \u001b[96magent.py:retrieve\u001b[0m | [RAGAgent.retrieve] Trimmed context: 10397 chars\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'web_search'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: 'Compose a \u001b[0m\u001b[1;32m1000\u001b[0m\u001b[1;32m-\u001b[0m\u001b[1;32m1500\u001b[0m\u001b[1;32m word blog arguing why observability layers are essential in modern LL\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m6.\u001b[0m\u001b[2m204s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m7.\u001b[0m\u001b[2m151s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mresearch\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m151s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;33mğŸ§  Thinking\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36moutline\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m11.\u001b[0m\u001b[2m306s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m11.\u001b[0m\u001b[2m307s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36moutline\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;32mFinal response:\u001b[0m\n",
      "**Title:**  \n",
      "*Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems*\n",
      "\n",
      "**Description:**  \n",
      "This blog post explores the critical need for observability in large language model (LLM) systems. As LLMs become more integrated into production applications, the lack of visibility into their internal workings has led to significant challenges, including hallucinations, performance bottlenecks, and compliance risks. By adopting an observability-first approach, organizations can gain real-time insights into model behavior, trace requests end-to-end, measure performance metrics, and create feedback loops for continuous improvement. This article outlines the key components of an observability-first strategy, discusses common failure patterns in LLM systems, and highlights the role of tools and best practices in building transparent, reliable, and ethical AI systems.\n",
      "\n",
      "---\n",
      "\n",
      "### **Outline of the Blog Post**\n",
      "\n",
      "#### **1. Introduction: The Rise of LLMs and the Black Box Problem**\n",
      "- **Overview of LLMs and Their Growing Role**  \n",
      "  - Explain the rapid adoption of LLMs across industries.  \n",
      "  - Highlight their complexity and the challenges of deploying them at scale.  \n",
      "\n",
      "- **The Black Box Conundrum**  \n",
      "  - Define the \"black box\" problem in LLMs.  \n",
      "  - Discuss the limitations of traditional monitoring and debugging approaches.  \n",
      "  - Introduce the concept of **observability** as a solution.  \n",
      "\n",
      "- **Why Observability Matters Now**  \n",
      "  - Link the increasing complexity of LLM systems to the need for deeper visibility.  \n",
      "  - Preview the key components of observability: tracing, metrics, feedback loops, and failure analysis.  \n",
      "\n",
      "---\n",
      "\n",
      "#### **2. Understanding Observability in LLM Systems**\n",
      "- **What is Observability?**  \n",
      "  - Define observability in the context of LLMs.  \n",
      "  - Differentiate between **observability** and **monitoring**.  \n",
      "  - Emphasize the importance of **comprehensive visibility** into model behavior.  \n",
      "\n",
      "- **The Observability Stack for LLMs**  \n",
      "  - Break down the key elements of an observability layer:  \n",
      "    - **Tracing**: Tracking requests through the system.  \n",
      "    - **Metrics**: Measuring performance and resource usage.  \n",
      "    - **Feedback Loops**: Using data to improve model behavior.  \n",
      "    - **Content Safety and Compliance**: Ensuring ethical and legal standards.  \n",
      "\n",
      "- **The Role of Observability in AI Ethics and Trust**  \n",
      "  - Discuss how observability supports transparency\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m999s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;33mğŸ§  Thinking\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mdraft\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m52.\u001b[0m\u001b[2m274s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m52.\u001b[0m\u001b[2m276s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mdraft\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;32mFinal response:\u001b[0m\n",
      "# Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\n",
      "\n",
      "## Introduction: The Rise of LLMs and the Black Box Problem\n",
      "\n",
      "Large language models (LLMs) have rapidly transformed the landscape of artificial intelligence, becoming integral to applications across industries such as finance, healthcare, customer service, and content creation. Their ability to understand and generate human-like text has made them a cornerstone of modern AI systems. However, as these models scale in complexity and usage, a critical challenge has emerged: the **black box problem**.\n",
      "\n",
      "The black box problem refers to the lack of transparency in how LLMs process inputs, generate outputs, and make decisions. Unlike traditional machine learning models, which often have more interpretable structures, LLMs are inherently complex and opaque. This opacity makes it difficult for developers and stakeholders to understand how the model behaves, especially in production environments where reliability, safety, and compliance are paramount.\n",
      "\n",
      "Traditional monitoring and debugging approaches, which are well-suited for conventional software systems, fall short when applied to LLMs. These approaches typically focus on system-level metrics such as CPU usage, memory consumption, and response times. However, they fail to capture the internal behavior of the model itselfâ€”what the model is thinking, how it processes data, and whether it is generating safe, accurate, or ethical outputs.\n",
      "\n",
      "This is where **observability** comes in. Observability is not just about monitoring; it is about **understanding** the behavior of a system in real time. For LLMs, observability means having the ability to track requests end-to-end, measure performance across all layers, and create feedback loops to continuously improve the model's behavior.\n",
      "\n",
      "In this blog post, we will explore the concept of observability in the context of LLM systems. We will break down its key componentsâ€”tracing, metrics, feedback loops, and content safetyâ€”and discuss how they contribute to building transparent, reliable, and ethical AI systems. We will also examine common failure patterns in LLM systems and how observability can help address them.\n",
      "\n",
      "By the end of this post, you will understand why observability is not just a nice-to-haveâ€”it is essential for the future of AI.\n",
      "\n",
      "---\n",
      "\n",
      "## Understanding Observability in LLM Systems\n",
      "\n",
      "### What is Observability?\n",
      "\n",
      "Observability is the ability to understand the internal state of a system based on its external outputs. In the context of LLM systems, observability goes beyond traditional monitoring. It involves **tracking the flow of requests through the model**, **measuring performance at every layer**, and **analyzing the model's behavior in real time**.\n",
      "\n",
      "Unlike monitoring, which is reactive and focuses on predefined metrics, observability is **proactive and holistic**. It provides a **comprehensive view of the system**, enabling developers to not only detect issues but also understand why they are happening.\n",
      "\n",
      "For example, while monitoring might tell you that a model is returning incorrect answers, observability would tell you **why** the model is generating those answersâ€”whether it's due to a faulty prompt, a data bias, or a misalignment in the training data.\n",
      "\n",
      "### The Observability Stack for LLMs\n",
      "\n",
      "An effective observability strategy for LLM systems consists of several key components. These components work together to provide a complete picture of the model's behavior and performance. Let's explore each of them:\n",
      "\n",
      "#### 1. Tracing\n",
      "\n",
      "**Tracing** is the process of tracking a request through the entire system, from the initial user input to the final output. In LLM systems, tracing is especially important because it allows developers to understand how the model processes inputs, interacts with external tools, and generates outputs.\n",
      "\n",
      "For example, consider an application that uses an LLM to answer customer questions. The request might start with a user query, then pass through a database lookup, an API call, and finally the LLM itself. Tracing would allow developers to see the entire journey of the request, including any delays or errors that occurred at each step.\n",
      "\n",
      "Tools like **LangSmith** and **W&B Weave** provide end-to-end tracing capabilities, allowing developers to visualize the flow of requests and identify performance bottlenecks.\n",
      "\n",
      "#### 2. Metrics\n",
      "\n",
      "**Metrics** are quantitative measures of system performance and behavior. In the context of LLM systems, metrics can include:\n",
      "\n",
      "- **Response latency**: How long it takes the model to generate a response.\n",
      "- **Token usage**: The number of tokens processed by the model.\n",
      "- **Error rates**: The percentage of requests that result in errors.\n",
      "- **Throughput**: The number of requests handled per second.\n",
      "- **Resource usage**: CPU, memory, and GPU usage.\n",
      "\n",
      "These metrics provide valuable insights into the performance of the model and help developers identify issues such as latency spikes, resource exhaustion, or inefficient token usage.\n",
      "\n",
      "For instance, if a model starts to take longer than expected to generate responses, a developer might use metrics to determine whether the issue is due to a slow API call, a misconfigured model, or an overload of incoming requests.\n",
      "\n",
      "#### 3. Feedback Loops\n",
      "\n",
      "**Feedback loops** are mechanisms that allow the model to learn from its own behavior. In the context of LLM systems, feedback loops involve **collecting data on model performance** and using it to **improve the model over time**.\n",
      "\n",
      "For example, if a model generates incorrect answers, developers can use feedback loops to **retrain the model on the incorrect outputs**, helping it to avoid making the same mistakes in the future. This process is often referred to as **model fine-tuning** or **reinforcement learning from human feedback (RLHF)**.\n",
      "\n",
      "Tools like **W&B Weave** and **LangSmith** provide features that enable developers to collect and analyze feedback data, making it easier to iterate on model improvements.\n",
      "\n",
      "#### 4. Content Safety and Compliance\n",
      "\n",
      "As LLMs become more integrated into production applications, **content safety and compliance** have become a major concern. These systems must ensure that the model's outputs are **accurate, safe, and aligned with ethical and legal standards**.\n",
      "\n",
      "Observability plays a crucial role in addressing these concerns. By **monitoring the model's outputs in real time**, developers can detect and flag potentially harmful or unethical content. This includes identifying **hallucinations**, **bias**, **profanity**, and **inappropriate content**.\n",
      "\n",
      "For example, a healthcare application using an LLM to generate patient summaries must ensure that the model does not disclose sensitive information or make false claims. Observability tools can help detect such issues by **scanning model outputs for PII (Personally Identifiable Information)** or **violations of ethical guidelines**.\n",
      "\n",
      "In regulated industries, **observability also means maintaining an audit trail**. This ensures that if there is ever a question or incident, there is a record to review. Features like **PII redaction** and **access control** are essential for maintaining compliance in such environments.\n",
      "\n",
      "---\n",
      "\n",
      "## The Role of Observability in AI Ethics and Trust\n",
      "\n",
      "### Building Trust Through Transparency\n",
      "\n",
      "Trust is a fundamental component of any AI system. For users, developers, and stakeholders, trust is built through **transparency, reliability, and accountability**. Observability plays a crucial role in building trust by providing **visibility into the model's behavior**.\n",
      "\n",
      "When users know that an AI system is **transparent and accountable**, they are more likely to trust its outputs. This is especially important in high-stakes applications such as **healthcare, finance, and legal services**, where the consequences of incorrect outputs can be severe.\n",
      "\n",
      "Observability also helps build **trust among developers and data scientists**. By providing **real-time insights into model behavior**, observability enables developers to **debug issues more effectively** and **improve the model's performance over time**.\n",
      "\n",
      "### Ensuring Ethical AI\n",
      "\n",
      "Ethical AI is not just about avoiding harm; it's also about **ensuring that AI systems are fair, just, and aligned with societal values**. Observability supports ethical AI by providing **insights into model behavior**, **detecting biases**, and **ensuring compliance with ethical guidelines**.\n",
      "\n",
      "For example, if an LLM is used in a hiring application, it must be **free from biases that could disadvantage certain groups**. Observability tools can help detect such biases by **analyzing the model's outputs for fairness** and **flagging any discriminatory patterns**.\n",
      "\n",
      "In addition, observability helps ensure that **AI systems are aligned with ethical guidelines**. For instance, if an LLM is used to generate content for a news website, it must be **free from misinformation and bias**. Observability tools can help detect such issues by **scanning model outputs for factual accuracy** and **flagging any potential misinformation**.\n",
      "\n",
      "---\n",
      "\n",
      "## Common Failure Patterns in LLM Systems\n",
      "\n",
      "### Hallucinations\n",
      "\n",
      "One of the most common failure patterns in LLM systems is **hallucination**, where the model generates **false or made-up information**. This can be a significant issue, especially in applications where **accuracy is critical**.\n",
      "\n",
      "For example, an LLM used in a customer support application might generate **incorrect information about product features**, leading to **confusion and dissatisfaction** among users. Observability tools can help detect hallucinations by **monitoring model outputs** and **flagging any inconsistencies**.\n",
      "\n",
      "### Performance Bottlenecks\n",
      "\n",
      "As LLMs scale in complexity and usage, **performance bottlenecks** can emerge. These bottlenecks can be due to a variety of factors, including **slow API calls**, **inefficient token usage**, or **resource exhaustion**.\n",
      "\n",
      "Observability tools can help identify these bottlenecks by **tracking performance metrics** and **analyzing the flow of requests**. For example, if a model starts to take longer than expected to generate responses, a developer might use observability tools to **identify the slow API call** or **optimize token usage**.\n",
      "\n",
      "### Cost Overruns\n",
      "\n",
      "Many LLM services charge based on **token usage or compute time**, making **cost overruns** a significant concern. Without observability, it is difficult to **track and optimize costs**.\n",
      "\n",
      "Observability tools can help prevent cost overruns by **tracking token usage in real time** and **identifying any excessive usage**. For example, if a model is generating **long or unnecessary prompts**, observability tools can **flag these prompts** and **suggest optimizations**.\n",
      "\n",
      "---\n",
      "\n",
      "## The Future of Observability in AI\n",
      "\n",
      "As LLMs continue to evolve and become more integrated into production systems, **observability will play an increasingly important role** in building **transparent, reliable, and ethical AI**.\n",
      "\n",
      "Tools like **W&B Weave**, **LangSmith**, and **Lunary** are at the forefront of this movement, providing **comprehensive observability solutions** for LLM systems. These tools not only help developers **monitor and debug their models** but also enable them to **improve model performance over time**.\n",
      "\n",
      "In the future, we can expect to see **more advanced observability tools** that provide **even deeper insights into model behavior**, **automated feedback loops**, and **real-time ethical compliance checks**. These tools will be essential for **building AI systems that are not only powerful but also trustworthy**.\n",
      "\n",
      "---\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "In conclusion, **observability is not just a technical necessityâ€”it is a strategic imperative** for the future of AI. As LLMs become more complex and widely used, **the need for transparency and accountability has never been greater**.\n",
      "\n",
      "By adopting an **observability-first approach**, organizations can **gain real-time insights into model behavior**, **detect and fix issues quickly**, and **ensure that their AI systems are safe, reliable, and ethical**.\n",
      "\n",
      "In the next section, we will explore **practical examples of observability in action**, including **how to implement observability in your own LLM projects** and **best practices for building observability-first AI systems**. Stay tuned for more insights on this critical topic.\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m301s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;33mğŸ§  Thinking\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mreview\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m31.\u001b[0m\u001b[2m051s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m31.\u001b[0m\u001b[2m052s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mreview\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;32mFinal response:\u001b[0m\n",
      "# Review of the Blog Post: \"Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\"\n",
      "\n",
      "---\n",
      "\n",
      "## âœ… Strengths\n",
      "\n",
      "- **Clear structure**: The blog post is well-organized with logical sections and a clear progression from introduction to conclusion.\n",
      "- **Relevant content**: It effectively covers the core aspects of observability in LLM systems, including tracing, metrics, feedback loops, and content safety.\n",
      "- **Practical tone**: The tone is practical and slightly opinionated, as requested, making it accessible for intermediate ML engineers.\n",
      "- **Use of examples**: The post uses concrete examples (e.g., hallucinations, performance bottlenecks, cost overruns) to illustrate key points.\n",
      "- **Actionable insights**: The post provides actionable insights for developers, such as using tools like LangSmith, W&B Weave, and Lunary.\n",
      "- **Alignment with query**: The content thoroughly addresses the importance of observability in LLM systems and covers all requested components (tracing, metrics, feedback loops, failure patterns).\n",
      "\n",
      "---\n",
      "\n",
      "## ğŸš¨ Issues and Suggestions\n",
      "\n",
      "### 1. **Factual Inaccuracies and Missing Explanations**\n",
      "\n",
      "- **Tool Mentioned Without Context**: The post mentions tools like **LangSmith**, **W&B Weave**, and **Lunary**, but it doesnâ€™t explain what they are or how they are used in the context of LLM observability. This could confuse readers who are unfamiliar with these tools.  \n",
      "  **Suggestion**: Add brief descriptions of each tool and its role in LLM observability, or provide links to their documentation for further reading.\n",
      "\n",
      "- **Overgeneralization of Observability**: The post uses the term \"observability\" broadly, but it doesnâ€™t clearly differentiate between **observability**, **monitoring**, and **debugging**. This can lead to confusion.  \n",
      "  **Suggestion**: Clarify the distinction between these concepts, especially in the section on \"LLM Observability vs. LLM Monitoring.\"\n",
      "\n",
      "- **Limited Discussion on Feedback Loops**: While the post mentions feedback loops, it doesnâ€™t go into detail about how they are implemented or their impact on model behavior.  \n",
      "  **Suggestion**: Expand on the concept of feedback loops, including examples like **reinforcement learning from human feedback (RLHF)** and **active learning**.\n",
      "\n",
      "- **Ambiguity Around \"Common Failure Patterns\"**: The post lists failure patterns (e.g., hallucinations, performance bottlenecks, cost overruns) but doesnâ€™t provide enough depth on how observability helps detect or mitigate these issues.  \n",
      "  **Suggestion**: Include specific examples of how observability tools detect and address these failure patterns (e.g., how a tool identifies a hallucination and triggers a model retraining).\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Stylistic and Clarity Issues**\n",
      "\n",
      "- **Repetition of Terms**: The term \"observability\" is used repeatedly, which can make the post feel redundant.  \n",
      "  **Suggestion**: Vary the language to avoid repetition. For example, use synonyms like \"visibility,\" \"diagnostic insights,\" or \"behavioral analysis.\"\n",
      "\n",
      "- **Unclear Transition Between Sections**: The transition from the section on \"Observability Stack for LLMs\" to \"The Role of Observability in AI Ethics and Trust\" is abrupt.  \n",
      "  **Suggestion**: Add a brief paragraph or sentence that connects these sections, explaining how observability supports both technical and ethical aspects of AI.\n",
      "\n",
      "- **Lack of Visual Aids**: The post is text-heavy and lacks visual aids such as diagrams or charts that could help explain complex concepts like tracing or feedback loops.  \n",
      "  **Suggestion**: Suggest including visual aids (e.g., flowcharts of a request lifecycle, graphs of performance metrics) in future versions of the post.\n",
      "\n",
      "- **Some Sentences Are Too Long**: Some sentences are long and complex, making them difficult to parse.  \n",
      "  **Suggestion**: Break up long sentences into shorter ones for better readability. For example:\n",
      "  > \"While monitoring might tell you that a model is returning incorrect answers, observability would tell you why the model is generating those answersâ€”whether it's due to a faulty prompt, a data bias, or a misalignment in the training data.\"\n",
      "  â†’\n",
      "  > \"While monitoring might tell you that a model is returning incorrect answers, observability goes further. It tells you why the model is generating those answers. The cause could be a faulty prompt, data bias, or a misalignment in the training data.\"\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Unclarified Concepts**\n",
      "\n",
      "- **\"Feedback Loops\"**: The term is used without a clear definition. The post mentions that feedback loops involve collecting data on model performance and using it to improve the model, but it doesnâ€™t explain how this process works in practice.  \n",
      "  **Suggestion**: Define \"feedback loops\" more clearly, perhaps with an example such as:\n",
      "  > \"A feedback loop in the context of LLMs involves collecting data on model performance (e.g., incorrect outputs, bias) and using that data to retrain or fine-tune the model. This process is often referred to as reinforcement learning from human feedback (RLHF).\"\n",
      "\n",
      "- **\"Content Safety and Compliance\"**: The post touches on content safety and compliance but doesnâ€™t provide enough detail on how observability tools enforce these standards.  \n",
      "  **Suggestion**: Expand on the role of observability in content safety, including examples of how tools detect and flag problematic content (e.g., profanity, bias, hallucinations).\n",
      "\n",
      "---\n",
      "\n",
      "## âœ… Summary of Actionable Edits\n",
      "\n",
      "| Issue | Suggestion |\n",
      "|------|------------|\n",
      "| Tool descriptions are too vague | Add brief descriptions of tools like LangSmith, W&B Weave, and Lunary |\n",
      "| Overgeneralization of observability | Clarify the difference between observability, monitoring, and debugging |\n",
      "| Limited discussion on feedback loops | Expand on how feedback loops are implemented and their impact |\n",
      "| Ambiguity around failure patterns | Provide specific examples of how observability detects and mitigates failure patterns |\n",
      "| Repetition of terms | Vary the language to avoid repetition |\n",
      "| Unclear transitions between sections | Add connecting sentences between sections |\n",
      "| Lack of visual aids | Suggest including diagrams or charts for better clarity |\n",
      "| Long sentences | Break up long sentences for better readability |\n",
      "| Unclarified concepts | Define \"feedback loops\" and \"content safety\" more clearly |\n",
      "\n",
      "---\n",
      "\n",
      "## âœ… Final Assessment\n",
      "\n",
      "The blog post is well-written, informative, and aligned with the original query. It provides a clear argument for the importance of observability in LLM systems and covers the key components (tracing, metrics, feedback loops, content safety). However, there are opportunities for improvement in terms of clarity, structure, and depth of explanation. With the suggested edits, the post can be made even more effective for its target audience of intermediate ML engineers.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:16:32\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node research output to exports/research_20251211_211441.json\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:16:32\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node outline output to exports/outline_20251211_211451.md\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:16:32\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node draft output to exports/draft_20251211_211505.md\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-11 21:16:32\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node review output to exports/review_20251211_211601.md\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "from neurosurfer.agents.graph import GraphAgent, ManagerConfig\n",
    "\n",
    "graph_agent = GraphAgent(\n",
    "    llm=LLM,\n",
    "    graph_yaml=\"blog_workflow.yml\",\n",
    "    toolkit=toolkit,\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.3,\n",
    "        max_new_tokens=4096,\n",
    "    ),\n",
    "    manager_llm=LLM,\n",
    "    log_traces=True\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "# graph_inputs = {\n",
    "#     \"topic_title\": \"The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models\",\n",
    "#     \"query\": \"Compose a 1000-1500 word blog on why tool-routing layers matter more than scaling LLM size, covering practical design patterns, examples, and tradeoffs.\",\n",
    "#     \"audience\": \"Intermediate ML engineers\",\n",
    "#     \"tone\": \"Practical and slightly opinionated\",\n",
    "# }\n",
    "\n",
    "graph_inputs = {\n",
    "    \"topic_title\": \"Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\",\n",
    "    \"query\": \"Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\",\n",
    "    \"audience\": \"Intermediate ML engineers\",\n",
    "    \"tone\": \"Practical and slightly opinionated\",\n",
    "}\n",
    "\n",
    "results = graph_agent.run(inputs=graph_inputs)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1205b51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': {'name': 'blog_workflow',\n",
       "  'description': 'Example multi-agent workflow for writing and reviewing a technical blog using multiple specialized nodes (each node uses an Agent under the hood).\\n',\n",
       "  'inputs': [{'name': 'topic_title',\n",
       "    'type': 'string',\n",
       "    'required': True,\n",
       "    'description': None},\n",
       "   {'name': 'query', 'type': 'string', 'required': True, 'description': None},\n",
       "   {'name': 'audience',\n",
       "    'type': 'string',\n",
       "    'required': True,\n",
       "    'description': None},\n",
       "   {'name': 'tone', 'type': 'string', 'required': True, 'description': None}],\n",
       "  'nodes': [{'id': 'research',\n",
       "    'description': None,\n",
       "    'kind': 'base',\n",
       "    'purpose': 'Perform focused research on the requested topic titled {topic_title}.',\n",
       "    'goal': 'Collect key facts, terminology, and references that are directly useful for writing a technical blog post.',\n",
       "    'expected_result': \"A compact, structured summary with sections for 'key_points', 'sources', and 'risks_or_caveats'.\",\n",
       "    'tools': ['web_search'],\n",
       "    'depends_on': [],\n",
       "    'mode': <NodeMode.AUTO: 'auto'>,\n",
       "    'output_schema': None,\n",
       "    'model': None,\n",
       "    'policy': None,\n",
       "    'export': True,\n",
       "    'export_path': None},\n",
       "   {'id': 'outline',\n",
       "    'description': None,\n",
       "    'kind': 'base',\n",
       "    'purpose': 'Design a clear structure for the article.',\n",
       "    'goal': 'Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.',\n",
       "    'expected_result': 'A title, a detailed description, and an ordered list of sections with headings and bullet points.',\n",
       "    'tools': [],\n",
       "    'depends_on': ['research'],\n",
       "    'mode': <NodeMode.STRUCTURED: 'structured'>,\n",
       "    'output_schema': None,\n",
       "    'model': None,\n",
       "    'policy': None,\n",
       "    'export': True,\n",
       "    'export_path': None},\n",
       "   {'id': 'draft',\n",
       "    'description': None,\n",
       "    'kind': 'base',\n",
       "    'purpose': 'Write the first full draft of the article of about 3000 words including every detail.',\n",
       "    'goal': 'Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n',\n",
       "    'expected_result': 'A complete draft in markdown, including title, headings, and paragraphs.',\n",
       "    'tools': [],\n",
       "    'depends_on': ['outline', 'research'],\n",
       "    'mode': <NodeMode.TEXT: 'text'>,\n",
       "    'output_schema': None,\n",
       "    'model': None,\n",
       "    'policy': {'max_new_tokens': 16000,\n",
       "     'temperature': 0.7,\n",
       "     'retries': None,\n",
       "     'timeout_s': None,\n",
       "     'allow_input_pruning': None,\n",
       "     'repair_with_llm': True,\n",
       "     'strict_tool_call': None,\n",
       "     'strict_json': None,\n",
       "     'max_json_repair_attempts': None,\n",
       "     'skip_special_tokens': None,\n",
       "     'return_stream_by_default': None,\n",
       "     'log_internal_thoughts': None},\n",
       "    'export': True,\n",
       "    'export_path': None},\n",
       "   {'id': 'review',\n",
       "    'description': None,\n",
       "    'kind': 'base',\n",
       "    'purpose': 'Perform technical and editorial review of the draft.',\n",
       "    'goal': 'Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n',\n",
       "    'expected_result': 'A structured review with strengths, issues, and concrete suggestions.',\n",
       "    'tools': [],\n",
       "    'depends_on': ['draft', 'research'],\n",
       "    'mode': <NodeMode.STRUCTURED: 'structured'>,\n",
       "    'output_schema': None,\n",
       "    'model': None,\n",
       "    'policy': {'max_new_tokens': 16000,\n",
       "     'temperature': 0.7,\n",
       "     'retries': None,\n",
       "     'timeout_s': None,\n",
       "     'allow_input_pruning': None,\n",
       "     'repair_with_llm': True,\n",
       "     'strict_tool_call': None,\n",
       "     'strict_json': None,\n",
       "     'max_json_repair_attempts': None,\n",
       "     'skip_special_tokens': None,\n",
       "     'return_stream_by_default': None,\n",
       "     'log_internal_thoughts': None},\n",
       "    'export': True,\n",
       "    'export_path': None}],\n",
       "  'outputs': ['draft', 'review']},\n",
       " 'nodes': {'research': {'node_id': 'research',\n",
       "   'mode': <NodeMode.AUTO: 'auto'>,\n",
       "   'raw_output': {'query': 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.',\n",
       "    'summary': \"Top 3 results out of ~113 results for: 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.'\\n1. LLM observability tools: Monitoring, debugging, and ... â€” https://medium.com/online-inference/llm-observability-tools-monitoring-debugging-and-improving-ai-systems-5af769796266\\n2. LLM Observability Explained: Prevent Hallucinations, ... â€” https://www.splunk.com/en_us/blog/learn/llm-observability.html\\n3. What Is LLM Observability? Use Cases and Best Practices â€” https://www.tredence.com/blog/llm-observability\",\n",
       "    'provider': 'serpapi',\n",
       "    'elapsed_ms': 6055,\n",
       "    'rag_content': 'Source: de17dd0dd7eabff1:cc35f490\\nLLM observability tools: Monitoring, debugging, and improving AI systems Dave Davies 24 min read Â· Aug 22, 2025 -- Listen Share LLM observability is crucial for maintaining the operational health of applications powered by large language models. As AI systems become more complex and widely deployed, having visibility into their behavior is increasingly important. Observability tools provide comprehensive insight into all layers of an LLM-powered application, helping teams monitor performance, debug issues, and ensure outputs remain safe and reliable. Press enter or click to view image in full size By capturing everything from system metrics to model inputs and outputs, ... anomalies. This gives engineers actionable insights to fix inaccuracies, optimize performance, and uphold safety standards. In short, LLM observability creates a feedback loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to d\\n\\n---\\n\\nSource: 09ad15b0683646b8:cc35f490\\nck loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to distinguish observability from monitoring in the context of LLM applications. LLM monitoring typically focuses on the â€œwhatâ€ â€” it tracks key performance metrics and system health indicators to ensure the service is up and responsive. For example, monitoring will measure metrics such as API response time, error rates, request throughput, and token usage counts. If something goes ... wrong; observability helps you understand exactly what happened inside the system and how to fix it. Both are necessary â€” monitoring provides early warnings, while observability provides deep diagnosis â€” but observability offers the comprehensive visibility that LLM applications especially need. Challenges addressed by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability too\\n\\n---\\n\\nSource: a11a9e62cab8284b:cc35f490\\nt overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without ... observability solutions To solve the challenges above, an effective LLM observability solution provides several key capabilities. At the core is real-time performance monitoring across the entire system. This means the tool tracks metrics such as response latency, throughput of requests, error rates, and resource usage (CPU, memory, GPU, or API tokens) in real time. With these insights, teams can immediately spot performance degradation â€” for example, if the average response time of the model starts creeping up or if the error rate exceeds a threshold. Real-time monitoring ensures that any latency spikes, timeouts, or bottlenecks in the LLM or its ... tools integrate checks for content safety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content mo\\n\\n---\\n\\nSource: 6b08b29bc2b9891d:cc35f490\\nd by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability tools are designed to address these issues. One major problem is hallucinations â€” when an LLM generates answers that sound plausible but are factually incorrect or completely made-up. For example, an LLM might confidently provide a wrong ... external API call holding things up? LLM observability ties together data from all components, so teams can pinpoint if a particular step (like a database search for context or a third-party API call) is causing the delay. Similarly, failures or errors in a pipeline can be tricky to reproduce given the complexity of LLM systems. Observability tools trace each step of a request, making it easier to debug when something goes wrong in a multi-step process. Cost overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without\\n\\n---\\n\\nSource: 724c404f6a885694:cc35f490\\nsafety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content moderation APIs. A good observability platform might, for example, automatically tag any response that seems to contain personally identifiable information or that violates certain ethical guidelines. In regulated industries, observability also means keeping an audit trail â€” the tool should log all prompts and responses securely so that if thereâ€™s ever a question or incident, thereâ€™s a record to review. Features like PII redaction (masking sensitive user data in logs) and access control become ... LLM observability tools As the demand for LLM observability has grown, a number of tools and platforms have emerged to help developers monitor and debug their language model applications. Each tool has its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this sp\\n\\n---\\n\\nSource: 06f031e91c9c0236:cc35f490\\nheir applications in just a few lines of code and immediately gain end-to-end visibility and confidence in their modelâ€™s behavior. The tutorial illustrated how easy it is to get started with Weave and how it can be leveraged for tasks ranging from real-time monitoring to quality assurance and ethical compliance. Looking ahead, LLM observability tools will likely ... know they can catch mistakes and iterate quickly. Tools like W&B Weave are at the forefront of this effort, providing the means to monitor, debug, and improve LLM applications in one unified environment. By adopting LLM observability practices now, developers and organizations set themselves up for success â€” ensuring that their AI systems remain performant, trustworthy, and aligned with user needs as both the models and usage grow. As these observability tools evolve, they will undoubtedly play a central role in the future of AI deployments, helping us harness the full potential of LLMs while keeping a watchful eye on\\n\\n---\\n\\nSource: 9758ab006e75cff3:cc35f490\\n Weave, instrumented our LLM call with one line ( @weave.op ), ran the application to log data, optionally added an evaluation, and then ... bottlenecks in your LLM application. Suppose your app has higher-than-desired latency; by looking at traces, you might discover that a database lookup or a particular model call is the slow part. With that insight, you could try caching results, using a smaller model for that step, or otherwise improving the architecture. Likewise, Weaveâ€™s token usage tracking can show if certain prompts are excessively long (costly) â€” prompting you to optimize prompt formats to reduce token counts. Over time, you can use Weave metrics to verify that optimizations are effective (e.g., see average latency drop after a change, or a reduction ... when you have a robust observability tool in place. Continuous evaluation and model improvement: You can use Weave not just for monitoring but for ongoing evaluation even after deployment. Letâ€™s say you regularly update your\\n\\n---\\n\\nSource: d7c061743dc2e1ee:cc35f490\\n on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and compliance features) gives confidence to companies that need to monitor LLMs in production while meeting security requirements. In summary, W&B Weave is a preferred observability tool because it combines comprehensive tracing, real-time performance monitoring, automated output evaluation, and an intuitive UI in one platform. It effectively bridges the gap between model development ... enter your API key Once installed and authenticated, initialize Weave in your script or notebook by calling weave.init() at the start of your program. This sets up a new Weave project where all your logs and traces will be stored. For example: import weave # Initialize a Weave project (give a name for this observability run) weave.init(project=\"llm-observability-demo\") After this initialization, Weave is ready to capture data. It will associate all logs with the pro\\n\\n---\\n\\nSource: 2d3c24ba61c5ba18:cc35f490\\nas its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this space include Lunary, LangSmith, and W&B Weave, among others. Lunary Lunary is an open-source platform that provides analytics and tracing for LLM-powered apps. Itâ€™s designed to be model-agnostic, meaning it can work with any LLM provider or architecture. Lunary focuses on ... and intermediate actions (like calls to tools or external APIs). This provides end-to-end tracing for chain-of-thought style applications. LangSmith also emphasizes prompt evaluation and testing. It allows developers to systematically evaluate their prompts and model outputs by using datasets of queries and expected answers. In the LangSmith dashboard, you can see how often your modelâ€™s responses match the expected results or where it might be failing. It supports scoring of outputs for accuracy, completeness, or custom metrics you define. Additionally, LangSmith prov\\n\\n---\\n\\nSource: e5ee1e1a6d3f0816:cc35f490\\nthen to an LLM, and then into some post-processing, ... means W&B Weave not only tells you that an answer was given, but also gives an indication of whether that answer was good or potentially problematic â€” all in real time. Few other observability tools have this level of integrated quality checking. Seamless integration and agnostic support are also key features of W&B Weave. It is designed to be framework-agnostic and model-agnostic: whether youâ€™re using OpenAIâ€™s GPT-4 via API, an open-source model on Hugging Face, or a LangChain application, Weave can plug in. The tool provides simple SDK methods and decorators to instrument your code. For instance, by adding a ... in a W&B report format) to communicate your findings. The collaborative features (permissions, team projects, comments) make it a strong choice for enterprise teams working on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and complian'},\n",
       "   'structured_output': None,\n",
       "   'tool_call_output': {'selected_tool': 'web_search',\n",
       "    'inputs': {'query': 'Stop Treating LMs as Black Boxes: The Case for Observability-First AI Systems',\n",
       "     'hl': 'en'},\n",
       "    'returns': {'query': 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.',\n",
       "     'summary': \"Top 3 results out of ~113 results for: 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.'\\n1. LLM observability tools: Monitoring, debugging, and ... â€” https://medium.com/online-inference/llm-observability-tools-monitoring-debugging-and-improving-ai-systems-5af769796266\\n2. LLM Observability Explained: Prevent Hallucinations, ... â€” https://www.splunk.com/en_us/blog/learn/llm-observability.html\\n3. What Is LLM Observability? Use Cases and Best Practices â€” https://www.tredence.com/blog/llm-observability\",\n",
       "     'provider': 'serpapi',\n",
       "     'elapsed_ms': 6055,\n",
       "     'rag_content': 'Source: de17dd0dd7eabff1:cc35f490\\nLLM observability tools: Monitoring, debugging, and improving AI systems Dave Davies 24 min read Â· Aug 22, 2025 -- Listen Share LLM observability is crucial for maintaining the operational health of applications powered by large language models. As AI systems become more complex and widely deployed, having visibility into their behavior is increasingly important. Observability tools provide comprehensive insight into all layers of an LLM-powered application, helping teams monitor performance, debug issues, and ensure outputs remain safe and reliable. Press enter or click to view image in full size By capturing everything from system metrics to model inputs and outputs, ... anomalies. This gives engineers actionable insights to fix inaccuracies, optimize performance, and uphold safety standards. In short, LLM observability creates a feedback loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to d\\n\\n---\\n\\nSource: 09ad15b0683646b8:cc35f490\\nck loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to distinguish observability from monitoring in the context of LLM applications. LLM monitoring typically focuses on the â€œwhatâ€ â€” it tracks key performance metrics and system health indicators to ensure the service is up and responsive. For example, monitoring will measure metrics such as API response time, error rates, request throughput, and token usage counts. If something goes ... wrong; observability helps you understand exactly what happened inside the system and how to fix it. Both are necessary â€” monitoring provides early warnings, while observability provides deep diagnosis â€” but observability offers the comprehensive visibility that LLM applications especially need. Challenges addressed by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability too\\n\\n---\\n\\nSource: a11a9e62cab8284b:cc35f490\\nt overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without ... observability solutions To solve the challenges above, an effective LLM observability solution provides several key capabilities. At the core is real-time performance monitoring across the entire system. This means the tool tracks metrics such as response latency, throughput of requests, error rates, and resource usage (CPU, memory, GPU, or API tokens) in real time. With these insights, teams can immediately spot performance degradation â€” for example, if the average response time of the model starts creeping up or if the error rate exceeds a threshold. Real-time monitoring ensures that any latency spikes, timeouts, or bottlenecks in the LLM or its ... tools integrate checks for content safety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content mo\\n\\n---\\n\\nSource: 6b08b29bc2b9891d:cc35f490\\nd by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability tools are designed to address these issues. One major problem is hallucinations â€” when an LLM generates answers that sound plausible but are factually incorrect or completely made-up. For example, an LLM might confidently provide a wrong ... external API call holding things up? LLM observability ties together data from all components, so teams can pinpoint if a particular step (like a database search for context or a third-party API call) is causing the delay. Similarly, failures or errors in a pipeline can be tricky to reproduce given the complexity of LLM systems. Observability tools trace each step of a request, making it easier to debug when something goes wrong in a multi-step process. Cost overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without\\n\\n---\\n\\nSource: 724c404f6a885694:cc35f490\\nsafety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content moderation APIs. A good observability platform might, for example, automatically tag any response that seems to contain personally identifiable information or that violates certain ethical guidelines. In regulated industries, observability also means keeping an audit trail â€” the tool should log all prompts and responses securely so that if thereâ€™s ever a question or incident, thereâ€™s a record to review. Features like PII redaction (masking sensitive user data in logs) and access control become ... LLM observability tools As the demand for LLM observability has grown, a number of tools and platforms have emerged to help developers monitor and debug their language model applications. Each tool has its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this sp\\n\\n---\\n\\nSource: 06f031e91c9c0236:cc35f490\\nheir applications in just a few lines of code and immediately gain end-to-end visibility and confidence in their modelâ€™s behavior. The tutorial illustrated how easy it is to get started with Weave and how it can be leveraged for tasks ranging from real-time monitoring to quality assurance and ethical compliance. Looking ahead, LLM observability tools will likely ... know they can catch mistakes and iterate quickly. Tools like W&B Weave are at the forefront of this effort, providing the means to monitor, debug, and improve LLM applications in one unified environment. By adopting LLM observability practices now, developers and organizations set themselves up for success â€” ensuring that their AI systems remain performant, trustworthy, and aligned with user needs as both the models and usage grow. As these observability tools evolve, they will undoubtedly play a central role in the future of AI deployments, helping us harness the full potential of LLMs while keeping a watchful eye on\\n\\n---\\n\\nSource: 9758ab006e75cff3:cc35f490\\n Weave, instrumented our LLM call with one line ( @weave.op ), ran the application to log data, optionally added an evaluation, and then ... bottlenecks in your LLM application. Suppose your app has higher-than-desired latency; by looking at traces, you might discover that a database lookup or a particular model call is the slow part. With that insight, you could try caching results, using a smaller model for that step, or otherwise improving the architecture. Likewise, Weaveâ€™s token usage tracking can show if certain prompts are excessively long (costly) â€” prompting you to optimize prompt formats to reduce token counts. Over time, you can use Weave metrics to verify that optimizations are effective (e.g., see average latency drop after a change, or a reduction ... when you have a robust observability tool in place. Continuous evaluation and model improvement: You can use Weave not just for monitoring but for ongoing evaluation even after deployment. Letâ€™s say you regularly update your\\n\\n---\\n\\nSource: d7c061743dc2e1ee:cc35f490\\n on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and compliance features) gives confidence to companies that need to monitor LLMs in production while meeting security requirements. In summary, W&B Weave is a preferred observability tool because it combines comprehensive tracing, real-time performance monitoring, automated output evaluation, and an intuitive UI in one platform. It effectively bridges the gap between model development ... enter your API key Once installed and authenticated, initialize Weave in your script or notebook by calling weave.init() at the start of your program. This sets up a new Weave project where all your logs and traces will be stored. For example: import weave # Initialize a Weave project (give a name for this observability run) weave.init(project=\"llm-observability-demo\") After this initialization, Weave is ready to capture data. It will associate all logs with the pro\\n\\n---\\n\\nSource: 2d3c24ba61c5ba18:cc35f490\\nas its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this space include Lunary, LangSmith, and W&B Weave, among others. Lunary Lunary is an open-source platform that provides analytics and tracing for LLM-powered apps. Itâ€™s designed to be model-agnostic, meaning it can work with any LLM provider or architecture. Lunary focuses on ... and intermediate actions (like calls to tools or external APIs). This provides end-to-end tracing for chain-of-thought style applications. LangSmith also emphasizes prompt evaluation and testing. It allows developers to systematically evaluate their prompts and model outputs by using datasets of queries and expected answers. In the LangSmith dashboard, you can see how often your modelâ€™s responses match the expected results or where it might be failing. It supports scoring of outputs for accuracy, completeness, or custom metrics you define. Additionally, LangSmith prov\\n\\n---\\n\\nSource: e5ee1e1a6d3f0816:cc35f490\\nthen to an LLM, and then into some post-processing, ... means W&B Weave not only tells you that an answer was given, but also gives an indication of whether that answer was good or potentially problematic â€” all in real time. Few other observability tools have this level of integrated quality checking. Seamless integration and agnostic support are also key features of W&B Weave. It is designed to be framework-agnostic and model-agnostic: whether youâ€™re using OpenAIâ€™s GPT-4 via API, an open-source model on Hugging Face, or a LangChain application, Weave can plug in. The tool provides simple SDK methods and decorators to instrument your code. For instance, by adding a ... in a W&B report format) to communicate your findings. The collaborative features (permissions, team projects, comments) make it a strong choice for enterprise teams working on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and complian'},\n",
       "    'final': False,\n",
       "    'extras': {}},\n",
       "   'started_at': 1765473281.1212542,\n",
       "   'duration_ms': 7155,\n",
       "   'error': None,\n",
       "   'traces': {'steps': [{'step_id': 1,\n",
       "      'kind': 'agent',\n",
       "      'label': 'agent.run',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'research',\n",
       "      'started_at': 1765473281.1237457,\n",
       "      'duration_ms': 7151,\n",
       "      'inputs': {'agent_type': 'Agent',\n",
       "       'has_toolkit': True,\n",
       "       'structured': False,\n",
       "       'stream': False,\n",
       "       'strict_tool_call': False},\n",
       "      'outputs': {},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': []},\n",
       "     {'step_id': 2,\n",
       "      'kind': 'llm.call',\n",
       "      'label': 'agent.route_and_call.router_llm_call',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'research',\n",
       "      'started_at': 1765473281.1247797,\n",
       "      'duration_ms': 944,\n",
       "      'inputs': {'attempt': 1,\n",
       "       'strict_tool_call': False,\n",
       "       'system_prompt_len': 1316,\n",
       "       'user_prompt_len': 528,\n",
       "       'user_prompt': 'Perform focused research on the topic \"Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\". Collect key facts, terminology, and references that are directly useful for writing a technical blog post. Focus on observability layers, tracing, metrics, feedback loops, and common failure patterns in modern LLM systems. Use web search to gather relevant sources and ensure the information is up-to-date and credible. Organize the findings into sections for \\'key_points\\', \\'sources\\', and \\'risks_or_caveats\\'.',\n",
       "       'system_prompt': 'You are a stateless tool router. \\nYour task is to decide whether to call a tool or not, and respond with STRICT JSON.\\n\\nAlways respond with a single one-line valid JSON object:\\n{\"tool\": \"<tool_name>\", \"inputs\": {<param>: <value>}}\\n\\nRules:\\n- Choose at most ONE tool per request.\\n- If no tool fits the request or inputs are ambiguous, output:\\n  {\"tool\": \"none\", \"inputs\": {}}\\n- Use only explicit parameters defined by that tool. Do NOT invent or rename parameters.\\n- Include only required parameters unless an optional one is clearly implied.\\n- Do NOT produce natural language answers. Emit JSON only.\\n\\nTOOLS CATALOG:\\nAvailable tools:\\nTool Name: `web_search`\\nDescription: Search the web using a pluggable backend (e.g. SerpAPI). Optionally crawls the top results, extracts page content, and summarizes it with an LLM.\\nWhen to use: Use this tool when you need up-to-date information, external web content, or detailed summaries combining multiple sources. The tool can return raw results or a refined LLM summary.\\nTool Inputs:\\n- `query`: string (required) â€” The web search query.\\n- `hl`: string (optional) â€” Interface language (e.g. \\'en\\'). Defaults to \\'en\\'.\\nTool Return: object â€” JSON object with keys: `query`, `summary`, `results`, `provider`, `elapsed_ms`, and optionally `llm_summary` if summarization is enabled.\\n\\n\\n',\n",
       "       'temperature': 0.7,\n",
       "       'max_new_tokens': 512,\n",
       "       'stream': False},\n",
       "      'outputs': {'model_response': '{\"tool\": \"web_search\", \"inputs\": {\"query\": \"Stop Treating LMs as Black Boxes: The Case for Observability-First AI Systems\", \"hl\": \"en\"}}',\n",
       "       'model_response_len': 136},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': [{'ts': 1765473282.0682263,\n",
       "        'message': 'Selected tool: web_search',\n",
       "        'data': {},\n",
       "        'type': 'info'},\n",
       "       {'ts': 1765473282.0690644,\n",
       "        'message': \"Raw inputs: {'query': 'Stop Treating LMs as Black Boxes: The Case for Observability-First AI Systems', 'hl': 'en'}\",\n",
       "        'data': {},\n",
       "        'type': 'info'}]},\n",
       "     {'step_id': 3,\n",
       "      'kind': 'tool.execute',\n",
       "      'label': 'agent.route_and_call.tool_execute',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'research',\n",
       "      'started_at': 1765473282.070135,\n",
       "      'duration_ms': 6203,\n",
       "      'inputs': {'tool_name': 'web_search',\n",
       "       'payload': {'query': 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.',\n",
       "        'hl': 'en',\n",
       "        'dependencies': {},\n",
       "        'topic_title': 'Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems',\n",
       "        'audience': 'Intermediate ML engineers',\n",
       "        'tone': 'Practical and slightly opinionated'}},\n",
       "      'outputs': {'tool_return': {'query': 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.',\n",
       "        'summary': \"Top 3 results out of ~113 results for: 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.'\\n1. LLM observability tools: Monitoring, debugging, and ... â€” https://medium.com/online-inference/llm-observability-tools-monitoring-debugging-and-improving-ai-systems-5af769796266\\n2. LLM Observability Explained: Prevent Hallucinations, ... â€” https://www.splunk.com/en_us/blog/learn/llm-observability.html\\n3. What Is LLM Observability? Use Cases and Best Practices â€” https://www.tredence.com/blog/llm-observability\",\n",
       "        'provider': 'serpapi',\n",
       "        'elapsed_ms': 6055,\n",
       "        'rag_content': 'Source: de17dd0dd7eabff1:cc35f490\\nLLM observability tools: Monitoring, debugging, and improving AI systems Dave Davies 24 min read Â· Aug 22, 2025 -- Listen Share LLM observability is crucial for maintaining the operational health of applications powered by large language models. As AI systems become more complex and widely deployed, having visibility into their behavior is increasingly important. Observability tools provide comprehensive insight into all layers of an LLM-powered application, helping teams monitor performance, debug issues, and ensure outputs remain safe and reliable. Press enter or click to view image in full size By capturing everything from system metrics to model inputs and outputs, ... anomalies. This gives engineers actionable insights to fix inaccuracies, optimize performance, and uphold safety standards. In short, LLM observability creates a feedback loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to d\\n\\n---\\n\\nSource: 09ad15b0683646b8:cc35f490\\nck loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to distinguish observability from monitoring in the context of LLM applications. LLM monitoring typically focuses on the â€œwhatâ€ â€” it tracks key performance metrics and system health indicators to ensure the service is up and responsive. For example, monitoring will measure metrics such as API response time, error rates, request throughput, and token usage counts. If something goes ... wrong; observability helps you understand exactly what happened inside the system and how to fix it. Both are necessary â€” monitoring provides early warnings, while observability provides deep diagnosis â€” but observability offers the comprehensive visibility that LLM applications especially need. Challenges addressed by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability too\\n\\n---\\n\\nSource: a11a9e62cab8284b:cc35f490\\nt overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without ... observability solutions To solve the challenges above, an effective LLM observability solution provides several key capabilities. At the core is real-time performance monitoring across the entire system. This means the tool tracks metrics such as response latency, throughput of requests, error rates, and resource usage (CPU, memory, GPU, or API tokens) in real time. With these insights, teams can immediately spot performance degradation â€” for example, if the average response time of the model starts creeping up or if the error rate exceeds a threshold. Real-time monitoring ensures that any latency spikes, timeouts, or bottlenecks in the LLM or its ... tools integrate checks for content safety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content mo\\n\\n---\\n\\nSource: 6b08b29bc2b9891d:cc35f490\\nd by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability tools are designed to address these issues. One major problem is hallucinations â€” when an LLM generates answers that sound plausible but are factually incorrect or completely made-up. For example, an LLM might confidently provide a wrong ... external API call holding things up? LLM observability ties together data from all components, so teams can pinpoint if a particular step (like a database search for context or a third-party API call) is causing the delay. Similarly, failures or errors in a pipeline can be tricky to reproduce given the complexity of LLM systems. Observability tools trace each step of a request, making it easier to debug when something goes wrong in a multi-step process. Cost overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without\\n\\n---\\n\\nSource: 724c404f6a885694:cc35f490\\nsafety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content moderation APIs. A good observability platform might, for example, automatically tag any response that seems to contain personally identifiable information or that violates certain ethical guidelines. In regulated industries, observability also means keeping an audit trail â€” the tool should log all prompts and responses securely so that if thereâ€™s ever a question or incident, thereâ€™s a record to review. Features like PII redaction (masking sensitive user data in logs) and access control become ... LLM observability tools As the demand for LLM observability has grown, a number of tools and platforms have emerged to help developers monitor and debug their language model applications. Each tool has its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this sp\\n\\n---\\n\\nSource: 06f031e91c9c0236:cc35f490\\nheir applications in just a few lines of code and immediately gain end-to-end visibility and confidence in their modelâ€™s behavior. The tutorial illustrated how easy it is to get started with Weave and how it can be leveraged for tasks ranging from real-time monitoring to quality assurance and ethical compliance. Looking ahead, LLM observability tools will likely ... know they can catch mistakes and iterate quickly. Tools like W&B Weave are at the forefront of this effort, providing the means to monitor, debug, and improve LLM applications in one unified environment. By adopting LLM observability practices now, developers and organizations set themselves up for success â€” ensuring that their AI systems remain performant, trustworthy, and aligned with user needs as both the models and usage grow. As these observability tools evolve, they will undoubtedly play a central role in the future of AI deployments, helping us harness the full potential of LLMs while keeping a watchful eye on\\n\\n---\\n\\nSource: 9758ab006e75cff3:cc35f490\\n Weave, instrumented our LLM call with one line ( @weave.op ), ran the application to log data, optionally added an evaluation, and then ... bottlenecks in your LLM application. Suppose your app has higher-than-desired latency; by looking at traces, you might discover that a database lookup or a particular model call is the slow part. With that insight, you could try caching results, using a smaller model for that step, or otherwise improving the architecture. Likewise, Weaveâ€™s token usage tracking can show if certain prompts are excessively long (costly) â€” prompting you to optimize prompt formats to reduce token counts. Over time, you can use Weave metrics to verify that optimizations are effective (e.g., see average latency drop after a change, or a reduction ... when you have a robust observability tool in place. Continuous evaluation and model improvement: You can use Weave not just for monitoring but for ongoing evaluation even after deployment. Letâ€™s say you regularly update your\\n\\n---\\n\\nSource: d7c061743dc2e1ee:cc35f490\\n on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and compliance features) gives confidence to companies that need to monitor LLMs in production while meeting security requirements. In summary, W&B Weave is a preferred observability tool because it combines comprehensive tracing, real-time performance monitoring, automated output evaluation, and an intuitive UI in one platform. It effectively bridges the gap between model development ... enter your API key Once installed and authenticated, initialize Weave in your script or notebook by calling weave.init() at the start of your program. This sets up a new Weave project where all your logs and traces will be stored. For example: import weave # Initialize a Weave project (give a name for this observability run) weave.init(project=\"llm-observability-demo\") After this initialization, Weave is ready to capture data. It will associate all logs with the pro\\n\\n---\\n\\nSource: 2d3c24ba61c5ba18:cc35f490\\nas its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this space include Lunary, LangSmith, and W&B Weave, among others. Lunary Lunary is an open-source platform that provides analytics and tracing for LLM-powered apps. Itâ€™s designed to be model-agnostic, meaning it can work with any LLM provider or architecture. Lunary focuses on ... and intermediate actions (like calls to tools or external APIs). This provides end-to-end tracing for chain-of-thought style applications. LangSmith also emphasizes prompt evaluation and testing. It allows developers to systematically evaluate their prompts and model outputs by using datasets of queries and expected answers. In the LangSmith dashboard, you can see how often your modelâ€™s responses match the expected results or where it might be failing. It supports scoring of outputs for accuracy, completeness, or custom metrics you define. Additionally, LangSmith prov\\n\\n---\\n\\nSource: e5ee1e1a6d3f0816:cc35f490\\nthen to an LLM, and then into some post-processing, ... means W&B Weave not only tells you that an answer was given, but also gives an indication of whether that answer was good or potentially problematic â€” all in real time. Few other observability tools have this level of integrated quality checking. Seamless integration and agnostic support are also key features of W&B Weave. It is designed to be framework-agnostic and model-agnostic: whether youâ€™re using OpenAIâ€™s GPT-4 via API, an open-source model on Hugging Face, or a LangChain application, Weave can plug in. The tool provides simple SDK methods and decorators to instrument your code. For instance, by adding a ... in a W&B report format) to communicate your findings. The collaborative features (permissions, team projects, comments) make it a strong choice for enterprise teams working on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and complian'},\n",
       "       'extras': {}},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': [{'ts': 1765473288.2731433,\n",
       "        'message': \"Tool 'web_search' Tool Return: {'query': 'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LL...\",\n",
       "        'data': {},\n",
       "        'type': 'info'}]}],\n",
       "    'meta': {'agent_type': 'generic_agent',\n",
       "     'agent_config': {'allow_input_pruning': True,\n",
       "      'repair_with_llm': True,\n",
       "      'strict_tool_call': False,\n",
       "      'temperature': 0.7,\n",
       "      'max_new_tokens': 512,\n",
       "      'return_stream_by_default': False,\n",
       "      'retry': {'max_route_retries': 2,\n",
       "       'max_tool_retries': 1,\n",
       "       'backoff_sec': 0.7},\n",
       "      'strict_json': True,\n",
       "      'max_json_repair_attempts': 1},\n",
       "     'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit',\n",
       "     'toolkit': True,\n",
       "     'log_steps': True}}},\n",
       "  'outline': {'node_id': 'outline',\n",
       "   'mode': <NodeMode.STRUCTURED: 'structured'>,\n",
       "   'raw_output': '**Title:**  \\n*Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems*\\n\\n**Description:**  \\nThis blog post explores the critical need for observability in large language model (LLM) systems. As LLMs become more integrated into production applications, the lack of visibility into their internal workings has led to significant challenges, including hallucinations, performance bottlenecks, and compliance risks. By adopting an observability-first approach, organizations can gain real-time insights into model behavior, trace requests end-to-end, measure performance metrics, and create feedback loops for continuous improvement. This article outlines the key components of an observability-first strategy, discusses common failure patterns in LLM systems, and highlights the role of tools and best practices in building transparent, reliable, and ethical AI systems.\\n\\n---\\n\\n### **Outline of the Blog Post**\\n\\n#### **1. Introduction: The Rise of LLMs and the Black Box Problem**\\n- **Overview of LLMs and Their Growing Role**  \\n  - Explain the rapid adoption of LLMs across industries.  \\n  - Highlight their complexity and the challenges of deploying them at scale.  \\n\\n- **The Black Box Conundrum**  \\n  - Define the \"black box\" problem in LLMs.  \\n  - Discuss the limitations of traditional monitoring and debugging approaches.  \\n  - Introduce the concept of **observability** as a solution.  \\n\\n- **Why Observability Matters Now**  \\n  - Link the increasing complexity of LLM systems to the need for deeper visibility.  \\n  - Preview the key components of observability: tracing, metrics, feedback loops, and failure analysis.  \\n\\n---\\n\\n#### **2. Understanding Observability in LLM Systems**\\n- **What is Observability?**  \\n  - Define observability in the context of LLMs.  \\n  - Differentiate between **observability** and **monitoring**.  \\n  - Emphasize the importance of **comprehensive visibility** into model behavior.  \\n\\n- **The Observability Stack for LLMs**  \\n  - Break down the key elements of an observability layer:  \\n    - **Tracing**: Tracking requests through the system.  \\n    - **Metrics**: Measuring performance and resource usage.  \\n    - **Feedback Loops**: Using data to improve model behavior.  \\n    - **Content Safety and Compliance**: Ensuring ethical and legal standards.  \\n\\n- **The Role of Observability in AI Ethics and Trust**  \\n  - Discuss how observability supports transparency',\n",
       "   'structured_output': None,\n",
       "   'tool_call_output': None,\n",
       "   'started_at': 1765473291.4309845,\n",
       "   'duration_ms': 11311,\n",
       "   'error': None,\n",
       "   'traces': {'steps': [{'step_id': 1,\n",
       "      'kind': 'agent',\n",
       "      'label': 'agent.run',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'outline',\n",
       "      'started_at': 1765473291.431669,\n",
       "      'duration_ms': 11307,\n",
       "      'inputs': {'agent_type': 'Agent',\n",
       "       'has_toolkit': False,\n",
       "       'structured': False,\n",
       "       'stream': False,\n",
       "       'strict_tool_call': False},\n",
       "      'outputs': {},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': []},\n",
       "     {'step_id': 2,\n",
       "      'kind': 'llm.call',\n",
       "      'label': 'agent.free_text_call',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'outline',\n",
       "      'started_at': 1765473291.431949,\n",
       "      'duration_ms': 11305,\n",
       "      'inputs': {'system_prompt_len': 562,\n",
       "       'user_prompt_len': 11831,\n",
       "       'user_prompt': 'Based on the research summary provided, create a clear and logical outline for a 2000-2500 word blog post titled \"Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems.\" The outline should include a title, a detailed description, and an ordered list of sections with headings and bullet points. Focus on the importance of observability in LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\\n\\n# Context from dependency nodes:\\n## research\\n{\\'query\\': \\'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\\', \\'summary\\': \"Top 3 results out of ~113 results for: \\'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\\'\\\\n1. LLM observability tools: Monitoring, debugging, and ... â€” https://medium.com/online-inference/llm-observability-tools-monitoring-debugging-and-improving-ai-systems-5af769796266\\\\n2. LLM Observability Explained: Prevent Hallucinations, ... â€” https://www.splunk.com/en_us/blog/learn/llm-observability.html\\\\n3. What Is LLM Observability? Use Cases and Best Practices â€” https://www.tredence.com/blog/llm-observability\", \\'provider\\': \\'serpapi\\', \\'elapsed_ms\\': 6055, \\'rag_content\\': \\'Source: de17dd0dd7eabff1:cc35f490\\\\nLLM observability tools: Monitoring, debugging, and improving AI systems Dave Davies 24 min read Â· Aug 22, 2025 -- Listen Share LLM observability is crucial for maintaining the operational health of applications powered by large language models. As AI systems become more complex and widely deployed, having visibility into their behavior is increasingly important. Observability tools provide comprehensive insight into all layers of an LLM-powered application, helping teams monitor performance, debug issues, and ensure outputs remain safe and reliable. Press enter or click to view image in full size By capturing everything from system metrics to model inputs and outputs, ... anomalies. This gives engineers actionable insights to fix inaccuracies, optimize performance, and uphold safety standards. In short, LLM observability creates a feedback loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to d\\\\n\\\\n---\\\\n\\\\nSource: 09ad15b0683646b8:cc35f490\\\\nck loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to distinguish observability from monitoring in the context of LLM applications. LLM monitoring typically focuses on the â€œwhatâ€ â€” it tracks key performance metrics and system health indicators to ensure the service is up and responsive. For example, monitoring will measure metrics such as API response time, error rates, request throughput, and token usage counts. If something goes ... wrong; observability helps you understand exactly what happened inside the system and how to fix it. Both are necessary â€” monitoring provides early warnings, while observability provides deep diagnosis â€” but observability offers the comprehensive visibility that LLM applications especially need. Challenges addressed by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability too\\\\n\\\\n---\\\\n\\\\nSource: a11a9e62cab8284b:cc35f490\\\\nt overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without ... observability solutions To solve the challenges above, an effective LLM observability solution provides several key capabilities. At the core is real-time performance monitoring across the entire system. This means the tool tracks metrics such as response latency, throughput of requests, error rates, and resource usage (CPU, memory, GPU, or API tokens) in real time. With these insights, teams can immediately spot performance degradation â€” for example, if the average response time of the model starts creeping up or if the error rate exceeds a threshold. Real-time monitoring ensures that any latency spikes, timeouts, or bottlenecks in the LLM or its ... tools integrate checks for content safety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content mo\\\\n\\\\n---\\\\n\\\\nSource: 6b08b29bc2b9891d:cc35f490\\\\nd by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability tools are designed to address these issues. One major problem is hallucinations â€” when an LLM generates answers that sound plausible but are factually incorrect or completely made-up. For example, an LLM might confidently provide a wrong ... external API call holding things up? LLM observability ties together data from all components, so teams can pinpoint if a particular step (like a database search for context or a third-party API call) is causing the delay. Similarly, failures or errors in a pipeline can be tricky to reproduce given the complexity of LLM systems. Observability tools trace each step of a request, making it easier to debug when something goes wrong in a multi-step process. Cost overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without\\\\n\\\\n---\\\\n\\\\nSource: 724c404f6a885694:cc35f490\\\\nsafety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content moderation APIs. A good observability platform might, for example, automatically tag any response that seems to contain personally identifiable information or that violates certain ethical guidelines. In regulated industries, observability also means keeping an audit trail â€” the tool should log all prompts and responses securely so that if thereâ€™s ever a question or incident, thereâ€™s a record to review. Features like PII redaction (masking sensitive user data in logs) and access control become ... LLM observability tools As the demand for LLM observability has grown, a number of tools and platforms have emerged to help developers monitor and debug their language model applications. Each tool has its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this sp\\\\n\\\\n---\\\\n\\\\nSource: 06f031e91c9c0236:cc35f490\\\\nheir applications in just a few lines of code and immediately gain end-to-end visibility and confidence in their modelâ€™s behavior. The tutorial illustrated how easy it is to get started with Weave and how it can be leveraged for tasks ranging from real-time monitoring to quality assurance and ethical compliance. Looking ahead, LLM observability tools will likely ... know they can catch mistakes and iterate quickly. Tools like W&B Weave are at the forefront of this effort, providing the means to monitor, debug, and improve LLM applications in one unified environment. By adopting LLM observability practices now, developers and organizations set themselves up for success â€” ensuring that their AI systems remain performant, trustworthy, and aligned with user needs as both the models and usage grow. As these observability tools evolve, they will undoubtedly play a central role in the future of AI deployments, helping us harness the full potential of LLMs while keeping a watchful eye on\\\\n\\\\n---\\\\n\\\\nSource: 9758ab006e75cff3:cc35f490\\\\n Weave, instrumented our LLM call with one line ( @weave.op ), ran the application to log data, optionally added an evaluation, and then ... bottlenecks in your LLM application. Suppose your app has higher-than-desired latency; by looking at traces, you might discover that a database lookup or a particular model call is the slow part. With that insight, you could try caching results, using a smaller model for that step, or otherwise improving the architecture. Likewise, Weaveâ€™s token usage tracking can show if certain prompts are excessively long (costly) â€” prompting you to optimize prompt formats to reduce token counts. Over time, you can use Weave metrics to verify that optimizations are effective (e.g., see average latency drop after a change, or a reduction ... when you have a robust observability tool in place. Continuous evaluation and model improvement: You can use Weave not just for monitoring but for ongoing evaluation even after deployment. Letâ€™s say you regularly update your\\\\n\\\\n---\\\\n\\\\nSource: d7c061743dc2e1ee:cc35f490\\\\n on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and compliance features) gives confidence to companies that need to monitor LLMs in production while meeting security requirements. In summary, W&B Weave is a preferred observability tool because it combines comprehensive tracing, real-time performance monitoring, automated output evaluation, and an intuitive UI in one platform. It effectively bridges the gap between model development ... enter your API key Once installed and authenticated, initialize Weave in your script or notebook by calling weave.init() at the start of your program. This sets up a new Weave project where all your logs and traces will be stored. For example: import weave # Initialize a Weave project (give a name for this observability run) weave.init(project=\"llm-observability-demo\") After this initialization, Weave is ready to capture data. It will associate all logs with the pro\\\\n\\\\n---\\\\n\\\\nSource: 2d3c24ba61c5ba18:cc35f490\\\\nas its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this space include Lunary, LangSmith, and W&B Weave, among others. Lunary Lunary is an open-source platform that provides analytics and tracing for LLM-powered apps. Itâ€™s designed to be model-agnostic, meaning it can work with any LLM provider or architecture. Lunary focuses on ... and intermediate actions (like calls to tools or external APIs). This provides end-to-end tracing for chain-of-thought style applications. LangSmith also emphasizes prompt evaluation and testing. It allows developers to systematically evaluate their prompts and model outputs by using datasets of queries and expected answers. In the LangSmith dashboard, you can see how often your modelâ€™s responses match the expected results or where it might be failing. It supports scoring of outputs for accuracy, completeness, or custom metrics you define. Additionally, LangSmith prov\\\\n\\\\n---\\\\n\\\\nSource: e5ee1e1a6d3f0816:cc35f490\\\\nthen to an LLM, and then into some post-processing, ... means W&B Weave not only tells you that an answer was given, but also gives an indication of whether that answer was good or potentially problematic â€” all in real time. Few other observability tools have this level of integrated quality checking. Seamless integration and agnostic support are also key features of W&B Weave. It is designed to be framework-agnostic and model-agnostic: whether youâ€™re using OpenAIâ€™s GPT-4 via API, an open-source model on Hugging Face, or a LangChain application, Weave can plug in. The tool provides simple SDK methods and decorators to instrument your code. For instance, by adding a ... in a W&B report format) to communicate your findings. The collaborative features (permissions, team projects, comments) make it a strong choice for enterprise teams working on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and complian\\'}',\n",
       "       'system_prompt': 'You are a specialized agent in a larger workflow.\\n\\nYour role:\\n- PURPOSE: Design a clear structure for the article.\\n- GOAL: Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.\\n- EXPECTED_RESULT: A title, a detailed description, and an ordered list of sections with headings and bullet points.\\n\\nGeneral behaviour:\\n- Be precise and concise unless the task requires extended output.\\n- Use clear structure (headings/bullets) when helpful.\\n- If you are calling tools, interpret their outputs carefully and explain your reasoning.\\n',\n",
       "       'temperature': 0.7,\n",
       "       'max_new_tokens': 512,\n",
       "       'stream': False},\n",
       "      'outputs': {'output': '**Title:**  \\n*Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems*\\n\\n**Description:**  \\nThis blog post explores the critical need for observability in large language model (LLM) systems. As LLMs become more integrated into production applications, the lack of visibility into their internal workings has led to significant challenges, including hallucinations, performance bottlenecks, and compliance risks. By adopting an observability-first approach, organizations can gain real-time insights into model behavior, trace requests end-to-end, measure performance metrics, and create feedback loops for continuous improvement. This article outlines the key components of an observability-first strategy, discusses common failure patterns in LLM systems, and highlights the role of tools and best practices in building transparent, reliable, and ethical AI systems.\\n\\n---\\n\\n### **Outline of the Blog Post**\\n\\n#### **1. Introduction: The Rise of LLMs and the Black Box Problem**\\n- **Overview of LLMs and Their Growing Role**  \\n  - Explain the rapid adoption of LLMs across industries.  \\n  - Highlight their complexity and the challenges of deploying them at scale.  \\n\\n- **The Black Box Conundrum**  \\n  - Define the \"black box\" problem in LLMs.  \\n  - Discuss the limitations of traditional monitoring and debugging approaches.  \\n  - Introduce the concept of **observability** as a solution.  \\n\\n- **Why Observability Matters Now**  \\n  - Link the increasing complexity of LLM systems to the need for deeper visibility.  \\n  - Preview the key components of observability: tracing, metrics, feedback loops, and failure analysis.  \\n\\n---\\n\\n#### **2. Understanding Observability in LLM Systems**\\n- **What is Observability?**  \\n  - Define observability in the context of LLMs.  \\n  - Differentiate between **observability** and **monitoring**.  \\n  - Emphasize the importance of **comprehensive visibility** into model behavior.  \\n\\n- **The Observability Stack for LLMs**  \\n  - Break down the key elements of an observability layer:  \\n    - **Tracing**: Tracking requests through the system.  \\n    - **Metrics**: Measuring performance and resource usage.  \\n    - **Feedback Loops**: Using data to improve model behavior.  \\n    - **Content Safety and Compliance**: Ensuring ethical and legal standards.  \\n\\n- **The Role of Observability in AI Ethics and Trust**  \\n  - Discuss how observability supports transparency'},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': []}],\n",
       "    'meta': {'agent_type': 'generic_agent',\n",
       "     'agent_config': {'allow_input_pruning': True,\n",
       "      'repair_with_llm': True,\n",
       "      'strict_tool_call': False,\n",
       "      'temperature': 0.7,\n",
       "      'max_new_tokens': 512,\n",
       "      'return_stream_by_default': False,\n",
       "      'retry': {'max_route_retries': 2,\n",
       "       'max_tool_retries': 1,\n",
       "       'backoff_sec': 0.7},\n",
       "      'strict_json': True,\n",
       "      'max_json_repair_attempts': 1},\n",
       "     'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit',\n",
       "     'toolkit': False,\n",
       "     'log_steps': True}}},\n",
       "  'draft': {'node_id': 'draft',\n",
       "   'mode': <NodeMode.TEXT: 'text'>,\n",
       "   'raw_output': \"# Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\\n\\n## Introduction: The Rise of LLMs and the Black Box Problem\\n\\nLarge language models (LLMs) have rapidly transformed the landscape of artificial intelligence, becoming integral to applications across industries such as finance, healthcare, customer service, and content creation. Their ability to understand and generate human-like text has made them a cornerstone of modern AI systems. However, as these models scale in complexity and usage, a critical challenge has emerged: the **black box problem**.\\n\\nThe black box problem refers to the lack of transparency in how LLMs process inputs, generate outputs, and make decisions. Unlike traditional machine learning models, which often have more interpretable structures, LLMs are inherently complex and opaque. This opacity makes it difficult for developers and stakeholders to understand how the model behaves, especially in production environments where reliability, safety, and compliance are paramount.\\n\\nTraditional monitoring and debugging approaches, which are well-suited for conventional software systems, fall short when applied to LLMs. These approaches typically focus on system-level metrics such as CPU usage, memory consumption, and response times. However, they fail to capture the internal behavior of the model itselfâ€”what the model is thinking, how it processes data, and whether it is generating safe, accurate, or ethical outputs.\\n\\nThis is where **observability** comes in. Observability is not just about monitoring; it is about **understanding** the behavior of a system in real time. For LLMs, observability means having the ability to track requests end-to-end, measure performance across all layers, and create feedback loops to continuously improve the model's behavior.\\n\\nIn this blog post, we will explore the concept of observability in the context of LLM systems. We will break down its key componentsâ€”tracing, metrics, feedback loops, and content safetyâ€”and discuss how they contribute to building transparent, reliable, and ethical AI systems. We will also examine common failure patterns in LLM systems and how observability can help address them.\\n\\nBy the end of this post, you will understand why observability is not just a nice-to-haveâ€”it is essential for the future of AI.\\n\\n---\\n\\n## Understanding Observability in LLM Systems\\n\\n### What is Observability?\\n\\nObservability is the ability to understand the internal state of a system based on its external outputs. In the context of LLM systems, observability goes beyond traditional monitoring. It involves **tracking the flow of requests through the model**, **measuring performance at every layer**, and **analyzing the model's behavior in real time**.\\n\\nUnlike monitoring, which is reactive and focuses on predefined metrics, observability is **proactive and holistic**. It provides a **comprehensive view of the system**, enabling developers to not only detect issues but also understand why they are happening.\\n\\nFor example, while monitoring might tell you that a model is returning incorrect answers, observability would tell you **why** the model is generating those answersâ€”whether it's due to a faulty prompt, a data bias, or a misalignment in the training data.\\n\\n### The Observability Stack for LLMs\\n\\nAn effective observability strategy for LLM systems consists of several key components. These components work together to provide a complete picture of the model's behavior and performance. Let's explore each of them:\\n\\n#### 1. Tracing\\n\\n**Tracing** is the process of tracking a request through the entire system, from the initial user input to the final output. In LLM systems, tracing is especially important because it allows developers to understand how the model processes inputs, interacts with external tools, and generates outputs.\\n\\nFor example, consider an application that uses an LLM to answer customer questions. The request might start with a user query, then pass through a database lookup, an API call, and finally the LLM itself. Tracing would allow developers to see the entire journey of the request, including any delays or errors that occurred at each step.\\n\\nTools like **LangSmith** and **W&B Weave** provide end-to-end tracing capabilities, allowing developers to visualize the flow of requests and identify performance bottlenecks.\\n\\n#### 2. Metrics\\n\\n**Metrics** are quantitative measures of system performance and behavior. In the context of LLM systems, metrics can include:\\n\\n- **Response latency**: How long it takes the model to generate a response.\\n- **Token usage**: The number of tokens processed by the model.\\n- **Error rates**: The percentage of requests that result in errors.\\n- **Throughput**: The number of requests handled per second.\\n- **Resource usage**: CPU, memory, and GPU usage.\\n\\nThese metrics provide valuable insights into the performance of the model and help developers identify issues such as latency spikes, resource exhaustion, or inefficient token usage.\\n\\nFor instance, if a model starts to take longer than expected to generate responses, a developer might use metrics to determine whether the issue is due to a slow API call, a misconfigured model, or an overload of incoming requests.\\n\\n#### 3. Feedback Loops\\n\\n**Feedback loops** are mechanisms that allow the model to learn from its own behavior. In the context of LLM systems, feedback loops involve **collecting data on model performance** and using it to **improve the model over time**.\\n\\nFor example, if a model generates incorrect answers, developers can use feedback loops to **retrain the model on the incorrect outputs**, helping it to avoid making the same mistakes in the future. This process is often referred to as **model fine-tuning** or **reinforcement learning from human feedback (RLHF)**.\\n\\nTools like **W&B Weave** and **LangSmith** provide features that enable developers to collect and analyze feedback data, making it easier to iterate on model improvements.\\n\\n#### 4. Content Safety and Compliance\\n\\nAs LLMs become more integrated into production applications, **content safety and compliance** have become a major concern. These systems must ensure that the model's outputs are **accurate, safe, and aligned with ethical and legal standards**.\\n\\nObservability plays a crucial role in addressing these concerns. By **monitoring the model's outputs in real time**, developers can detect and flag potentially harmful or unethical content. This includes identifying **hallucinations**, **bias**, **profanity**, and **inappropriate content**.\\n\\nFor example, a healthcare application using an LLM to generate patient summaries must ensure that the model does not disclose sensitive information or make false claims. Observability tools can help detect such issues by **scanning model outputs for PII (Personally Identifiable Information)** or **violations of ethical guidelines**.\\n\\nIn regulated industries, **observability also means maintaining an audit trail**. This ensures that if there is ever a question or incident, there is a record to review. Features like **PII redaction** and **access control** are essential for maintaining compliance in such environments.\\n\\n---\\n\\n## The Role of Observability in AI Ethics and Trust\\n\\n### Building Trust Through Transparency\\n\\nTrust is a fundamental component of any AI system. For users, developers, and stakeholders, trust is built through **transparency, reliability, and accountability**. Observability plays a crucial role in building trust by providing **visibility into the model's behavior**.\\n\\nWhen users know that an AI system is **transparent and accountable**, they are more likely to trust its outputs. This is especially important in high-stakes applications such as **healthcare, finance, and legal services**, where the consequences of incorrect outputs can be severe.\\n\\nObservability also helps build **trust among developers and data scientists**. By providing **real-time insights into model behavior**, observability enables developers to **debug issues more effectively** and **improve the model's performance over time**.\\n\\n### Ensuring Ethical AI\\n\\nEthical AI is not just about avoiding harm; it's also about **ensuring that AI systems are fair, just, and aligned with societal values**. Observability supports ethical AI by providing **insights into model behavior**, **detecting biases**, and **ensuring compliance with ethical guidelines**.\\n\\nFor example, if an LLM is used in a hiring application, it must be **free from biases that could disadvantage certain groups**. Observability tools can help detect such biases by **analyzing the model's outputs for fairness** and **flagging any discriminatory patterns**.\\n\\nIn addition, observability helps ensure that **AI systems are aligned with ethical guidelines**. For instance, if an LLM is used to generate content for a news website, it must be **free from misinformation and bias**. Observability tools can help detect such issues by **scanning model outputs for factual accuracy** and **flagging any potential misinformation**.\\n\\n---\\n\\n## Common Failure Patterns in LLM Systems\\n\\n### Hallucinations\\n\\nOne of the most common failure patterns in LLM systems is **hallucination**, where the model generates **false or made-up information**. This can be a significant issue, especially in applications where **accuracy is critical**.\\n\\nFor example, an LLM used in a customer support application might generate **incorrect information about product features**, leading to **confusion and dissatisfaction** among users. Observability tools can help detect hallucinations by **monitoring model outputs** and **flagging any inconsistencies**.\\n\\n### Performance Bottlenecks\\n\\nAs LLMs scale in complexity and usage, **performance bottlenecks** can emerge. These bottlenecks can be due to a variety of factors, including **slow API calls**, **inefficient token usage**, or **resource exhaustion**.\\n\\nObservability tools can help identify these bottlenecks by **tracking performance metrics** and **analyzing the flow of requests**. For example, if a model starts to take longer than expected to generate responses, a developer might use observability tools to **identify the slow API call** or **optimize token usage**.\\n\\n### Cost Overruns\\n\\nMany LLM services charge based on **token usage or compute time**, making **cost overruns** a significant concern. Without observability, it is difficult to **track and optimize costs**.\\n\\nObservability tools can help prevent cost overruns by **tracking token usage in real time** and **identifying any excessive usage**. For example, if a model is generating **long or unnecessary prompts**, observability tools can **flag these prompts** and **suggest optimizations**.\\n\\n---\\n\\n## The Future of Observability in AI\\n\\nAs LLMs continue to evolve and become more integrated into production systems, **observability will play an increasingly important role** in building **transparent, reliable, and ethical AI**.\\n\\nTools like **W&B Weave**, **LangSmith**, and **Lunary** are at the forefront of this movement, providing **comprehensive observability solutions** for LLM systems. These tools not only help developers **monitor and debug their models** but also enable them to **improve model performance over time**.\\n\\nIn the future, we can expect to see **more advanced observability tools** that provide **even deeper insights into model behavior**, **automated feedback loops**, and **real-time ethical compliance checks**. These tools will be essential for **building AI systems that are not only powerful but also trustworthy**.\\n\\n---\\n\\n## Conclusion\\n\\nIn conclusion, **observability is not just a technical necessityâ€”it is a strategic imperative** for the future of AI. As LLMs become more complex and widely used, **the need for transparency and accountability has never been greater**.\\n\\nBy adopting an **observability-first approach**, organizations can **gain real-time insights into model behavior**, **detect and fix issues quickly**, and **ensure that their AI systems are safe, reliable, and ethical**.\\n\\nIn the next section, we will explore **practical examples of observability in action**, including **how to implement observability in your own LLM projects** and **best practices for building observability-first AI systems**. Stay tuned for more insights on this critical topic.\",\n",
       "   'structured_output': None,\n",
       "   'tool_call_output': None,\n",
       "   'started_at': 1765473305.7463915,\n",
       "   'duration_ms': 52281,\n",
       "   'error': None,\n",
       "   'traces': {'steps': [{'step_id': 1,\n",
       "      'kind': 'agent',\n",
       "      'label': 'agent.run',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'draft',\n",
       "      'started_at': 1765473305.748451,\n",
       "      'duration_ms': 52276,\n",
       "      'inputs': {'agent_type': 'Agent',\n",
       "       'has_toolkit': False,\n",
       "       'structured': False,\n",
       "       'stream': False,\n",
       "       'strict_tool_call': False},\n",
       "      'outputs': {},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': []},\n",
       "     {'step_id': 2,\n",
       "      'kind': 'llm.call',\n",
       "      'label': 'agent.free_text_call',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'draft',\n",
       "      'started_at': 1765473305.7492301,\n",
       "      'duration_ms': 52274,\n",
       "      'inputs': {'system_prompt_len': 619,\n",
       "       'user_prompt_len': 14362,\n",
       "       'user_prompt': 'Write a full draft of the blog post based on the provided outline and research, ensuring it is approximately 3000 words. Include clear headings, subheadings, and paragraphs that flow smoothly. Cover the introduction, the concept of observability, its components (tracing, metrics, feedback loops, and content safety), and the role of observability in AI ethics and trust. Use practical examples and insights from the research to support your arguments. Maintain a practical and slightly opinionated tone for an intermediate ML engineering audience.\\n\\n# Context from dependency nodes:\\n## outline\\n**Title:**  \\n*Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems*\\n\\n**Description:**  \\nThis blog post explores the critical need for observability in large language model (LLM) systems. As LLMs become more integrated into production applications, the lack of visibility into their internal workings has led to significant challenges, including hallucinations, performance bottlenecks, and compliance risks. By adopting an observability-first approach, organizations can gain real-time insights into model behavior, trace requests end-to-end, measure performance metrics, and create feedback loops for continuous improvement. This article outlines the key components of an observability-first strategy, discusses common failure patterns in LLM systems, and highlights the role of tools and best practices in building transparent, reliable, and ethical AI systems.\\n\\n---\\n\\n### **Outline of the Blog Post**\\n\\n#### **1. Introduction: The Rise of LLMs and the Black Box Problem**\\n- **Overview of LLMs and Their Growing Role**  \\n  - Explain the rapid adoption of LLMs across industries.  \\n  - Highlight their complexity and the challenges of deploying them at scale.  \\n\\n- **The Black Box Conundrum**  \\n  - Define the \"black box\" problem in LLMs.  \\n  - Discuss the limitations of traditional monitoring and debugging approaches.  \\n  - Introduce the concept of **observability** as a solution.  \\n\\n- **Why Observability Matters Now**  \\n  - Link the increasing complexity of LLM systems to the need for deeper visibility.  \\n  - Preview the key components of observability: tracing, metrics, feedback loops, and failure analysis.  \\n\\n---\\n\\n#### **2. Understanding Observability in LLM Systems**\\n- **What is Observability?**  \\n  - Define observability in the context of LLMs.  \\n  - Differentiate between **observability** and **monitoring**.  \\n  - Emphasize the importance of **comprehensive visibility** into model behavior.  \\n\\n- **The Observability Stack for LLMs**  \\n  - Break down the key elements of an observability layer:  \\n    - **Tracing**: Tracking requests through the system.  \\n    - **Metrics**: Measuring performance and resource usage.  \\n    - **Feedback Loops**: Using data to improve model behavior.  \\n    - **Content Safety and Compliance**: Ensuring ethical and legal standards.  \\n\\n- **The Role of Observability in AI Ethics and Trust**  \\n  - Discuss how observability supports transparency\\n\\n## research\\n{\\'query\\': \\'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\\', \\'summary\\': \"Top 3 results out of ~113 results for: \\'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\\'\\\\n1. LLM observability tools: Monitoring, debugging, and ... â€” https://medium.com/online-inference/llm-observability-tools-monitoring-debugging-and-improving-ai-systems-5af769796266\\\\n2. LLM Observability Explained: Prevent Hallucinations, ... â€” https://www.splunk.com/en_us/blog/learn/llm-observability.html\\\\n3. What Is LLM Observability? Use Cases and Best Practices â€” https://www.tredence.com/blog/llm-observability\", \\'provider\\': \\'serpapi\\', \\'elapsed_ms\\': 6055, \\'rag_content\\': \\'Source: de17dd0dd7eabff1:cc35f490\\\\nLLM observability tools: Monitoring, debugging, and improving AI systems Dave Davies 24 min read Â· Aug 22, 2025 -- Listen Share LLM observability is crucial for maintaining the operational health of applications powered by large language models. As AI systems become more complex and widely deployed, having visibility into their behavior is increasingly important. Observability tools provide comprehensive insight into all layers of an LLM-powered application, helping teams monitor performance, debug issues, and ensure outputs remain safe and reliable. Press enter or click to view image in full size By capturing everything from system metrics to model inputs and outputs, ... anomalies. This gives engineers actionable insights to fix inaccuracies, optimize performance, and uphold safety standards. In short, LLM observability creates a feedback loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to d\\\\n\\\\n---\\\\n\\\\nSource: 09ad15b0683646b8:cc35f490\\\\nck loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to distinguish observability from monitoring in the context of LLM applications. LLM monitoring typically focuses on the â€œwhatâ€ â€” it tracks key performance metrics and system health indicators to ensure the service is up and responsive. For example, monitoring will measure metrics such as API response time, error rates, request throughput, and token usage counts. If something goes ... wrong; observability helps you understand exactly what happened inside the system and how to fix it. Both are necessary â€” monitoring provides early warnings, while observability provides deep diagnosis â€” but observability offers the comprehensive visibility that LLM applications especially need. Challenges addressed by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability too\\\\n\\\\n---\\\\n\\\\nSource: a11a9e62cab8284b:cc35f490\\\\nt overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without ... observability solutions To solve the challenges above, an effective LLM observability solution provides several key capabilities. At the core is real-time performance monitoring across the entire system. This means the tool tracks metrics such as response latency, throughput of requests, error rates, and resource usage (CPU, memory, GPU, or API tokens) in real time. With these insights, teams can immediately spot performance degradation â€” for example, if the average response time of the model starts creeping up or if the error rate exceeds a threshold. Real-time monitoring ensures that any latency spikes, timeouts, or bottlenecks in the LLM or its ... tools integrate checks for content safety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content mo\\\\n\\\\n---\\\\n\\\\nSource: 6b08b29bc2b9891d:cc35f490\\\\nd by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability tools are designed to address these issues. One major problem is hallucinations â€” when an LLM generates answers that sound plausible but are factually incorrect or completely made-up. For example, an LLM might confidently provide a wrong ... external API call holding things up? LLM observability ties together data from all components, so teams can pinpoint if a particular step (like a database search for context or a third-party API call) is causing the delay. Similarly, failures or errors in a pipeline can be tricky to reproduce given the complexity of LLM systems. Observability tools trace each step of a request, making it easier to debug when something goes wrong in a multi-step process. Cost overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without\\\\n\\\\n---\\\\n\\\\nSource: 724c404f6a885694:cc35f490\\\\nsafety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content moderation APIs. A good observability platform might, for example, automatically tag any response that seems to contain personally identifiable information or that violates certain ethical guidelines. In regulated industries, observability also means keeping an audit trail â€” the tool should log all prompts and responses securely so that if thereâ€™s ever a question or incident, thereâ€™s a record to review. Features like PII redaction (masking sensitive user data in logs) and access control become ... LLM observability tools As the demand for LLM observability has grown, a number of tools and platforms have emerged to help developers monitor and debug their language model applications. Each tool has its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this sp\\\\n\\\\n---\\\\n\\\\nSource: 06f031e91c9c0236:cc35f490\\\\nheir applications in just a few lines of code and immediately gain end-to-end visibility and confidence in their modelâ€™s behavior. The tutorial illustrated how easy it is to get started with Weave and how it can be leveraged for tasks ranging from real-time monitoring to quality assurance and ethical compliance. Looking ahead, LLM observability tools will likely ... know they can catch mistakes and iterate quickly. Tools like W&B Weave are at the forefront of this effort, providing the means to monitor, debug, and improve LLM applications in one unified environment. By adopting LLM observability practices now, developers and organizations set themselves up for success â€” ensuring that their AI systems remain performant, trustworthy, and aligned with user needs as both the models and usage grow. As these observability tools evolve, they will undoubtedly play a central role in the future of AI deployments, helping us harness the full potential of LLMs while keeping a watchful eye on\\\\n\\\\n---\\\\n\\\\nSource: 9758ab006e75cff3:cc35f490\\\\n Weave, instrumented our LLM call with one line ( @weave.op ), ran the application to log data, optionally added an evaluation, and then ... bottlenecks in your LLM application. Suppose your app has higher-than-desired latency; by looking at traces, you might discover that a database lookup or a particular model call is the slow part. With that insight, you could try caching results, using a smaller model for that step, or otherwise improving the architecture. Likewise, Weaveâ€™s token usage tracking can show if certain prompts are excessively long (costly) â€” prompting you to optimize prompt formats to reduce token counts. Over time, you can use Weave metrics to verify that optimizations are effective (e.g., see average latency drop after a change, or a reduction ... when you have a robust observability tool in place. Continuous evaluation and model improvement: You can use Weave not just for monitoring but for ongoing evaluation even after deployment. Letâ€™s say you regularly update your\\\\n\\\\n---\\\\n\\\\nSource: d7c061743dc2e1ee:cc35f490\\\\n on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and compliance features) gives confidence to companies that need to monitor LLMs in production while meeting security requirements. In summary, W&B Weave is a preferred observability tool because it combines comprehensive tracing, real-time performance monitoring, automated output evaluation, and an intuitive UI in one platform. It effectively bridges the gap between model development ... enter your API key Once installed and authenticated, initialize Weave in your script or notebook by calling weave.init() at the start of your program. This sets up a new Weave project where all your logs and traces will be stored. For example: import weave # Initialize a Weave project (give a name for this observability run) weave.init(project=\"llm-observability-demo\") After this initialization, Weave is ready to capture data. It will associate all logs with the pro\\\\n\\\\n---\\\\n\\\\nSource: 2d3c24ba61c5ba18:cc35f490\\\\nas its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this space include Lunary, LangSmith, and W&B Weave, among others. Lunary Lunary is an open-source platform that provides analytics and tracing for LLM-powered apps. Itâ€™s designed to be model-agnostic, meaning it can work with any LLM provider or architecture. Lunary focuses on ... and intermediate actions (like calls to tools or external APIs). This provides end-to-end tracing for chain-of-thought style applications. LangSmith also emphasizes prompt evaluation and testing. It allows developers to systematically evaluate their prompts and model outputs by using datasets of queries and expected answers. In the LangSmith dashboard, you can see how often your modelâ€™s responses match the expected results or where it might be failing. It supports scoring of outputs for accuracy, completeness, or custom metrics you define. Additionally, LangSmith prov\\\\n\\\\n---\\\\n\\\\nSource: e5ee1e1a6d3f0816:cc35f490\\\\nthen to an LLM, and then into some post-processing, ... means W&B Weave not only tells you that an answer was given, but also gives an indication of whether that answer was good or potentially problematic â€” all in real time. Few other observability tools have this level of integrated quality checking. Seamless integration and agnostic support are also key features of W&B Weave. It is designed to be framework-agnostic and model-agnostic: whether youâ€™re using OpenAIâ€™s GPT-4 via API, an open-source model on Hugging Face, or a LangChain application, Weave can plug in. The tool provides simple SDK methods and decorators to instrument your code. For instance, by adding a ... in a W&B report format) to communicate your findings. The collaborative features (permissions, team projects, comments) make it a strong choice for enterprise teams working on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and complian\\'}',\n",
       "       'system_prompt': 'You are a specialized agent in a larger workflow.\\n\\nYour role:\\n- PURPOSE: Write the first full draft of the article of about 3000 words including every detail.\\n- GOAL: Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n\\n- EXPECTED_RESULT: A complete draft in markdown, including title, headings, and paragraphs.\\n\\nGeneral behaviour:\\n- Be precise and concise unless the task requires extended output.\\n- Use clear structure (headings/bullets) when helpful.\\n- If you are calling tools, interpret their outputs carefully and explain your reasoning.\\n',\n",
       "       'temperature': 0.7,\n",
       "       'max_new_tokens': 16000,\n",
       "       'stream': False},\n",
       "      'outputs': {'output': \"# Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\\n\\n## Introduction: The Rise of LLMs and the Black Box Problem\\n\\nLarge language models (LLMs) have rapidly transformed the landscape of artificial intelligence, becoming integral to applications across industries such as finance, healthcare, customer service, and content creation. Their ability to understand and generate human-like text has made them a cornerstone of modern AI systems. However, as these models scale in complexity and usage, a critical challenge has emerged: the **black box problem**.\\n\\nThe black box problem refers to the lack of transparency in how LLMs process inputs, generate outputs, and make decisions. Unlike traditional machine learning models, which often have more interpretable structures, LLMs are inherently complex and opaque. This opacity makes it difficult for developers and stakeholders to understand how the model behaves, especially in production environments where reliability, safety, and compliance are paramount.\\n\\nTraditional monitoring and debugging approaches, which are well-suited for conventional software systems, fall short when applied to LLMs. These approaches typically focus on system-level metrics such as CPU usage, memory consumption, and response times. However, they fail to capture the internal behavior of the model itselfâ€”what the model is thinking, how it processes data, and whether it is generating safe, accurate, or ethical outputs.\\n\\nThis is where **observability** comes in. Observability is not just about monitoring; it is about **understanding** the behavior of a system in real time. For LLMs, observability means having the ability to track requests end-to-end, measure performance across all layers, and create feedback loops to continuously improve the model's behavior.\\n\\nIn this blog post, we will explore the concept of observability in the context of LLM systems. We will break down its key componentsâ€”tracing, metrics, feedback loops, and content safetyâ€”and discuss how they contribute to building transparent, reliable, and ethical AI systems. We will also examine common failure patterns in LLM systems and how observability can help address them.\\n\\nBy the end of this post, you will understand why observability is not just a nice-to-haveâ€”it is essential for the future of AI.\\n\\n---\\n\\n## Understanding Observability in LLM Systems\\n\\n### What is Observability?\\n\\nObservability is the ability to understand the internal state of a system based on its external outputs. In the context of LLM systems, observability goes beyond traditional monitoring. It involves **tracking the flow of requests through the model**, **measuring performance at every layer**, and **analyzing the model's behavior in real time**.\\n\\nUnlike monitoring, which is reactive and focuses on predefined metrics, observability is **proactive and holistic**. It provides a **comprehensive view of the system**, enabling developers to not only detect issues but also understand why they are happening.\\n\\nFor example, while monitoring might tell you that a model is returning incorrect answers, observability would tell you **why** the model is generating those answersâ€”whether it's due to a faulty prompt, a data bias, or a misalignment in the training data.\\n\\n### The Observability Stack for LLMs\\n\\nAn effective observability strategy for LLM systems consists of several key components. These components work together to provide a complete picture of the model's behavior and performance. Let's explore each of them:\\n\\n#### 1. Tracing\\n\\n**Tracing** is the process of tracking a request through the entire system, from the initial user input to the final output. In LLM systems, tracing is especially important because it allows developers to understand how the model processes inputs, interacts with external tools, and generates outputs.\\n\\nFor example, consider an application that uses an LLM to answer customer questions. The request might start with a user query, then pass through a database lookup, an API call, and finally the LLM itself. Tracing would allow developers to see the entire journey of the request, including any delays or errors that occurred at each step.\\n\\nTools like **LangSmith** and **W&B Weave** provide end-to-end tracing capabilities, allowing developers to visualize the flow of requests and identify performance bottlenecks.\\n\\n#### 2. Metrics\\n\\n**Metrics** are quantitative measures of system performance and behavior. In the context of LLM systems, metrics can include:\\n\\n- **Response latency**: How long it takes the model to generate a response.\\n- **Token usage**: The number of tokens processed by the model.\\n- **Error rates**: The percentage of requests that result in errors.\\n- **Throughput**: The number of requests handled per second.\\n- **Resource usage**: CPU, memory, and GPU usage.\\n\\nThese metrics provide valuable insights into the performance of the model and help developers identify issues such as latency spikes, resource exhaustion, or inefficient token usage.\\n\\nFor instance, if a model starts to take longer than expected to generate responses, a developer might use metrics to determine whether the issue is due to a slow API call, a misconfigured model, or an overload of incoming requests.\\n\\n#### 3. Feedback Loops\\n\\n**Feedback loops** are mechanisms that allow the model to learn from its own behavior. In the context of LLM systems, feedback loops involve **collecting data on model performance** and using it to **improve the model over time**.\\n\\nFor example, if a model generates incorrect answers, developers can use feedback loops to **retrain the model on the incorrect outputs**, helping it to avoid making the same mistakes in the future. This process is often referred to as **model fine-tuning** or **reinforcement learning from human feedback (RLHF)**.\\n\\nTools like **W&B Weave** and **LangSmith** provide features that enable developers to collect and analyze feedback data, making it easier to iterate on model improvements.\\n\\n#### 4. Content Safety and Compliance\\n\\nAs LLMs become more integrated into production applications, **content safety and compliance** have become a major concern. These systems must ensure that the model's outputs are **accurate, safe, and aligned with ethical and legal standards**.\\n\\nObservability plays a crucial role in addressing these concerns. By **monitoring the model's outputs in real time**, developers can detect and flag potentially harmful or unethical content. This includes identifying **hallucinations**, **bias**, **profanity**, and **inappropriate content**.\\n\\nFor example, a healthcare application using an LLM to generate patient summaries must ensure that the model does not disclose sensitive information or make false claims. Observability tools can help detect such issues by **scanning model outputs for PII (Personally Identifiable Information)** or **violations of ethical guidelines**.\\n\\nIn regulated industries, **observability also means maintaining an audit trail**. This ensures that if there is ever a question or incident, there is a record to review. Features like **PII redaction** and **access control** are essential for maintaining compliance in such environments.\\n\\n---\\n\\n## The Role of Observability in AI Ethics and Trust\\n\\n### Building Trust Through Transparency\\n\\nTrust is a fundamental component of any AI system. For users, developers, and stakeholders, trust is built through **transparency, reliability, and accountability**. Observability plays a crucial role in building trust by providing **visibility into the model's behavior**.\\n\\nWhen users know that an AI system is **transparent and accountable**, they are more likely to trust its outputs. This is especially important in high-stakes applications such as **healthcare, finance, and legal services**, where the consequences of incorrect outputs can be severe.\\n\\nObservability also helps build **trust among developers and data scientists**. By providing **real-time insights into model behavior**, observability enables developers to **debug issues more effectively** and **improve the model's performance over time**.\\n\\n### Ensuring Ethical AI\\n\\nEthical AI is not just about avoiding harm; it's also about **ensuring that AI systems are fair, just, and aligned with societal values**. Observability supports ethical AI by providing **insights into model behavior**, **detecting biases**, and **ensuring compliance with ethical guidelines**.\\n\\nFor example, if an LLM is used in a hiring application, it must be **free from biases that could disadvantage certain groups**. Observability tools can help detect such biases by **analyzing the model's outputs for fairness** and **flagging any discriminatory patterns**.\\n\\nIn addition, observability helps ensure that **AI systems are aligned with ethical guidelines**. For instance, if an LLM is used to generate content for a news website, it must be **free from misinformation and bias**. Observability tools can help detect such issues by **scanning model outputs for factual accuracy** and **flagging any potential misinformation**.\\n\\n---\\n\\n## Common Failure Patterns in LLM Systems\\n\\n### Hallucinations\\n\\nOne of the most common failure patterns in LLM systems is **hallucination**, where the model generates **false or made-up information**. This can be a significant issue, especially in applications where **accuracy is critical**.\\n\\nFor example, an LLM used in a customer support application might generate **incorrect information about product features**, leading to **confusion and dissatisfaction** among users. Observability tools can help detect hallucinations by **monitoring model outputs** and **flagging any inconsistencies**.\\n\\n### Performance Bottlenecks\\n\\nAs LLMs scale in complexity and usage, **performance bottlenecks** can emerge. These bottlenecks can be due to a variety of factors, including **slow API calls**, **inefficient token usage**, or **resource exhaustion**.\\n\\nObservability tools can help identify these bottlenecks by **tracking performance metrics** and **analyzing the flow of requests**. For example, if a model starts to take longer than expected to generate responses, a developer might use observability tools to **identify the slow API call** or **optimize token usage**.\\n\\n### Cost Overruns\\n\\nMany LLM services charge based on **token usage or compute time**, making **cost overruns** a significant concern. Without observability, it is difficult to **track and optimize costs**.\\n\\nObservability tools can help prevent cost overruns by **tracking token usage in real time** and **identifying any excessive usage**. For example, if a model is generating **long or unnecessary prompts**, observability tools can **flag these prompts** and **suggest optimizations**.\\n\\n---\\n\\n## The Future of Observability in AI\\n\\nAs LLMs continue to evolve and become more integrated into production systems, **observability will play an increasingly important role** in building **transparent, reliable, and ethical AI**.\\n\\nTools like **W&B Weave**, **LangSmith**, and **Lunary** are at the forefront of this movement, providing **comprehensive observability solutions** for LLM systems. These tools not only help developers **monitor and debug their models** but also enable them to **improve model performance over time**.\\n\\nIn the future, we can expect to see **more advanced observability tools** that provide **even deeper insights into model behavior**, **automated feedback loops**, and **real-time ethical compliance checks**. These tools will be essential for **building AI systems that are not only powerful but also trustworthy**.\\n\\n---\\n\\n## Conclusion\\n\\nIn conclusion, **observability is not just a technical necessityâ€”it is a strategic imperative** for the future of AI. As LLMs become more complex and widely used, **the need for transparency and accountability has never been greater**.\\n\\nBy adopting an **observability-first approach**, organizations can **gain real-time insights into model behavior**, **detect and fix issues quickly**, and **ensure that their AI systems are safe, reliable, and ethical**.\\n\\nIn the next section, we will explore **practical examples of observability in action**, including **how to implement observability in your own LLM projects** and **best practices for building observability-first AI systems**. Stay tuned for more insights on this critical topic.\"},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': []}],\n",
       "    'meta': {'agent_type': 'generic_agent',\n",
       "     'agent_config': {'allow_input_pruning': True,\n",
       "      'repair_with_llm': True,\n",
       "      'strict_tool_call': False,\n",
       "      'temperature': 0.7,\n",
       "      'max_new_tokens': 16000,\n",
       "      'return_stream_by_default': False,\n",
       "      'retry': {'max_route_retries': 2,\n",
       "       'max_tool_retries': 1,\n",
       "       'backoff_sec': 0.7},\n",
       "      'strict_json': True,\n",
       "      'max_json_repair_attempts': 1},\n",
       "     'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit',\n",
       "     'toolkit': False,\n",
       "     'log_steps': True}}},\n",
       "  'review': {'node_id': 'review',\n",
       "   'mode': <NodeMode.STRUCTURED: 'structured'>,\n",
       "   'raw_output': '# Review of the Blog Post: \"Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\"\\n\\n---\\n\\n## âœ… Strengths\\n\\n- **Clear structure**: The blog post is well-organized with logical sections and a clear progression from introduction to conclusion.\\n- **Relevant content**: It effectively covers the core aspects of observability in LLM systems, including tracing, metrics, feedback loops, and content safety.\\n- **Practical tone**: The tone is practical and slightly opinionated, as requested, making it accessible for intermediate ML engineers.\\n- **Use of examples**: The post uses concrete examples (e.g., hallucinations, performance bottlenecks, cost overruns) to illustrate key points.\\n- **Actionable insights**: The post provides actionable insights for developers, such as using tools like LangSmith, W&B Weave, and Lunary.\\n- **Alignment with query**: The content thoroughly addresses the importance of observability in LLM systems and covers all requested components (tracing, metrics, feedback loops, failure patterns).\\n\\n---\\n\\n## ğŸš¨ Issues and Suggestions\\n\\n### 1. **Factual Inaccuracies and Missing Explanations**\\n\\n- **Tool Mentioned Without Context**: The post mentions tools like **LangSmith**, **W&B Weave**, and **Lunary**, but it doesnâ€™t explain what they are or how they are used in the context of LLM observability. This could confuse readers who are unfamiliar with these tools.  \\n  **Suggestion**: Add brief descriptions of each tool and its role in LLM observability, or provide links to their documentation for further reading.\\n\\n- **Overgeneralization of Observability**: The post uses the term \"observability\" broadly, but it doesnâ€™t clearly differentiate between **observability**, **monitoring**, and **debugging**. This can lead to confusion.  \\n  **Suggestion**: Clarify the distinction between these concepts, especially in the section on \"LLM Observability vs. LLM Monitoring.\"\\n\\n- **Limited Discussion on Feedback Loops**: While the post mentions feedback loops, it doesnâ€™t go into detail about how they are implemented or their impact on model behavior.  \\n  **Suggestion**: Expand on the concept of feedback loops, including examples like **reinforcement learning from human feedback (RLHF)** and **active learning**.\\n\\n- **Ambiguity Around \"Common Failure Patterns\"**: The post lists failure patterns (e.g., hallucinations, performance bottlenecks, cost overruns) but doesnâ€™t provide enough depth on how observability helps detect or mitigate these issues.  \\n  **Suggestion**: Include specific examples of how observability tools detect and address these failure patterns (e.g., how a tool identifies a hallucination and triggers a model retraining).\\n\\n---\\n\\n### 2. **Stylistic and Clarity Issues**\\n\\n- **Repetition of Terms**: The term \"observability\" is used repeatedly, which can make the post feel redundant.  \\n  **Suggestion**: Vary the language to avoid repetition. For example, use synonyms like \"visibility,\" \"diagnostic insights,\" or \"behavioral analysis.\"\\n\\n- **Unclear Transition Between Sections**: The transition from the section on \"Observability Stack for LLMs\" to \"The Role of Observability in AI Ethics and Trust\" is abrupt.  \\n  **Suggestion**: Add a brief paragraph or sentence that connects these sections, explaining how observability supports both technical and ethical aspects of AI.\\n\\n- **Lack of Visual Aids**: The post is text-heavy and lacks visual aids such as diagrams or charts that could help explain complex concepts like tracing or feedback loops.  \\n  **Suggestion**: Suggest including visual aids (e.g., flowcharts of a request lifecycle, graphs of performance metrics) in future versions of the post.\\n\\n- **Some Sentences Are Too Long**: Some sentences are long and complex, making them difficult to parse.  \\n  **Suggestion**: Break up long sentences into shorter ones for better readability. For example:\\n  > \"While monitoring might tell you that a model is returning incorrect answers, observability would tell you why the model is generating those answersâ€”whether it\\'s due to a faulty prompt, a data bias, or a misalignment in the training data.\"\\n  â†’\\n  > \"While monitoring might tell you that a model is returning incorrect answers, observability goes further. It tells you why the model is generating those answers. The cause could be a faulty prompt, data bias, or a misalignment in the training data.\"\\n\\n---\\n\\n### 3. **Unclarified Concepts**\\n\\n- **\"Feedback Loops\"**: The term is used without a clear definition. The post mentions that feedback loops involve collecting data on model performance and using it to improve the model, but it doesnâ€™t explain how this process works in practice.  \\n  **Suggestion**: Define \"feedback loops\" more clearly, perhaps with an example such as:\\n  > \"A feedback loop in the context of LLMs involves collecting data on model performance (e.g., incorrect outputs, bias) and using that data to retrain or fine-tune the model. This process is often referred to as reinforcement learning from human feedback (RLHF).\"\\n\\n- **\"Content Safety and Compliance\"**: The post touches on content safety and compliance but doesnâ€™t provide enough detail on how observability tools enforce these standards.  \\n  **Suggestion**: Expand on the role of observability in content safety, including examples of how tools detect and flag problematic content (e.g., profanity, bias, hallucinations).\\n\\n---\\n\\n## âœ… Summary of Actionable Edits\\n\\n| Issue | Suggestion |\\n|------|------------|\\n| Tool descriptions are too vague | Add brief descriptions of tools like LangSmith, W&B Weave, and Lunary |\\n| Overgeneralization of observability | Clarify the difference between observability, monitoring, and debugging |\\n| Limited discussion on feedback loops | Expand on how feedback loops are implemented and their impact |\\n| Ambiguity around failure patterns | Provide specific examples of how observability detects and mitigates failure patterns |\\n| Repetition of terms | Vary the language to avoid repetition |\\n| Unclear transitions between sections | Add connecting sentences between sections |\\n| Lack of visual aids | Suggest including diagrams or charts for better clarity |\\n| Long sentences | Break up long sentences for better readability |\\n| Unclarified concepts | Define \"feedback loops\" and \"content safety\" more clearly |\\n\\n---\\n\\n## âœ… Final Assessment\\n\\nThe blog post is well-written, informative, and aligned with the original query. It provides a clear argument for the importance of observability in LLM systems and covers the key components (tracing, metrics, feedback loops, content safety). However, there are opportunities for improvement in terms of clarity, structure, and depth of explanation. With the suggested edits, the post can be made even more effective for its target audience of intermediate ML engineers.',\n",
       "   'structured_output': None,\n",
       "   'tool_call_output': None,\n",
       "   'started_at': 1765473361.3331904,\n",
       "   'duration_ms': 31056,\n",
       "   'error': None,\n",
       "   'traces': {'steps': [{'step_id': 1,\n",
       "      'kind': 'agent',\n",
       "      'label': 'agent.run',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'review',\n",
       "      'started_at': 1765473361.3351858,\n",
       "      'duration_ms': 31052,\n",
       "      'inputs': {'agent_type': 'Agent',\n",
       "       'has_toolkit': False,\n",
       "       'structured': False,\n",
       "       'stream': False,\n",
       "       'strict_tool_call': False},\n",
       "      'outputs': {},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': []},\n",
       "     {'step_id': 2,\n",
       "      'kind': 'llm.call',\n",
       "      'label': 'agent.free_text_call',\n",
       "      'node_id': None,\n",
       "      'agent_id': 'review',\n",
       "      'started_at': 1765473361.335976,\n",
       "      'duration_ms': 31050,\n",
       "      'inputs': {'system_prompt_len': 583,\n",
       "       'user_prompt_len': 24253,\n",
       "       'user_prompt': 'Review the draft blog post for factual accuracy, clarity, and alignment with the original query. Identify any technical inaccuracies, missing explanations, or stylistic issues. Provide actionable suggestions for improvement and mark any unclear sections. Ensure the content thoroughly addresses the importance of observability in LLM systems, including tracing, metrics, feedback loops, and common failure patterns, while maintaining a practical and slightly opinionated tone for intermediate ML engineers.\\n\\n# Context from dependency nodes:\\n## draft\\n# Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\\n\\n## Introduction: The Rise of LLMs and the Black Box Problem\\n\\nLarge language models (LLMs) have rapidly transformed the landscape of artificial intelligence, becoming integral to applications across industries such as finance, healthcare, customer service, and content creation. Their ability to understand and generate human-like text has made them a cornerstone of modern AI systems. However, as these models scale in complexity and usage, a critical challenge has emerged: the **black box problem**.\\n\\nThe black box problem refers to the lack of transparency in how LLMs process inputs, generate outputs, and make decisions. Unlike traditional machine learning models, which often have more interpretable structures, LLMs are inherently complex and opaque. This opacity makes it difficult for developers and stakeholders to understand how the model behaves, especially in production environments where reliability, safety, and compliance are paramount.\\n\\nTraditional monitoring and debugging approaches, which are well-suited for conventional software systems, fall short when applied to LLMs. These approaches typically focus on system-level metrics such as CPU usage, memory consumption, and response times. However, they fail to capture the internal behavior of the model itselfâ€”what the model is thinking, how it processes data, and whether it is generating safe, accurate, or ethical outputs.\\n\\nThis is where **observability** comes in. Observability is not just about monitoring; it is about **understanding** the behavior of a system in real time. For LLMs, observability means having the ability to track requests end-to-end, measure performance across all layers, and create feedback loops to continuously improve the model\\'s behavior.\\n\\nIn this blog post, we will explore the concept of observability in the context of LLM systems. We will break down its key componentsâ€”tracing, metrics, feedback loops, and content safetyâ€”and discuss how they contribute to building transparent, reliable, and ethical AI systems. We will also examine common failure patterns in LLM systems and how observability can help address them.\\n\\nBy the end of this post, you will understand why observability is not just a nice-to-haveâ€”it is essential for the future of AI.\\n\\n---\\n\\n## Understanding Observability in LLM Systems\\n\\n### What is Observability?\\n\\nObservability is the ability to understand the internal state of a system based on its external outputs. In the context of LLM systems, observability goes beyond traditional monitoring. It involves **tracking the flow of requests through the model**, **measuring performance at every layer**, and **analyzing the model\\'s behavior in real time**.\\n\\nUnlike monitoring, which is reactive and focuses on predefined metrics, observability is **proactive and holistic**. It provides a **comprehensive view of the system**, enabling developers to not only detect issues but also understand why they are happening.\\n\\nFor example, while monitoring might tell you that a model is returning incorrect answers, observability would tell you **why** the model is generating those answersâ€”whether it\\'s due to a faulty prompt, a data bias, or a misalignment in the training data.\\n\\n### The Observability Stack for LLMs\\n\\nAn effective observability strategy for LLM systems consists of several key components. These components work together to provide a complete picture of the model\\'s behavior and performance. Let\\'s explore each of them:\\n\\n#### 1. Tracing\\n\\n**Tracing** is the process of tracking a request through the entire system, from the initial user input to the final output. In LLM systems, tracing is especially important because it allows developers to understand how the model processes inputs, interacts with external tools, and generates outputs.\\n\\nFor example, consider an application that uses an LLM to answer customer questions. The request might start with a user query, then pass through a database lookup, an API call, and finally the LLM itself. Tracing would allow developers to see the entire journey of the request, including any delays or errors that occurred at each step.\\n\\nTools like **LangSmith** and **W&B Weave** provide end-to-end tracing capabilities, allowing developers to visualize the flow of requests and identify performance bottlenecks.\\n\\n#### 2. Metrics\\n\\n**Metrics** are quantitative measures of system performance and behavior. In the context of LLM systems, metrics can include:\\n\\n- **Response latency**: How long it takes the model to generate a response.\\n- **Token usage**: The number of tokens processed by the model.\\n- **Error rates**: The percentage of requests that result in errors.\\n- **Throughput**: The number of requests handled per second.\\n- **Resource usage**: CPU, memory, and GPU usage.\\n\\nThese metrics provide valuable insights into the performance of the model and help developers identify issues such as latency spikes, resource exhaustion, or inefficient token usage.\\n\\nFor instance, if a model starts to take longer than expected to generate responses, a developer might use metrics to determine whether the issue is due to a slow API call, a misconfigured model, or an overload of incoming requests.\\n\\n#### 3. Feedback Loops\\n\\n**Feedback loops** are mechanisms that allow the model to learn from its own behavior. In the context of LLM systems, feedback loops involve **collecting data on model performance** and using it to **improve the model over time**.\\n\\nFor example, if a model generates incorrect answers, developers can use feedback loops to **retrain the model on the incorrect outputs**, helping it to avoid making the same mistakes in the future. This process is often referred to as **model fine-tuning** or **reinforcement learning from human feedback (RLHF)**.\\n\\nTools like **W&B Weave** and **LangSmith** provide features that enable developers to collect and analyze feedback data, making it easier to iterate on model improvements.\\n\\n#### 4. Content Safety and Compliance\\n\\nAs LLMs become more integrated into production applications, **content safety and compliance** have become a major concern. These systems must ensure that the model\\'s outputs are **accurate, safe, and aligned with ethical and legal standards**.\\n\\nObservability plays a crucial role in addressing these concerns. By **monitoring the model\\'s outputs in real time**, developers can detect and flag potentially harmful or unethical content. This includes identifying **hallucinations**, **bias**, **profanity**, and **inappropriate content**.\\n\\nFor example, a healthcare application using an LLM to generate patient summaries must ensure that the model does not disclose sensitive information or make false claims. Observability tools can help detect such issues by **scanning model outputs for PII (Personally Identifiable Information)** or **violations of ethical guidelines**.\\n\\nIn regulated industries, **observability also means maintaining an audit trail**. This ensures that if there is ever a question or incident, there is a record to review. Features like **PII redaction** and **access control** are essential for maintaining compliance in such environments.\\n\\n---\\n\\n## The Role of Observability in AI Ethics and Trust\\n\\n### Building Trust Through Transparency\\n\\nTrust is a fundamental component of any AI system. For users, developers, and stakeholders, trust is built through **transparency, reliability, and accountability**. Observability plays a crucial role in building trust by providing **visibility into the model\\'s behavior**.\\n\\nWhen users know that an AI system is **transparent and accountable**, they are more likely to trust its outputs. This is especially important in high-stakes applications such as **healthcare, finance, and legal services**, where the consequences of incorrect outputs can be severe.\\n\\nObservability also helps build **trust among developers and data scientists**. By providing **real-time insights into model behavior**, observability enables developers to **debug issues more effectively** and **improve the model\\'s performance over time**.\\n\\n### Ensuring Ethical AI\\n\\nEthical AI is not just about avoiding harm; it\\'s also about **ensuring that AI systems are fair, just, and aligned with societal values**. Observability supports ethical AI by providing **insights into model behavior**, **detecting biases**, and **ensuring compliance with ethical guidelines**.\\n\\nFor example, if an LLM is used in a hiring application, it must be **free from biases that could disadvantage certain groups**. Observability tools can help detect such biases by **analyzing the model\\'s outputs for fairness** and **flagging any discriminatory patterns**.\\n\\nIn addition, observability helps ensure that **AI systems are aligned with ethical guidelines**. For instance, if an LLM is used to generate content for a news website, it must be **free from misinformation and bias**. Observability tools can help detect such issues by **scanning model outputs for factual accuracy** and **flagging any potential misinformation**.\\n\\n---\\n\\n## Common Failure Patterns in LLM Systems\\n\\n### Hallucinations\\n\\nOne of the most common failure patterns in LLM systems is **hallucination**, where the model generates **false or made-up information**. This can be a significant issue, especially in applications where **accuracy is critical**.\\n\\nFor example, an LLM used in a customer support application might generate **incorrect information about product features**, leading to **confusion and dissatisfaction** among users. Observability tools can help detect hallucinations by **monitoring model outputs** and **flagging any inconsistencies**.\\n\\n### Performance Bottlenecks\\n\\nAs LLMs scale in complexity and usage, **performance bottlenecks** can emerge. These bottlenecks can be due to a variety of factors, including **slow API calls**, **inefficient token usage**, or **resource exhaustion**.\\n\\nObservability tools can help identify these bottlenecks by **tracking performance metrics** and **analyzing the flow of requests**. For example, if a model starts to take longer than expected to generate responses, a developer might use observability tools to **identify the slow API call** or **optimize token usage**.\\n\\n### Cost Overruns\\n\\nMany LLM services charge based on **token usage or compute time**, making **cost overruns** a significant concern. Without observability, it is difficult to **track and optimize costs**.\\n\\nObservability tools can help prevent cost overruns by **tracking token usage in real time** and **identifying any excessive usage**. For example, if a model is generating **long or unnecessary prompts**, observability tools can **flag these prompts** and **suggest optimizations**.\\n\\n---\\n\\n## The Future of Observability in AI\\n\\nAs LLMs continue to evolve and become more integrated into production systems, **observability will play an increasingly important role** in building **transparent, reliable, and ethical AI**.\\n\\nTools like **W&B Weave**, **LangSmith**, and **Lunary** are at the forefront of this movement, providing **comprehensive observability solutions** for LLM systems. These tools not only help developers **monitor and debug their models** but also enable them to **improve model performance over time**.\\n\\nIn the future, we can expect to see **more advanced observability tools** that provide **even deeper insights into model behavior**, **automated feedback loops**, and **real-time ethical compliance checks**. These tools will be essential for **building AI systems that are not only powerful but also trustworthy**.\\n\\n---\\n\\n## Conclusion\\n\\nIn conclusion, **observability is not just a technical necessityâ€”it is a strategic imperative** for the future of AI. As LLMs become more complex and widely used, **the need for transparency and accountability has never been greater**.\\n\\nBy adopting an **observability-first approach**, organizations can **gain real-time insights into model behavior**, **detect and fix issues quickly**, and **ensure that their AI systems are safe, reliable, and ethical**.\\n\\nIn the next section, we will explore **practical examples of observability in action**, including **how to implement observability in your own LLM projects** and **best practices for building observability-first AI systems**. Stay tuned for more insights on this critical topic.\\n\\n## research\\n{\\'query\\': \\'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\\', \\'summary\\': \"Top 3 results out of ~113 results for: \\'Compose a 1000-1500 word blog arguing why observability layers are essential in modern LLM systems, including tracing, metrics, feedback loops, and common failure patterns.\\'\\\\n1. LLM observability tools: Monitoring, debugging, and ... â€” https://medium.com/online-inference/llm-observability-tools-monitoring-debugging-and-improving-ai-systems-5af769796266\\\\n2. LLM Observability Explained: Prevent Hallucinations, ... â€” https://www.splunk.com/en_us/blog/learn/llm-observability.html\\\\n3. What Is LLM Observability? Use Cases and Best Practices â€” https://www.tredence.com/blog/llm-observability\", \\'provider\\': \\'serpapi\\', \\'elapsed_ms\\': 6055, \\'rag_content\\': \\'Source: de17dd0dd7eabff1:cc35f490\\\\nLLM observability tools: Monitoring, debugging, and improving AI systems Dave Davies 24 min read Â· Aug 22, 2025 -- Listen Share LLM observability is crucial for maintaining the operational health of applications powered by large language models. As AI systems become more complex and widely deployed, having visibility into their behavior is increasingly important. Observability tools provide comprehensive insight into all layers of an LLM-powered application, helping teams monitor performance, debug issues, and ensure outputs remain safe and reliable. Press enter or click to view image in full size By capturing everything from system metrics to model inputs and outputs, ... anomalies. This gives engineers actionable insights to fix inaccuracies, optimize performance, and uphold safety standards. In short, LLM observability creates a feedback loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to d\\\\n\\\\n---\\\\n\\\\nSource: 09ad15b0683646b8:cc35f490\\\\nck loop that turns raw model behavior into useful information for improving your application. LLM observability vs. LLM monitoring Itâ€™s important to distinguish observability from monitoring in the context of LLM applications. LLM monitoring typically focuses on the â€œwhatâ€ â€” it tracks key performance metrics and system health indicators to ensure the service is up and responsive. For example, monitoring will measure metrics such as API response time, error rates, request throughput, and token usage counts. If something goes ... wrong; observability helps you understand exactly what happened inside the system and how to fix it. Both are necessary â€” monitoring provides early warnings, while observability provides deep diagnosis â€” but observability offers the comprehensive visibility that LLM applications especially need. Challenges addressed by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability too\\\\n\\\\n---\\\\n\\\\nSource: a11a9e62cab8284b:cc35f490\\\\nt overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without ... observability solutions To solve the challenges above, an effective LLM observability solution provides several key capabilities. At the core is real-time performance monitoring across the entire system. This means the tool tracks metrics such as response latency, throughput of requests, error rates, and resource usage (CPU, memory, GPU, or API tokens) in real time. With these insights, teams can immediately spot performance degradation â€” for example, if the average response time of the model starts creeping up or if the error rate exceeds a threshold. Real-time monitoring ensures that any latency spikes, timeouts, or bottlenecks in the LLM or its ... tools integrate checks for content safety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content mo\\\\n\\\\n---\\\\n\\\\nSource: 6b08b29bc2b9891d:cc35f490\\\\nd by LLM observability tools Large language model applications face a range of challenges that traditional software doesnâ€™t, and LLM observability tools are designed to address these issues. One major problem is hallucinations â€” when an LLM generates answers that sound plausible but are factually incorrect or completely made-up. For example, an LLM might confidently provide a wrong ... external API call holding things up? LLM observability ties together data from all components, so teams can pinpoint if a particular step (like a database search for context or a third-party API call) is causing the delay. Similarly, failures or errors in a pipeline can be tricky to reproduce given the complexity of LLM systems. Observability tools trace each step of a request, making it easier to debug when something goes wrong in a multi-step process. Cost overruns are another issue addressed by observability. Many LLM services (such as OpenAIâ€™s API) charge based on token usage or compute time. Without\\\\n\\\\n---\\\\n\\\\nSource: 724c404f6a885694:cc35f490\\\\nsafety and compliance. This may involve scanning model outputs with profanity or hate speech detectors, bias evaluators, or using AI-driven content moderation APIs. A good observability platform might, for example, automatically tag any response that seems to contain personally identifiable information or that violates certain ethical guidelines. In regulated industries, observability also means keeping an audit trail â€” the tool should log all prompts and responses securely so that if thereâ€™s ever a question or incident, thereâ€™s a record to review. Features like PII redaction (masking sensitive user data in logs) and access control become ... LLM observability tools As the demand for LLM observability has grown, a number of tools and platforms have emerged to help developers monitor and debug their language model applications. Each tool has its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this sp\\\\n\\\\n---\\\\n\\\\nSource: 06f031e91c9c0236:cc35f490\\\\nheir applications in just a few lines of code and immediately gain end-to-end visibility and confidence in their modelâ€™s behavior. The tutorial illustrated how easy it is to get started with Weave and how it can be leveraged for tasks ranging from real-time monitoring to quality assurance and ethical compliance. Looking ahead, LLM observability tools will likely ... know they can catch mistakes and iterate quickly. Tools like W&B Weave are at the forefront of this effort, providing the means to monitor, debug, and improve LLM applications in one unified environment. By adopting LLM observability practices now, developers and organizations set themselves up for success â€” ensuring that their AI systems remain performant, trustworthy, and aligned with user needs as both the models and usage grow. As these observability tools evolve, they will undoubtedly play a central role in the future of AI deployments, helping us harness the full potential of LLMs while keeping a watchful eye on\\\\n\\\\n---\\\\n\\\\nSource: 9758ab006e75cff3:cc35f490\\\\n Weave, instrumented our LLM call with one line ( @weave.op ), ran the application to log data, optionally added an evaluation, and then ... bottlenecks in your LLM application. Suppose your app has higher-than-desired latency; by looking at traces, you might discover that a database lookup or a particular model call is the slow part. With that insight, you could try caching results, using a smaller model for that step, or otherwise improving the architecture. Likewise, Weaveâ€™s token usage tracking can show if certain prompts are excessively long (costly) â€” prompting you to optimize prompt formats to reduce token counts. Over time, you can use Weave metrics to verify that optimizations are effective (e.g., see average latency drop after a change, or a reduction ... when you have a robust observability tool in place. Continuous evaluation and model improvement: You can use Weave not just for monitoring but for ongoing evaluation even after deployment. Letâ€™s say you regularly update your\\\\n\\\\n---\\\\n\\\\nSource: d7c061743dc2e1ee:cc35f490\\\\n on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and compliance features) gives confidence to companies that need to monitor LLMs in production while meeting security requirements. In summary, W&B Weave is a preferred observability tool because it combines comprehensive tracing, real-time performance monitoring, automated output evaluation, and an intuitive UI in one platform. It effectively bridges the gap between model development ... enter your API key Once installed and authenticated, initialize Weave in your script or notebook by calling weave.init() at the start of your program. This sets up a new Weave project where all your logs and traces will be stored. For example: import weave # Initialize a Weave project (give a name for this observability run) weave.init(project=\"llm-observability-demo\") After this initialization, Weave is ready to capture data. It will associate all logs with the pro\\\\n\\\\n---\\\\n\\\\nSource: 2d3c24ba61c5ba18:cc35f490\\\\nas its own focus and strengths, but all aim to shed light on the â€œblack boxâ€ of LLMs in production. Some of the leading observability tools in this space include Lunary, LangSmith, and W&B Weave, among others. Lunary Lunary is an open-source platform that provides analytics and tracing for LLM-powered apps. Itâ€™s designed to be model-agnostic, meaning it can work with any LLM provider or architecture. Lunary focuses on ... and intermediate actions (like calls to tools or external APIs). This provides end-to-end tracing for chain-of-thought style applications. LangSmith also emphasizes prompt evaluation and testing. It allows developers to systematically evaluate their prompts and model outputs by using datasets of queries and expected answers. In the LangSmith dashboard, you can see how often your modelâ€™s responses match the expected results or where it might be failing. It supports scoring of outputs for accuracy, completeness, or custom metrics you define. Additionally, LangSmith prov\\\\n\\\\n---\\\\n\\\\nSource: e5ee1e1a6d3f0816:cc35f490\\\\nthen to an LLM, and then into some post-processing, ... means W&B Weave not only tells you that an answer was given, but also gives an indication of whether that answer was good or potentially problematic â€” all in real time. Few other observability tools have this level of integrated quality checking. Seamless integration and agnostic support are also key features of W&B Weave. It is designed to be framework-agnostic and model-agnostic: whether youâ€™re using OpenAIâ€™s GPT-4 via API, an open-source model on Hugging Face, or a LangChain application, Weave can plug in. The tool provides simple SDK methods and decorators to instrument your code. For instance, by adding a ... in a W&B report format) to communicate your findings. The collaborative features (permissions, team projects, comments) make it a strong choice for enterprise teams working on LLM deployments. On top of all that, W&Bâ€™s focus on enterprise readiness (with secure cloud hosting, or on-prem deployment if needed, and complian\\'}',\n",
       "       'system_prompt': 'You are a specialized agent in a larger workflow.\\n\\nYour role:\\n- PURPOSE: Perform technical and editorial review of the draft.\\n- GOAL: Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n\\n- EXPECTED_RESULT: A structured review with strengths, issues, and concrete suggestions.\\n\\nGeneral behaviour:\\n- Be precise and concise unless the task requires extended output.\\n- Use clear structure (headings/bullets) when helpful.\\n- If you are calling tools, interpret their outputs carefully and explain your reasoning.\\n',\n",
       "       'temperature': 0.7,\n",
       "       'max_new_tokens': 16000,\n",
       "       'stream': False},\n",
       "      'outputs': {'output': '# Review of the Blog Post: \"Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\"\\n\\n---\\n\\n## âœ… Strengths\\n\\n- **Clear structure**: The blog post is well-organized with logical sections and a clear progression from introduction to conclusion.\\n- **Relevant content**: It effectively covers the core aspects of observability in LLM systems, including tracing, metrics, feedback loops, and content safety.\\n- **Practical tone**: The tone is practical and slightly opinionated, as requested, making it accessible for intermediate ML engineers.\\n- **Use of examples**: The post uses concrete examples (e.g., hallucinations, performance bottlenecks, cost overruns) to illustrate key points.\\n- **Actionable insights**: The post provides actionable insights for developers, such as using tools like LangSmith, W&B Weave, and Lunary.\\n- **Alignment with query**: The content thoroughly addresses the importance of observability in LLM systems and covers all requested components (tracing, metrics, feedback loops, failure patterns).\\n\\n---\\n\\n## ğŸš¨ Issues and Suggestions\\n\\n### 1. **Factual Inaccuracies and Missing Explanations**\\n\\n- **Tool Mentioned Without Context**: The post mentions tools like **LangSmith**, **W&B Weave**, and **Lunary**, but it doesnâ€™t explain what they are or how they are used in the context of LLM observability. This could confuse readers who are unfamiliar with these tools.  \\n  **Suggestion**: Add brief descriptions of each tool and its role in LLM observability, or provide links to their documentation for further reading.\\n\\n- **Overgeneralization of Observability**: The post uses the term \"observability\" broadly, but it doesnâ€™t clearly differentiate between **observability**, **monitoring**, and **debugging**. This can lead to confusion.  \\n  **Suggestion**: Clarify the distinction between these concepts, especially in the section on \"LLM Observability vs. LLM Monitoring.\"\\n\\n- **Limited Discussion on Feedback Loops**: While the post mentions feedback loops, it doesnâ€™t go into detail about how they are implemented or their impact on model behavior.  \\n  **Suggestion**: Expand on the concept of feedback loops, including examples like **reinforcement learning from human feedback (RLHF)** and **active learning**.\\n\\n- **Ambiguity Around \"Common Failure Patterns\"**: The post lists failure patterns (e.g., hallucinations, performance bottlenecks, cost overruns) but doesnâ€™t provide enough depth on how observability helps detect or mitigate these issues.  \\n  **Suggestion**: Include specific examples of how observability tools detect and address these failure patterns (e.g., how a tool identifies a hallucination and triggers a model retraining).\\n\\n---\\n\\n### 2. **Stylistic and Clarity Issues**\\n\\n- **Repetition of Terms**: The term \"observability\" is used repeatedly, which can make the post feel redundant.  \\n  **Suggestion**: Vary the language to avoid repetition. For example, use synonyms like \"visibility,\" \"diagnostic insights,\" or \"behavioral analysis.\"\\n\\n- **Unclear Transition Between Sections**: The transition from the section on \"Observability Stack for LLMs\" to \"The Role of Observability in AI Ethics and Trust\" is abrupt.  \\n  **Suggestion**: Add a brief paragraph or sentence that connects these sections, explaining how observability supports both technical and ethical aspects of AI.\\n\\n- **Lack of Visual Aids**: The post is text-heavy and lacks visual aids such as diagrams or charts that could help explain complex concepts like tracing or feedback loops.  \\n  **Suggestion**: Suggest including visual aids (e.g., flowcharts of a request lifecycle, graphs of performance metrics) in future versions of the post.\\n\\n- **Some Sentences Are Too Long**: Some sentences are long and complex, making them difficult to parse.  \\n  **Suggestion**: Break up long sentences into shorter ones for better readability. For example:\\n  > \"While monitoring might tell you that a model is returning incorrect answers, observability would tell you why the model is generating those answersâ€”whether it\\'s due to a faulty prompt, a data bias, or a misalignment in the training data.\"\\n  â†’\\n  > \"While monitoring might tell you that a model is returning incorrect answers, observability goes further. It tells you why the model is generating those answers. The cause could be a faulty prompt, data bias, or a misalignment in the training data.\"\\n\\n---\\n\\n### 3. **Unclarified Concepts**\\n\\n- **\"Feedback Loops\"**: The term is used without a clear definition. The post mentions that feedback loops involve collecting data on model performance and using it to improve the model, but it doesnâ€™t explain how this process works in practice.  \\n  **Suggestion**: Define \"feedback loops\" more clearly, perhaps with an example such as:\\n  > \"A feedback loop in the context of LLMs involves collecting data on model performance (e.g., incorrect outputs, bias) and using that data to retrain or fine-tune the model. This process is often referred to as reinforcement learning from human feedback (RLHF).\"\\n\\n- **\"Content Safety and Compliance\"**: The post touches on content safety and compliance but doesnâ€™t provide enough detail on how observability tools enforce these standards.  \\n  **Suggestion**: Expand on the role of observability in content safety, including examples of how tools detect and flag problematic content (e.g., profanity, bias, hallucinations).\\n\\n---\\n\\n## âœ… Summary of Actionable Edits\\n\\n| Issue | Suggestion |\\n|------|------------|\\n| Tool descriptions are too vague | Add brief descriptions of tools like LangSmith, W&B Weave, and Lunary |\\n| Overgeneralization of observability | Clarify the difference between observability, monitoring, and debugging |\\n| Limited discussion on feedback loops | Expand on how feedback loops are implemented and their impact |\\n| Ambiguity around failure patterns | Provide specific examples of how observability detects and mitigates failure patterns |\\n| Repetition of terms | Vary the language to avoid repetition |\\n| Unclear transitions between sections | Add connecting sentences between sections |\\n| Lack of visual aids | Suggest including diagrams or charts for better clarity |\\n| Long sentences | Break up long sentences for better readability |\\n| Unclarified concepts | Define \"feedback loops\" and \"content safety\" more clearly |\\n\\n---\\n\\n## âœ… Final Assessment\\n\\nThe blog post is well-written, informative, and aligned with the original query. It provides a clear argument for the importance of observability in LLM systems and covers the key components (tracing, metrics, feedback loops, content safety). However, there are opportunities for improvement in terms of clarity, structure, and depth of explanation. With the suggested edits, the post can be made even more effective for its target audience of intermediate ML engineers.'},\n",
       "      'meta': {},\n",
       "      'ok': True,\n",
       "      'error': None,\n",
       "      'logs': []}],\n",
       "    'meta': {'agent_type': 'generic_agent',\n",
       "     'agent_config': {'allow_input_pruning': True,\n",
       "      'repair_with_llm': True,\n",
       "      'strict_tool_call': False,\n",
       "      'temperature': 0.7,\n",
       "      'max_new_tokens': 16000,\n",
       "      'return_stream_by_default': False,\n",
       "      'retry': {'max_route_retries': 2,\n",
       "       'max_tool_retries': 1,\n",
       "       'backoff_sec': 0.7},\n",
       "      'strict_json': True,\n",
       "      'max_json_repair_attempts': 1},\n",
       "     'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit',\n",
       "     'toolkit': False,\n",
       "     'log_steps': True}}}},\n",
       " 'final': {'draft': \"# Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\\n\\n## Introduction: The Rise of LLMs and the Black Box Problem\\n\\nLarge language models (LLMs) have rapidly transformed the landscape of artificial intelligence, becoming integral to applications across industries such as finance, healthcare, customer service, and content creation. Their ability to understand and generate human-like text has made them a cornerstone of modern AI systems. However, as these models scale in complexity and usage, a critical challenge has emerged: the **black box problem**.\\n\\nThe black box problem refers to the lack of transparency in how LLMs process inputs, generate outputs, and make decisions. Unlike traditional machine learning models, which often have more interpretable structures, LLMs are inherently complex and opaque. This opacity makes it difficult for developers and stakeholders to understand how the model behaves, especially in production environments where reliability, safety, and compliance are paramount.\\n\\nTraditional monitoring and debugging approaches, which are well-suited for conventional software systems, fall short when applied to LLMs. These approaches typically focus on system-level metrics such as CPU usage, memory consumption, and response times. However, they fail to capture the internal behavior of the model itselfâ€”what the model is thinking, how it processes data, and whether it is generating safe, accurate, or ethical outputs.\\n\\nThis is where **observability** comes in. Observability is not just about monitoring; it is about **understanding** the behavior of a system in real time. For LLMs, observability means having the ability to track requests end-to-end, measure performance across all layers, and create feedback loops to continuously improve the model's behavior.\\n\\nIn this blog post, we will explore the concept of observability in the context of LLM systems. We will break down its key componentsâ€”tracing, metrics, feedback loops, and content safetyâ€”and discuss how they contribute to building transparent, reliable, and ethical AI systems. We will also examine common failure patterns in LLM systems and how observability can help address them.\\n\\nBy the end of this post, you will understand why observability is not just a nice-to-haveâ€”it is essential for the future of AI.\\n\\n---\\n\\n## Understanding Observability in LLM Systems\\n\\n### What is Observability?\\n\\nObservability is the ability to understand the internal state of a system based on its external outputs. In the context of LLM systems, observability goes beyond traditional monitoring. It involves **tracking the flow of requests through the model**, **measuring performance at every layer**, and **analyzing the model's behavior in real time**.\\n\\nUnlike monitoring, which is reactive and focuses on predefined metrics, observability is **proactive and holistic**. It provides a **comprehensive view of the system**, enabling developers to not only detect issues but also understand why they are happening.\\n\\nFor example, while monitoring might tell you that a model is returning incorrect answers, observability would tell you **why** the model is generating those answersâ€”whether it's due to a faulty prompt, a data bias, or a misalignment in the training data.\\n\\n### The Observability Stack for LLMs\\n\\nAn effective observability strategy for LLM systems consists of several key components. These components work together to provide a complete picture of the model's behavior and performance. Let's explore each of them:\\n\\n#### 1. Tracing\\n\\n**Tracing** is the process of tracking a request through the entire system, from the initial user input to the final output. In LLM systems, tracing is especially important because it allows developers to understand how the model processes inputs, interacts with external tools, and generates outputs.\\n\\nFor example, consider an application that uses an LLM to answer customer questions. The request might start with a user query, then pass through a database lookup, an API call, and finally the LLM itself. Tracing would allow developers to see the entire journey of the request, including any delays or errors that occurred at each step.\\n\\nTools like **LangSmith** and **W&B Weave** provide end-to-end tracing capabilities, allowing developers to visualize the flow of requests and identify performance bottlenecks.\\n\\n#### 2. Metrics\\n\\n**Metrics** are quantitative measures of system performance and behavior. In the context of LLM systems, metrics can include:\\n\\n- **Response latency**: How long it takes the model to generate a response.\\n- **Token usage**: The number of tokens processed by the model.\\n- **Error rates**: The percentage of requests that result in errors.\\n- **Throughput**: The number of requests handled per second.\\n- **Resource usage**: CPU, memory, and GPU usage.\\n\\nThese metrics provide valuable insights into the performance of the model and help developers identify issues such as latency spikes, resource exhaustion, or inefficient token usage.\\n\\nFor instance, if a model starts to take longer than expected to generate responses, a developer might use metrics to determine whether the issue is due to a slow API call, a misconfigured model, or an overload of incoming requests.\\n\\n#### 3. Feedback Loops\\n\\n**Feedback loops** are mechanisms that allow the model to learn from its own behavior. In the context of LLM systems, feedback loops involve **collecting data on model performance** and using it to **improve the model over time**.\\n\\nFor example, if a model generates incorrect answers, developers can use feedback loops to **retrain the model on the incorrect outputs**, helping it to avoid making the same mistakes in the future. This process is often referred to as **model fine-tuning** or **reinforcement learning from human feedback (RLHF)**.\\n\\nTools like **W&B Weave** and **LangSmith** provide features that enable developers to collect and analyze feedback data, making it easier to iterate on model improvements.\\n\\n#### 4. Content Safety and Compliance\\n\\nAs LLMs become more integrated into production applications, **content safety and compliance** have become a major concern. These systems must ensure that the model's outputs are **accurate, safe, and aligned with ethical and legal standards**.\\n\\nObservability plays a crucial role in addressing these concerns. By **monitoring the model's outputs in real time**, developers can detect and flag potentially harmful or unethical content. This includes identifying **hallucinations**, **bias**, **profanity**, and **inappropriate content**.\\n\\nFor example, a healthcare application using an LLM to generate patient summaries must ensure that the model does not disclose sensitive information or make false claims. Observability tools can help detect such issues by **scanning model outputs for PII (Personally Identifiable Information)** or **violations of ethical guidelines**.\\n\\nIn regulated industries, **observability also means maintaining an audit trail**. This ensures that if there is ever a question or incident, there is a record to review. Features like **PII redaction** and **access control** are essential for maintaining compliance in such environments.\\n\\n---\\n\\n## The Role of Observability in AI Ethics and Trust\\n\\n### Building Trust Through Transparency\\n\\nTrust is a fundamental component of any AI system. For users, developers, and stakeholders, trust is built through **transparency, reliability, and accountability**. Observability plays a crucial role in building trust by providing **visibility into the model's behavior**.\\n\\nWhen users know that an AI system is **transparent and accountable**, they are more likely to trust its outputs. This is especially important in high-stakes applications such as **healthcare, finance, and legal services**, where the consequences of incorrect outputs can be severe.\\n\\nObservability also helps build **trust among developers and data scientists**. By providing **real-time insights into model behavior**, observability enables developers to **debug issues more effectively** and **improve the model's performance over time**.\\n\\n### Ensuring Ethical AI\\n\\nEthical AI is not just about avoiding harm; it's also about **ensuring that AI systems are fair, just, and aligned with societal values**. Observability supports ethical AI by providing **insights into model behavior**, **detecting biases**, and **ensuring compliance with ethical guidelines**.\\n\\nFor example, if an LLM is used in a hiring application, it must be **free from biases that could disadvantage certain groups**. Observability tools can help detect such biases by **analyzing the model's outputs for fairness** and **flagging any discriminatory patterns**.\\n\\nIn addition, observability helps ensure that **AI systems are aligned with ethical guidelines**. For instance, if an LLM is used to generate content for a news website, it must be **free from misinformation and bias**. Observability tools can help detect such issues by **scanning model outputs for factual accuracy** and **flagging any potential misinformation**.\\n\\n---\\n\\n## Common Failure Patterns in LLM Systems\\n\\n### Hallucinations\\n\\nOne of the most common failure patterns in LLM systems is **hallucination**, where the model generates **false or made-up information**. This can be a significant issue, especially in applications where **accuracy is critical**.\\n\\nFor example, an LLM used in a customer support application might generate **incorrect information about product features**, leading to **confusion and dissatisfaction** among users. Observability tools can help detect hallucinations by **monitoring model outputs** and **flagging any inconsistencies**.\\n\\n### Performance Bottlenecks\\n\\nAs LLMs scale in complexity and usage, **performance bottlenecks** can emerge. These bottlenecks can be due to a variety of factors, including **slow API calls**, **inefficient token usage**, or **resource exhaustion**.\\n\\nObservability tools can help identify these bottlenecks by **tracking performance metrics** and **analyzing the flow of requests**. For example, if a model starts to take longer than expected to generate responses, a developer might use observability tools to **identify the slow API call** or **optimize token usage**.\\n\\n### Cost Overruns\\n\\nMany LLM services charge based on **token usage or compute time**, making **cost overruns** a significant concern. Without observability, it is difficult to **track and optimize costs**.\\n\\nObservability tools can help prevent cost overruns by **tracking token usage in real time** and **identifying any excessive usage**. For example, if a model is generating **long or unnecessary prompts**, observability tools can **flag these prompts** and **suggest optimizations**.\\n\\n---\\n\\n## The Future of Observability in AI\\n\\nAs LLMs continue to evolve and become more integrated into production systems, **observability will play an increasingly important role** in building **transparent, reliable, and ethical AI**.\\n\\nTools like **W&B Weave**, **LangSmith**, and **Lunary** are at the forefront of this movement, providing **comprehensive observability solutions** for LLM systems. These tools not only help developers **monitor and debug their models** but also enable them to **improve model performance over time**.\\n\\nIn the future, we can expect to see **more advanced observability tools** that provide **even deeper insights into model behavior**, **automated feedback loops**, and **real-time ethical compliance checks**. These tools will be essential for **building AI systems that are not only powerful but also trustworthy**.\\n\\n---\\n\\n## Conclusion\\n\\nIn conclusion, **observability is not just a technical necessityâ€”it is a strategic imperative** for the future of AI. As LLMs become more complex and widely used, **the need for transparency and accountability has never been greater**.\\n\\nBy adopting an **observability-first approach**, organizations can **gain real-time insights into model behavior**, **detect and fix issues quickly**, and **ensure that their AI systems are safe, reliable, and ethical**.\\n\\nIn the next section, we will explore **practical examples of observability in action**, including **how to implement observability in your own LLM projects** and **best practices for building observability-first AI systems**. Stay tuned for more insights on this critical topic.\",\n",
       "  'review': '# Review of the Blog Post: \"Stop Treating LLMs as Black Boxes: The Case for Observability-First AI Systems\"\\n\\n---\\n\\n## âœ… Strengths\\n\\n- **Clear structure**: The blog post is well-organized with logical sections and a clear progression from introduction to conclusion.\\n- **Relevant content**: It effectively covers the core aspects of observability in LLM systems, including tracing, metrics, feedback loops, and content safety.\\n- **Practical tone**: The tone is practical and slightly opinionated, as requested, making it accessible for intermediate ML engineers.\\n- **Use of examples**: The post uses concrete examples (e.g., hallucinations, performance bottlenecks, cost overruns) to illustrate key points.\\n- **Actionable insights**: The post provides actionable insights for developers, such as using tools like LangSmith, W&B Weave, and Lunary.\\n- **Alignment with query**: The content thoroughly addresses the importance of observability in LLM systems and covers all requested components (tracing, metrics, feedback loops, failure patterns).\\n\\n---\\n\\n## ğŸš¨ Issues and Suggestions\\n\\n### 1. **Factual Inaccuracies and Missing Explanations**\\n\\n- **Tool Mentioned Without Context**: The post mentions tools like **LangSmith**, **W&B Weave**, and **Lunary**, but it doesnâ€™t explain what they are or how they are used in the context of LLM observability. This could confuse readers who are unfamiliar with these tools.  \\n  **Suggestion**: Add brief descriptions of each tool and its role in LLM observability, or provide links to their documentation for further reading.\\n\\n- **Overgeneralization of Observability**: The post uses the term \"observability\" broadly, but it doesnâ€™t clearly differentiate between **observability**, **monitoring**, and **debugging**. This can lead to confusion.  \\n  **Suggestion**: Clarify the distinction between these concepts, especially in the section on \"LLM Observability vs. LLM Monitoring.\"\\n\\n- **Limited Discussion on Feedback Loops**: While the post mentions feedback loops, it doesnâ€™t go into detail about how they are implemented or their impact on model behavior.  \\n  **Suggestion**: Expand on the concept of feedback loops, including examples like **reinforcement learning from human feedback (RLHF)** and **active learning**.\\n\\n- **Ambiguity Around \"Common Failure Patterns\"**: The post lists failure patterns (e.g., hallucinations, performance bottlenecks, cost overruns) but doesnâ€™t provide enough depth on how observability helps detect or mitigate these issues.  \\n  **Suggestion**: Include specific examples of how observability tools detect and address these failure patterns (e.g., how a tool identifies a hallucination and triggers a model retraining).\\n\\n---\\n\\n### 2. **Stylistic and Clarity Issues**\\n\\n- **Repetition of Terms**: The term \"observability\" is used repeatedly, which can make the post feel redundant.  \\n  **Suggestion**: Vary the language to avoid repetition. For example, use synonyms like \"visibility,\" \"diagnostic insights,\" or \"behavioral analysis.\"\\n\\n- **Unclear Transition Between Sections**: The transition from the section on \"Observability Stack for LLMs\" to \"The Role of Observability in AI Ethics and Trust\" is abrupt.  \\n  **Suggestion**: Add a brief paragraph or sentence that connects these sections, explaining how observability supports both technical and ethical aspects of AI.\\n\\n- **Lack of Visual Aids**: The post is text-heavy and lacks visual aids such as diagrams or charts that could help explain complex concepts like tracing or feedback loops.  \\n  **Suggestion**: Suggest including visual aids (e.g., flowcharts of a request lifecycle, graphs of performance metrics) in future versions of the post.\\n\\n- **Some Sentences Are Too Long**: Some sentences are long and complex, making them difficult to parse.  \\n  **Suggestion**: Break up long sentences into shorter ones for better readability. For example:\\n  > \"While monitoring might tell you that a model is returning incorrect answers, observability would tell you why the model is generating those answersâ€”whether it\\'s due to a faulty prompt, a data bias, or a misalignment in the training data.\"\\n  â†’\\n  > \"While monitoring might tell you that a model is returning incorrect answers, observability goes further. It tells you why the model is generating those answers. The cause could be a faulty prompt, data bias, or a misalignment in the training data.\"\\n\\n---\\n\\n### 3. **Unclarified Concepts**\\n\\n- **\"Feedback Loops\"**: The term is used without a clear definition. The post mentions that feedback loops involve collecting data on model performance and using it to improve the model, but it doesnâ€™t explain how this process works in practice.  \\n  **Suggestion**: Define \"feedback loops\" more clearly, perhaps with an example such as:\\n  > \"A feedback loop in the context of LLMs involves collecting data on model performance (e.g., incorrect outputs, bias) and using that data to retrain or fine-tune the model. This process is often referred to as reinforcement learning from human feedback (RLHF).\"\\n\\n- **\"Content Safety and Compliance\"**: The post touches on content safety and compliance but doesnâ€™t provide enough detail on how observability tools enforce these standards.  \\n  **Suggestion**: Expand on the role of observability in content safety, including examples of how tools detect and flag problematic content (e.g., profanity, bias, hallucinations).\\n\\n---\\n\\n## âœ… Summary of Actionable Edits\\n\\n| Issue | Suggestion |\\n|------|------------|\\n| Tool descriptions are too vague | Add brief descriptions of tools like LangSmith, W&B Weave, and Lunary |\\n| Overgeneralization of observability | Clarify the difference between observability, monitoring, and debugging |\\n| Limited discussion on feedback loops | Expand on how feedback loops are implemented and their impact |\\n| Ambiguity around failure patterns | Provide specific examples of how observability detects and mitigates failure patterns |\\n| Repetition of terms | Vary the language to avoid repetition |\\n| Unclear transitions between sections | Add connecting sentences between sections |\\n| Lack of visual aids | Suggest including diagrams or charts for better clarity |\\n| Long sentences | Break up long sentences for better readability |\\n| Unclarified concepts | Define \"feedback loops\" and \"content safety\" more clearly |\\n\\n---\\n\\n## âœ… Final Assessment\\n\\nThe blog post is well-written, informative, and aligned with the original query. It provides a clear argument for the importance of observability in LLM systems and covers the key components (tracing, metrics, feedback loops, content safety). However, there are opportunities for improvement in terms of clarity, structure, and depth of explanation. With the suggested edits, the post can be made even more effective for its target audience of intermediate ML engineers.'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324b84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f682b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9f986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50884f2f",
   "metadata": {},
   "source": [
    "# GRAPH TEST WITH RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10c548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84383012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2026-01-04 12:03:56\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2026-01-04 12:03:56\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No embedder provided to RAGAgent, using default SentenceTransformerEmbedder\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 12:03:56\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | Initializing Embedding model. This may take a moment...\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 12:03:57\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 12:03:57\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2026-01-04 12:03:57\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | Ingesting knowledge base for GraphAgent...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74c203545a44a89a4df26c9f05c8a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccd53d063dd4729b77a168789c10fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3a6977ce364adb9bfb33eb20ba999e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae272c980de4e40a8b750ea7c6f372a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04842877cb04875b324f25c871ef2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59c20210edc42d280f15beb11ab4fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fb9c8144b74adbb7fb7357654a1c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5a69e2066b41a1a197300b6384b253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10008369ecad466fa44dcfe803fb22bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592a7ae600684e13b2e917723377be14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff7ab768f62494994e0b09e613cf9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8692566822f04e918e92c347e6eb4849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb3a3cb32134d41aae4e807fe733de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deb8da2db2c40f683ac45fd3a4481db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9728f0b83ae4bb7869128a41cd6ddfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d1d7b8d44e41c7bee3d09454909114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cfb8a3611c46348ba08826639667af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fd68871ea34eb9b21993a037029227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ec821a58714dcd9b55e9aa92e56bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m[\u001b[0m\u001b[1;36mgraph_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Executing Graph\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.graph.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'graph_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.graph.execute'\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m780s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mnormalize_request\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'normalize_request'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mnormalize_request\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'normalize_request'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'normalize_request'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m856s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mnormalize_request\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'normalize_request'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m860s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mnormalize_request\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node normalize_request output to exports/normalize_request_20260104_120403.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m489s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting RAGAgent retrieve\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'wide'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'aggregation'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'retrieve code snippets and references related to the `neurosurger/agents/graph/executor.py` module, including file paths, short quoted snippets, and what each \u001b[0m\n",
      "\u001b[1;32msnippet proves. Include additional references and callers for \u001b[0m\u001b[1;32mdepth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32mdeep\u001b[0m\u001b[1;32m. Also, document the `DataProcessor` module with overview, symbol map, call flow, diagram, usage examples, and gotchas.'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m50\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32f04e797d84af7a45815fc7c08d477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m50\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m49582\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m34564\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m396s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed RAGAgent retrieve!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m34564\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mretrieve_module_evidence\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'retrieve_module_evidence'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mretrieve_module_evidence\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'retrieve_module_evidence'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'retrieve_module_evidence'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m18.\u001b[0m\u001b[2m093s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mretrieve_module_evidence\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'retrieve_module_evidence'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m18.\u001b[0m\u001b[2m095s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mretrieve_module_evidence\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node retrieve_module_evidence output to exports/retrieve_module_evidence_20260104_120407.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m9\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m9\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m491s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting RAGAgent retrieve\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m10\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'small'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'short_list'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'Identify key symbols such as public classes, key methods, important dataclasses, and notable exceptions from the neurosurfer/agents/graph/executor.py module, \u001b[0m\n",
      "\u001b[1;32mincluding their signature, purpose, and definition location.'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m10\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433853c028cb446e94c24b55e050a19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m10\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m8977\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m8977\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m10\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m812s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed RAGAgent retrieve!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m8977\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mbuild_symbol_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m11\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mbuild_symbol_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m12\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m12\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m14.\u001b[0m\u001b[2m143s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mbuild_symbol_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m11\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m14.\u001b[0m\u001b[2m147s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mbuild_symbol_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node build_symbol_map output to exports/build_symbol_map_20260104_120431.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m13\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m13\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m432s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;33mWARNING: Rag in ReAct Agents is currently not supported. Use tools instead. Skipping RAG\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1;33mğŸ§  Thinking\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;36m Tracing Start!\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mtrace_call_flow\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting react_agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m14\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'trace_call_flow'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mtrace_call_flow\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m15\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'trace_call_flow'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mThe \u001b[0m\u001b[3;90mprovided \u001b[0m\u001b[3;90mdependency \u001b[0m\u001b[3;90mcontext \u001b[0m\u001b[3;90mincludes \u001b[0m\u001b[3;90msymbols \u001b[0m\u001b[3;90mfrom \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90m'neurosurfer/agents/graph/executor.py'\u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90mmodule \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mrelated \u001b[0m\u001b[3;90mmodules. \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mwill \u001b[0m\u001b[3;90muse \u001b[0m\u001b[3;90mthis \u001b[0m\u001b[3;90minformation \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90midentify \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mtypical \u001b[0m\u001b[3;90mcall \u001b[0m\u001b[3;90mchain, \u001b[0m\u001b[3;90mdependencies, \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mcallers \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mmodule.\u001b[0m\n",
      "        \n",
      "        \u001b[3;90mAction: \u001b[0m\u001b[3;90mNone\u001b[0m            \u001b[1;32mINFO: Generating final answer with \u001b[0m\u001b[1;32mlanguage\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mlength\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mhistory_len\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m1\u001b[0m\n",
      "\n",
      "        \u001b[1;32mFinal Response:\u001b[0m\n",
      "        \u001b[1;37m1\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m \u001b[0m\u001b[1;37mA \u001b[0m\u001b[1;37mshort \u001b[0m\u001b[1;37mcall-flow \u001b[0m\u001b[1;37mnarrative:  \u001b[0m\n",
      "        \u001b[1;37mThe \u001b[0m\u001b[1;37m`GraphExecutor` \u001b[0m\u001b[1;37mclass \u001b[0m\u001b[1;37min \u001b[0m\u001b[1;37m`neurosurfer/agents/graph/executor.py` \u001b[0m\u001b[1;37mis \u001b[0m\u001b[1;37mthe \u001b[0m\u001b[1;37mmain \u001b[0m\u001b[1;37mentry \u001b[0m\u001b[1;37mpoint \u001b[0m\u001b[1;37mfor \u001b[0m\u001b[1;37mexecuting \u001b[0m\u001b[1;37mgraph-based \u001b[0m\u001b[1;37mworkflows. \u001b[0m\u001b[1;37mIt \u001b[0m\u001b[1;37minteracts \u001b[0m\u001b[1;37mwith \u001b[0m\u001b[1;37m`GraphNode` \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37m`Graph` \u001b[0m\u001b[1;37mclasses \u001b[0m\u001b[1;37mto \u001b[0m\u001b[1;37mmanage \u001b[0m\u001b[1;37mnode \u001b[0m\u001b[1;37mexecution. \u001b[0m\u001b[1;37mThe \u001b[0m\u001b[1;37mexecution \u001b[0m\u001b[1;37mprocess \u001b[0m\u001b[1;37minvolves \u001b[0m\u001b[1;37mcoordinating \u001b[0m\u001b[1;37mwith \u001b[0m\u001b[1;37m`PythonExecTool` \u001b[0m\u001b[1;37mfor \u001b[0m\u001b[1;37mcode \u001b[0m\u001b[1;37mexecution, \u001b[0m\u001b[1;37mhandling \u001b[0m\u001b[1;37m`ToolCall` \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37m`ToolCallResponse` \u001b[0m\u001b[1;37mobjects \u001b[0m\u001b[1;37mto \u001b[0m\u001b[1;37mtrack \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37mreturn \u001b[0m\u001b[1;37mresults. \u001b[0m\u001b[1;37mThe \u001b[0m\u001b[1;37m`ReactAgentResponse` \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37m`AgentResponse` \u001b[0m\u001b[1;37mclasses \u001b[0m\u001b[1;37mare \u001b[0m\u001b[1;37mused \u001b[0m\u001b[1;37mto \u001b[0m\u001b[1;37mencapsulate \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37mpropagate \u001b[0m\u001b[1;37mresponses \u001b[0m\u001b[1;37mthrough \u001b[0m\u001b[1;37mthe \u001b[0m\u001b[1;37msystem. \u001b[0m\u001b[1;37mThe \u001b[0m\u001b[1;37m`GateDecision` \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37m`RAGResult` \u001b[0m\u001b[1;37mclasses \u001b[0m\u001b[1;37mmay \u001b[0m\u001b[1;37mbe \u001b[0m\u001b[1;37minvolved \u001b[0m\u001b[1;37min \u001b[0m\u001b[1;37mrouting \u001b[0m\u001b[1;37mdecisions \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37mcontext \u001b[0m\u001b[1;37maugmentation \u001b[0m\u001b[1;37mduring \u001b[0m\u001b[1;37mthe \u001b[0m\u001b[1;37mexecution \u001b[0m\u001b[1;37mprocess.\u001b[0m\n",
      "        \n",
      "        \u001b[1;37m2\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m \u001b[0m\u001b[1;37mBullet \u001b[0m\u001b[1;37mlist \u001b[0m\u001b[1;37mof \u001b[0m\u001b[1;37mdependencies \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mimports \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37mruntime \u001b[0m\u001b[1;37mcalls\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m:  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`ToolCallResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`StructuredResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`AgentResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`ToolCall` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/react/agent.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`ReactAgentResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/react/agent.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`CodeAgent` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/code/agent.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`PythonExecTool` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`GateDecision` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/services/rag/models.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`RAGResult` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/services/rag/models.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \n",
      "        \u001b[1;37m3\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m \u001b[0m\u001b[1;37mCallers \u001b[0m\u001b[1;37mlist:  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`CodeAgent` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/code/agent.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`ReactAgentResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/react/agent.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`Graph` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/graph/graph.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`GraphNode` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/graph/node.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`PythonExecTool` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`ToolCall` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/agents/react/agent.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`ToolCallResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`StructuredResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`AgentResponse` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/tools/python_exec_tool.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`GateDecision` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/services/rag/models.py`\u001b[0m\u001b[1;37m)\u001b[0m\u001b[1;37m  \u001b[0m\n",
      "        \u001b[1;37m- \u001b[0m\u001b[1;37m`RAGResult` \u001b[0m\u001b[1;37m(\u001b[0m\u001b[1;37mfrom \u001b[0m\u001b[1;37m`neurosurfer/services/rag/models.py`\u001b[0m\u001b[1;37m)\u001b[0m        \n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m15\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'trace_call_flow'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m14.\u001b[0m\u001b[2m556s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mtrace_call_flow\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m14\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'trace_call_flow'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m14.\u001b[0m\u001b[2m561s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mtrace_call_flow\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed react_agent!\u001b[0m\n",
      "\n",
      "\u001b[1;36m Tracing End!\u001b[0m\n",
      "\n",
      "    \u001b[1;32mINFO: Exported node trace_call_flow output to exports/trace_call_flow_20260104_120447.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m16\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m16\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m920s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting RAGAgent retrieve\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m17\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'medium'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'short_list'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'code examples using GraphExecutor class from neurosurfer/agents/graph/executor.py with notes on real vs pseudo-usage'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m20\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436351a5f50c43f99bdc2dc2f16cb074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m20\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m19612\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m19612\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m17\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m402s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed RAGAgent retrieve!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m19612\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mdraft_usage_examples\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m18\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft_usage_examples'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mdraft_usage_examples\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m19\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft_usage_examples'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m19\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft_usage_examples'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m11.\u001b[0m\u001b[2m357s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mdraft_usage_examples\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m18\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft_usage_examples'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m11.\u001b[0m\u001b[2m361s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mdraft_usage_examples\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node draft_usage_examples output to exports/draft_usage_examples_20260104_120506.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m20\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m20\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m511s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mgenerate_mermaid_diagram\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m21\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'generate_mermaid_diagram'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mgenerate_mermaid_diagram\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m22\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'generate_mermaid_diagram'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m22\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'generate_mermaid_diagram'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m723s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mgenerate_mermaid_diagram\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m21\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'generate_mermaid_diagram'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m726s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mgenerate_mermaid_diagram\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node generate_mermaid_diagram output to exports/generate_mermaid_diagram_20260104_120520.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m23\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m23\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m379s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_doc_page\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m24\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_doc_page'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_doc_page\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m25\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_doc_page'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m25\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_doc_page'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m19.\u001b[0m\u001b[2m463s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_doc_page\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m24\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_doc_page'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m19.\u001b[0m\u001b[2m470s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_doc_page\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node write_doc_page output to exports/write_doc_page_20260104_120526.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m26\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m26\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m214s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting RAGAgent retrieve\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m27\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'medium'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'short_list'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'Verify claims about the GraphExecutor module against the provided evidence and identify unsupported statements with proposed edits'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m20\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\n",
      "\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d619a7ae1a5482dbd08c2283f2d261f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m20\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m17252\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m17252\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m27\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m455s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed RAGAgent retrieve!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m17252\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mgroundedness_check\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m28\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'groundedness_check'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mgroundedness_check\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m29\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'groundedness_check'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m29\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'groundedness_check'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m008s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mgroundedness_check\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m28\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'groundedness_check'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m010s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mgroundedness_check\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "\u001b[91mERROR   \u001b[0m | \u001b[90m2026-01-04 12:05:49\u001b[0m | \u001b[96mexecutor.py:_run_node\u001b[0m | Node groundedness_check failed: `temperature` (=0.0) has to be a strictly positive float, otherwise your next token scores will be invalid. If you're looking for greedy decoding strategies, set `do_sample=False`.\n",
      "    \u001b[1;31mERROR: Error executing node finalize_docs: object of type \u001b[0m\u001b[1;31m'NoneType'\u001b[0m\u001b[1;31m has no \u001b[0m\u001b[1;31mlen\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;33mWARNING: Returning partial results from executed nodes\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported graph traces to exports/traces_20260104_120549.json\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.graph.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'graph_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.graph.execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m108.\u001b[0m\u001b[2m600s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mgraph_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Graph Execution Complete!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "from neurosurfer.agents.graph import GraphAgent, ManagerConfig\n",
    "\n",
    "export_dir = \"exports\"\n",
    "shutil.rmtree(export_dir, ignore_errors=True)\n",
    "\n",
    "graph_agent = GraphAgent(\n",
    "    llm=LLM,\n",
    "    graph_yaml=\"workflows/rag_code_docs_workflow.yml\",\n",
    "    toolkit=None,\n",
    "    knowledge_sources=[\"/home/nomi/workspace/neurosurfer/neurosurfer\"],\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.3,\n",
    "        max_new_tokens=8000,\n",
    "    ),\n",
    "    export_dir=export_dir,\n",
    "    manager_llm=LLM,\n",
    "    log_traces=True,\n",
    "    log_traces_format=\"markdown\"\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "# graph_inputs = {\n",
    "#     \"topic_title\": \"The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models\",\n",
    "#     \"query\": \"Compose a 1000-1500 word blog on why tool-routing layers matter more than scaling LLM size, covering practical design patterns, examples, and tradeoffs.\",\n",
    "#     \"audience\": \"Intermediate ML engineers\",\n",
    "#     \"tone\": \"Practical and slightly opinionated\",\n",
    "# }\n",
    "\n",
    "# graph_inputs = {\n",
    "#     \"query\": \"How do I reduce hallucinations in a local LLM setup?\",\n",
    "#     \"format\": \"bullet\"\n",
    "# }\n",
    "\n",
    "graph_inputs={\n",
    "    \"module_path\": \"neurosurfer/agents/graph/executor.py\",\n",
    "    \"doc_title\": \"GraphExecutor â€” Design & API\",\n",
    "    \"audience\": \"Neurosurfer contributors\",\n",
    "    \"depth\": \"deep\",\n",
    "}\n",
    "\n",
    "results = graph_agent.run(inputs=graph_inputs, reset_tracer=True)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6e1992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results.logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "271688ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"step_id\": 1,\n",
      "      \"kind\": \"graph.execute\",\n",
      "      \"label\": \"agent.graph.execute\",\n",
      "      \"node_id\": null,\n",
      "      \"agent_id\": \"graph_agent\",\n",
      "      \"started_at\": 1767513429.469487,\n",
      "      \"duration_ms\": 5600,\n",
      "      \"inputs\": {\n",
      "        \"inputs\": {\n",
      "          \"module_path\": \"neurosurfer/agents/graph/executor.py\",\n",
      "          \"doc_title\": \"GraphExecutor \\u2014 Design & API\",\n",
      "          \"audience\": \"Neurosurfer contributors\",\n",
      "          \"depth\": \"deep\"\n",
      "        },\n",
      "        \"manager_temperature\": null,\n",
      "        \"manager_max_new_tokens\": null\n",
      "      },\n",
      "      \"outputs\": {},\n",
      "      \"meta\": {},\n",
      "      \"ok\": true,\n",
      "      \"error\": null,\n",
      "      \"logs\": [\n",
      "        {\n",
      "          \"ts\": 1767513433.4393473,\n",
      "          \"message\": \"Exported node normalize_request output to exports/normalize_request_20260104_115711.md\",\n",
      "          \"data\": {},\n",
      "          \"type\": \"info\"\n",
      "        },\n",
      "        {\n",
      "          \"ts\": 1767513435.0642612,\n",
      "          \"message\": \"Rag in ReAct Agents is currently not supported. Use tools instead. Skipping RAG...\",\n",
      "          \"data\": {},\n",
      "          \"type\": \"warning\"\n",
      "        },\n",
      "        {\n",
      "          \"ts\": 1767513435.0661583,\n",
      "          \"message\": \"Error executing node build_symbol_map: object of type 'NoneType' has no len()\",\n",
      "          \"data\": {},\n",
      "          \"type\": \"error\"\n",
      "        },\n",
      "        {\n",
      "          \"ts\": 1767513435.067421,\n",
      "          \"message\": \"Returning partial results from executed nodes...\",\n",
      "          \"data\": {},\n",
      "          \"type\": \"warning\"\n",
      "        },\n",
      "        {\n",
      "          \"ts\": 1767513435.0694516,\n",
      "          \"message\": \"Exported graph traces to exports/traces_20260104_115715.json\",\n",
      "          \"data\": {},\n",
      "          \"type\": \"info\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 2,\n",
      "      \"kind\": \"llm.call\",\n",
      "      \"label\": \"manager.compose_user_prompt\",\n",
      "      \"node_id\": null,\n",
      "      \"agent_id\": \"manager\",\n",
      "      \"started_at\": 1767513429.4723449,\n",
      "      \"duration_ms\": 1973,\n",
      "      \"inputs\": {\n",
      "        \"system_prompt_len\": 778,\n",
      "        \"user_prompt_len\": 1121,\n",
      "        \"mode\": \"text\",\n",
      "        \"dependency_results\": \"(none)\"\n",
      "      },\n",
      "      \"outputs\": {\n",
      "        \"output\": \"Restate the documentation task by specifying the module to document and the six required artifacts: overview, symbol map, call flow, diagram, usage examples, and gotchas. Keep it concise and reusable.  \\n\\nOutput must be a single paragraph, no markdown, no extra text.  \\n\\nConstraints: Max 150 words. Use the provided module path, doc title, audience, and depth to inform the restatement.\\n\\n<BEGIN_DEPENDENCY_CONTEXT>\\n(none)\\n<END_DEPENDENCY_CONTEXT>\"\n",
      "      },\n",
      "      \"meta\": {},\n",
      "      \"ok\": true,\n",
      "      \"error\": null,\n",
      "      \"logs\": []\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 3,\n",
      "      \"kind\": \"agent\",\n",
      "      \"label\": \"agent.run\",\n",
      "      \"node_id\": null,\n",
      "      \"agent_id\": \"normalize_request\",\n",
      "      \"started_at\": 1767513431.449855,\n",
      "      \"duration_ms\": 1986,\n",
      "      \"inputs\": {\n",
      "        \"agent_type\": \"Agent\",\n",
      "        \"has_toolkit\": false,\n",
      "        \"strict_tool_call\": false,\n",
      "        \"structured\": false,\n",
      "        \"stream\": false\n",
      "      },\n",
      "      \"outputs\": {},\n",
      "      \"meta\": {},\n",
      "      \"ok\": true,\n",
      "      \"error\": null,\n",
      "      \"logs\": []\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 4,\n",
      "      \"kind\": \"llm.call\",\n",
      "      \"label\": \"agent.free_text_call\",\n",
      "      \"node_id\": null,\n",
      "      \"agent_id\": \"normalize_request\",\n",
      "      \"started_at\": 1767513431.4518723,\n",
      "      \"duration_ms\": 1982,\n",
      "      \"inputs\": {\n",
      "        \"system_prompt_len\": 622,\n",
      "        \"user_prompt_len\": 445,\n",
      "        \"user_prompt\": \"Restate the documentation task by specifying the module to document and the six required artifacts: overview, symbol map, call flow, diagram, usage examples, and gotchas. Keep it concise and reusable.  \\n\\nOutput must be a single paragraph, no markdown, no extra text.  \\n\\nConstraints: Max 150 words. Use the provided module path, doc title, audience, and depth to inform the restatement.\\n\\n<BEGIN_DEPENDENCY_CONTEXT>\\n(none)\\n<END_DEPENDENCY_CONTEXT>\",\n",
      "        \"system_prompt\": \"You are a specialized agent in a larger workflow.\\n\\nYour role:\\n- PURPOSE: Normalize inputs and restate the documentation task.\\n- GOAL: Restate what module we are documenting and the artifacts to produce: (1) overview, (2) symbol map, (3) call flow, (4) diagram, (5) usage examples, (6) gotchas. Keep it short and reusable downstream.\\n\\n- EXPECTED_RESULT: A concise normalized task statement.\\n\\nGeneral behaviour:\\n- Be precise and concise unless the task requires extended output.\\n- Use clear structure (headings/bullets) when helpful.\\n- If you are calling tools, interpret their outputs carefully and explain your reasoning.\\n\",\n",
      "        \"temperature\": 0.2,\n",
      "        \"max_new_tokens\": 1024,\n",
      "        \"stream\": false\n",
      "      },\n",
      "      \"outputs\": {\n",
      "        \"output\": \"Document the module located at the provided path with the title specified, targeting the identified audience. The documentation must include an overview of the module's purpose and functionality, a symbol map detailing all components and their relationships, a call flow illustrating execution paths, a diagram for visual clarity, usage examples demonstrating common scenarios, and a section highlighting potential gotchas or common pitfalls. Ensure the output is concise, structured, and reusable for downstream processes.\"\n",
      "      },\n",
      "      \"meta\": {},\n",
      "      \"ok\": true,\n",
      "      \"error\": null,\n",
      "      \"logs\": []\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 5,\n",
      "      \"kind\": \"llm.call\",\n",
      "      \"label\": \"manager.compose_user_prompt\",\n",
      "      \"node_id\": null,\n",
      "      \"agent_id\": \"manager\",\n",
      "      \"started_at\": 1767513433.4418535,\n",
      "      \"duration_ms\": 1619,\n",
      "      \"inputs\": {\n",
      "        \"system_prompt_len\": 778,\n",
      "        \"user_prompt_len\": 1847,\n",
      "        \"mode\": \"text\",\n",
      "        \"dependency_results\": \"**NODE: normalize_request**: Document the module located at the provided path with the title specified, targeting the identified audience. The documentation must include an overview of the module's purpose and functionality, a symbol map detailing all components and their relationships, a call flow illustrating execution paths, a diagram for visual clarity, usage examples demonstrating common scenarios, and a section highlighting potential gotchas or common pitfalls. Ensure the output is concise, structured, and reusable for downstream processes.\\n\"\n",
      "      },\n",
      "      \"outputs\": {\n",
      "        \"output\": \"Retrieve evidence for the module at 'neurosurger/agents/graph/executor.py' by searching through the ingested repo. Include the module header, key classes/functions, and references from other files. If depth=deep, include more detailed references. Output an evidence pack with file paths, quoted snippets, and what each snippet proves.\\n\\n<BEGIN_DEPENDENCY_CONTEXT>\\n<BEGIN_DEP node_id=normalize_request>\\nDocument the module located at the provided path with the title specified, targeting the identified audience. The documentation must include an overview of the module's purpose and functionality, a symbol map detailing all components and their relationships, a call flow illustrating execution paths, a diagram for visual clarity, usage examples demonstrating common scenarios, and a section highlighting potential gotchas or common pitfalls. Ensure the output is concise, structured, and reusable for downstream processes.\\n<END_DEP node_id=normalize_request>\\n\\n<END_DEPENDENCY_CONTEXT>\"\n",
      "      },\n",
      "      \"meta\": {},\n",
      "      \"ok\": true,\n",
      "      \"error\": null,\n",
      "      \"logs\": []\n",
      "    }\n",
      "  ],\n",
      "  \"meta\": {\n",
      "    \"agent_type\": \"graph_agent\",\n",
      "    \"graph\": {\n",
      "      \"name\": \"rag_code_docs_workflow\",\n",
      "      \"description\": \"RAG-first workflow to generate documentation for a target neurosurfer module. Nodes with rag=true must ground outputs in retrieved code from the ingested repo directory.\\n\",\n",
      "      \"inputs\": [\n",
      "        {\n",
      "          \"name\": \"module_path\",\n",
      "          \"type\": \"string\",\n",
      "          \"required\": true,\n",
      "          \"description\": \"Repo-relative path, \"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"doc_title\",\n",
      "          \"type\": \"string\",\n",
      "          \"required\": true,\n",
      "          \"description\": null\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"audience\",\n",
      "          \"type\": \"string\",\n",
      "          \"required\": true,\n",
      "          \"description\": null\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"depth\",\n",
      "          \"type\": \"string\",\n",
      "          \"required\": true,\n",
      "          \"description\": \"low | medium | deep\"\n",
      "        }\n",
      "      ],\n",
      "      \"nodes\": [\n",
      "        {\n",
      "          \"id\": \"normalize_request\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"base\",\n",
      "          \"purpose\": \"Normalize inputs and restate the documentation task.\",\n",
      "          \"goal\": \"Restate what module we are documenting and the artifacts to produce: (1) overview, (2) symbol map, (3) call flow, (4) diagram, (5) usage examples, (6) gotchas. Keep it short and reusable downstream.\\n\",\n",
      "          \"expected_result\": \"A concise normalized task statement.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [],\n",
      "          \"mode\": \"text\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": false,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 1024,\n",
      "            \"temperature\": 0.2,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"retrieve_module_evidence\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"react\",\n",
      "          \"purpose\": \"Retrieve evidence for the target module.\",\n",
      "          \"goal\": \"Using RAG over the ingested repo, retrieve the most relevant chunks for module_path: - module header/docstring/imports - key classes/functions and their signatures - any references to this module from other files (callers) Output an evidence pack with: - file paths - small quoted snippets (short) - what each snippet proves If depth=deep, include more references/callers.\\n\",\n",
      "          \"expected_result\": \"An evidence pack grounded in retrieved code snippets.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"normalize_request\"\n",
      "          ],\n",
      "          \"mode\": \"text\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": true,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 2048,\n",
      "            \"temperature\": 0.2,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"build_symbol_map\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"react\",\n",
      "          \"purpose\": \"Build a structured API/symbol map from evidence.\",\n",
      "          \"goal\": \"From retrieved code, list key symbols: - public classes, key methods, key functions - important dataclasses/models/constants - notable exceptions / error paths For each symbol include: - signature (as seen in code) - purpose (1\\u20132 lines) - where defined (file + line hint if available) Keep it grounded; if unsure, mark as \\\"uncertain\\\".\\n\",\n",
      "          \"expected_result\": \"Structured symbol map.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"retrieve_module_evidence\"\n",
      "          ],\n",
      "          \"mode\": \"structured\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": true,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 2048,\n",
      "            \"temperature\": 0.2,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"trace_call_flow\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"react\",\n",
      "          \"purpose\": \"Extract runtime call flow and cross-module interactions.\",\n",
      "          \"goal\": \"Using RAG, identify the typical call chain for the module: - main entry points (e.g., run/execute/stream/etc.) - interactions with related modules/classes - data passed between components Output: 1) a short call-flow narrative 2) a bullet list of dependencies (imports and runtime calls) 3) 'callers' list: where this module is invoked from (if found)\\n\",\n",
      "          \"expected_result\": \"Call-flow description + dependency bullets + callers list.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"build_symbol_map\"\n",
      "          ],\n",
      "          \"mode\": \"text\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": true,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 2048,\n",
      "            \"temperature\": 0.2,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"generate_mermaid_diagram\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"base\",\n",
      "          \"purpose\": \"Turn the discovered call-flow into a Mermaid diagram.\",\n",
      "          \"goal\": \"Create a Mermaid flowchart (not sequence diagram) showing the main components and calls. Keep it readable: 8\\u201318 nodes max. Use meaningful node labels. Return ONLY a mermaid code block.\\n\",\n",
      "          \"expected_result\": \"Mermaid diagram code block.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"trace_call_flow\"\n",
      "          ],\n",
      "          \"mode\": \"text\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": false,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 2048,\n",
      "            \"temperature\": 0.2,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"draft_usage_examples\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"react\",\n",
      "          \"purpose\": \"Produce 2\\u20133 grounded usage examples.\",\n",
      "          \"goal\": \"Using RAG, find real usage patterns in the repo (tests, examples, call sites). Produce 2\\u20133 short code snippets that demonstrate how to use the module. If no real usage exists, generate minimal pseudo-usage but mark it clearly as pseudo.\\n\",\n",
      "          \"expected_result\": \"2\\u20133 usage examples with notes on whether they are real or pseudo.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"trace_call_flow\"\n",
      "          ],\n",
      "          \"mode\": \"text\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": true,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 2048,\n",
      "            \"temperature\": 0.2,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"write_doc_page\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"base\",\n",
      "          \"purpose\": \"Write a single clean Markdown docs page.\",\n",
      "          \"goal\": \"Write an MkDocs-ready Markdown page with sections: - Overview - Responsibilities & Non-goals - Key Types / Functions (from symbol map) - Call Flow (from trace_call_flow) - Mermaid Diagram - Usage Examples - Gotchas / Edge Cases - Evidence (list file paths + brief snippet references) Keep it dev-facing and concise.\\n\",\n",
      "          \"expected_result\": \"A Markdown docs page.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"normalize_request\",\n",
      "            \"retrieve_module_evidence\",\n",
      "            \"build_symbol_map\",\n",
      "            \"trace_call_flow\",\n",
      "            \"generate_mermaid_diagram\",\n",
      "            \"draft_usage_examples\"\n",
      "          ],\n",
      "          \"mode\": \"text\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": false,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 2400,\n",
      "            \"temperature\": 0.3,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"groundedness_check\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"react\",\n",
      "          \"purpose\": \"Strict hallucination check against retrieved evidence.\",\n",
      "          \"goal\": \"Using RAG, verify claims in the doc page: - Identify statements not supported by retrieved code snippets. - For each, propose a concrete edit: remove/replace/mark as assumption. Output a strict QA report.\\n\",\n",
      "          \"expected_result\": \"Structured QA report listing unsupported claims and fixes.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"write_doc_page\",\n",
      "            \"retrieve_module_evidence\"\n",
      "          ],\n",
      "          \"mode\": \"structured\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": true,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 2048,\n",
      "            \"temperature\": 0.0,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"finalize_docs\",\n",
      "          \"description\": null,\n",
      "          \"kind\": \"base\",\n",
      "          \"purpose\": \"Apply fixes and output final docs.\",\n",
      "          \"goal\": \"Apply groundedness_check fixes to the doc page. If something cannot be grounded, remove it or label as assumption. Append a short 'Next improvements' section with suggested future lookups.\\n\",\n",
      "          \"expected_result\": \"Final Markdown documentation page.\",\n",
      "          \"tools\": [],\n",
      "          \"depends_on\": [\n",
      "            \"write_doc_page\",\n",
      "            \"groundedness_check\"\n",
      "          ],\n",
      "          \"mode\": \"text\",\n",
      "          \"output_schema\": null,\n",
      "          \"model\": null,\n",
      "          \"rag\": false,\n",
      "          \"policy\": {\n",
      "            \"max_new_tokens\": 3000,\n",
      "            \"temperature\": 0.2,\n",
      "            \"retries\": null,\n",
      "            \"timeout_s\": null,\n",
      "            \"allow_input_pruning\": null,\n",
      "            \"repair_with_llm\": null,\n",
      "            \"strict_tool_call\": null,\n",
      "            \"strict_json\": null,\n",
      "            \"max_json_repair_attempts\": null,\n",
      "            \"skip_special_tokens\": null,\n",
      "            \"return_stream_by_default\": null,\n",
      "            \"log_internal_thoughts\": null\n",
      "          },\n",
      "          \"export\": true,\n",
      "          \"export_path\": null\n",
      "        }\n",
      "      ],\n",
      "      \"outputs\": [\n",
      "        \"retrieve_module_evidence\",\n",
      "        \"build_symbol_map\",\n",
      "        \"generate_mermaid_diagram\",\n",
      "        \"finalize_docs\"\n",
      "      ]\n",
      "    },\n",
      "    \"model\": \"/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit\",\n",
      "    \"toolkit\": false,\n",
      "    \"log_steps\": true\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# results.traces.model_dump()\n",
    "\n",
    "import json\n",
    "print(json.dumps(results.traces.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19863b",
   "metadata": {},
   "source": [
    "## Doc Generation Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616aa999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-12-23 10:39:29\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-12-23 10:39:29\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No embedder provided to RAGAgent, using default SentenceTransformerEmbedder\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-23 10:39:29\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | Initializing Embedding model. This may take a moment...\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-23 10:39:31\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-23 10:39:31\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-23 10:39:31\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | Ingesting knowledge base for GraphAgent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m[\u001b[0m\u001b[1;36mgraph_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Executing Graph\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.graph.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'graph_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.graph.execute'\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m088s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'medium'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'single_fact'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'Identify the module root, key files, public objects, non-goals, and documentation entry points based on the provided module_path.'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m10\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\n",
      "\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m10\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m8449\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m8449\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m550s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed agent!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m8449\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mscope_module\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scope_module'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mscope_module\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scope_module'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scope_module'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m363s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mscope_module\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scope_module'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m364s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mscope_module\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node scope_module output to exports/scope_module_20251223_103936.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m643s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'medium'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'summary'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'Build a structured module_map JSON for the neurosurger_tracing_docs module, mapping main classes/functions, data models, call flows, configuration options, \u001b[0m\n",
      "\u001b[1;32mexamples, and edge cases based on the provided code context.'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m30\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 56.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m30\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m28445\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m28445\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m823s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed agent!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m28445\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mextract_module_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'extract_module_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mextract_module_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m9\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'extract_module_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m9\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'extract_module_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m10.\u001b[0m\u001b[2m159s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mextract_module_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'extract_module_map'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m10.\u001b[0m\u001b[2m160s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mextract_module_map\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node extract_module_map output to exports/extract_module_map_20251223_103945.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m10\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m10\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m891s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mplan_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m11\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mplan_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m12\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m12\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m13.\u001b[0m\u001b[2m800s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mplan_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m11\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m13.\u001b[0m\u001b[2m801s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mplan_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node plan_docs output to exports/plan_docs_20251223_103958.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m13\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m13\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m539s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m14\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'full'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'summary'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'Generate comprehensive Markdown documentation for the neurosurfer_tracing_docs module, including overview, components, flows, config, examples, and pitfalls, based \u001b[0m\n",
      "\u001b[1;32mon the provided plan and code facts.'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m50\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 58.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m49\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m47071\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m33594\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m14\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m921s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed agent!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m33594\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m15\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m16\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m16\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m47.\u001b[0m\u001b[2m506s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m15\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'write_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m47.\u001b[0m\u001b[2m508s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mwrite_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node write_docs output to exports/write_docs_20251223_104018.md\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Preparing Next Node\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m17\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m17\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m638s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmanager\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Next Node Ready For Execution!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieving context from knowledge base\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting agent\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m18\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieval plan: \u001b[0m\u001b[1;32mRetrievalPlan\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mmode\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'smart'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mscope\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'medium'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32manswer_breadth\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'summary'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32moptimized_query\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m'Review the neurosurfer_tracing_docs module documentation for correctness, completeness, and clarity. Identify strengths, issues, suggested edits, missing examples,\u001b[0m\n",
      "\u001b[1;32mand potential glossary additions. Ensure all APIs exist and match the code context, flag hallucinations, and propose concrete edits.'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mtop_k\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;32m30\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mnotes\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32mextra\u001b[0m\u001b[1;32m=\u001b[0m\u001b[1;3;32mNone\u001b[0m\u001b[1;32m)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 37.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Retrieved \u001b[0m\u001b[1;32m30\u001b[0m\u001b[1;32m documents\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Untrimmed context: \u001b[0m\u001b[1;32m26256\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mRAGAgent.retrieve\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Trimmed context: \u001b[0m\u001b[1;32m26256\u001b[0m\u001b[1;32m chars\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m18\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.rag.retrieve'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m575s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mmain_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed agent!\u001b[0m\n",
      "    \u001b[1;32mINFO: Retrieved context from knowledge base. Context length: \u001b[0m\u001b[1;32m26256\u001b[0m\u001b[1;32m chats\u001b[0m\n",
      "    \n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreview_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Thinking\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m19\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreview_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Starting llm.call\u001b[0m\u001b[1;36m...\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m20\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m20\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m15.\u001b[0m\u001b[2m710s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \u001b[1;36m[\u001b[0m\u001b[1;36mreview_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Completed llm.call!\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m19\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m15.\u001b[0m\u001b[2m712s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "    \u001b[1;36m[\u001b[0m\u001b[1;36mreview_docs\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m ğŸ§  Done!\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported node review_docs output to exports/review_docs_20251223_104111.md\u001b[0m\n",
      "    \u001b[1;32mINFO: Exported graph traces to exports/traces_20251223_104127.json\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.graph.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'graph_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.graph.execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m116.\u001b[0m\u001b[2m234s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[1;36mgraph_agent\u001b[0m\u001b[1;36m]\u001b[0m\u001b[1;36m Graph Execution Complete!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "from neurosurfer.agents.graph import GraphAgent, ManagerConfig\n",
    "\n",
    "export_dir = \"exports\"\n",
    "shutil.rmtree(export_dir, ignore_errors=True)\n",
    "\n",
    "knowledge_sources = [\"../neurosurfer/agents\"]\n",
    "graph_agent = GraphAgent(\n",
    "    llm=LLM,\n",
    "    graph_yaml=\"doc_gen_workflow.yml\",\n",
    "    toolkit=None,\n",
    "    knowledge_sources=knowledge_sources,\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.3,\n",
    "        max_new_tokens=4096,\n",
    "    ),\n",
    "    export_dir=export_dir,\n",
    "    manager_llm=LLM,\n",
    "    log_traces=True,\n",
    "    log_traces_format=\"text\"\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "graph_inputs = {\n",
    "    \"project_name\": \"neurosurfer_tracing_docs\",\n",
    "    \"module_path\": \"../neurosurfer/tracing\",\n",
    "    \"target_audience\": \"Intermediate ML engineers\",\n",
    "    \"tone\": \"Practical and concise\",\n",
    "    \"doc_depth\": \"deep\",\n",
    "    \"output_format\": \"mkdocs\"\n",
    "  }\n",
    "\n",
    "results = graph_agent.run(inputs=graph_inputs, reset_tracer=True)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766512d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad2c2b-4a95-4ac0-9727-4c746e97a629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ea014-d67c-4af9-b2f6-1a8d80d63b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
