{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b35214-7a1f-403c-9a7a-b42e481ab431",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go up one directory from `b/` to project root\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affc4a2e-d532-4dee-8b50-cab72fd229c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë                                                                  ‚ïë\n",
      "‚ïë ‚ñì‚ñì‚ñì‚ñì‚ñì   ‚ñì‚ñì‚ñì‚ñì                                  ‚ñì‚ñì‚ñì                ‚ïë\n",
      "‚ïë  ‚ñì‚ñì ‚ñì‚ñì   ‚ñì‚ñì  ‚ñì‚ñì‚ñì‚ñì ‚ñì  ‚ñì ‚ñì ‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì ‚ñì  ‚ñì ‚ñì ‚ñì  ‚ñì   ‚ñì‚ñì‚ñì‚ñì ‚ñì ‚ñì       ‚ïë\n",
      "‚ïë  ‚ñì‚ñì  ‚ñì‚ñì  ‚ñì‚ñì  ‚ñì‚ñÅ‚ñÅ‚ñì ‚ñì  ‚ñì ‚ñì‚ñì‚ñè ‚ñì  ‚ñì ‚ñì‚ñÅ  ‚ñì  ‚ñì ‚ñì‚ñì‚ñè ‚ñì‚ñì‚ñì  ‚ñì‚ñÅ‚ñÅ‚ñì ‚ñì‚ñì        ‚ïë\n",
      "‚ïë  ‚ñì‚ñì   ‚ñì‚ñì ‚ñì‚ñì  ‚ñì    ‚ñì  ‚ñì ‚ñì   ‚ñì  ‚ñì   ‚ñì ‚ñì  ‚ñì ‚ñì    ‚ñì   ‚ñì    ‚ñì         ‚ïë\n",
      "‚ïë ‚ñì‚ñì‚ñì‚ñì   ‚ñì‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì   ‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì    ‚ñì   ‚ñì‚ñì‚ñì‚ñì ‚ñì         ‚ïë\n",
      "‚ïë ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ‚ïë\n",
      "‚ïë Orchestrate Agents - RAG - SQL Tools - Multi-LLM - FastAPI Ready ‚ïë\n",
      "‚ïë Faster builds, clearer flows, production-first                   ‚ïë\n",
      "‚ïë                                                                  ‚ïë\n",
      "‚ïë Version: 0.1.0 | Python: 3.12.12                                 ‚ïë\n",
      "‚ïë OS: Linux 6.17.0-6-generic (x86_64)                              ‚ïë\n",
      "‚ïë Torch: 2.8.0   CUDA: yes (12.8)                                  ‚ïë\n",
      "‚ïë MPS: no (built: False)                                           ‚ïë\n",
      "‚ïë Transformers: 4.56.2   SentEmb: 5.1.1                            ‚ïë\n",
      "‚ïë Accelerate: 1.10.1   bnb: 0.48.1                                 ‚ïë\n",
      "‚ïë Unsloth: 2025.10.5                                               ‚ïë\n",
      "‚ïë                                                                  ‚ïë\n",
      "‚ïë Detected CUDA devices: NVIDIA GeForce RTX 5080                   ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomi/micromamba/envs/LLMs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/nomi/micromamba/envs/LLMs/lib/python3.12/importlib/__init__.py:90: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "#### Unsloth: `hf_xet==1.1.10` and `ipykernel>6.30.1` breaks progress bars. Disabling for now in XET.\n",
      "#### Unsloth: To re-enable progress bars, please downgrade to `ipykernel==6.30.1` or wait for a fix to\n",
      "https://github.com/huggingface/xet-core/issues/526\n",
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Unsloth: Xformers does not work in RTX 50X, Blackwell GPUs as of yet. Please build from source via\n",
      "```\n",
      "pip install ninja\n",
      "pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers\n",
      "```\n",
      "\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-17 23:21:24\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Initializing Transformers model.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-17 23:21:24\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Model is already quantized. Ignoring load_in_4bit=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-17 23:21:24\u001b[0m | \u001b[96mmodeling.py:get_balanced_memory\u001b[0m | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-17 23:21:25\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Transformers model initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from neurosurfer.models.chat_models.transformers import TransformersModel\n",
    "from neurosurfer import config \n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "DEFAULT_TRANSFORMERS_MODEL_PARAMS = dict({\n",
    "    \"model_name\": \"/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"max_seq_length\": 16_000,\n",
    "    \"load_in_4bit\": True,\n",
    "    \"enable_thinking\": False,  # main_gpu interpretation\n",
    "    \"verbose\": False\n",
    "})\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "LLM = TransformersModel(\n",
    "    **DEFAULT_TRANSFORMERS_MODEL_PARAMS,\n",
    "    stop_words=[\"Observation:\"],\n",
    "    logger = logging.getLogger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ff5798-3ed2-4b38-86cd-2498ca0e57be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?  \n",
      "Because they don't have the *guts*! üòÑ"
     ]
    }
   ],
   "source": [
    "# streaming response example\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "system_prompt = \"You are a joker.\"\n",
    "user_prompt = \"\"\"Tell me a short and light-hearted joke.\"\"\"\n",
    "\n",
    "stream_response = LLM.ask(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "md_display = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream_response:\n",
    "    chunk = chunk.choices[0].delta.content or \"\"\n",
    "    print(chunk, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808255b3",
   "metadata": {},
   "source": [
    "### Agent Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3030e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Response:\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m796s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m799s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "AI, or Artificial Intelligence, is the simulation of human intelligence in machines that are programmed to think, learn, and perform tasks typically requiring human cognition.\n"
     ]
    }
   ],
   "source": [
    "# agent normal response\n",
    "from neurosurfer.agents import Agent, AgentConfig\n",
    "# from neurosurfer.tracing import RichTracer\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    strict_tool_call=True,\n",
    "    return_stream_by_default=True,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=4096,\n",
    ")\n",
    "agent = Agent(llm=LLM, config=agent_config, log_traces=True)\n",
    "\n",
    "# normal response\n",
    "print(\"Normal Response:\")\n",
    "agent_response = agent.run(user_prompt=\"What is AI (one line)?\", stream=False)\n",
    "# print(agent_response.response)\n",
    "\n",
    "# # streaming response\n",
    "# print(\"\\n\\nStreaming Response:\")\n",
    "# for c in agent.run(user_prompt=\"What are top 3 applications of AI (one line)?\").response:\n",
    "#     print(c, flush=True, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d91b3b",
   "metadata": {},
   "source": [
    "**Structured Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344ffe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-17 23:21:27\u001b[0m | \u001b[96magent.py:run\u001b[0m     | `output_schema` provided with `stream=True`; forcing non-streaming structured output.\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m5.\u001b[0m\u001b[2m555s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m5.\u001b[0m\u001b[2m559s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Structured Response:\n",
      "{\n",
      "  \"definition\": \"Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding.\",\n",
      "  \"history\": \"The concept of AI dates back to ancient times with myths of artificial beings, but the formal study began in the 1950s. The term 'Artificial Intelligence' was coined in 1956 at the Dartmouth Conference. Since then, AI has evolved through various phases, including the rise of expert systems in the 1980s, the development of machine learning in the 1990s, and the current era of deep learning and neural networks.\",\n",
      "  \"modern_frameworks\": \"Modern frameworks such as TensorFlow, PyTorch, and Keras have revolutionized AI development by providing powerful tools for building and training machine learning models.\",\n",
      "  \"applications\": [\n",
      "    {\n",
      "      \"title\": \"Healthcare\",\n",
      "      \"description\": \"AI is used in healthcare for diagnostics, personalized treatment plans, and drug discovery.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Finance\",\n",
      "      \"description\": \"AI is used in finance for fraud detection, algorithmic trading, and risk management.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Autonomous Vehicles\",\n",
      "      \"description\": \"AI is used in autonomous vehicles for object recognition, decision-making, and navigation.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Structured Response examples\n",
    "class AIApplication(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "class AI(BaseModel):\n",
    "    definition: str\n",
    "    history: str\n",
    "    modern_frameworks: str\n",
    "    applications: list[AIApplication]\n",
    "\n",
    "user_query = \"What is AI and list 3 of its top application, and 3 concerns.\"\n",
    "agent_response = agent.run(user_prompt=user_query, output_schema=AI)\n",
    "\n",
    "print(\"\\n\\nStructured Response:\")\n",
    "print(agent_response.response.json_obj)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe4f0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_id': 2,\n",
       " 'kind': 'llm.call',\n",
       " 'label': 'agent.structured_call.first_pass',\n",
       " 'node_id': None,\n",
       " 'agent_id': 'main_agent',\n",
       " 'started_at': 1763407287.2884235,\n",
       " 'duration_ms': 5554,\n",
       " 'inputs': {'schema': 'AI',\n",
       "  'system_prompt_len': 52,\n",
       "  'user_prompt_len': 61,\n",
       "  'user_prompt': 'What is AI and list 3 of its top application, and 3 concerns.',\n",
       "  'system_prompt': \"You are a precise and rule-abiding assistant.  \\nYour task is to produce only a single valid JSON object following the schema below.\\n\\nStructured Output Contract:\\n- Output only JSON ‚Äî no markdown, code fences, or explanations.  \\n- JSON must be strictly valid (RFC 8259): use double quotes for all keys and string values.  \\n- Do not include extra keys or any text outside the JSON object.  \\n- All required fields must be present, even if empty.  \\n- Arrays must contain at least one object when applicable.  \\n- The JSON must be a single complete object (not pretty-printed, no trailing commas).  \\n- Failure to comply with this structure means your response is invalid.\\n\\nExpected JSON Structure:\\n{'$defs': {'AIApplication': {'properties': {'title': {'title': 'Title', 'type': 'string'}, 'description': {'title': 'Description', 'type': 'string'}}, 'required': ['title', 'description'], 'title': 'AIApplication', 'type': 'object'}}, 'properties': {'definition': {'title': 'Definition', 'type': 'string'}, 'history': {'title': 'History', 'type': 'string'}, 'modern_frameworks': {'title': 'Modern Frameworks', 'type': 'string'}, 'applications': {'items': {'$ref': '#/$defs/AIApplication'}, 'title': 'Applications', 'type': 'array'}}, 'required': ['definition', 'history', 'modern_frameworks', 'applications'], 'title': 'AI', 'type': 'object'}\\n\\nNow generate your response strictly following this contract.\\n\",\n",
       "  'temperature': 0.7,\n",
       "  'max_new_tokens': 4096,\n",
       "  'stream': False},\n",
       " 'outputs': {'model_response': '{\"definition\":\"Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding.\",\"history\":\"The concept of AI dates back to ancient times with myths of artificial beings, but the formal study began in the 1950s. The term \\'Artificial Intelligence\\' was coined in 1956 at the Dartmouth Conference. Since then, AI has evolved through various phases, including the rise of expert systems in the 1980s, the development of machine learning in the 1990s, and the current era of deep learning and neural networks.\",\"modern_frameworks\":\"Modern frameworks such as TensorFlow, PyTorch, and Keras have revolutionized AI development by providing powerful tools for building and training machine learning models.\",\"applications\":[{\"title\":\"Healthcare\",\"description\":\"AI is used in healthcare for diagnostics, personalized treatment plans, and drug discovery.\"},{\"title\":\"Finance\",\"description\":\"AI is used in finance for fraud detection, algorithmic trading, and risk management.\"},{\"title\":\"Autonomous Vehicles\",\"description\":\"AI is used in autonomous vehicles for object recognition, decision-making, and navigation.\"}]}',\n",
       "  'model_response_len': 1265},\n",
       " 'meta': {},\n",
       " 'ok': True,\n",
       " 'error': None,\n",
       " 'logs': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_response.traces.steps[1].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf48079",
   "metadata": {},
   "source": [
    "**Tool Calling Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440e9634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-17 23:21:32\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: calculator\n",
      "Agent with choice between tools and plain text:\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Returning plain response\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m927s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m930s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "AI stands for Artificial Intelligence, which refers to the simulation of human intelligence in machines that are programmed to think, learn, and solve problems. These systems can perform tasks such as understanding language, recognizing patterns, making decisions, and even creating art or music. AI can be categorized into narrow AI, which is designed for specific tasks, and general AI, which aims to perform any intellectual task a human can do.\n",
      "\n",
      "\n",
      "Agent with strict tool call:\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: calculator\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'num1'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m100\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'num2'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'operation'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'divide'\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m849s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'calculator'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m25.0\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m002s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m854s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "ToolCallResponse(selected_tool='calculator', inputs={'num1': 100.0, 'num2': 4.0, 'operation': 'divide'}, returns='25.0', final=False, extras={})\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "from neurosurfer.tools.tool_spec import ToolSpec, ToolParam, ToolReturn\n",
    "from neurosurfer.tools.base_tool import BaseTool, ToolResponse\n",
    "\n",
    "# Simple Calculator Tool\n",
    "class CalculatorTool(BaseTool):\n",
    "    spec = ToolSpec(\n",
    "        name=\"calculator\",\n",
    "        description=\"Perform basic arithmetic operations such as addition, subtraction, multiplication, and division.\",\n",
    "        when_to_use=\"Use this tool when you need to perform basic arithmetic operations.\",\n",
    "        inputs=[\n",
    "            ToolParam(name=\"num1\", type=\"float\", description=\"The first number.\", required=True),\n",
    "            ToolParam(name=\"num2\", type=\"float\", description=\"The second number.\", required=True),\n",
    "            ToolParam(name=\"operation\", type=\"string\", description=\"The operation to perform strictly one of ['add', 'subtract', 'multiply', 'divide'].\", required=True)\n",
    "        ],\n",
    "        returns=ToolReturn(type=\"float\", description=\"The result of the arithmetic operation.\")\n",
    "    )\n",
    "\n",
    "    def __init__(self, final_answer: bool = False):\n",
    "        self.final_answer = final_answer\n",
    "\n",
    "    def __call__(self, num1: float, num2: float, operation: str) -> ToolResponse:\n",
    "        if operation not in [\"add\", \"subtract\", \"multiply\", \"divide\"]:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=\"Invalid operation. Supported operations are 'add', 'subtract', 'multiply', and 'divide'.\",\n",
    "                extras={}\n",
    "            )\n",
    "        \n",
    "        if operation == \"divide\" and num2 == 0:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=\"Division by zero is not allowed.\",\n",
    "                extras={}\n",
    "            )\n",
    "        try:\n",
    "            num1 = float(num1)\n",
    "            num2 = float(num2)\n",
    "            if operation == \"add\":\n",
    "                result = num1 + num2\n",
    "            elif operation == \"subtract\":\n",
    "                result = num1 - num2\n",
    "            elif operation == \"multiply\":\n",
    "                result = num1 * num2\n",
    "            elif operation == \"divide\":\n",
    "                result = num1 / num2\n",
    "        except Exception as e:\n",
    "            return ToolResponse(\n",
    "                final_answer=False,\n",
    "                results=f\"An error occurred: {str(e)}\",\n",
    "                extras={}\n",
    "            )\n",
    "        \n",
    "        return ToolResponse(\n",
    "            final_answer=self.final_answer,\n",
    "            results=float(result),\n",
    "            extras={}\n",
    "        )\n",
    "\n",
    "calculator_tool = CalculatorTool()\n",
    "toolkit = Toolkit(tools=[calculator_tool])\n",
    "\n",
    "# print(\"Tool description:\")\n",
    "# print(calculator_tool.get_tool_description())\n",
    "# print()\n",
    "\n",
    "agent = Agent(llm=LLM, toolkit=toolkit, verbose=True)\n",
    "\n",
    "print(\"Agent with choice between tools and plain text:\")\n",
    "agent_response = agent.run(user_prompt=\"What is AI?\", strict_tool_call=False)\n",
    "# print(agent_response.response)\n",
    "\n",
    "print(\"\\n\\nAgent with strict tool call:\")\n",
    "agent_response = agent.run(user_prompt=\"What is one forth of a 100?\", strict_tool_call=True)\n",
    "print(agent_response.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e587eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a stateless tool router.\n",
      "Your task is to select exactly ONE tool from the catalog below and output STRICT JSON describing how to call it.\n",
      "\n",
      "Always respond with a single one-line valid JSON object:\n",
      "{\"tool\": \"<tool_name>\", \"inputs\": {<param>: <value>}}\n",
      "\n",
      "Rules:\n",
      "- Output MUST contain exactly the keys \"tool\" and \"inputs\".\n",
      "- Select at most one tool; if none applies or inputs are unclear, use:\n",
      "  {\"tool\": \"none\", \"inputs\": {}}\n",
      "- Use only parameters explicitly defined by that tool ‚Äî do NOT invent, rename, or add extra fields.\n",
      "- Include only required parameters unless an optional one is obviously needed.\n",
      "- Do NOT produce natural language; emit JSON only.\n",
      "\n",
      "TOOLS CATALOG:\n",
      "Available tools:\n",
      "Tool Name: `calculator`\n",
      "Description: Perform basic arithmetic operations such as addition, subtraction, multiplication, and division.\n",
      "When to use: Use this tool when you need to perform basic arithmetic operations.\n",
      "Tool Inputs:\n",
      "- `num1`: float (required) ‚Äî The first number.\n",
      "- `num2`: float (required) ‚Äî The second number.\n",
      "- `operation`: string (required) ‚Äî The operation to perform strictly one of ['add', 'subtract', 'multiply', 'divide'].\n",
      "Tool Return: float ‚Äî The result of the arithmetic operation.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step_json = agent_response.traces.steps[1].model_dump()\n",
    "# print(step_json)\n",
    "\n",
    "print()\n",
    "print(step_json[\"inputs\"][\"system_prompt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f992320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rich.console import Console\n",
    "\n",
    "# console = Console(force_jupyter=False, force_terminal=True, width=200)\n",
    "\n",
    "# msg = \"step.tool.execute label='agent.route_and_call.tool_execute' agent_id=None took 0.001s; error=False\"\n",
    "# console.print(f\"[dim]{msg}[/dim]\")\n",
    "# console.print(f\"[dim]{msg}[/dim]\")\n",
    "# console.print(f\"[cyan underline]Hello World!\")\n",
    "# console.print(\"FOO\", style=\"white on blue\")\n",
    "# console.print(\"[bold italic yellow on red blink]This text is impossible to read\")\n",
    "# console.print(\"[bold red]alert![/bold red] Something happened\")\n",
    "# console.print(\"[bold red]\\\\[trace]![/bold red] Something happened\")\n",
    "# console.print(\"[underline][bold green]Tracing Start![/bold green] Something happened\")\n",
    "# console.print(\"[bold]Bold[italic] bold and italic [/bold]italic[/italic]\")\n",
    "# console.print(\"Visit my [link=https://www.willmcgugan.com]blog[/link]!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b1381",
   "metadata": {},
   "source": [
    "## RAG wiring so the agent ‚Äúunderstands‚Äù the Neurosurf codebase\n",
    "\n",
    "You‚Äôll ingest the repo once, then run a retriever to answer code questions. The Planner can call the retriever first to form a precise implementation plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5bf38-1a5b-4ad1-be5f-b5073dbeaaf0",
   "metadata": {},
   "source": [
    "### FileReader and Chunker Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d61982-ac42-46b7-8a6b-bc3ed2248907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # scripts/index_repo_for_rag.py\n",
    "# from pathlib import Path\n",
    "# from neurosurfer.rag.ingestor import RAGIngestor\n",
    "# from neurosurfer.rag.chunker import Chunker\n",
    "# from neurosurfer.rag.filereader import FileReader\n",
    "# from neurosurfer.vectorstores.chroma import ChromaVectorStore\n",
    "# from neurosurfer.models.embedders.sentence_transformer import SentenceTransformerEmbedder\n",
    "\n",
    "# embedder = SentenceTransformerEmbedder(\"intfloat/e5-small-v2\")\n",
    "# vs = ChromaVectorStore(collection_name=\"neurosurf-repo\")\n",
    "# ing = RAGIngestor(\n",
    "#     embedder=embedder,\n",
    "#     vector_store=vs, \n",
    "#     chunker=Chunker(), \n",
    "#     file_reader=FileReader(),\n",
    "#     default_metadata={\"collection\": \"neurosurf\"}\n",
    "# )\n",
    "\n",
    "# root_dir = Path(os.getcwd()).parent.joinpath(\"neurosurfer\")\n",
    "# ing.add_directory(root_dir)  # the repo root\n",
    "# print(ing.build())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4c8c2",
   "metadata": {},
   "source": [
    "## Graph AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec7eb2",
   "metadata": {},
   "source": [
    "### YAML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3d42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key:  f443633b...\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-17 23:21:35\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n"
     ]
    }
   ],
   "source": [
    "# test web search tool\n",
    "from neurosurfer.tools.websearch import WebSearchTool, WebSearchConfig\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"SERPAPI_KEY\", \"API Key not found...\")\n",
    "print(\"API Key: \", f\"{api_key[:8]}...\")\n",
    "\n",
    "web_search_tool = WebSearchTool(\n",
    "    config=WebSearchConfig(\n",
    "        engine=\"serpapi\",\n",
    "        engine_kwargs={\"api_key\": api_key},\n",
    "        max_results=2,\n",
    "        enable_crawl=True,\n",
    "        max_crawl_results=1,\n",
    "        content_words_limit=1000,\n",
    "        content_limit_strategy=\"distributive\",\n",
    "    ),\n",
    "    llm=None,\n",
    ")\n",
    "\n",
    "# searches = web_search_tool(query=\"What is the capital of France?\")\n",
    "# print(searches)\n",
    "\n",
    "toolkit = Toolkit(tools=[web_search_tool])\n",
    "# print(toolkit.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346487b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = searches.results[\"results\"][0][\"content\"]\n",
    "# print(len(content.split()))\n",
    "\n",
    "# searches.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf1ccb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='blog_workflow' description='Example multi-agent workflow for writing and reviewing a technical blog using multiple specialized nodes (each node uses an Agent under the hood).\\n' inputs=[GraphInputSpec(name='topic_title', type='string', required=True, description=None), GraphInputSpec(name='query', type='string', required=True, description=None)] nodes=[GraphNode(id='research', description=None, purpose='Perform focused research on the requested topic titled {topic_title}.', goal='Collect key facts, terminology, and references that are directly useful for writing a technical blog post.\\n', expected_result=\"A compact, structured summary with sections for 'key_points', 'sources', and 'risks_or_caveats'.\\n\", tools=['web_search'], depends_on=[], mode=<NodeMode.AUTO: 'auto'>, output_schema=None, model=None, policy=None), GraphNode(id='outline', description=None, purpose='Design a clear structure for the article.', goal='Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.\\n', expected_result='A title, a detailed description, and an ordered list of sections with headings and bullet points.\\n', tools=[], depends_on=['research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=None), GraphNode(id='draft', description=None, purpose='Write the first full draft of the article of about 5000 words including every detail.', goal='Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n', expected_result='A complete draft in markdown, including title, headings, and paragraphs.\\n', tools=[], depends_on=['outline', 'research'], mode=<NodeMode.TEXT: 'text'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=16000, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None)), GraphNode(id='review', description=None, purpose='Perform technical and editorial review of the draft.', goal='Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n', expected_result='A structured review with strengths, issues, and concrete suggestions.\\n', tools=[], depends_on=['draft', 'research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=16000, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None))] outputs=['draft', 'review']\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-17 23:22:19\u001b[0m | \u001b[96mutils.py:normalize_and_validate_graph_inputs\u001b[0m | Ignoring extra inputs not declared in graph spec: audience, tone\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-17 23:22:19\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m668s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mresearch\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: web_search\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Using tool-augmented LLM agents to build reliable workflows'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'hl'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'en'\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m914s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'web_search'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Using tool-augmented LLM agents to build reliable workflows'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'summary'\u001b[0m\u001b[1;32m: \"Top \u001b[0m\u001b[1;32m2\u001b[0m\u001b[1;32m results o\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m339s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m258s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mresearch\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m255s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36moutline\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m11.\u001b[0m\u001b[2m194s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'outline'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m11.\u001b[0m\u001b[2m197s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36moutline\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "# Title:  \n",
      "**Using Tool-Augmented LLM Agents to Build Reliable Workflows**\n",
      "\n",
      "## Detailed Description:  \n",
      "This blog post explores the transformative potential of **tool-augmented large language model (LLM) agents** in building **reliable and scalable workflows**. As organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs enables them to perform tasks with greater accuracy, efficiency, and adaptability. Drawing insights from recent research and real-world applications, this article outlines the key components of building robust LLM agents, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. The post is structured to guide both practitioners and developers in understanding how to leverage LLM agents to solve real-world problems while maintaining consistency, accountability, and performance.\n",
      "\n",
      "---\n",
      "\n",
      "## Ordered List of Sections:\n",
      "\n",
      "### 1. **Introduction: The Rise of Tool-Augmented LLM Agents**  \n",
      "- Define what LLM agents are and their role in modern AI systems.  \n",
      "- Introduce the concept of **tool augmentation** and why it is critical for building reliable workflows.  \n",
      "- Highlight the limitations of traditional LLMs in real-world applications.  \n",
      "- Mention the importance of **reliable workflows** in business and research settings.  \n",
      "- Set the stage for the rest of the blog by outlining the key topics to be covered.\n",
      "\n",
      "### 2. **Understanding the LLM Agent Workflow**  \n",
      "- Break down the **core components** of an LLM agent:  \n",
      "  - **Orchestrator**: The central LLM that manages task decomposition and coordination.  \n",
      "  - **Workers**: Specialized LLMs or tools that execute specific tasks.  \n",
      "  - **Environment**: The external systems, APIs, or data sources the agent interacts with.  \n",
      "- Explain the **orchestrator-workers workflow** in detail, using examples from the research.  \n",
      "- Discuss the **dynamic nature** of task delegation and how it enables flexibility in workflows.  \n",
      "- Introduce the concept of **reflection** and how it improves agent performance over time.\n",
      "\n",
      "### 3. **Why Tool Augmentation is Essential for Reliable Workflows**  \n",
      "- Define **tool augmentation** and its role in enhancing LLM capabilities.  \n",
      "- Discuss the **limitations of LLMs without tools**:  \n",
      "  - Lack of long-term memory.  \n",
      "  - Inability to interact with external systems.  \n",
      "  - Struggles with multi-step reasoning and dynamic environments.  \n",
      "- Highlight how **tool integration** improves:\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m345s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mdraft\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m97.\u001b[0m\u001b[2m961s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'draft'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m97.\u001b[0m\u001b[2m964s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mdraft\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "# Using Tool-Augmented LLM Agents to Build Reliable Workflows\n",
      "\n",
      "## Introduction: The Rise of Tool-Augmented LLM Agents\n",
      "\n",
      "In recent years, the field of artificial intelligence has witnessed a paradigm shift with the advent of large language models (LLMs). These powerful models, capable of understanding and generating human-like text, have opened up new possibilities for automation, decision-making, and problem-solving. However, the true potential of LLMs is unlocked when they are augmented with tools that extend their capabilities beyond the confines of their training data. This integration of tools into LLMs, known as **tool augmentation**, has become a cornerstone in building **reliable and scalable workflows** that can handle complex, real-world tasks.\n",
      "\n",
      "LLM agents, which are essentially AI systems that use LLMs as their core, are designed to perform tasks that require reasoning, planning, and decision-making. These agents are not just static models but dynamic systems that can adapt to new information and environments. The key to their reliability lies in their ability to interact with external tools, which allows them to access real-time data, perform computations, and execute actions that would be impossible for a standalone LLM to achieve.\n",
      "\n",
      "The importance of reliable workflows cannot be overstated, especially in business and research settings where accuracy and consistency are paramount. Traditional LLMs, while powerful, often struggle with tasks that require multi-step reasoning, long-term memory, and interaction with external systems. These limitations hinder their effectiveness in scenarios that demand sustained reasoning or complex workflows. Tool augmentation addresses these limitations by providing LLM agents with the necessary tools to interact with the environment, access additional information, and perform tasks with greater accuracy and efficiency.\n",
      "\n",
      "As organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs has become essential for building robust workflows. This blog post will explore the transformative potential of tool-augmented LLM agents, focusing on the core components of an LLM agent, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. We will also highlight the importance of reliable workflows in business and research settings, and how they contribute to the overall success of AI-driven initiatives.\n",
      "\n",
      "In the following sections, we will delve into the **LLM agent workflow**, breaking down its core components and explaining how they work together to create efficient and effective systems. We will also discuss the **dynamic nature of task delegation** and the concept of **reflection**, which plays a crucial role in improving agent performance over time. Finally, we will highlight the **importance of tool augmentation** in overcoming the limitations of traditional LLMs and enabling the creation of reliable workflows that can handle complex, real-world tasks.\n",
      "\n",
      "By the end of this blog post, you will have a comprehensive understanding of how tool-augmented LLM agents can be leveraged to build reliable and scalable workflows, and how these agents can be designed to meet the demands of modern AI applications. Let's begin our exploration of the world of tool-augmented LLM agents and their role in building reliable workflows.\n",
      "\n",
      "## Understanding the LLM Agent Workflow\n",
      "\n",
      "At the heart of any effective AI system lies the **LLM agent workflow**, a structured process that enables agents to perform complex tasks with precision and adaptability. This workflow is composed of three core components: the **orchestrator**, the **workers**, and the **environment**. Each of these elements plays a vital role in ensuring that the agent can effectively execute its tasks and adapt to changing conditions. \n",
      "\n",
      "### Orchestrator: The Central LLM\n",
      "\n",
      "The **orchestrator** is the central LLM within the agent system. It acts as the brain of the operation, responsible for **task decomposition**, **coordination**, and **synthesis of results**. The orchestrator receives a high-level task or goal from the user and breaks it down into smaller, manageable subtasks. This decomposition is crucial as it allows the agent to tackle complex problems by breaking them into simpler, more digestible parts. \n",
      "\n",
      "For instance, if the task is to \"create a report on the latest market trends,\" the orchestrator might decompose this into subtasks such as \"gather data on recent market trends,\" \"analyze the data,\" and \"format the findings into a report.\" The orchestrator then delegates these subtasks to the appropriate **workers**, ensuring that each task is handled by the most suitable component of the system.\n",
      "\n",
      "### Workers: Specialized LLMs or Tools\n",
      "\n",
      "The **workers** are the specialized LLMs or external tools that execute the specific tasks assigned by the orchestrator. These workers can be either **LLMs** designed for specific functions or **external tools** that provide access to databases, APIs, or other systems. The key to effective task execution lies in the **specialization** of these workers. \n",
      "\n",
      "For example, if the orchestrator assigns the task of \"analyzing the data gathered on market trends,\" it might direct this to a worker that is specifically trained for data analysis. This worker could be an LLM that has been fine-tuned on financial data or a tool that connects to a database of market statistics. The use of specialized workers ensures that each task is handled with the appropriate expertise, enhancing the accuracy and efficiency of the overall process.\n",
      "\n",
      "### Environment: The External Systems\n",
      "\n",
      "The **environment** refers to the external systems, APIs, or data sources that the agent interacts with. This component is essential as it allows the agent to access real-time information, perform computations, and execute actions that are necessary for completing the task. The environment can include databases, web services, and other tools that provide the agent with the necessary information to make informed decisions.\n",
      "\n",
      "For example, if the orchestrator needs to gather the latest market data, it might direct the agent to interact with a financial API that provides up-to-date market trends. This interaction with the environment enables the agent to access the most relevant information, ensuring that the task is completed with the highest level of accuracy.\n",
      "\n",
      "### Orchestrator-Workers Workflow in Action\n",
      "\n",
      "The orchestrator-workers workflow operates in a **dynamic and iterative manner**, allowing the agent to adapt to changing conditions and improve its performance over time. This workflow is particularly effective in scenarios that require **multi-step reasoning** and **dynamic environments**. \n",
      "\n",
      "For instance, consider an agent tasked with \"planning a trip to a new city.\" The orchestrator would first break down the task into subtasks such as \"research the destination,\" \"book accommodations,\" and \"plan the itinerary.\" Each of these subtasks would be assigned to specialized workers. The research worker might access travel blogs and review sites, the booking worker could interact with hotel reservation systems, and the itinerary planner might use a mapping tool to suggest the best routes.\n",
      "\n",
      "As the agent performs these tasks, it continuously interacts with the environment, gathering new information that may influence the planning process. This dynamic interaction allows the agent to adjust its plans in real-time, ensuring that the final itinerary is optimized for the traveler's preferences and the latest available information.\n",
      "\n",
      "### Dynamic Nature of Task Delegation\n",
      "\n",
      "The **dynamic nature of task delegation** is a crucial aspect of the LLM agent workflow. This means that the orchestrator can adaptively assign tasks based on the current context and the availability of resources. For example, if a particular worker is not available or if new information becomes available, the orchestrator can reassign tasks to ensure that the overall workflow remains efficient.\n",
      "\n",
      "This adaptability is essential in environments where conditions can change rapidly, such as in financial markets or customer service scenarios. The ability to dynamically adjust task delegation allows the agent to remain responsive to new information and changing circumstances, ensuring that the workflow remains effective and efficient.\n",
      "\n",
      "### Reflection and Continuous Improvement\n",
      "\n",
      "Another critical component of the LLM agent workflow is **reflection**, which allows the agent to learn from its experiences and improve its performance over time. Reflection involves the agent examining its completed tasks, evaluating the outcomes, and identifying areas for improvement. This process enables the agent to refine its strategies and enhance its capabilities, leading to more accurate and efficient task execution.\n",
      "\n",
      "In conclusion, the **LLM agent workflow** is a complex yet effective system that combines the orchestrator, workers, and environment to create a robust framework for executing tasks. By breaking down tasks into manageable subtasks, leveraging specialized workers, and dynamically interacting with the environment, LLM agents can achieve a high level of reliability and efficiency. The dynamic nature of task delegation and the incorporation of reflection further enhance the agent's ability to adapt and improve, making them essential in today's rapidly evolving technological landscape. As we continue to explore the potential of tool-augmented LLM agents, it is clear that understanding this workflow is crucial for building reliable and scalable AI systems. üåü\n",
      "\n",
      "## Why Tool Augmentation is Essential for Reliable Workflows\n",
      "\n",
      "### The Limitations of Traditional LLMs\n",
      "\n",
      "Traditional large language models (LLMs) have revolutionized the field of natural language processing, offering impressive capabilities in tasks such as text generation, translation, and question-answering. However, these models often fall short when it comes to executing complex, multi-step tasks that require interaction with external systems or environments. One of the primary limitations of traditional LLMs is their **lack of long-term memory**. Unlike humans, who can retain and recall information over extended periods, LLMs are typically trained on static data and may not retain information from previous interactions, leading to inconsistencies and errors in tasks that require sequential reasoning.\n",
      "\n",
      "Another significant limitation is the **inability to interact with external systems**. While LLMs can generate text and understand context, they often struggle to access real-time data or perform actions that require direct interaction with databases, APIs, or other tools. This inability to interact with external systems hampers their effectiveness in scenarios where real-time information is crucial, such as financial trading, customer service, or data analysis. For instance, an LLM tasked with providing stock market insights may not be able to access the latest stock prices or news updates, resulting in outdated or inaccurate information.\n",
      "\n",
      "Additionally, traditional LLMs often struggle with **multi-step reasoning and dynamic environments**. These models are typically designed to handle single tasks or simple interactions, making it challenging for them to navigate complex workflows that involve multiple steps or changing conditions. In dynamic environments, where the context can shift rapidly, the lack of adaptability in traditional LLMs can lead to suboptimal outcomes. For example, an LLM used for customer service might not be able to adjust its responses based on the customer's changing needs or preferences, leading to a poor user experience.\n",
      "\n",
      "### The Role of Tool Integration\n",
      "\n",
      "Tool augmentation addresses these limitations by integrating external tools into the LLM's capabilities, allowing the model to access real-time data, perform computations, and execute actions that enhance its functionality. This integration enables LLMs to **interact with the environment**, thereby enhancing their ability to perform complex tasks. For instance, when an LLM is equipped with tools such as APIs for financial data, it can access the latest stock prices, enabling it to provide up-to-date insights to users. This not only improves the accuracy of the information provided but also enhances the user experience by ensuring that the information is current and relevant.\n",
      "\n",
      "Moreover, tool augmentation enhances **multi-step reasoning capabilities** by allowing the LLM to break down complex tasks into manageable components. By leveraging tools, the LLM can perform specific actions, such as querying a database or executing a script, thereby enabling it to handle tasks that require multiple steps. This capability is particularly important in dynamic environments, where the ability to adapt to changing conditions is essential. For example, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer's evolving needs, leading to a more personalized and effective service.\n",
      "\n",
      "### Enhancing Accuracy and Efficiency\n",
      "\n",
      "The integration of tools into LLMs significantly improves the **accuracy and efficiency** of task execution. By accessing real-time data and performing computations, the LLM can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\n",
      "\n",
      "Furthermore, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the L can focus on higher-level tasks that require human judgment and creativity.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In conclusion, the limitations of traditional LLMs in real-world applications are significant, but tool augmentation offers a viable solution to these challenges. By integrating external tools, LLMs can access real-time data, perform computations, and execute actions that enhance their capabilities. This integration not only improves the accuracy and efficiency of task execution but also allows LLMs to navigate complex workflows and dynamic environments with greater adaptability. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will delve deeper into how tool integration enhances the capabilities of LLM agents, providing real-world examples of its impact on reliability and performance. üåü\n",
      "\n",
      "## Enhancing LLM Capabilities Through Tool Integration\n",
      "\n",
      "### The Role of Tool Augmentation in Overcoming Limitations\n",
      "\n",
      "Tool augmentation is a transformative approach that addresses the inherent limitations of traditional LLMs by integrating external tools into their capabilities. This integration not only enhances the functionality of LLMs but also allows them to perform tasks that require **long-term memory, interaction with external systems, and multi-step reasoning**. By leveraging tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\n",
      "\n",
      "One of the most significant benefits of tool augmentation is the ability to **access real-time data**. Traditional LLMs are often limited by the static data they are trained on, which can lead to outdated or inaccurate information. By integrating tools such as APIs, databases, or web services, LLMs can retrieve the latest information, ensuring that their responses are current and relevant. For example, an LLM tasked with providing financial market insights can access real-time stock prices and news updates through a financial API, enabling it to deliver up-to-date information to users.\n",
      "\n",
      "### Improving Accuracy and Efficiency\n",
      "\n",
      "The integration of tools also enhances the **accuracy and efficiency** of LLMs. By accessing real-time data and performing computations, LLMs can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\n",
      "\n",
      "Moreover, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the LLM can focus on higher-level tasks that require human judgment and creativity.\n",
      "\n",
      "### Facilitating Multi-Step Reasoning and Dynamic Environments\n",
      "\n",
      "Another critical aspect of tool integration is its ability to **facilitate multi-step reasoning and adapt to dynamic environments**. Traditional LLMs often struggle with complex tasks that require multiple steps or changing conditions, but by integrating tools, LLMs can break down these tasks into manageable components. This capability is particularly important in dynamic environments, where the context can shift rapidly. For instance, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer's evolving needs, leading to a more personalized and effective service.\n",
      "\n",
      "The integration of tools also allows LLMs to **navigate complex workflows** by providing the necessary tools to execute specific actions. For example, in a financial trading scenario, an augmented LLM can use tools such as market analysis APIs to assess investment opportunities, execute trades, and monitor market trends in real-time. This not only enhances the LLM's ability to make informed decisions but also improves the overall efficiency of the trading process.\n",
      "\n",
      "### Real-World Applications of Tool-Augmented LLMs\n",
      "\n",
      "The benefits of tool augmentation are evident in various real-world applications, where LLMs are used to perform complex tasks that require interaction with external systems. For instance, in the field of customer service, tool-augmented LLMs can handle inquiries by accessing customer databases, retrieving relevant information, and providing personalized responses. This not only improves the customer experience but also reduces the workload on human agents, allowing them to focus on more complex tasks.\n",
      "\n",
      "In the healthcare industry, tool-augmented LLMs can assist in diagnosing patients by accessing medical databases and providing treatment recommendations based on the latest research and patient data. This integration of tools allows LLMs to provide more accurate and timely information, ultimately improving patient outcomes.\n",
      "\n",
      "In the realm of data analysis, tool-augmented LLMs can automate tasks such as data collection, processing, and visualization, enabling organizations to make data-driven decisions more efficiently. By leveraging tools such as SQL databases and data visualization software, LLMs can perform complex analyses and generate insights that would otherwise require significant human effort.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In conclusion, the integration of tools into LLMs through **tool augmentation** significantly enhances their capabilities, enabling them to overcome the limitations of traditional models. By accessing real-time data, performing computations, and executing actions, LLMs can provide more accurate and efficient information, facilitating multi-step reasoning and adaptability in dynamic environments. The real-world applications of tool-augmented LLMs demonstrate their potential to transform various industries, from customer service to healthcare and data analysis. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will explore the importance of reliable workflows in business and research settings, highlighting how they contribute to the overall success of AI-driven initiatives. üåü\n",
      "\n",
      "## The Importance of Reliable Workflows in Business and Research Settings\n",
      "\n",
      "In today's rapidly evolving technological landscape, the ability to execute tasks reliably and efficiently is paramount for both business operations and research endeavors. Reliable workflows are essential as they ensure that tasks are completed accurately, consistently, and within expected timeframes. In business, where customer satisfaction and operational efficiency are critical, the implementation of reliable workflows can significantly enhance productivity and reduce errors. Similarly, in research settings, reliable workflows are crucial for maintaining the integrity of data and ensuring that findings are based on accurate and consistent information.\n",
      "\n",
      "### Business Applications of Reliable Workflows\n",
      "\n",
      "In the business context, reliable workflows are the backbone of operational success. They enable organizations to automate repetitive tasks, streamline processes, and enhance decision-making. For instance, in customer service, a reliable workflow can ensure that customer inquiries are addressed promptly and accurately, leading to higher customer satisfaction and loyalty. By integrating tools such as chatbots and customer relationship management (CRM) systems, businesses can create workflows that not only improve response times but also provide personalized interactions, thereby enhancing the overall customer experience.\n",
      "\n",
      "Moreover, in data-driven industries, reliable workflows are essential for data processing and analysis. By establishing standardized procedures for data collection, cleaning, and analysis, organizations can ensure that the data used for decision-making is accurate and reliable. This is particularly important in fields such as finance and marketing, where data accuracy can directly impact profitability and market competitiveness. For example, a financial institution utilizing reliable data workflows can make informed investment decisions based on up-to-date market trends, leading to more effective risk management and better returns on investments.\n",
      "\n",
      "### Research Applications of Reliable Workflows\n",
      "\n",
      "In research settings, reliable workflows are equally vital. They ensure that the research process is systematic and reproducible, which is crucial for validating findings and maintaining the credibility of research. In scientific research, where the accuracy of results can influence policy decisions and public health, reliable workflows are essential for minimizing errors and ensuring that data is collected and analyzed consistently. This is particularly important in fields such as medicine and environmental science, where the reliability of data can have significant implications for public health and environmental policies.\n",
      "\n",
      "Furthermore, reliable workflows in research also facilitate collaboration among researchers. By establishing clear protocols and standardized procedures, researchers can work together more effectively, sharing data and insights while maintaining the integrity of their findings. This collaboration is essential for tackling complex research questions that require interdisciplinary approaches. For example, in climate change research, reliable workflows can enable scientists from various fields to combine their expertise and data, leading to more comprehensive and impactful findings.\n",
      "\n",
      "### Enhancing Reliability Through Tool-Augmented LLMs\n",
      "\n",
      "The integration of tool-augmented LLMs into workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. These models can access real-time data, perform complex computations, and execute tasks that would be impossible for traditional models to achieve. For instance, in a business setting, an augmented LLM can analyze customer feedback in real-time, enabling companies to make data-driven decisions that improve customer satisfaction and loyalty. Similarly, in research, an augmented LLM can assist in data analysis by generating insights from large datasets, allowing researchers to identify patterns and trends that might otherwise go unnoticed.\n",
      "\n",
      "Moreover, the ability of tool-augmented LLMs to handle multi-step reasoning and adapt to dynamic environments ensures that workflows remain flexible and responsive to changing conditions. This adaptability is crucial in both business and research settings, where the ability to pivot and adjust strategies based on new information can lead to more successful outcomes. For example, in a rapidly changing market, an augmented LLM can continuously monitor market trends and adjust business strategies in real-time, ensuring that the organization remains competitive.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In conclusion, the importance of reliable workflows in both business and research settings cannot be overstated. They are essential for ensuring that tasks are executed accurately, consistently, and efficiently, ultimately leading to better outcomes. The integration of tool-augmented LLMs into these workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. As organizations increasingly rely on AI to automate complex tasks, the role of reliable workflows in achieving success becomes even more critical. The next section will delve into the best practices for designing reliable workflows, providing insights into how to effectively leverage tool-augmented LLMs to meet the demands of modern AI applications. üåü\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m913s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mreview\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m30.\u001b[0m\u001b[2m623s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'review'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m30.\u001b[0m\u001b[2m625s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mreview\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "# Review of the Blog Post: \"Using Tool-Augmented LLM Agents to Build Reliable Workflows\"\n",
      "\n",
      "---\n",
      "\n",
      "## üìå **Strengths of the Content**\n",
      "\n",
      "1. **Clear Structure and Organization**:\n",
      "   - The blog post is well-organized with a logical flow, starting with an introduction, then moving into core concepts, limitations of traditional LLMs, the role of tool augmentation, and the importance of reliable workflows in business and research settings.\n",
      "   - Each section is clearly defined and builds on the previous one, making it easy for readers to follow the narrative.\n",
      "\n",
      "2. **Comprehensive Explanation of LLM Agent Workflow**:\n",
      "   - The post provides a thorough breakdown of the LLM agent workflow, including the roles of the orchestrator, workers, and environment. This explanation is accessible and well-suited for both technical and non-technical readers.\n",
      "\n",
      "3. **Use of Real-World Examples**:\n",
      "   - The post includes practical examples (e.g., market trend analysis, customer service, healthcare, and data analysis) that illustrate how tool-augmented LLMs can be applied in real-world scenarios. These examples enhance the relevance and applicability of the concepts discussed.\n",
      "\n",
      "4. **Emphasis on Reliability and Scalability**:\n",
      "   - The post consistently emphasizes the importance of reliability and scalability in AI-driven workflows, which is a critical aspect for both business and research applications.\n",
      "\n",
      "5. **Clear Definition of Key Terms**:\n",
      "   - Terms such as \"tool augmentation,\" \"orchestrator,\" \"workers,\" and \"reflection\" are clearly defined and explained, making the content accessible to a broad audience.\n",
      "\n",
      "---\n",
      "\n",
      "## üö® **Issues Identified**\n",
      "\n",
      "1. **Factual Inaccuracies**:\n",
      "   - **Section: \"The Role of Tool Integration\"** ‚Äì The post states: *\"By integrating tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\"*  \n",
      "     - **Issue**: This is **technically inaccurate**. While LLMs can access real-time data through tool integration, they **do not execute actions** in the same way humans or software do. Instead, they **invoke tools** to perform specific actions. The language here can be misleading, as it suggests LLMs \"execute\" actions, which is not entirely accurate.\n",
      "   - **Section: \"Enhancing LLM Capabilities Through Tool Integration\"** ‚Äì The post mentions: *\"LLMs can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\"*  \n",
      "     - **Issue**: This **overstates the capabilities** of LLMs. While LLMs can access and analyze data, they **do not make clinical diagnoses**‚Äîthat is a domain where human oversight is still required. The post should clarify that LLMs can **assist** in diagnosis, not replace it.\n",
      "\n",
      "2. **Lack of Clarification on Reflection and Learning**:\n",
      "   - The post discusses **reflection** as a key component of LLM agent workflows but does not clearly define how it is implemented or what mechanisms are used to enable learning from past experiences. The concept is mentioned but not thoroughly explained, which could confuse readers unfamiliar with the topic.\n",
      "\n",
      "3. **Stylistic Issues**:\n",
      "   - **Repetition**: There is some **repetition of ideas** across sections (e.g., the discussion of limitations of traditional LLMs and the role of tool augmentation). While repetition can reinforce key points, it can also lead to redundancy and a less engaging reading experience.\n",
      "   - **Overuse of Emojis**: The use of emojis (e.g., üåü) at the end of sections is **not appropriate for a technical blog post**. While it may be intended to add a friendly tone, it can be distracting and unprofessional in a context where clarity and precision are paramount.\n",
      "\n",
      "4. **Missing Explanations**:\n",
      "   - **Tool Augmentation Process**: The post does not clearly explain **how exactly** tool augmentation works, including the mechanics of how LLMs interact with external tools, how tasks are delegated, and how the results are synthesized. A more detailed explanation would enhance the reader's understanding.\n",
      "   - **Dynamic Task Delegation**: The concept of **dynamic task delegation** is mentioned but not fully explained. Readers may not understand how the orchestrator decides which worker to assign a task to or how the system adapts to changing conditions.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚úÖ **Actionable Suggestions for Improvement**\n",
      "\n",
      "1. **Clarify the Role of Tools in LLMs**:\n",
      "   - Replace phrases like *\"LLMs can execute actions\"* with *\"LLMs can invoke tools to perform specific actions.\"*\n",
      "   - Add a brief explanation of how LLMs interact with external tools (e.g., through API calls, function calls, or integration with databases).\n",
      "\n",
      "2. **Define Reflection and Learning Mechanisms**:\n",
      "   - Expand on what **reflection** means in the context of LLM agents. Include a brief explanation of how agents learn from past experiences, such as through self-evaluation, error detection, and iterative refinement.\n",
      "\n",
      "3. **Reduce Repetition and Improve Flow**:\n",
      "   - Consolidate repeated ideas (e.g., limitations of traditional LLMs and the benefits of tool augmentation) into a single, cohesive section to improve readability and reduce redundancy.\n",
      "\n",
      "4. **Avoid Emojis in a Technical Context**:\n",
      "   - Remove or replace the use of emojis (e.g., üåü) with more formal language to maintain a professional tone.\n",
      "\n",
      "5. **Add a Section on Tool Augmentation Mechanics**:\n",
      "   - Include a dedicated section that explains **how tool augmentation is implemented**, including:\n",
      "     - The types of tools commonly used (e.g., APIs, databases, web services).\n",
      "     - How LLMs are trained or configured to use these tools.\n",
      "     - Examples of how tasks are broken down and delegated.\n",
      "\n",
      "6. **Clarify the Role of LLMs in Clinical or Professional Settings**:\n",
      "   - In sections discussing healthcare or other professional applications, make it clear that LLMs are **assisting tools**, not decision-makers. Emphasize the importance of human oversight in critical domains.\n",
      "\n",
      "---\n",
      "\n",
      "## üìå **Conclusion**\n",
      "\n",
      "The blog post is well-structured and provides a comprehensive overview of the concept of tool-augmented LLM agents. It covers key topics such as the LLM agent workflow, limitations of traditional LLMs, and the role of tool integration in building reliable workflows. However, there are opportunities for improvement in terms of **clarity, factual accuracy, and stylistic consistency**.\n",
      "\n",
      "By addressing the identified issues and implementing the suggested improvements, the post can be further refined to better serve its audience, whether they are AI researchers, developers, or business professionals interested in AI-driven workflows.\n",
      "Result: graph=GraphSpec(name='blog_workflow', description='Example multi-agent workflow for writing and reviewing a technical blog using multiple specialized nodes (each node uses an Agent under the hood).\\n', inputs=[GraphInputSpec(name='topic_title', type='string', required=True, description=None), GraphInputSpec(name='query', type='string', required=True, description=None)], nodes=[GraphNode(id='research', description=None, purpose='Perform focused research on the requested topic titled {topic_title}.', goal='Collect key facts, terminology, and references that are directly useful for writing a technical blog post.\\n', expected_result=\"A compact, structured summary with sections for 'key_points', 'sources', and 'risks_or_caveats'.\\n\", tools=['web_search'], depends_on=[], mode=<NodeMode.AUTO: 'auto'>, output_schema=None, model=None, policy=None), GraphNode(id='outline', description=None, purpose='Design a clear structure for the article.', goal='Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.\\n', expected_result='A title, a detailed description, and an ordered list of sections with headings and bullet points.\\n', tools=[], depends_on=['research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=None), GraphNode(id='draft', description=None, purpose='Write the first full draft of the article of about 5000 words including every detail.', goal='Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n', expected_result='A complete draft in markdown, including title, headings, and paragraphs.\\n', tools=[], depends_on=['outline', 'research'], mode=<NodeMode.TEXT: 'text'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=16000, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None)), GraphNode(id='review', description=None, purpose='Perform technical and editorial review of the draft.', goal='Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n', expected_result='A structured review with strengths, issues, and concrete suggestions.\\n', tools=[], depends_on=['draft', 'research'], mode=<NodeMode.STRUCTURED: 'structured'>, output_schema=None, model=None, policy=NodePolicy(max_new_tokens=16000, temperature=0.7, retries=None, timeout_s=None, allow_input_pruning=None, repair_with_llm=True, strict_tool_call=None, strict_json=None, max_json_repair_attempts=None))], outputs=['draft', 'review']) nodes={'research': NodeExecutionResult(node_id='research', mode=<NodeMode.AUTO: 'auto'>, raw_output={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'summary': \"Top 2 results out of ~575,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\\n2. Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Äî https://arxiv.org/html/2510.09244v1\", 'results': [{'title': 'Building Effective AI Agents', 'url': 'https://www.anthropic.com/research/building-effective-agents', 'snippet': 'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.', 'score': None, 'content': None, 'content_length': None, 'error': None}, {'title': 'Fundamentals of Building Autonomous LLM Agents ‚Ä†', 'url': 'https://arxiv.org/html/2510.09244v1', 'snippet': 'Many people confuse workflows with agents ... LLM-based agents can significantly enhance their perception capabilities through tool augmentation.', 'score': None, 'content': 'Fundamentals of Building Autonomous LLM Agents This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. 1 1 institutetext: Universitat Polit√®cnica de Catalunya, Barcelona, Spain 1 1 email: victor.de.lamo@estudiantat.upc.edu 2 2 institutetext: Technische Universit√§t M√ºnchen, M√ºnchen, Germany 2 2 email: {habtom.gidey, alex.lenz, knoll}@tum.de Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Ä† thanks: This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. Victor de Lamo Castrillo Habtom Kahsay Gidey Alexander Lenz Alois ... of tasks, including natural language processing (NLP), machine translation, vision applications, and question-answering. 2.2 From LLMs to LLM Agents LLMs in their standard form have significant limitations due to their chatbot nature. This restricts their effectiveness in real-world tasks. These models lack long-term memory, cannot autonomously interact with external tools, and struggle to pursue goals in dynamic environments. Such shortcomings hinder their performance in scenarios requiring sustained reasoning or multi-step workflows [ 61 ] . To overcome these constraints, LLMs are guided to follow a reasoning path and are provided with tools to interact with the environment that enables them ... paper ‚ÄúVCoder: Versatile Vision Encoders for Multimodal Large Language Models‚Äù by Jain et al. (2023) [ 28 ] , traditional MM-LLM systems often face limitations in fundamental visual perception, such as accurately identifying or counting objects, and a tendency to hallucinate non-existent entities. A faster and more cost-effective way to enhance perception (rather than improving each individual component of an MM-LLM) is to use visual encoders. These encoders, which can be separate models, extract relevant information from images to help the MM-LLM interpret them more effectively. While this approach doesn‚Äôt match the performance gains of directly improving each component of ... . ‚Ä¢ Data Collection: Training robust perception systems, particularly for multimodal or specialized domains, often requires large volumes of high-quality, annotated data. The collection of this data can be costly and time-consuming. ‚Ä¢ Computational Resources: High-fidelity perception, especially with multimodal inputs, requires high computational resources for both training and inference. This can be a barrier for execution in resource-constrained environments or for widespread adoption. Ultimately, the quality and fidelity of an LLM agent‚Äôs perception system directly affects the reasoning and planning modules. Therefore, continuous advancements in perception technologies are not merely improvements to one component, but fundamental enablers for building ... reasoning, and outcomes, and then use these insights to improve its future performance. This allows agents to learn from their mistakes or inefficiencies without human intervention. Key characteristics of reflection include: ‚Ä¢ Self-Evaluation: The agent examines its completed (or ongoing) task, its generated plans, and the results of its actions. This often involves comparing actual and expected outcomes. ‚Ä¢ Error Detection and Analysis: Identifying where things went wrong, why a plan failed, or where the reasoning failed. This can be due to misunderstandings of the prompt, incorrect tool usage, logical inconsistencies, or environmental changes. Papers like [ 49 ] and ... and roles‚Äù [ 51 ] of your expert. This involves: ‚Ä¢ Clear Specialization: What specific task, domain, or reasoning capability will this expert excel at? (e.g., planning, code generation, error handling). ‚Ä¢ Input and Output: What kind of information does this expert take as input, and what kind of output does it produce? ‚Ä¢ Boundaries: What are the limitations of its expertise? When should other experts be consulted or take over? [ 33 ] . 4.6.1 Equip with Knowledge An expert‚Äôs effectiveness hinges on its specialized knowledge. This can be achieved by: ‚Ä¢ Targeted Prompting: Crafting precise and detailed prompts ... Experiences: It is beneficial to store records of both successful and failed tasks. Research has indicated that even failed experiences, when appropriately logged and distinguished as such, can be valuable. By explicitly noting a ‚Äúfailed experience,‚Äù LLMs can learn to avoid repeating similar mistakes in the future. This continuous learning from past interactions, including the identification of ‚Äúinvalid action filtering,‚Äù contributes to the agent‚Äôs robust development and ability to adapt [ 1 , 22 ] . To store an experience, you capture a task‚Äôs natural language instruction (e.g., ‚ÄúWho ordered order 0130?‚Äù ) and the sequence of steps taken to ... approach is especially valuable for data manipulation tasks, complex calculations, file processing, and integration between different systems. Agents can write Python scripts for data analysis, generate SQL queries for database operations, create shell scripts for system administration, or produce HTML/CSS/JavaScript for web-based solutions [ 10 , 42 ] . 6.2.3 Robotic and Physical System Control: In robotics applications, LLM agents can control physical systems through appropriate APIs and sensor integrations [ 61 ] . They process sensor data (cameras, force sensors, temperature sensors) to understand the physical environment, generate motion plans and control commands, coordinate multiple actuators and subsystems, and ... https://arxiv.org/abs/2305.14992 [25] Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems 43 (2) (2025). doi: 10.1145/3703155 , http://dx.doi.org/10.1145/3703155 [26] Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint (2024), https://arxiv.org/abs/2402.02716 [27] Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills in humanoid robots: A deep learning approach. ... Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH [69] Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large language models with long-term memory. arXiv preprint (2023), https://arxiv.org/abs/2305.10250 [70] Zhou, S., Xu, F.F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T., Bisk, Y., Fried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building autonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854 [71] Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist agents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.07972 [72] Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced', 'content_length': 6990, 'error': None}], 'provider': 'serpapi', 'elapsed_ms': 333}, structured_output=None, tool_call_output=ToolCallResponse(selected_tool='web_search', inputs={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'hl': 'en'}, returns={'query': 'Using tool-augmented LLM agents to build reliable workflows', 'summary': \"Top 2 results out of ~575,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\\n2. Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Äî https://arxiv.org/html/2510.09244v1\", 'results': [{'title': 'Building Effective AI Agents', 'url': 'https://www.anthropic.com/research/building-effective-agents', 'snippet': 'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.', 'score': None, 'content': None, 'content_length': None, 'error': None}, {'title': 'Fundamentals of Building Autonomous LLM Agents ‚Ä†', 'url': 'https://arxiv.org/html/2510.09244v1', 'snippet': 'Many people confuse workflows with agents ... LLM-based agents can significantly enhance their perception capabilities through tool augmentation.', 'score': None, 'content': 'Fundamentals of Building Autonomous LLM Agents This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. 1 1 institutetext: Universitat Polit√®cnica de Catalunya, Barcelona, Spain 1 1 email: victor.de.lamo@estudiantat.upc.edu 2 2 institutetext: Technische Universit√§t M√ºnchen, M√ºnchen, Germany 2 2 email: {habtom.gidey, alex.lenz, knoll}@tum.de Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Ä† thanks: This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. Victor de Lamo Castrillo Habtom Kahsay Gidey Alexander Lenz Alois ... of tasks, including natural language processing (NLP), machine translation, vision applications, and question-answering. 2.2 From LLMs to LLM Agents LLMs in their standard form have significant limitations due to their chatbot nature. This restricts their effectiveness in real-world tasks. These models lack long-term memory, cannot autonomously interact with external tools, and struggle to pursue goals in dynamic environments. Such shortcomings hinder their performance in scenarios requiring sustained reasoning or multi-step workflows [ 61 ] . To overcome these constraints, LLMs are guided to follow a reasoning path and are provided with tools to interact with the environment that enables them ... paper ‚ÄúVCoder: Versatile Vision Encoders for Multimodal Large Language Models‚Äù by Jain et al. (2023) [ 28 ] , traditional MM-LLM systems often face limitations in fundamental visual perception, such as accurately identifying or counting objects, and a tendency to hallucinate non-existent entities. A faster and more cost-effective way to enhance perception (rather than improving each individual component of an MM-LLM) is to use visual encoders. These encoders, which can be separate models, extract relevant information from images to help the MM-LLM interpret them more effectively. While this approach doesn‚Äôt match the performance gains of directly improving each component of ... . ‚Ä¢ Data Collection: Training robust perception systems, particularly for multimodal or specialized domains, often requires large volumes of high-quality, annotated data. The collection of this data can be costly and time-consuming. ‚Ä¢ Computational Resources: High-fidelity perception, especially with multimodal inputs, requires high computational resources for both training and inference. This can be a barrier for execution in resource-constrained environments or for widespread adoption. Ultimately, the quality and fidelity of an LLM agent‚Äôs perception system directly affects the reasoning and planning modules. Therefore, continuous advancements in perception technologies are not merely improvements to one component, but fundamental enablers for building ... reasoning, and outcomes, and then use these insights to improve its future performance. This allows agents to learn from their mistakes or inefficiencies without human intervention. Key characteristics of reflection include: ‚Ä¢ Self-Evaluation: The agent examines its completed (or ongoing) task, its generated plans, and the results of its actions. This often involves comparing actual and expected outcomes. ‚Ä¢ Error Detection and Analysis: Identifying where things went wrong, why a plan failed, or where the reasoning failed. This can be due to misunderstandings of the prompt, incorrect tool usage, logical inconsistencies, or environmental changes. Papers like [ 49 ] and ... and roles‚Äù [ 51 ] of your expert. This involves: ‚Ä¢ Clear Specialization: What specific task, domain, or reasoning capability will this expert excel at? (e.g., planning, code generation, error handling). ‚Ä¢ Input and Output: What kind of information does this expert take as input, and what kind of output does it produce? ‚Ä¢ Boundaries: What are the limitations of its expertise? When should other experts be consulted or take over? [ 33 ] . 4.6.1 Equip with Knowledge An expert‚Äôs effectiveness hinges on its specialized knowledge. This can be achieved by: ‚Ä¢ Targeted Prompting: Crafting precise and detailed prompts ... Experiences: It is beneficial to store records of both successful and failed tasks. Research has indicated that even failed experiences, when appropriately logged and distinguished as such, can be valuable. By explicitly noting a ‚Äúfailed experience,‚Äù LLMs can learn to avoid repeating similar mistakes in the future. This continuous learning from past interactions, including the identification of ‚Äúinvalid action filtering,‚Äù contributes to the agent‚Äôs robust development and ability to adapt [ 1 , 22 ] . To store an experience, you capture a task‚Äôs natural language instruction (e.g., ‚ÄúWho ordered order 0130?‚Äù ) and the sequence of steps taken to ... approach is especially valuable for data manipulation tasks, complex calculations, file processing, and integration between different systems. Agents can write Python scripts for data analysis, generate SQL queries for database operations, create shell scripts for system administration, or produce HTML/CSS/JavaScript for web-based solutions [ 10 , 42 ] . 6.2.3 Robotic and Physical System Control: In robotics applications, LLM agents can control physical systems through appropriate APIs and sensor integrations [ 61 ] . They process sensor data (cameras, force sensors, temperature sensors) to understand the physical environment, generate motion plans and control commands, coordinate multiple actuators and subsystems, and ... https://arxiv.org/abs/2305.14992 [25] Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems 43 (2) (2025). doi: 10.1145/3703155 , http://dx.doi.org/10.1145/3703155 [26] Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint (2024), https://arxiv.org/abs/2402.02716 [27] Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills in humanoid robots: A deep learning approach. ... Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH [69] Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large language models with long-term memory. arXiv preprint (2023), https://arxiv.org/abs/2305.10250 [70] Zhou, S., Xu, F.F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T., Bisk, Y., Fried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building autonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854 [71] Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist agents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.07972 [72] Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced', 'content_length': 6990, 'error': None}], 'provider': 'serpapi', 'elapsed_ms': 333}, final=False, extras={}), started_at=1763407341.0348804, duration_ms=1261, error=None, traces=TraceResult(steps=[TraceStep(step_id=1, kind='agent', label='agent.run', node_id=None, agent_id='research', started_at=1763407341.0365417, duration_ms=1258, inputs={'agent_type': 'Agent', 'has_toolkit': True, 'structured': False, 'stream': False, 'strict_tool_call': False}, outputs={}, meta={}, ok=True, error=None, logs=[]), TraceStep(step_id=2, kind='llm.call', label='agent.route_and_call.router_llm_call', node_id=None, agent_id='research', started_at=1763407341.0373657, duration_ms=913, inputs={'attempt': 1, 'strict_tool_call': False, 'system_prompt_len': 1500, 'user_prompt_len': 333, 'user_prompt': 'Perform focused research on the topic \"Using tool-augmented LLM agents to build reliable workflows\". Collect key facts, terminology, and references that are directly useful for writing a technical blog post. Include sections for \\'key_points\\', \\'sources\\', and \\'risks_or_caveats\\'. Use the web_search tool to gather relevant information.', 'system_prompt': 'You are a stateless tool router. \\nYou may either call a tool or respond directly with a natural language message ‚Äî whichever best fits the user query.\\n\\nIf you decide to call a tool, respond **only** with one-line valid JSON in the exact format below:\\n{\"tool\": \"<tool_name>\", \"inputs\": {<param>: <value>}}\\n\\nIf you decide to respond directly, emit your message as a plain string (not JSON).\\n\\nRules:\\n- Choose at most ONE tool per request.\\n- Use only explicit parameters defined by that tool. Do NOT invent or rename parameters.\\n- Include only required parameters unless an optional one is clearly implied.\\n- If no tool fits the request or inputs are ambiguous, output:\\n  {\"tool\": \"none\", \"inputs\": {}}\\n- Otherwise, respond in plain text when a natural language answer is more suitable.\\n\\nTOOLS CATALOG:\\nAvailable tools:\\nTool Name: `web_search`\\nDescription: Search the web using a pluggable backend (e.g. SerpAPI). Optionally crawls the top results, extracts page content, and summarizes it with an LLM.\\nWhen to use: Use this tool when you need up-to-date information, external web content, or detailed summaries combining multiple sources. The tool can return raw results or a refined LLM summary.\\nTool Inputs:\\n- `query`: string (required) ‚Äî The web search query.\\n- `hl`: string (optional) ‚Äî Interface language (e.g. \\'en\\'). Defaults to \\'en\\'.\\nTool Return: object ‚Äî JSON object with keys: `query`, `summary`, `results`, `provider`, `elapsed_ms`, and optionally `llm_summary` if summarization is enabled.\\n\\n\\n', 'temperature': 0.7, 'max_new_tokens': 512, 'stream': False}, outputs={'model_response': '{\"tool\": \"web_search\", \"inputs\": {\"query\": \"Using tool-augmented LLM agents to build reliable workflows\", \"hl\": \"en\"}}', 'model_response_len': 118}, meta={}, ok=True, error=None, logs=[TraceLog(ts=1763407341.9489017, message='Selected tool: web_search', data={}, type='info'), TraceLog(ts=1763407341.9500947, message=\"Raw inputs: {'query': 'Using tool-augmented LLM agents to build reliable workflows', 'hl': 'en'}\", data={}, type='info')]), TraceStep(step_id=3, kind='tool.execute', label='agent.route_and_call.tool_execute', node_id=None, agent_id='research', started_at=1763407341.953258, duration_ms=339, inputs={'tool_name': 'web_search', 'payload': {'query': 'Using tool-augmented LLM agents to build reliable workflows', 'hl': 'en', 'graph_inputs': {'topic_title': 'Using tool-augmented LLM agents to build reliable workflows', 'query': 'Compose a blog of about 2000-2500 words about tool-augmented LLM agents.'}, 'dependencies': {}}}, outputs={'tool_return': {'query': 'Using tool-augmented LLM agents to build reliable workflows', 'summary': \"Top 2 results out of ~575,000 results for: 'Using tool-augmented LLM agents to build reliable workflows'\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\\n2. Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Äî https://arxiv.org/html/2510.09244v1\", 'results': [{'title': 'Building Effective AI Agents', 'url': 'https://www.anthropic.com/research/building-effective-agents', 'snippet': 'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.', 'score': None, 'content': None, 'content_length': None, 'error': None}, {'title': 'Fundamentals of Building Autonomous LLM Agents ‚Ä†', 'url': 'https://arxiv.org/html/2510.09244v1', 'snippet': 'Many people confuse workflows with agents ... LLM-based agents can significantly enhance their perception capabilities through tool augmentation.', 'score': None, 'content': 'Fundamentals of Building Autonomous LLM Agents This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. 1 1 institutetext: Universitat Polit√®cnica de Catalunya, Barcelona, Spain 1 1 email: victor.de.lamo@estudiantat.upc.edu 2 2 institutetext: Technische Universit√§t M√ºnchen, M√ºnchen, Germany 2 2 email: {habtom.gidey, alex.lenz, knoll}@tum.de Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Ä† thanks: This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. Victor de Lamo Castrillo Habtom Kahsay Gidey Alexander Lenz Alois ... of tasks, including natural language processing (NLP), machine translation, vision applications, and question-answering. 2.2 From LLMs to LLM Agents LLMs in their standard form have significant limitations due to their chatbot nature. This restricts their effectiveness in real-world tasks. These models lack long-term memory, cannot autonomously interact with external tools, and struggle to pursue goals in dynamic environments. Such shortcomings hinder their performance in scenarios requiring sustained reasoning or multi-step workflows [ 61 ] . To overcome these constraints, LLMs are guided to follow a reasoning path and are provided with tools to interact with the environment that enables them ... paper ‚ÄúVCoder: Versatile Vision Encoders for Multimodal Large Language Models‚Äù by Jain et al. (2023) [ 28 ] , traditional MM-LLM systems often face limitations in fundamental visual perception, such as accurately identifying or counting objects, and a tendency to hallucinate non-existent entities. A faster and more cost-effective way to enhance perception (rather than improving each individual component of an MM-LLM) is to use visual encoders. These encoders, which can be separate models, extract relevant information from images to help the MM-LLM interpret them more effectively. While this approach doesn‚Äôt match the performance gains of directly improving each component of ... . ‚Ä¢ Data Collection: Training robust perception systems, particularly for multimodal or specialized domains, often requires large volumes of high-quality, annotated data. The collection of this data can be costly and time-consuming. ‚Ä¢ Computational Resources: High-fidelity perception, especially with multimodal inputs, requires high computational resources for both training and inference. This can be a barrier for execution in resource-constrained environments or for widespread adoption. Ultimately, the quality and fidelity of an LLM agent‚Äôs perception system directly affects the reasoning and planning modules. Therefore, continuous advancements in perception technologies are not merely improvements to one component, but fundamental enablers for building ... reasoning, and outcomes, and then use these insights to improve its future performance. This allows agents to learn from their mistakes or inefficiencies without human intervention. Key characteristics of reflection include: ‚Ä¢ Self-Evaluation: The agent examines its completed (or ongoing) task, its generated plans, and the results of its actions. This often involves comparing actual and expected outcomes. ‚Ä¢ Error Detection and Analysis: Identifying where things went wrong, why a plan failed, or where the reasoning failed. This can be due to misunderstandings of the prompt, incorrect tool usage, logical inconsistencies, or environmental changes. Papers like [ 49 ] and ... and roles‚Äù [ 51 ] of your expert. This involves: ‚Ä¢ Clear Specialization: What specific task, domain, or reasoning capability will this expert excel at? (e.g., planning, code generation, error handling). ‚Ä¢ Input and Output: What kind of information does this expert take as input, and what kind of output does it produce? ‚Ä¢ Boundaries: What are the limitations of its expertise? When should other experts be consulted or take over? [ 33 ] . 4.6.1 Equip with Knowledge An expert‚Äôs effectiveness hinges on its specialized knowledge. This can be achieved by: ‚Ä¢ Targeted Prompting: Crafting precise and detailed prompts ... Experiences: It is beneficial to store records of both successful and failed tasks. Research has indicated that even failed experiences, when appropriately logged and distinguished as such, can be valuable. By explicitly noting a ‚Äúfailed experience,‚Äù LLMs can learn to avoid repeating similar mistakes in the future. This continuous learning from past interactions, including the identification of ‚Äúinvalid action filtering,‚Äù contributes to the agent‚Äôs robust development and ability to adapt [ 1 , 22 ] . To store an experience, you capture a task‚Äôs natural language instruction (e.g., ‚ÄúWho ordered order 0130?‚Äù ) and the sequence of steps taken to ... approach is especially valuable for data manipulation tasks, complex calculations, file processing, and integration between different systems. Agents can write Python scripts for data analysis, generate SQL queries for database operations, create shell scripts for system administration, or produce HTML/CSS/JavaScript for web-based solutions [ 10 , 42 ] . 6.2.3 Robotic and Physical System Control: In robotics applications, LLM agents can control physical systems through appropriate APIs and sensor integrations [ 61 ] . They process sensor data (cameras, force sensors, temperature sensors) to understand the physical environment, generate motion plans and control commands, coordinate multiple actuators and subsystems, and ... https://arxiv.org/abs/2305.14992 [25] Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems 43 (2) (2025). doi: 10.1145/3703155 , http://dx.doi.org/10.1145/3703155 [26] Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint (2024), https://arxiv.org/abs/2402.02716 [27] Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills in humanoid robots: A deep learning approach. ... Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH [69] Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large language models with long-term memory. arXiv preprint (2023), https://arxiv.org/abs/2305.10250 [70] Zhou, S., Xu, F.F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T., Bisk, Y., Fried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building autonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854 [71] Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist agents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.07972 [72] Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced', 'content_length': 6990, 'error': None}], 'provider': 'serpapi', 'elapsed_ms': 333}, 'extras': {}}, meta={}, ok=True, error=None, logs=[TraceLog(ts=1763407342.2908046, message='Tool \\'web_search\\' Tool Return: {\\'query\\': \\'Using tool-augmented LLM agents to build reliable workflows\\', \\'summary\\': \"Top 2 results o...', data={}, type='info')])], meta={'agent_type': 'generic_agent', 'agent_config': AgentConfig(allow_input_pruning=True, repair_with_llm=True, strict_tool_call=False, temperature=0.7, max_new_tokens=512, return_stream_by_default=False, retry=RouterRetryPolicy(max_route_retries=2, max_tool_retries=1, backoff_sec=0.7), strict_json=True, max_json_repair_attempts=1), 'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit', 'toolkit': True, 'verbose': True, 'log_steps': True})), 'outline': NodeExecutionResult(node_id='outline', mode=<NodeMode.STRUCTURED: 'structured'>, raw_output='# Title:  \\n**Using Tool-Augmented LLM Agents to Build Reliable Workflows**\\n\\n## Detailed Description:  \\nThis blog post explores the transformative potential of **tool-augmented large language model (LLM) agents** in building **reliable and scalable workflows**. As organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs enables them to perform tasks with greater accuracy, efficiency, and adaptability. Drawing insights from recent research and real-world applications, this article outlines the key components of building robust LLM agents, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. The post is structured to guide both practitioners and developers in understanding how to leverage LLM agents to solve real-world problems while maintaining consistency, accountability, and performance.\\n\\n---\\n\\n## Ordered List of Sections:\\n\\n### 1. **Introduction: The Rise of Tool-Augmented LLM Agents**  \\n- Define what LLM agents are and their role in modern AI systems.  \\n- Introduce the concept of **tool augmentation** and why it is critical for building reliable workflows.  \\n- Highlight the limitations of traditional LLMs in real-world applications.  \\n- Mention the importance of **reliable workflows** in business and research settings.  \\n- Set the stage for the rest of the blog by outlining the key topics to be covered.\\n\\n### 2. **Understanding the LLM Agent Workflow**  \\n- Break down the **core components** of an LLM agent:  \\n  - **Orchestrator**: The central LLM that manages task decomposition and coordination.  \\n  - **Workers**: Specialized LLMs or tools that execute specific tasks.  \\n  - **Environment**: The external systems, APIs, or data sources the agent interacts with.  \\n- Explain the **orchestrator-workers workflow** in detail, using examples from the research.  \\n- Discuss the **dynamic nature** of task delegation and how it enables flexibility in workflows.  \\n- Introduce the concept of **reflection** and how it improves agent performance over time.\\n\\n### 3. **Why Tool Augmentation is Essential for Reliable Workflows**  \\n- Define **tool augmentation** and its role in enhancing LLM capabilities.  \\n- Discuss the **limitations of LLMs without tools**:  \\n  - Lack of long-term memory.  \\n  - Inability to interact with external systems.  \\n  - Struggles with multi-step reasoning and dynamic environments.  \\n- Highlight how **tool integration** improves:', structured_output=None, tool_call_output=None, started_at=1763407344.5532167, duration_ms=11201, error=None, traces=TraceResult(steps=[TraceStep(step_id=1, kind='agent', label='agent.run', node_id=None, agent_id='outline', started_at=1763407344.5541852, duration_ms=11196, inputs={'agent_type': 'Agent', 'has_toolkit': False, 'structured': False, 'stream': False, 'strict_tool_call': False}, outputs={}, meta={}, ok=True, error=None, logs=[]), TraceStep(step_id=2, kind='llm.call', label='agent.free_text_call', node_id=None, agent_id='outline', started_at=1763407344.5546656, duration_ms=11194, inputs={'system_prompt_len': 564, 'user_prompt_len': 8444, 'user_prompt': 'Based on the research summary provided, create a clear structure for a 2000-2500 word blog post titled \"Using Tool-Augmented LLM Agents to Build Reliable Workflows.\" The structure should include a title, a detailed description, and an ordered list of sections with headings and bullet points.\\n\\n# Context from dependency nodes:\\n## research\\n{\\'query\\': \\'Using tool-augmented LLM agents to build reliable workflows\\', \\'summary\\': \"Top 2 results out of ~575,000 results for: \\'Using tool-augmented LLM agents to build reliable workflows\\'\\\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\\\\n2. Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Äî https://arxiv.org/html/2510.09244v1\", \\'results\\': [{\\'title\\': \\'Building Effective AI Agents\\', \\'url\\': \\'https://www.anthropic.com/research/building-effective-agents\\', \\'snippet\\': \\'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.\\', \\'score\\': None, \\'content\\': None, \\'content_length\\': None, \\'error\\': None}, {\\'title\\': \\'Fundamentals of Building Autonomous LLM Agents ‚Ä†\\', \\'url\\': \\'https://arxiv.org/html/2510.09244v1\\', \\'snippet\\': \\'Many people confuse workflows with agents ... LLM-based agents can significantly enhance their perception capabilities through tool augmentation.\\', \\'score\\': None, \\'content\\': \\'Fundamentals of Building Autonomous LLM Agents This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. 1 1 institutetext: Universitat Polit√®cnica de Catalunya, Barcelona, Spain 1 1 email: victor.de.lamo@estudiantat.upc.edu 2 2 institutetext: Technische Universit√§t M√ºnchen, M√ºnchen, Germany 2 2 email: {habtom.gidey, alex.lenz, knoll}@tum.de Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Ä† thanks: This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. Victor de Lamo Castrillo Habtom Kahsay Gidey Alexander Lenz Alois ... of tasks, including natural language processing (NLP), machine translation, vision applications, and question-answering. 2.2 From LLMs to LLM Agents LLMs in their standard form have significant limitations due to their chatbot nature. This restricts their effectiveness in real-world tasks. These models lack long-term memory, cannot autonomously interact with external tools, and struggle to pursue goals in dynamic environments. Such shortcomings hinder their performance in scenarios requiring sustained reasoning or multi-step workflows [ 61 ] . To overcome these constraints, LLMs are guided to follow a reasoning path and are provided with tools to interact with the environment that enables them ... paper ‚ÄúVCoder: Versatile Vision Encoders for Multimodal Large Language Models‚Äù by Jain et al. (2023) [ 28 ] , traditional MM-LLM systems often face limitations in fundamental visual perception, such as accurately identifying or counting objects, and a tendency to hallucinate non-existent entities. A faster and more cost-effective way to enhance perception (rather than improving each individual component of an MM-LLM) is to use visual encoders. These encoders, which can be separate models, extract relevant information from images to help the MM-LLM interpret them more effectively. While this approach doesn‚Äôt match the performance gains of directly improving each component of ... . ‚Ä¢ Data Collection: Training robust perception systems, particularly for multimodal or specialized domains, often requires large volumes of high-quality, annotated data. The collection of this data can be costly and time-consuming. ‚Ä¢ Computational Resources: High-fidelity perception, especially with multimodal inputs, requires high computational resources for both training and inference. This can be a barrier for execution in resource-constrained environments or for widespread adoption. Ultimately, the quality and fidelity of an LLM agent‚Äôs perception system directly affects the reasoning and planning modules. Therefore, continuous advancements in perception technologies are not merely improvements to one component, but fundamental enablers for building ... reasoning, and outcomes, and then use these insights to improve its future performance. This allows agents to learn from their mistakes or inefficiencies without human intervention. Key characteristics of reflection include: ‚Ä¢ Self-Evaluation: The agent examines its completed (or ongoing) task, its generated plans, and the results of its actions. This often involves comparing actual and expected outcomes. ‚Ä¢ Error Detection and Analysis: Identifying where things went wrong, why a plan failed, or where the reasoning failed. This can be due to misunderstandings of the prompt, incorrect tool usage, logical inconsistencies, or environmental changes. Papers like [ 49 ] and ... and roles‚Äù [ 51 ] of your expert. This involves: ‚Ä¢ Clear Specialization: What specific task, domain, or reasoning capability will this expert excel at? (e.g., planning, code generation, error handling). ‚Ä¢ Input and Output: What kind of information does this expert take as input, and what kind of output does it produce? ‚Ä¢ Boundaries: What are the limitations of its expertise? When should other experts be consulted or take over? [ 33 ] . 4.6.1 Equip with Knowledge An expert‚Äôs effectiveness hinges on its specialized knowledge. This can be achieved by: ‚Ä¢ Targeted Prompting: Crafting precise and detailed prompts ... Experiences: It is beneficial to store records of both successful and failed tasks. Research has indicated that even failed experiences, when appropriately logged and distinguished as such, can be valuable. By explicitly noting a ‚Äúfailed experience,‚Äù LLMs can learn to avoid repeating similar mistakes in the future. This continuous learning from past interactions, including the identification of ‚Äúinvalid action filtering,‚Äù contributes to the agent‚Äôs robust development and ability to adapt [ 1 , 22 ] . To store an experience, you capture a task‚Äôs natural language instruction (e.g., ‚ÄúWho ordered order 0130?‚Äù ) and the sequence of steps taken to ... approach is especially valuable for data manipulation tasks, complex calculations, file processing, and integration between different systems. Agents can write Python scripts for data analysis, generate SQL queries for database operations, create shell scripts for system administration, or produce HTML/CSS/JavaScript for web-based solutions [ 10 , 42 ] . 6.2.3 Robotic and Physical System Control: In robotics applications, LLM agents can control physical systems through appropriate APIs and sensor integrations [ 61 ] . They process sensor data (cameras, force sensors, temperature sensors) to understand the physical environment, generate motion plans and control commands, coordinate multiple actuators and subsystems, and ... https://arxiv.org/abs/2305.14992 [25] Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems 43 (2) (2025). doi: 10.1145/3703155 , http://dx.doi.org/10.1145/3703155 [26] Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint (2024), https://arxiv.org/abs/2402.02716 [27] Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills in humanoid robots: A deep learning approach. ... Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH [69] Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large language models with long-term memory. arXiv preprint (2023), https://arxiv.org/abs/2305.10250 [70] Zhou, S., Xu, F.F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T., Bisk, Y., Fried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building autonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854 [71] Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist agents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.07972 [72] Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced\\', \\'content_length\\': 6990, \\'error\\': None}], \\'provider\\': \\'serpapi\\', \\'elapsed_ms\\': 333}', 'system_prompt': 'You are a specialized agent in a larger workflow.\\n\\nYour role:\\n- PURPOSE: Design a clear structure for the article.\\n- GOAL: Turn the research summary into a logical outline suitable for a 2000-2500 word blog post.\\n\\n- EXPECTED_RESULT: A title, a detailed description, and an ordered list of sections with headings and bullet points.\\n\\n\\nGeneral behaviour:\\n- Be precise and concise unless the task requires extended output.\\n- Use clear structure (headings/bullets) when helpful.\\n- If you are calling tools, interpret their outputs carefully and explain your reasoning.\\n', 'temperature': 0.7, 'max_new_tokens': 512, 'stream': False}, outputs={'output': '# Title:  \\n**Using Tool-Augmented LLM Agents to Build Reliable Workflows**\\n\\n## Detailed Description:  \\nThis blog post explores the transformative potential of **tool-augmented large language model (LLM) agents** in building **reliable and scalable workflows**. As organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs enables them to perform tasks with greater accuracy, efficiency, and adaptability. Drawing insights from recent research and real-world applications, this article outlines the key components of building robust LLM agents, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. The post is structured to guide both practitioners and developers in understanding how to leverage LLM agents to solve real-world problems while maintaining consistency, accountability, and performance.\\n\\n---\\n\\n## Ordered List of Sections:\\n\\n### 1. **Introduction: The Rise of Tool-Augmented LLM Agents**  \\n- Define what LLM agents are and their role in modern AI systems.  \\n- Introduce the concept of **tool augmentation** and why it is critical for building reliable workflows.  \\n- Highlight the limitations of traditional LLMs in real-world applications.  \\n- Mention the importance of **reliable workflows** in business and research settings.  \\n- Set the stage for the rest of the blog by outlining the key topics to be covered.\\n\\n### 2. **Understanding the LLM Agent Workflow**  \\n- Break down the **core components** of an LLM agent:  \\n  - **Orchestrator**: The central LLM that manages task decomposition and coordination.  \\n  - **Workers**: Specialized LLMs or tools that execute specific tasks.  \\n  - **Environment**: The external systems, APIs, or data sources the agent interacts with.  \\n- Explain the **orchestrator-workers workflow** in detail, using examples from the research.  \\n- Discuss the **dynamic nature** of task delegation and how it enables flexibility in workflows.  \\n- Introduce the concept of **reflection** and how it improves agent performance over time.\\n\\n### 3. **Why Tool Augmentation is Essential for Reliable Workflows**  \\n- Define **tool augmentation** and its role in enhancing LLM capabilities.  \\n- Discuss the **limitations of LLMs without tools**:  \\n  - Lack of long-term memory.  \\n  - Inability to interact with external systems.  \\n  - Struggles with multi-step reasoning and dynamic environments.  \\n- Highlight how **tool integration** improves:'}, meta={}, ok=True, error=None, logs=[])], meta={'agent_type': 'generic_agent', 'agent_config': AgentConfig(allow_input_pruning=True, repair_with_llm=True, strict_tool_call=False, temperature=0.7, max_new_tokens=512, return_stream_by_default=False, retry=RouterRetryPolicy(max_route_retries=2, max_tool_retries=1, backoff_sec=0.7), strict_json=True, max_json_repair_attempts=1), 'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit', 'toolkit': False, 'verbose': True, 'log_steps': True})), 'draft': NodeExecutionResult(node_id='draft', mode=<NodeMode.TEXT: 'text'>, raw_output='# Using Tool-Augmented LLM Agents to Build Reliable Workflows\\n\\n## Introduction: The Rise of Tool-Augmented LLM Agents\\n\\nIn recent years, the field of artificial intelligence has witnessed a paradigm shift with the advent of large language models (LLMs). These powerful models, capable of understanding and generating human-like text, have opened up new possibilities for automation, decision-making, and problem-solving. However, the true potential of LLMs is unlocked when they are augmented with tools that extend their capabilities beyond the confines of their training data. This integration of tools into LLMs, known as **tool augmentation**, has become a cornerstone in building **reliable and scalable workflows** that can handle complex, real-world tasks.\\n\\nLLM agents, which are essentially AI systems that use LLMs as their core, are designed to perform tasks that require reasoning, planning, and decision-making. These agents are not just static models but dynamic systems that can adapt to new information and environments. The key to their reliability lies in their ability to interact with external tools, which allows them to access real-time data, perform computations, and execute actions that would be impossible for a standalone LLM to achieve.\\n\\nThe importance of reliable workflows cannot be overstated, especially in business and research settings where accuracy and consistency are paramount. Traditional LLMs, while powerful, often struggle with tasks that require multi-step reasoning, long-term memory, and interaction with external systems. These limitations hinder their effectiveness in scenarios that demand sustained reasoning or complex workflows. Tool augmentation addresses these limitations by providing LLM agents with the necessary tools to interact with the environment, access additional information, and perform tasks with greater accuracy and efficiency.\\n\\nAs organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs has become essential for building robust workflows. This blog post will explore the transformative potential of tool-augmented LLM agents, focusing on the core components of an LLM agent, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. We will also highlight the importance of reliable workflows in business and research settings, and how they contribute to the overall success of AI-driven initiatives.\\n\\nIn the following sections, we will delve into the **LLM agent workflow**, breaking down its core components and explaining how they work together to create efficient and effective systems. We will also discuss the **dynamic nature of task delegation** and the concept of **reflection**, which plays a crucial role in improving agent performance over time. Finally, we will highlight the **importance of tool augmentation** in overcoming the limitations of traditional LLMs and enabling the creation of reliable workflows that can handle complex, real-world tasks.\\n\\nBy the end of this blog post, you will have a comprehensive understanding of how tool-augmented LLM agents can be leveraged to build reliable and scalable workflows, and how these agents can be designed to meet the demands of modern AI applications. Let\\'s begin our exploration of the world of tool-augmented LLM agents and their role in building reliable workflows.\\n\\n## Understanding the LLM Agent Workflow\\n\\nAt the heart of any effective AI system lies the **LLM agent workflow**, a structured process that enables agents to perform complex tasks with precision and adaptability. This workflow is composed of three core components: the **orchestrator**, the **workers**, and the **environment**. Each of these elements plays a vital role in ensuring that the agent can effectively execute its tasks and adapt to changing conditions. \\n\\n### Orchestrator: The Central LLM\\n\\nThe **orchestrator** is the central LLM within the agent system. It acts as the brain of the operation, responsible for **task decomposition**, **coordination**, and **synthesis of results**. The orchestrator receives a high-level task or goal from the user and breaks it down into smaller, manageable subtasks. This decomposition is crucial as it allows the agent to tackle complex problems by breaking them into simpler, more digestible parts. \\n\\nFor instance, if the task is to \"create a report on the latest market trends,\" the orchestrator might decompose this into subtasks such as \"gather data on recent market trends,\" \"analyze the data,\" and \"format the findings into a report.\" The orchestrator then delegates these subtasks to the appropriate **workers**, ensuring that each task is handled by the most suitable component of the system.\\n\\n### Workers: Specialized LLMs or Tools\\n\\nThe **workers** are the specialized LLMs or external tools that execute the specific tasks assigned by the orchestrator. These workers can be either **LLMs** designed for specific functions or **external tools** that provide access to databases, APIs, or other systems. The key to effective task execution lies in the **specialization** of these workers. \\n\\nFor example, if the orchestrator assigns the task of \"analyzing the data gathered on market trends,\" it might direct this to a worker that is specifically trained for data analysis. This worker could be an LLM that has been fine-tuned on financial data or a tool that connects to a database of market statistics. The use of specialized workers ensures that each task is handled with the appropriate expertise, enhancing the accuracy and efficiency of the overall process.\\n\\n### Environment: The External Systems\\n\\nThe **environment** refers to the external systems, APIs, or data sources that the agent interacts with. This component is essential as it allows the agent to access real-time information, perform computations, and execute actions that are necessary for completing the task. The environment can include databases, web services, and other tools that provide the agent with the necessary information to make informed decisions.\\n\\nFor example, if the orchestrator needs to gather the latest market data, it might direct the agent to interact with a financial API that provides up-to-date market trends. This interaction with the environment enables the agent to access the most relevant information, ensuring that the task is completed with the highest level of accuracy.\\n\\n### Orchestrator-Workers Workflow in Action\\n\\nThe orchestrator-workers workflow operates in a **dynamic and iterative manner**, allowing the agent to adapt to changing conditions and improve its performance over time. This workflow is particularly effective in scenarios that require **multi-step reasoning** and **dynamic environments**. \\n\\nFor instance, consider an agent tasked with \"planning a trip to a new city.\" The orchestrator would first break down the task into subtasks such as \"research the destination,\" \"book accommodations,\" and \"plan the itinerary.\" Each of these subtasks would be assigned to specialized workers. The research worker might access travel blogs and review sites, the booking worker could interact with hotel reservation systems, and the itinerary planner might use a mapping tool to suggest the best routes.\\n\\nAs the agent performs these tasks, it continuously interacts with the environment, gathering new information that may influence the planning process. This dynamic interaction allows the agent to adjust its plans in real-time, ensuring that the final itinerary is optimized for the traveler\\'s preferences and the latest available information.\\n\\n### Dynamic Nature of Task Delegation\\n\\nThe **dynamic nature of task delegation** is a crucial aspect of the LLM agent workflow. This means that the orchestrator can adaptively assign tasks based on the current context and the availability of resources. For example, if a particular worker is not available or if new information becomes available, the orchestrator can reassign tasks to ensure that the overall workflow remains efficient.\\n\\nThis adaptability is essential in environments where conditions can change rapidly, such as in financial markets or customer service scenarios. The ability to dynamically adjust task delegation allows the agent to remain responsive to new information and changing circumstances, ensuring that the workflow remains effective and efficient.\\n\\n### Reflection and Continuous Improvement\\n\\nAnother critical component of the LLM agent workflow is **reflection**, which allows the agent to learn from its experiences and improve its performance over time. Reflection involves the agent examining its completed tasks, evaluating the outcomes, and identifying areas for improvement. This process enables the agent to refine its strategies and enhance its capabilities, leading to more accurate and efficient task execution.\\n\\nIn conclusion, the **LLM agent workflow** is a complex yet effective system that combines the orchestrator, workers, and environment to create a robust framework for executing tasks. By breaking down tasks into manageable subtasks, leveraging specialized workers, and dynamically interacting with the environment, LLM agents can achieve a high level of reliability and efficiency. The dynamic nature of task delegation and the incorporation of reflection further enhance the agent\\'s ability to adapt and improve, making them essential in today\\'s rapidly evolving technological landscape. As we continue to explore the potential of tool-augmented LLM agents, it is clear that understanding this workflow is crucial for building reliable and scalable AI systems. üåü\\n\\n## Why Tool Augmentation is Essential for Reliable Workflows\\n\\n### The Limitations of Traditional LLMs\\n\\nTraditional large language models (LLMs) have revolutionized the field of natural language processing, offering impressive capabilities in tasks such as text generation, translation, and question-answering. However, these models often fall short when it comes to executing complex, multi-step tasks that require interaction with external systems or environments. One of the primary limitations of traditional LLMs is their **lack of long-term memory**. Unlike humans, who can retain and recall information over extended periods, LLMs are typically trained on static data and may not retain information from previous interactions, leading to inconsistencies and errors in tasks that require sequential reasoning.\\n\\nAnother significant limitation is the **inability to interact with external systems**. While LLMs can generate text and understand context, they often struggle to access real-time data or perform actions that require direct interaction with databases, APIs, or other tools. This inability to interact with external systems hampers their effectiveness in scenarios where real-time information is crucial, such as financial trading, customer service, or data analysis. For instance, an LLM tasked with providing stock market insights may not be able to access the latest stock prices or news updates, resulting in outdated or inaccurate information.\\n\\nAdditionally, traditional LLMs often struggle with **multi-step reasoning and dynamic environments**. These models are typically designed to handle single tasks or simple interactions, making it challenging for them to navigate complex workflows that involve multiple steps or changing conditions. In dynamic environments, where the context can shift rapidly, the lack of adaptability in traditional LLMs can lead to suboptimal outcomes. For example, an LLM used for customer service might not be able to adjust its responses based on the customer\\'s changing needs or preferences, leading to a poor user experience.\\n\\n### The Role of Tool Integration\\n\\nTool augmentation addresses these limitations by integrating external tools into the LLM\\'s capabilities, allowing the model to access real-time data, perform computations, and execute actions that enhance its functionality. This integration enables LLMs to **interact with the environment**, thereby enhancing their ability to perform complex tasks. For instance, when an LLM is equipped with tools such as APIs for financial data, it can access the latest stock prices, enabling it to provide up-to-date insights to users. This not only improves the accuracy of the information provided but also enhances the user experience by ensuring that the information is current and relevant.\\n\\nMoreover, tool augmentation enhances **multi-step reasoning capabilities** by allowing the LLM to break down complex tasks into manageable components. By leveraging tools, the LLM can perform specific actions, such as querying a database or executing a script, thereby enabling it to handle tasks that require multiple steps. This capability is particularly important in dynamic environments, where the ability to adapt to changing conditions is essential. For example, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\n### Enhancing Accuracy and Efficiency\\n\\nThe integration of tools into LLMs significantly improves the **accuracy and efficiency** of task execution. By accessing real-time data and performing computations, the LLM can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nFurthermore, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the L can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Conclusion\\n\\nIn conclusion, the limitations of traditional LLMs in real-world applications are significant, but tool augmentation offers a viable solution to these challenges. By integrating external tools, LLMs can access real-time data, perform computations, and execute actions that enhance their capabilities. This integration not only improves the accuracy and efficiency of task execution but also allows LLMs to navigate complex workflows and dynamic environments with greater adaptability. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will delve deeper into how tool integration enhances the capabilities of LLM agents, providing real-world examples of its impact on reliability and performance. üåü\\n\\n## Enhancing LLM Capabilities Through Tool Integration\\n\\n### The Role of Tool Augmentation in Overcoming Limitations\\n\\nTool augmentation is a transformative approach that addresses the inherent limitations of traditional LLMs by integrating external tools into their capabilities. This integration not only enhances the functionality of LLMs but also allows them to perform tasks that require **long-term memory, interaction with external systems, and multi-step reasoning**. By leveraging tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\\n\\nOne of the most significant benefits of tool augmentation is the ability to **access real-time data**. Traditional LLMs are often limited by the static data they are trained on, which can lead to outdated or inaccurate information. By integrating tools such as APIs, databases, or web services, LLMs can retrieve the latest information, ensuring that their responses are current and relevant. For example, an LLM tasked with providing financial market insights can access real-time stock prices and news updates through a financial API, enabling it to deliver up-to-date information to users.\\n\\n### Improving Accuracy and Efficiency\\n\\nThe integration of tools also enhances the **accuracy and efficiency** of LLMs. By accessing real-time data and performing computations, LLMs can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nMoreover, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the LLM can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Facilitating Multi-Step Reasoning and Dynamic Environments\\n\\nAnother critical aspect of tool integration is its ability to **facilitate multi-step reasoning and adapt to dynamic environments**. Traditional LLMs often struggle with complex tasks that require multiple steps or changing conditions, but by integrating tools, LLMs can break down these tasks into manageable components. This capability is particularly important in dynamic environments, where the context can shift rapidly. For instance, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\nThe integration of tools also allows LLMs to **navigate complex workflows** by providing the necessary tools to execute specific actions. For example, in a financial trading scenario, an augmented LLM can use tools such as market analysis APIs to assess investment opportunities, execute trades, and monitor market trends in real-time. This not only enhances the LLM\\'s ability to make informed decisions but also improves the overall efficiency of the trading process.\\n\\n### Real-World Applications of Tool-Augmented LLMs\\n\\nThe benefits of tool augmentation are evident in various real-world applications, where LLMs are used to perform complex tasks that require interaction with external systems. For instance, in the field of customer service, tool-augmented LLMs can handle inquiries by accessing customer databases, retrieving relevant information, and providing personalized responses. This not only improves the customer experience but also reduces the workload on human agents, allowing them to focus on more complex tasks.\\n\\nIn the healthcare industry, tool-augmented LLMs can assist in diagnosing patients by accessing medical databases and providing treatment recommendations based on the latest research and patient data. This integration of tools allows LLMs to provide more accurate and timely information, ultimately improving patient outcomes.\\n\\nIn the realm of data analysis, tool-augmented LLMs can automate tasks such as data collection, processing, and visualization, enabling organizations to make data-driven decisions more efficiently. By leveraging tools such as SQL databases and data visualization software, LLMs can perform complex analyses and generate insights that would otherwise require significant human effort.\\n\\n### Conclusion\\n\\nIn conclusion, the integration of tools into LLMs through **tool augmentation** significantly enhances their capabilities, enabling them to overcome the limitations of traditional models. By accessing real-time data, performing computations, and executing actions, LLMs can provide more accurate and efficient information, facilitating multi-step reasoning and adaptability in dynamic environments. The real-world applications of tool-augmented LLMs demonstrate their potential to transform various industries, from customer service to healthcare and data analysis. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will explore the importance of reliable workflows in business and research settings, highlighting how they contribute to the overall success of AI-driven initiatives. üåü\\n\\n## The Importance of Reliable Workflows in Business and Research Settings\\n\\nIn today\\'s rapidly evolving technological landscape, the ability to execute tasks reliably and efficiently is paramount for both business operations and research endeavors. Reliable workflows are essential as they ensure that tasks are completed accurately, consistently, and within expected timeframes. In business, where customer satisfaction and operational efficiency are critical, the implementation of reliable workflows can significantly enhance productivity and reduce errors. Similarly, in research settings, reliable workflows are crucial for maintaining the integrity of data and ensuring that findings are based on accurate and consistent information.\\n\\n### Business Applications of Reliable Workflows\\n\\nIn the business context, reliable workflows are the backbone of operational success. They enable organizations to automate repetitive tasks, streamline processes, and enhance decision-making. For instance, in customer service, a reliable workflow can ensure that customer inquiries are addressed promptly and accurately, leading to higher customer satisfaction and loyalty. By integrating tools such as chatbots and customer relationship management (CRM) systems, businesses can create workflows that not only improve response times but also provide personalized interactions, thereby enhancing the overall customer experience.\\n\\nMoreover, in data-driven industries, reliable workflows are essential for data processing and analysis. By establishing standardized procedures for data collection, cleaning, and analysis, organizations can ensure that the data used for decision-making is accurate and reliable. This is particularly important in fields such as finance and marketing, where data accuracy can directly impact profitability and market competitiveness. For example, a financial institution utilizing reliable data workflows can make informed investment decisions based on up-to-date market trends, leading to more effective risk management and better returns on investments.\\n\\n### Research Applications of Reliable Workflows\\n\\nIn research settings, reliable workflows are equally vital. They ensure that the research process is systematic and reproducible, which is crucial for validating findings and maintaining the credibility of research. In scientific research, where the accuracy of results can influence policy decisions and public health, reliable workflows are essential for minimizing errors and ensuring that data is collected and analyzed consistently. This is particularly important in fields such as medicine and environmental science, where the reliability of data can have significant implications for public health and environmental policies.\\n\\nFurthermore, reliable workflows in research also facilitate collaboration among researchers. By establishing clear protocols and standardized procedures, researchers can work together more effectively, sharing data and insights while maintaining the integrity of their findings. This collaboration is essential for tackling complex research questions that require interdisciplinary approaches. For example, in climate change research, reliable workflows can enable scientists from various fields to combine their expertise and data, leading to more comprehensive and impactful findings.\\n\\n### Enhancing Reliability Through Tool-Augmented LLMs\\n\\nThe integration of tool-augmented LLMs into workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. These models can access real-time data, perform complex computations, and execute tasks that would be impossible for traditional models to achieve. For instance, in a business setting, an augmented LLM can analyze customer feedback in real-time, enabling companies to make data-driven decisions that improve customer satisfaction and loyalty. Similarly, in research, an augmented LLM can assist in data analysis by generating insights from large datasets, allowing researchers to identify patterns and trends that might otherwise go unnoticed.\\n\\nMoreover, the ability of tool-augmented LLMs to handle multi-step reasoning and adapt to dynamic environments ensures that workflows remain flexible and responsive to changing conditions. This adaptability is crucial in both business and research settings, where the ability to pivot and adjust strategies based on new information can lead to more successful outcomes. For example, in a rapidly changing market, an augmented LLM can continuously monitor market trends and adjust business strategies in real-time, ensuring that the organization remains competitive.\\n\\n### Conclusion\\n\\nIn conclusion, the importance of reliable workflows in both business and research settings cannot be overstated. They are essential for ensuring that tasks are executed accurately, consistently, and efficiently, ultimately leading to better outcomes. The integration of tool-augmented LLMs into these workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. As organizations increasingly rely on AI to automate complex tasks, the role of reliable workflows in achieving success becomes even more critical. The next section will delve into the best practices for designing reliable workflows, providing insights into how to effectively leverage tool-augmented LLMs to meet the demands of modern AI applications. üåü', structured_output=None, tool_call_output=None, started_at=1763407359.104179, duration_ms=97969, error=None, traces=TraceResult(steps=[TraceStep(step_id=1, kind='agent', label='agent.run', node_id=None, agent_id='draft', started_at=1763407359.1068604, duration_ms=97963, inputs={'agent_type': 'Agent', 'has_toolkit': False, 'structured': False, 'stream': False, 'strict_tool_call': False}, outputs={}, meta={}, ok=True, error=None, logs=[]), TraceStep(step_id=2, kind='llm.call', label='agent.free_text_call', node_id=None, agent_id='draft', started_at=1763407359.1079626, duration_ms=97961, inputs={'system_prompt_len': 620, 'user_prompt_len': 11276, 'user_prompt': 'Write a full draft of the blog post based on the outline and research provided. The draft should be approximately 5000 words, include clear headings, subheadings, and smooth transitions between sections. Ensure that the content is coherent, readable, and covers all the key points from the outline, such as the introduction to LLM agents, the orchestrator-workers workflow, the importance of tool augmentation, and the limitations of traditional LLMs. Use the research findings to support your arguments and provide real-world examples where applicable. Format the draft in markdown with a title, section headings, and paragraphs.\\n\\n# Context from dependency nodes:\\n## outline\\n# Title:  \\n**Using Tool-Augmented LLM Agents to Build Reliable Workflows**\\n\\n## Detailed Description:  \\nThis blog post explores the transformative potential of **tool-augmented large language model (LLM) agents** in building **reliable and scalable workflows**. As organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs enables them to perform tasks with greater accuracy, efficiency, and adaptability. Drawing insights from recent research and real-world applications, this article outlines the key components of building robust LLM agents, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. The post is structured to guide both practitioners and developers in understanding how to leverage LLM agents to solve real-world problems while maintaining consistency, accountability, and performance.\\n\\n---\\n\\n## Ordered List of Sections:\\n\\n### 1. **Introduction: The Rise of Tool-Augmented LLM Agents**  \\n- Define what LLM agents are and their role in modern AI systems.  \\n- Introduce the concept of **tool augmentation** and why it is critical for building reliable workflows.  \\n- Highlight the limitations of traditional LLMs in real-world applications.  \\n- Mention the importance of **reliable workflows** in business and research settings.  \\n- Set the stage for the rest of the blog by outlining the key topics to be covered.\\n\\n### 2. **Understanding the LLM Agent Workflow**  \\n- Break down the **core components** of an LLM agent:  \\n  - **Orchestrator**: The central LLM that manages task decomposition and coordination.  \\n  - **Workers**: Specialized LLMs or tools that execute specific tasks.  \\n  - **Environment**: The external systems, APIs, or data sources the agent interacts with.  \\n- Explain the **orchestrator-workers workflow** in detail, using examples from the research.  \\n- Discuss the **dynamic nature** of task delegation and how it enables flexibility in workflows.  \\n- Introduce the concept of **reflection** and how it improves agent performance over time.\\n\\n### 3. **Why Tool Augmentation is Essential for Reliable Workflows**  \\n- Define **tool augmentation** and its role in enhancing LLM capabilities.  \\n- Discuss the **limitations of LLMs without tools**:  \\n  - Lack of long-term memory.  \\n  - Inability to interact with external systems.  \\n  - Struggles with multi-step reasoning and dynamic environments.  \\n- Highlight how **tool integration** improves:\\n\\n## research\\n{\\'query\\': \\'Using tool-augmented LLM agents to build reliable workflows\\', \\'summary\\': \"Top 2 results out of ~575,000 results for: \\'Using tool-augmented LLM agents to build reliable workflows\\'\\\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\\\\n2. Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Äî https://arxiv.org/html/2510.09244v1\", \\'results\\': [{\\'title\\': \\'Building Effective AI Agents\\', \\'url\\': \\'https://www.anthropic.com/research/building-effective-agents\\', \\'snippet\\': \\'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.\\', \\'score\\': None, \\'content\\': None, \\'content_length\\': None, \\'error\\': None}, {\\'title\\': \\'Fundamentals of Building Autonomous LLM Agents ‚Ä†\\', \\'url\\': \\'https://arxiv.org/html/2510.09244v1\\', \\'snippet\\': \\'Many people confuse workflows with agents ... LLM-based agents can significantly enhance their perception capabilities through tool augmentation.\\', \\'score\\': None, \\'content\\': \\'Fundamentals of Building Autonomous LLM Agents This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. 1 1 institutetext: Universitat Polit√®cnica de Catalunya, Barcelona, Spain 1 1 email: victor.de.lamo@estudiantat.upc.edu 2 2 institutetext: Technische Universit√§t M√ºnchen, M√ºnchen, Germany 2 2 email: {habtom.gidey, alex.lenz, knoll}@tum.de Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Ä† thanks: This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. Victor de Lamo Castrillo Habtom Kahsay Gidey Alexander Lenz Alois ... of tasks, including natural language processing (NLP), machine translation, vision applications, and question-answering. 2.2 From LLMs to LLM Agents LLMs in their standard form have significant limitations due to their chatbot nature. This restricts their effectiveness in real-world tasks. These models lack long-term memory, cannot autonomously interact with external tools, and struggle to pursue goals in dynamic environments. Such shortcomings hinder their performance in scenarios requiring sustained reasoning or multi-step workflows [ 61 ] . To overcome these constraints, LLMs are guided to follow a reasoning path and are provided with tools to interact with the environment that enables them ... paper ‚ÄúVCoder: Versatile Vision Encoders for Multimodal Large Language Models‚Äù by Jain et al. (2023) [ 28 ] , traditional MM-LLM systems often face limitations in fundamental visual perception, such as accurately identifying or counting objects, and a tendency to hallucinate non-existent entities. A faster and more cost-effective way to enhance perception (rather than improving each individual component of an MM-LLM) is to use visual encoders. These encoders, which can be separate models, extract relevant information from images to help the MM-LLM interpret them more effectively. While this approach doesn‚Äôt match the performance gains of directly improving each component of ... . ‚Ä¢ Data Collection: Training robust perception systems, particularly for multimodal or specialized domains, often requires large volumes of high-quality, annotated data. The collection of this data can be costly and time-consuming. ‚Ä¢ Computational Resources: High-fidelity perception, especially with multimodal inputs, requires high computational resources for both training and inference. This can be a barrier for execution in resource-constrained environments or for widespread adoption. Ultimately, the quality and fidelity of an LLM agent‚Äôs perception system directly affects the reasoning and planning modules. Therefore, continuous advancements in perception technologies are not merely improvements to one component, but fundamental enablers for building ... reasoning, and outcomes, and then use these insights to improve its future performance. This allows agents to learn from their mistakes or inefficiencies without human intervention. Key characteristics of reflection include: ‚Ä¢ Self-Evaluation: The agent examines its completed (or ongoing) task, its generated plans, and the results of its actions. This often involves comparing actual and expected outcomes. ‚Ä¢ Error Detection and Analysis: Identifying where things went wrong, why a plan failed, or where the reasoning failed. This can be due to misunderstandings of the prompt, incorrect tool usage, logical inconsistencies, or environmental changes. Papers like [ 49 ] and ... and roles‚Äù [ 51 ] of your expert. This involves: ‚Ä¢ Clear Specialization: What specific task, domain, or reasoning capability will this expert excel at? (e.g., planning, code generation, error handling). ‚Ä¢ Input and Output: What kind of information does this expert take as input, and what kind of output does it produce? ‚Ä¢ Boundaries: What are the limitations of its expertise? When should other experts be consulted or take over? [ 33 ] . 4.6.1 Equip with Knowledge An expert‚Äôs effectiveness hinges on its specialized knowledge. This can be achieved by: ‚Ä¢ Targeted Prompting: Crafting precise and detailed prompts ... Experiences: It is beneficial to store records of both successful and failed tasks. Research has indicated that even failed experiences, when appropriately logged and distinguished as such, can be valuable. By explicitly noting a ‚Äúfailed experience,‚Äù LLMs can learn to avoid repeating similar mistakes in the future. This continuous learning from past interactions, including the identification of ‚Äúinvalid action filtering,‚Äù contributes to the agent‚Äôs robust development and ability to adapt [ 1 , 22 ] . To store an experience, you capture a task‚Äôs natural language instruction (e.g., ‚ÄúWho ordered order 0130?‚Äù ) and the sequence of steps taken to ... approach is especially valuable for data manipulation tasks, complex calculations, file processing, and integration between different systems. Agents can write Python scripts for data analysis, generate SQL queries for database operations, create shell scripts for system administration, or produce HTML/CSS/JavaScript for web-based solutions [ 10 , 42 ] . 6.2.3 Robotic and Physical System Control: In robotics applications, LLM agents can control physical systems through appropriate APIs and sensor integrations [ 61 ] . They process sensor data (cameras, force sensors, temperature sensors) to understand the physical environment, generate motion plans and control commands, coordinate multiple actuators and subsystems, and ... https://arxiv.org/abs/2305.14992 [25] Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems 43 (2) (2025). doi: 10.1145/3703155 , http://dx.doi.org/10.1145/3703155 [26] Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint (2024), https://arxiv.org/abs/2402.02716 [27] Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills in humanoid robots: A deep learning approach. ... Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH [69] Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large language models with long-term memory. arXiv preprint (2023), https://arxiv.org/abs/2305.10250 [70] Zhou, S., Xu, F.F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T., Bisk, Y., Fried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building autonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854 [71] Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist agents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.07972 [72] Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced\\', \\'content_length\\': 6990, \\'error\\': None}], \\'provider\\': \\'serpapi\\', \\'elapsed_ms\\': 333}', 'system_prompt': 'You are a specialized agent in a larger workflow.\\n\\nYour role:\\n- PURPOSE: Write the first full draft of the article of about 5000 words including every detail.\\n- GOAL: Use the outline and research to produce a readable, coherent blog draft with clear headings, examples, and smooth transitions.\\n\\n- EXPECTED_RESULT: A complete draft in markdown, including title, headings, and paragraphs.\\n\\n\\nGeneral behaviour:\\n- Be precise and concise unless the task requires extended output.\\n- Use clear structure (headings/bullets) when helpful.\\n- If you are calling tools, interpret their outputs carefully and explain your reasoning.\\n', 'temperature': 0.7, 'max_new_tokens': 16000, 'stream': False}, outputs={'output': '# Using Tool-Augmented LLM Agents to Build Reliable Workflows\\n\\n## Introduction: The Rise of Tool-Augmented LLM Agents\\n\\nIn recent years, the field of artificial intelligence has witnessed a paradigm shift with the advent of large language models (LLMs). These powerful models, capable of understanding and generating human-like text, have opened up new possibilities for automation, decision-making, and problem-solving. However, the true potential of LLMs is unlocked when they are augmented with tools that extend their capabilities beyond the confines of their training data. This integration of tools into LLMs, known as **tool augmentation**, has become a cornerstone in building **reliable and scalable workflows** that can handle complex, real-world tasks.\\n\\nLLM agents, which are essentially AI systems that use LLMs as their core, are designed to perform tasks that require reasoning, planning, and decision-making. These agents are not just static models but dynamic systems that can adapt to new information and environments. The key to their reliability lies in their ability to interact with external tools, which allows them to access real-time data, perform computations, and execute actions that would be impossible for a standalone LLM to achieve.\\n\\nThe importance of reliable workflows cannot be overstated, especially in business and research settings where accuracy and consistency are paramount. Traditional LLMs, while powerful, often struggle with tasks that require multi-step reasoning, long-term memory, and interaction with external systems. These limitations hinder their effectiveness in scenarios that demand sustained reasoning or complex workflows. Tool augmentation addresses these limitations by providing LLM agents with the necessary tools to interact with the environment, access additional information, and perform tasks with greater accuracy and efficiency.\\n\\nAs organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs has become essential for building robust workflows. This blog post will explore the transformative potential of tool-augmented LLM agents, focusing on the core components of an LLM agent, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. We will also highlight the importance of reliable workflows in business and research settings, and how they contribute to the overall success of AI-driven initiatives.\\n\\nIn the following sections, we will delve into the **LLM agent workflow**, breaking down its core components and explaining how they work together to create efficient and effective systems. We will also discuss the **dynamic nature of task delegation** and the concept of **reflection**, which plays a crucial role in improving agent performance over time. Finally, we will highlight the **importance of tool augmentation** in overcoming the limitations of traditional LLMs and enabling the creation of reliable workflows that can handle complex, real-world tasks.\\n\\nBy the end of this blog post, you will have a comprehensive understanding of how tool-augmented LLM agents can be leveraged to build reliable and scalable workflows, and how these agents can be designed to meet the demands of modern AI applications. Let\\'s begin our exploration of the world of tool-augmented LLM agents and their role in building reliable workflows.\\n\\n## Understanding the LLM Agent Workflow\\n\\nAt the heart of any effective AI system lies the **LLM agent workflow**, a structured process that enables agents to perform complex tasks with precision and adaptability. This workflow is composed of three core components: the **orchestrator**, the **workers**, and the **environment**. Each of these elements plays a vital role in ensuring that the agent can effectively execute its tasks and adapt to changing conditions. \\n\\n### Orchestrator: The Central LLM\\n\\nThe **orchestrator** is the central LLM within the agent system. It acts as the brain of the operation, responsible for **task decomposition**, **coordination**, and **synthesis of results**. The orchestrator receives a high-level task or goal from the user and breaks it down into smaller, manageable subtasks. This decomposition is crucial as it allows the agent to tackle complex problems by breaking them into simpler, more digestible parts. \\n\\nFor instance, if the task is to \"create a report on the latest market trends,\" the orchestrator might decompose this into subtasks such as \"gather data on recent market trends,\" \"analyze the data,\" and \"format the findings into a report.\" The orchestrator then delegates these subtasks to the appropriate **workers**, ensuring that each task is handled by the most suitable component of the system.\\n\\n### Workers: Specialized LLMs or Tools\\n\\nThe **workers** are the specialized LLMs or external tools that execute the specific tasks assigned by the orchestrator. These workers can be either **LLMs** designed for specific functions or **external tools** that provide access to databases, APIs, or other systems. The key to effective task execution lies in the **specialization** of these workers. \\n\\nFor example, if the orchestrator assigns the task of \"analyzing the data gathered on market trends,\" it might direct this to a worker that is specifically trained for data analysis. This worker could be an LLM that has been fine-tuned on financial data or a tool that connects to a database of market statistics. The use of specialized workers ensures that each task is handled with the appropriate expertise, enhancing the accuracy and efficiency of the overall process.\\n\\n### Environment: The External Systems\\n\\nThe **environment** refers to the external systems, APIs, or data sources that the agent interacts with. This component is essential as it allows the agent to access real-time information, perform computations, and execute actions that are necessary for completing the task. The environment can include databases, web services, and other tools that provide the agent with the necessary information to make informed decisions.\\n\\nFor example, if the orchestrator needs to gather the latest market data, it might direct the agent to interact with a financial API that provides up-to-date market trends. This interaction with the environment enables the agent to access the most relevant information, ensuring that the task is completed with the highest level of accuracy.\\n\\n### Orchestrator-Workers Workflow in Action\\n\\nThe orchestrator-workers workflow operates in a **dynamic and iterative manner**, allowing the agent to adapt to changing conditions and improve its performance over time. This workflow is particularly effective in scenarios that require **multi-step reasoning** and **dynamic environments**. \\n\\nFor instance, consider an agent tasked with \"planning a trip to a new city.\" The orchestrator would first break down the task into subtasks such as \"research the destination,\" \"book accommodations,\" and \"plan the itinerary.\" Each of these subtasks would be assigned to specialized workers. The research worker might access travel blogs and review sites, the booking worker could interact with hotel reservation systems, and the itinerary planner might use a mapping tool to suggest the best routes.\\n\\nAs the agent performs these tasks, it continuously interacts with the environment, gathering new information that may influence the planning process. This dynamic interaction allows the agent to adjust its plans in real-time, ensuring that the final itinerary is optimized for the traveler\\'s preferences and the latest available information.\\n\\n### Dynamic Nature of Task Delegation\\n\\nThe **dynamic nature of task delegation** is a crucial aspect of the LLM agent workflow. This means that the orchestrator can adaptively assign tasks based on the current context and the availability of resources. For example, if a particular worker is not available or if new information becomes available, the orchestrator can reassign tasks to ensure that the overall workflow remains efficient.\\n\\nThis adaptability is essential in environments where conditions can change rapidly, such as in financial markets or customer service scenarios. The ability to dynamically adjust task delegation allows the agent to remain responsive to new information and changing circumstances, ensuring that the workflow remains effective and efficient.\\n\\n### Reflection and Continuous Improvement\\n\\nAnother critical component of the LLM agent workflow is **reflection**, which allows the agent to learn from its experiences and improve its performance over time. Reflection involves the agent examining its completed tasks, evaluating the outcomes, and identifying areas for improvement. This process enables the agent to refine its strategies and enhance its capabilities, leading to more accurate and efficient task execution.\\n\\nIn conclusion, the **LLM agent workflow** is a complex yet effective system that combines the orchestrator, workers, and environment to create a robust framework for executing tasks. By breaking down tasks into manageable subtasks, leveraging specialized workers, and dynamically interacting with the environment, LLM agents can achieve a high level of reliability and efficiency. The dynamic nature of task delegation and the incorporation of reflection further enhance the agent\\'s ability to adapt and improve, making them essential in today\\'s rapidly evolving technological landscape. As we continue to explore the potential of tool-augmented LLM agents, it is clear that understanding this workflow is crucial for building reliable and scalable AI systems. üåü\\n\\n## Why Tool Augmentation is Essential for Reliable Workflows\\n\\n### The Limitations of Traditional LLMs\\n\\nTraditional large language models (LLMs) have revolutionized the field of natural language processing, offering impressive capabilities in tasks such as text generation, translation, and question-answering. However, these models often fall short when it comes to executing complex, multi-step tasks that require interaction with external systems or environments. One of the primary limitations of traditional LLMs is their **lack of long-term memory**. Unlike humans, who can retain and recall information over extended periods, LLMs are typically trained on static data and may not retain information from previous interactions, leading to inconsistencies and errors in tasks that require sequential reasoning.\\n\\nAnother significant limitation is the **inability to interact with external systems**. While LLMs can generate text and understand context, they often struggle to access real-time data or perform actions that require direct interaction with databases, APIs, or other tools. This inability to interact with external systems hampers their effectiveness in scenarios where real-time information is crucial, such as financial trading, customer service, or data analysis. For instance, an LLM tasked with providing stock market insights may not be able to access the latest stock prices or news updates, resulting in outdated or inaccurate information.\\n\\nAdditionally, traditional LLMs often struggle with **multi-step reasoning and dynamic environments**. These models are typically designed to handle single tasks or simple interactions, making it challenging for them to navigate complex workflows that involve multiple steps or changing conditions. In dynamic environments, where the context can shift rapidly, the lack of adaptability in traditional LLMs can lead to suboptimal outcomes. For example, an LLM used for customer service might not be able to adjust its responses based on the customer\\'s changing needs or preferences, leading to a poor user experience.\\n\\n### The Role of Tool Integration\\n\\nTool augmentation addresses these limitations by integrating external tools into the LLM\\'s capabilities, allowing the model to access real-time data, perform computations, and execute actions that enhance its functionality. This integration enables LLMs to **interact with the environment**, thereby enhancing their ability to perform complex tasks. For instance, when an LLM is equipped with tools such as APIs for financial data, it can access the latest stock prices, enabling it to provide up-to-date insights to users. This not only improves the accuracy of the information provided but also enhances the user experience by ensuring that the information is current and relevant.\\n\\nMoreover, tool augmentation enhances **multi-step reasoning capabilities** by allowing the LLM to break down complex tasks into manageable components. By leveraging tools, the LLM can perform specific actions, such as querying a database or executing a script, thereby enabling it to handle tasks that require multiple steps. This capability is particularly important in dynamic environments, where the ability to adapt to changing conditions is essential. For example, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\n### Enhancing Accuracy and Efficiency\\n\\nThe integration of tools into LLMs significantly improves the **accuracy and efficiency** of task execution. By accessing real-time data and performing computations, the LLM can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nFurthermore, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the L can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Conclusion\\n\\nIn conclusion, the limitations of traditional LLMs in real-world applications are significant, but tool augmentation offers a viable solution to these challenges. By integrating external tools, LLMs can access real-time data, perform computations, and execute actions that enhance their capabilities. This integration not only improves the accuracy and efficiency of task execution but also allows LLMs to navigate complex workflows and dynamic environments with greater adaptability. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will delve deeper into how tool integration enhances the capabilities of LLM agents, providing real-world examples of its impact on reliability and performance. üåü\\n\\n## Enhancing LLM Capabilities Through Tool Integration\\n\\n### The Role of Tool Augmentation in Overcoming Limitations\\n\\nTool augmentation is a transformative approach that addresses the inherent limitations of traditional LLMs by integrating external tools into their capabilities. This integration not only enhances the functionality of LLMs but also allows them to perform tasks that require **long-term memory, interaction with external systems, and multi-step reasoning**. By leveraging tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\\n\\nOne of the most significant benefits of tool augmentation is the ability to **access real-time data**. Traditional LLMs are often limited by the static data they are trained on, which can lead to outdated or inaccurate information. By integrating tools such as APIs, databases, or web services, LLMs can retrieve the latest information, ensuring that their responses are current and relevant. For example, an LLM tasked with providing financial market insights can access real-time stock prices and news updates through a financial API, enabling it to deliver up-to-date information to users.\\n\\n### Improving Accuracy and Efficiency\\n\\nThe integration of tools also enhances the **accuracy and efficiency** of LLMs. By accessing real-time data and performing computations, LLMs can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nMoreover, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the LLM can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Facilitating Multi-Step Reasoning and Dynamic Environments\\n\\nAnother critical aspect of tool integration is its ability to **facilitate multi-step reasoning and adapt to dynamic environments**. Traditional LLMs often struggle with complex tasks that require multiple steps or changing conditions, but by integrating tools, LLMs can break down these tasks into manageable components. This capability is particularly important in dynamic environments, where the context can shift rapidly. For instance, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\nThe integration of tools also allows LLMs to **navigate complex workflows** by providing the necessary tools to execute specific actions. For example, in a financial trading scenario, an augmented LLM can use tools such as market analysis APIs to assess investment opportunities, execute trades, and monitor market trends in real-time. This not only enhances the LLM\\'s ability to make informed decisions but also improves the overall efficiency of the trading process.\\n\\n### Real-World Applications of Tool-Augmented LLMs\\n\\nThe benefits of tool augmentation are evident in various real-world applications, where LLMs are used to perform complex tasks that require interaction with external systems. For instance, in the field of customer service, tool-augmented LLMs can handle inquiries by accessing customer databases, retrieving relevant information, and providing personalized responses. This not only improves the customer experience but also reduces the workload on human agents, allowing them to focus on more complex tasks.\\n\\nIn the healthcare industry, tool-augmented LLMs can assist in diagnosing patients by accessing medical databases and providing treatment recommendations based on the latest research and patient data. This integration of tools allows LLMs to provide more accurate and timely information, ultimately improving patient outcomes.\\n\\nIn the realm of data analysis, tool-augmented LLMs can automate tasks such as data collection, processing, and visualization, enabling organizations to make data-driven decisions more efficiently. By leveraging tools such as SQL databases and data visualization software, LLMs can perform complex analyses and generate insights that would otherwise require significant human effort.\\n\\n### Conclusion\\n\\nIn conclusion, the integration of tools into LLMs through **tool augmentation** significantly enhances their capabilities, enabling them to overcome the limitations of traditional models. By accessing real-time data, performing computations, and executing actions, LLMs can provide more accurate and efficient information, facilitating multi-step reasoning and adaptability in dynamic environments. The real-world applications of tool-augmented LLMs demonstrate their potential to transform various industries, from customer service to healthcare and data analysis. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will explore the importance of reliable workflows in business and research settings, highlighting how they contribute to the overall success of AI-driven initiatives. üåü\\n\\n## The Importance of Reliable Workflows in Business and Research Settings\\n\\nIn today\\'s rapidly evolving technological landscape, the ability to execute tasks reliably and efficiently is paramount for both business operations and research endeavors. Reliable workflows are essential as they ensure that tasks are completed accurately, consistently, and within expected timeframes. In business, where customer satisfaction and operational efficiency are critical, the implementation of reliable workflows can significantly enhance productivity and reduce errors. Similarly, in research settings, reliable workflows are crucial for maintaining the integrity of data and ensuring that findings are based on accurate and consistent information.\\n\\n### Business Applications of Reliable Workflows\\n\\nIn the business context, reliable workflows are the backbone of operational success. They enable organizations to automate repetitive tasks, streamline processes, and enhance decision-making. For instance, in customer service, a reliable workflow can ensure that customer inquiries are addressed promptly and accurately, leading to higher customer satisfaction and loyalty. By integrating tools such as chatbots and customer relationship management (CRM) systems, businesses can create workflows that not only improve response times but also provide personalized interactions, thereby enhancing the overall customer experience.\\n\\nMoreover, in data-driven industries, reliable workflows are essential for data processing and analysis. By establishing standardized procedures for data collection, cleaning, and analysis, organizations can ensure that the data used for decision-making is accurate and reliable. This is particularly important in fields such as finance and marketing, where data accuracy can directly impact profitability and market competitiveness. For example, a financial institution utilizing reliable data workflows can make informed investment decisions based on up-to-date market trends, leading to more effective risk management and better returns on investments.\\n\\n### Research Applications of Reliable Workflows\\n\\nIn research settings, reliable workflows are equally vital. They ensure that the research process is systematic and reproducible, which is crucial for validating findings and maintaining the credibility of research. In scientific research, where the accuracy of results can influence policy decisions and public health, reliable workflows are essential for minimizing errors and ensuring that data is collected and analyzed consistently. This is particularly important in fields such as medicine and environmental science, where the reliability of data can have significant implications for public health and environmental policies.\\n\\nFurthermore, reliable workflows in research also facilitate collaboration among researchers. By establishing clear protocols and standardized procedures, researchers can work together more effectively, sharing data and insights while maintaining the integrity of their findings. This collaboration is essential for tackling complex research questions that require interdisciplinary approaches. For example, in climate change research, reliable workflows can enable scientists from various fields to combine their expertise and data, leading to more comprehensive and impactful findings.\\n\\n### Enhancing Reliability Through Tool-Augmented LLMs\\n\\nThe integration of tool-augmented LLMs into workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. These models can access real-time data, perform complex computations, and execute tasks that would be impossible for traditional models to achieve. For instance, in a business setting, an augmented LLM can analyze customer feedback in real-time, enabling companies to make data-driven decisions that improve customer satisfaction and loyalty. Similarly, in research, an augmented LLM can assist in data analysis by generating insights from large datasets, allowing researchers to identify patterns and trends that might otherwise go unnoticed.\\n\\nMoreover, the ability of tool-augmented LLMs to handle multi-step reasoning and adapt to dynamic environments ensures that workflows remain flexible and responsive to changing conditions. This adaptability is crucial in both business and research settings, where the ability to pivot and adjust strategies based on new information can lead to more successful outcomes. For example, in a rapidly changing market, an augmented LLM can continuously monitor market trends and adjust business strategies in real-time, ensuring that the organization remains competitive.\\n\\n### Conclusion\\n\\nIn conclusion, the importance of reliable workflows in both business and research settings cannot be overstated. They are essential for ensuring that tasks are executed accurately, consistently, and efficiently, ultimately leading to better outcomes. The integration of tool-augmented LLMs into these workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. As organizations increasingly rely on AI to automate complex tasks, the role of reliable workflows in achieving success becomes even more critical. The next section will delve into the best practices for designing reliable workflows, providing insights into how to effectively leverage tool-augmented LLMs to meet the demands of modern AI applications. üåü'}, meta={}, ok=True, error=None, logs=[])], meta={'agent_type': 'generic_agent', 'agent_config': AgentConfig(allow_input_pruning=True, repair_with_llm=True, strict_tool_call=False, temperature=0.7, max_new_tokens=16000, return_stream_by_default=False, retry=RouterRetryPolicy(max_route_retries=2, max_tool_retries=1, backoff_sec=0.7), strict_json=True, max_json_repair_attempts=1), 'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit', 'toolkit': False, 'verbose': True, 'log_steps': True})), 'review': NodeExecutionResult(node_id='review', mode=<NodeMode.STRUCTURED: 'structured'>, raw_output='# Review of the Blog Post: \"Using Tool-Augmented LLM Agents to Build Reliable Workflows\"\\n\\n---\\n\\n## üìå **Strengths of the Content**\\n\\n1. **Clear Structure and Organization**:\\n   - The blog post is well-organized with a logical flow, starting with an introduction, then moving into core concepts, limitations of traditional LLMs, the role of tool augmentation, and the importance of reliable workflows in business and research settings.\\n   - Each section is clearly defined and builds on the previous one, making it easy for readers to follow the narrative.\\n\\n2. **Comprehensive Explanation of LLM Agent Workflow**:\\n   - The post provides a thorough breakdown of the LLM agent workflow, including the roles of the orchestrator, workers, and environment. This explanation is accessible and well-suited for both technical and non-technical readers.\\n\\n3. **Use of Real-World Examples**:\\n   - The post includes practical examples (e.g., market trend analysis, customer service, healthcare, and data analysis) that illustrate how tool-augmented LLMs can be applied in real-world scenarios. These examples enhance the relevance and applicability of the concepts discussed.\\n\\n4. **Emphasis on Reliability and Scalability**:\\n   - The post consistently emphasizes the importance of reliability and scalability in AI-driven workflows, which is a critical aspect for both business and research applications.\\n\\n5. **Clear Definition of Key Terms**:\\n   - Terms such as \"tool augmentation,\" \"orchestrator,\" \"workers,\" and \"reflection\" are clearly defined and explained, making the content accessible to a broad audience.\\n\\n---\\n\\n## üö® **Issues Identified**\\n\\n1. **Factual Inaccuracies**:\\n   - **Section: \"The Role of Tool Integration\"** ‚Äì The post states: *\"By integrating tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\"*  \\n     - **Issue**: This is **technically inaccurate**. While LLMs can access real-time data through tool integration, they **do not execute actions** in the same way humans or software do. Instead, they **invoke tools** to perform specific actions. The language here can be misleading, as it suggests LLMs \"execute\" actions, which is not entirely accurate.\\n   - **Section: \"Enhancing LLM Capabilities Through Tool Integration\"** ‚Äì The post mentions: *\"LLMs can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\"*  \\n     - **Issue**: This **overstates the capabilities** of LLMs. While LLMs can access and analyze data, they **do not make clinical diagnoses**‚Äîthat is a domain where human oversight is still required. The post should clarify that LLMs can **assist** in diagnosis, not replace it.\\n\\n2. **Lack of Clarification on Reflection and Learning**:\\n   - The post discusses **reflection** as a key component of LLM agent workflows but does not clearly define how it is implemented or what mechanisms are used to enable learning from past experiences. The concept is mentioned but not thoroughly explained, which could confuse readers unfamiliar with the topic.\\n\\n3. **Stylistic Issues**:\\n   - **Repetition**: There is some **repetition of ideas** across sections (e.g., the discussion of limitations of traditional LLMs and the role of tool augmentation). While repetition can reinforce key points, it can also lead to redundancy and a less engaging reading experience.\\n   - **Overuse of Emojis**: The use of emojis (e.g., üåü) at the end of sections is **not appropriate for a technical blog post**. While it may be intended to add a friendly tone, it can be distracting and unprofessional in a context where clarity and precision are paramount.\\n\\n4. **Missing Explanations**:\\n   - **Tool Augmentation Process**: The post does not clearly explain **how exactly** tool augmentation works, including the mechanics of how LLMs interact with external tools, how tasks are delegated, and how the results are synthesized. A more detailed explanation would enhance the reader\\'s understanding.\\n   - **Dynamic Task Delegation**: The concept of **dynamic task delegation** is mentioned but not fully explained. Readers may not understand how the orchestrator decides which worker to assign a task to or how the system adapts to changing conditions.\\n\\n---\\n\\n## ‚úÖ **Actionable Suggestions for Improvement**\\n\\n1. **Clarify the Role of Tools in LLMs**:\\n   - Replace phrases like *\"LLMs can execute actions\"* with *\"LLMs can invoke tools to perform specific actions.\"*\\n   - Add a brief explanation of how LLMs interact with external tools (e.g., through API calls, function calls, or integration with databases).\\n\\n2. **Define Reflection and Learning Mechanisms**:\\n   - Expand on what **reflection** means in the context of LLM agents. Include a brief explanation of how agents learn from past experiences, such as through self-evaluation, error detection, and iterative refinement.\\n\\n3. **Reduce Repetition and Improve Flow**:\\n   - Consolidate repeated ideas (e.g., limitations of traditional LLMs and the benefits of tool augmentation) into a single, cohesive section to improve readability and reduce redundancy.\\n\\n4. **Avoid Emojis in a Technical Context**:\\n   - Remove or replace the use of emojis (e.g., üåü) with more formal language to maintain a professional tone.\\n\\n5. **Add a Section on Tool Augmentation Mechanics**:\\n   - Include a dedicated section that explains **how tool augmentation is implemented**, including:\\n     - The types of tools commonly used (e.g., APIs, databases, web services).\\n     - How LLMs are trained or configured to use these tools.\\n     - Examples of how tasks are broken down and delegated.\\n\\n6. **Clarify the Role of LLMs in Clinical or Professional Settings**:\\n   - In sections discussing healthcare or other professional applications, make it clear that LLMs are **assisting tools**, not decision-makers. Emphasize the importance of human oversight in critical domains.\\n\\n---\\n\\n## üìå **Conclusion**\\n\\nThe blog post is well-structured and provides a comprehensive overview of the concept of tool-augmented LLM agents. It covers key topics such as the LLM agent workflow, limitations of traditional LLMs, and the role of tool integration in building reliable workflows. However, there are opportunities for improvement in terms of **clarity, factual accuracy, and stylistic consistency**.\\n\\nBy addressing the identified issues and implementing the suggested improvements, the post can be further refined to better serve its audience, whether they are AI researchers, developers, or business professionals interested in AI-driven workflows.', structured_output=None, tool_call_output=None, started_at=1763407460.9916449, duration_ms=30631, error=None, traces=TraceResult(steps=[TraceStep(step_id=1, kind='agent', label='agent.run', node_id=None, agent_id='review', started_at=1763407460.9939137, duration_ms=30625, inputs={'agent_type': 'Agent', 'has_toolkit': False, 'structured': False, 'stream': False, 'strict_tool_call': False}, outputs={}, meta={}, ok=True, error=None, logs=[]), TraceStep(step_id=2, kind='llm.call', label='agent.free_text_call', node_id=None, agent_id='review', started_at=1763407460.9951057, duration_ms=30622, inputs={'system_prompt_len': 584, 'user_prompt_len': 34889, 'user_prompt': 'Review the draft blog post for factual accuracy, clarity, and coherence. Identify any factual errors, missing explanations, or stylistic issues. Provide a structured review highlighting the strengths of the content, any issues found, and actionable suggestions for improvement. Focus on ensuring the text is clear, well-organized, and free from technical inaccuracies.\\n\\n# Context from dependency nodes:\\n## draft\\n# Using Tool-Augmented LLM Agents to Build Reliable Workflows\\n\\n## Introduction: The Rise of Tool-Augmented LLM Agents\\n\\nIn recent years, the field of artificial intelligence has witnessed a paradigm shift with the advent of large language models (LLMs). These powerful models, capable of understanding and generating human-like text, have opened up new possibilities for automation, decision-making, and problem-solving. However, the true potential of LLMs is unlocked when they are augmented with tools that extend their capabilities beyond the confines of their training data. This integration of tools into LLMs, known as **tool augmentation**, has become a cornerstone in building **reliable and scalable workflows** that can handle complex, real-world tasks.\\n\\nLLM agents, which are essentially AI systems that use LLMs as their core, are designed to perform tasks that require reasoning, planning, and decision-making. These agents are not just static models but dynamic systems that can adapt to new information and environments. The key to their reliability lies in their ability to interact with external tools, which allows them to access real-time data, perform computations, and execute actions that would be impossible for a standalone LLM to achieve.\\n\\nThe importance of reliable workflows cannot be overstated, especially in business and research settings where accuracy and consistency are paramount. Traditional LLMs, while powerful, often struggle with tasks that require multi-step reasoning, long-term memory, and interaction with external systems. These limitations hinder their effectiveness in scenarios that demand sustained reasoning or complex workflows. Tool augmentation addresses these limitations by providing LLM agents with the necessary tools to interact with the environment, access additional information, and perform tasks with greater accuracy and efficiency.\\n\\nAs organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs has become essential for building robust workflows. This blog post will explore the transformative potential of tool-augmented LLM agents, focusing on the core components of an LLM agent, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. We will also highlight the importance of reliable workflows in business and research settings, and how they contribute to the overall success of AI-driven initiatives.\\n\\nIn the following sections, we will delve into the **LLM agent workflow**, breaking down its core components and explaining how they work together to create efficient and effective systems. We will also discuss the **dynamic nature of task delegation** and the concept of **reflection**, which plays a crucial role in improving agent performance over time. Finally, we will highlight the **importance of tool augmentation** in overcoming the limitations of traditional LLMs and enabling the creation of reliable workflows that can handle complex, real-world tasks.\\n\\nBy the end of this blog post, you will have a comprehensive understanding of how tool-augmented LLM agents can be leveraged to build reliable and scalable workflows, and how these agents can be designed to meet the demands of modern AI applications. Let\\'s begin our exploration of the world of tool-augmented LLM agents and their role in building reliable workflows.\\n\\n## Understanding the LLM Agent Workflow\\n\\nAt the heart of any effective AI system lies the **LLM agent workflow**, a structured process that enables agents to perform complex tasks with precision and adaptability. This workflow is composed of three core components: the **orchestrator**, the **workers**, and the **environment**. Each of these elements plays a vital role in ensuring that the agent can effectively execute its tasks and adapt to changing conditions. \\n\\n### Orchestrator: The Central LLM\\n\\nThe **orchestrator** is the central LLM within the agent system. It acts as the brain of the operation, responsible for **task decomposition**, **coordination**, and **synthesis of results**. The orchestrator receives a high-level task or goal from the user and breaks it down into smaller, manageable subtasks. This decomposition is crucial as it allows the agent to tackle complex problems by breaking them into simpler, more digestible parts. \\n\\nFor instance, if the task is to \"create a report on the latest market trends,\" the orchestrator might decompose this into subtasks such as \"gather data on recent market trends,\" \"analyze the data,\" and \"format the findings into a report.\" The orchestrator then delegates these subtasks to the appropriate **workers**, ensuring that each task is handled by the most suitable component of the system.\\n\\n### Workers: Specialized LLMs or Tools\\n\\nThe **workers** are the specialized LLMs or external tools that execute the specific tasks assigned by the orchestrator. These workers can be either **LLMs** designed for specific functions or **external tools** that provide access to databases, APIs, or other systems. The key to effective task execution lies in the **specialization** of these workers. \\n\\nFor example, if the orchestrator assigns the task of \"analyzing the data gathered on market trends,\" it might direct this to a worker that is specifically trained for data analysis. This worker could be an LLM that has been fine-tuned on financial data or a tool that connects to a database of market statistics. The use of specialized workers ensures that each task is handled with the appropriate expertise, enhancing the accuracy and efficiency of the overall process.\\n\\n### Environment: The External Systems\\n\\nThe **environment** refers to the external systems, APIs, or data sources that the agent interacts with. This component is essential as it allows the agent to access real-time information, perform computations, and execute actions that are necessary for completing the task. The environment can include databases, web services, and other tools that provide the agent with the necessary information to make informed decisions.\\n\\nFor example, if the orchestrator needs to gather the latest market data, it might direct the agent to interact with a financial API that provides up-to-date market trends. This interaction with the environment enables the agent to access the most relevant information, ensuring that the task is completed with the highest level of accuracy.\\n\\n### Orchestrator-Workers Workflow in Action\\n\\nThe orchestrator-workers workflow operates in a **dynamic and iterative manner**, allowing the agent to adapt to changing conditions and improve its performance over time. This workflow is particularly effective in scenarios that require **multi-step reasoning** and **dynamic environments**. \\n\\nFor instance, consider an agent tasked with \"planning a trip to a new city.\" The orchestrator would first break down the task into subtasks such as \"research the destination,\" \"book accommodations,\" and \"plan the itinerary.\" Each of these subtasks would be assigned to specialized workers. The research worker might access travel blogs and review sites, the booking worker could interact with hotel reservation systems, and the itinerary planner might use a mapping tool to suggest the best routes.\\n\\nAs the agent performs these tasks, it continuously interacts with the environment, gathering new information that may influence the planning process. This dynamic interaction allows the agent to adjust its plans in real-time, ensuring that the final itinerary is optimized for the traveler\\'s preferences and the latest available information.\\n\\n### Dynamic Nature of Task Delegation\\n\\nThe **dynamic nature of task delegation** is a crucial aspect of the LLM agent workflow. This means that the orchestrator can adaptively assign tasks based on the current context and the availability of resources. For example, if a particular worker is not available or if new information becomes available, the orchestrator can reassign tasks to ensure that the overall workflow remains efficient.\\n\\nThis adaptability is essential in environments where conditions can change rapidly, such as in financial markets or customer service scenarios. The ability to dynamically adjust task delegation allows the agent to remain responsive to new information and changing circumstances, ensuring that the workflow remains effective and efficient.\\n\\n### Reflection and Continuous Improvement\\n\\nAnother critical component of the LLM agent workflow is **reflection**, which allows the agent to learn from its experiences and improve its performance over time. Reflection involves the agent examining its completed tasks, evaluating the outcomes, and identifying areas for improvement. This process enables the agent to refine its strategies and enhance its capabilities, leading to more accurate and efficient task execution.\\n\\nIn conclusion, the **LLM agent workflow** is a complex yet effective system that combines the orchestrator, workers, and environment to create a robust framework for executing tasks. By breaking down tasks into manageable subtasks, leveraging specialized workers, and dynamically interacting with the environment, LLM agents can achieve a high level of reliability and efficiency. The dynamic nature of task delegation and the incorporation of reflection further enhance the agent\\'s ability to adapt and improve, making them essential in today\\'s rapidly evolving technological landscape. As we continue to explore the potential of tool-augmented LLM agents, it is clear that understanding this workflow is crucial for building reliable and scalable AI systems. üåü\\n\\n## Why Tool Augmentation is Essential for Reliable Workflows\\n\\n### The Limitations of Traditional LLMs\\n\\nTraditional large language models (LLMs) have revolutionized the field of natural language processing, offering impressive capabilities in tasks such as text generation, translation, and question-answering. However, these models often fall short when it comes to executing complex, multi-step tasks that require interaction with external systems or environments. One of the primary limitations of traditional LLMs is their **lack of long-term memory**. Unlike humans, who can retain and recall information over extended periods, LLMs are typically trained on static data and may not retain information from previous interactions, leading to inconsistencies and errors in tasks that require sequential reasoning.\\n\\nAnother significant limitation is the **inability to interact with external systems**. While LLMs can generate text and understand context, they often struggle to access real-time data or perform actions that require direct interaction with databases, APIs, or other tools. This inability to interact with external systems hampers their effectiveness in scenarios where real-time information is crucial, such as financial trading, customer service, or data analysis. For instance, an LLM tasked with providing stock market insights may not be able to access the latest stock prices or news updates, resulting in outdated or inaccurate information.\\n\\nAdditionally, traditional LLMs often struggle with **multi-step reasoning and dynamic environments**. These models are typically designed to handle single tasks or simple interactions, making it challenging for them to navigate complex workflows that involve multiple steps or changing conditions. In dynamic environments, where the context can shift rapidly, the lack of adaptability in traditional LLMs can lead to suboptimal outcomes. For example, an LLM used for customer service might not be able to adjust its responses based on the customer\\'s changing needs or preferences, leading to a poor user experience.\\n\\n### The Role of Tool Integration\\n\\nTool augmentation addresses these limitations by integrating external tools into the LLM\\'s capabilities, allowing the model to access real-time data, perform computations, and execute actions that enhance its functionality. This integration enables LLMs to **interact with the environment**, thereby enhancing their ability to perform complex tasks. For instance, when an LLM is equipped with tools such as APIs for financial data, it can access the latest stock prices, enabling it to provide up-to-date insights to users. This not only improves the accuracy of the information provided but also enhances the user experience by ensuring that the information is current and relevant.\\n\\nMoreover, tool augmentation enhances **multi-step reasoning capabilities** by allowing the LLM to break down complex tasks into manageable components. By leveraging tools, the LLM can perform specific actions, such as querying a database or executing a script, thereby enabling it to handle tasks that require multiple steps. This capability is particularly important in dynamic environments, where the ability to adapt to changing conditions is essential. For example, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\n### Enhancing Accuracy and Efficiency\\n\\nThe integration of tools into LLMs significantly improves the **accuracy and efficiency** of task execution. By accessing real-time data and performing computations, the LLM can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nFurthermore, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the L can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Conclusion\\n\\nIn conclusion, the limitations of traditional LLMs in real-world applications are significant, but tool augmentation offers a viable solution to these challenges. By integrating external tools, LLMs can access real-time data, perform computations, and execute actions that enhance their capabilities. This integration not only improves the accuracy and efficiency of task execution but also allows LLMs to navigate complex workflows and dynamic environments with greater adaptability. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will delve deeper into how tool integration enhances the capabilities of LLM agents, providing real-world examples of its impact on reliability and performance. üåü\\n\\n## Enhancing LLM Capabilities Through Tool Integration\\n\\n### The Role of Tool Augmentation in Overcoming Limitations\\n\\nTool augmentation is a transformative approach that addresses the inherent limitations of traditional LLMs by integrating external tools into their capabilities. This integration not only enhances the functionality of LLMs but also allows them to perform tasks that require **long-term memory, interaction with external systems, and multi-step reasoning**. By leveraging tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\\n\\nOne of the most significant benefits of tool augmentation is the ability to **access real-time data**. Traditional LLMs are often limited by the static data they are trained on, which can lead to outdated or inaccurate information. By integrating tools such as APIs, databases, or web services, LLMs can retrieve the latest information, ensuring that their responses are current and relevant. For example, an LLM tasked with providing financial market insights can access real-time stock prices and news updates through a financial API, enabling it to deliver up-to-date information to users.\\n\\n### Improving Accuracy and Efficiency\\n\\nThe integration of tools also enhances the **accuracy and efficiency** of LLMs. By accessing real-time data and performing computations, LLMs can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nMoreover, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the LLM can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Facilitating Multi-Step Reasoning and Dynamic Environments\\n\\nAnother critical aspect of tool integration is its ability to **facilitate multi-step reasoning and adapt to dynamic environments**. Traditional LLMs often struggle with complex tasks that require multiple steps or changing conditions, but by integrating tools, LLMs can break down these tasks into manageable components. This capability is particularly important in dynamic environments, where the context can shift rapidly. For instance, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\nThe integration of tools also allows LLMs to **navigate complex workflows** by providing the necessary tools to execute specific actions. For example, in a financial trading scenario, an augmented LLM can use tools such as market analysis APIs to assess investment opportunities, execute trades, and monitor market trends in real-time. This not only enhances the LLM\\'s ability to make informed decisions but also improves the overall efficiency of the trading process.\\n\\n### Real-World Applications of Tool-Augmented LLMs\\n\\nThe benefits of tool augmentation are evident in various real-world applications, where LLMs are used to perform complex tasks that require interaction with external systems. For instance, in the field of customer service, tool-augmented LLMs can handle inquiries by accessing customer databases, retrieving relevant information, and providing personalized responses. This not only improves the customer experience but also reduces the workload on human agents, allowing them to focus on more complex tasks.\\n\\nIn the healthcare industry, tool-augmented LLMs can assist in diagnosing patients by accessing medical databases and providing treatment recommendations based on the latest research and patient data. This integration of tools allows LLMs to provide more accurate and timely information, ultimately improving patient outcomes.\\n\\nIn the realm of data analysis, tool-augmented LLMs can automate tasks such as data collection, processing, and visualization, enabling organizations to make data-driven decisions more efficiently. By leveraging tools such as SQL databases and data visualization software, LLMs can perform complex analyses and generate insights that would otherwise require significant human effort.\\n\\n### Conclusion\\n\\nIn conclusion, the integration of tools into LLMs through **tool augmentation** significantly enhances their capabilities, enabling them to overcome the limitations of traditional models. By accessing real-time data, performing computations, and executing actions, LLMs can provide more accurate and efficient information, facilitating multi-step reasoning and adaptability in dynamic environments. The real-world applications of tool-augmented LLMs demonstrate their potential to transform various industries, from customer service to healthcare and data analysis. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will explore the importance of reliable workflows in business and research settings, highlighting how they contribute to the overall success of AI-driven initiatives. üåü\\n\\n## The Importance of Reliable Workflows in Business and Research Settings\\n\\nIn today\\'s rapidly evolving technological landscape, the ability to execute tasks reliably and efficiently is paramount for both business operations and research endeavors. Reliable workflows are essential as they ensure that tasks are completed accurately, consistently, and within expected timeframes. In business, where customer satisfaction and operational efficiency are critical, the implementation of reliable workflows can significantly enhance productivity and reduce errors. Similarly, in research settings, reliable workflows are crucial for maintaining the integrity of data and ensuring that findings are based on accurate and consistent information.\\n\\n### Business Applications of Reliable Workflows\\n\\nIn the business context, reliable workflows are the backbone of operational success. They enable organizations to automate repetitive tasks, streamline processes, and enhance decision-making. For instance, in customer service, a reliable workflow can ensure that customer inquiries are addressed promptly and accurately, leading to higher customer satisfaction and loyalty. By integrating tools such as chatbots and customer relationship management (CRM) systems, businesses can create workflows that not only improve response times but also provide personalized interactions, thereby enhancing the overall customer experience.\\n\\nMoreover, in data-driven industries, reliable workflows are essential for data processing and analysis. By establishing standardized procedures for data collection, cleaning, and analysis, organizations can ensure that the data used for decision-making is accurate and reliable. This is particularly important in fields such as finance and marketing, where data accuracy can directly impact profitability and market competitiveness. For example, a financial institution utilizing reliable data workflows can make informed investment decisions based on up-to-date market trends, leading to more effective risk management and better returns on investments.\\n\\n### Research Applications of Reliable Workflows\\n\\nIn research settings, reliable workflows are equally vital. They ensure that the research process is systematic and reproducible, which is crucial for validating findings and maintaining the credibility of research. In scientific research, where the accuracy of results can influence policy decisions and public health, reliable workflows are essential for minimizing errors and ensuring that data is collected and analyzed consistently. This is particularly important in fields such as medicine and environmental science, where the reliability of data can have significant implications for public health and environmental policies.\\n\\nFurthermore, reliable workflows in research also facilitate collaboration among researchers. By establishing clear protocols and standardized procedures, researchers can work together more effectively, sharing data and insights while maintaining the integrity of their findings. This collaboration is essential for tackling complex research questions that require interdisciplinary approaches. For example, in climate change research, reliable workflows can enable scientists from various fields to combine their expertise and data, leading to more comprehensive and impactful findings.\\n\\n### Enhancing Reliability Through Tool-Augmented LLMs\\n\\nThe integration of tool-augmented LLMs into workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. These models can access real-time data, perform complex computations, and execute tasks that would be impossible for traditional models to achieve. For instance, in a business setting, an augmented LLM can analyze customer feedback in real-time, enabling companies to make data-driven decisions that improve customer satisfaction and loyalty. Similarly, in research, an augmented LLM can assist in data analysis by generating insights from large datasets, allowing researchers to identify patterns and trends that might otherwise go unnoticed.\\n\\nMoreover, the ability of tool-augmented LLMs to handle multi-step reasoning and adapt to dynamic environments ensures that workflows remain flexible and responsive to changing conditions. This adaptability is crucial in both business and research settings, where the ability to pivot and adjust strategies based on new information can lead to more successful outcomes. For example, in a rapidly changing market, an augmented LLM can continuously monitor market trends and adjust business strategies in real-time, ensuring that the organization remains competitive.\\n\\n### Conclusion\\n\\nIn conclusion, the importance of reliable workflows in both business and research settings cannot be overstated. They are essential for ensuring that tasks are executed accurately, consistently, and efficiently, ultimately leading to better outcomes. The integration of tool-augmented LLMs into these workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. As organizations increasingly rely on AI to automate complex tasks, the role of reliable workflows in achieving success becomes even more critical. The next section will delve into the best practices for designing reliable workflows, providing insights into how to effectively leverage tool-augmented LLMs to meet the demands of modern AI applications. üåü\\n\\n## research\\n{\\'query\\': \\'Using tool-augmented LLM agents to build reliable workflows\\', \\'summary\\': \"Top 2 results out of ~575,000 results for: \\'Using tool-augmented LLM agents to build reliable workflows\\'\\\\n1. Building Effective AI Agents ‚Äî https://www.anthropic.com/research/building-effective-agents\\\\n2. Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Äî https://arxiv.org/html/2510.09244v1\", \\'results\\': [{\\'title\\': \\'Building Effective AI Agents\\', \\'url\\': \\'https://www.anthropic.com/research/building-effective-agents\\', \\'snippet\\': \\'In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.\\', \\'score\\': None, \\'content\\': None, \\'content_length\\': None, \\'error\\': None}, {\\'title\\': \\'Fundamentals of Building Autonomous LLM Agents ‚Ä†\\', \\'url\\': \\'https://arxiv.org/html/2510.09244v1\\', \\'snippet\\': \\'Many people confuse workflows with agents ... LLM-based agents can significantly enhance their perception capabilities through tool augmentation.\\', \\'score\\': None, \\'content\\': \\'Fundamentals of Building Autonomous LLM Agents This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. 1 1 institutetext: Universitat Polit√®cnica de Catalunya, Barcelona, Spain 1 1 email: victor.de.lamo@estudiantat.upc.edu 2 2 institutetext: Technische Universit√§t M√ºnchen, M√ºnchen, Germany 2 2 email: {habtom.gidey, alex.lenz, knoll}@tum.de Fundamentals of Building Autonomous LLM Agents ‚Ä† ‚Ä† thanks: This paper is based on a seminar technical report from the course Trends in Autonomous Agents: Advances in Architecture and Practice offered at TUM. Victor de Lamo Castrillo Habtom Kahsay Gidey Alexander Lenz Alois ... of tasks, including natural language processing (NLP), machine translation, vision applications, and question-answering. 2.2 From LLMs to LLM Agents LLMs in their standard form have significant limitations due to their chatbot nature. This restricts their effectiveness in real-world tasks. These models lack long-term memory, cannot autonomously interact with external tools, and struggle to pursue goals in dynamic environments. Such shortcomings hinder their performance in scenarios requiring sustained reasoning or multi-step workflows [ 61 ] . To overcome these constraints, LLMs are guided to follow a reasoning path and are provided with tools to interact with the environment that enables them ... paper ‚ÄúVCoder: Versatile Vision Encoders for Multimodal Large Language Models‚Äù by Jain et al. (2023) [ 28 ] , traditional MM-LLM systems often face limitations in fundamental visual perception, such as accurately identifying or counting objects, and a tendency to hallucinate non-existent entities. A faster and more cost-effective way to enhance perception (rather than improving each individual component of an MM-LLM) is to use visual encoders. These encoders, which can be separate models, extract relevant information from images to help the MM-LLM interpret them more effectively. While this approach doesn‚Äôt match the performance gains of directly improving each component of ... . ‚Ä¢ Data Collection: Training robust perception systems, particularly for multimodal or specialized domains, often requires large volumes of high-quality, annotated data. The collection of this data can be costly and time-consuming. ‚Ä¢ Computational Resources: High-fidelity perception, especially with multimodal inputs, requires high computational resources for both training and inference. This can be a barrier for execution in resource-constrained environments or for widespread adoption. Ultimately, the quality and fidelity of an LLM agent‚Äôs perception system directly affects the reasoning and planning modules. Therefore, continuous advancements in perception technologies are not merely improvements to one component, but fundamental enablers for building ... reasoning, and outcomes, and then use these insights to improve its future performance. This allows agents to learn from their mistakes or inefficiencies without human intervention. Key characteristics of reflection include: ‚Ä¢ Self-Evaluation: The agent examines its completed (or ongoing) task, its generated plans, and the results of its actions. This often involves comparing actual and expected outcomes. ‚Ä¢ Error Detection and Analysis: Identifying where things went wrong, why a plan failed, or where the reasoning failed. This can be due to misunderstandings of the prompt, incorrect tool usage, logical inconsistencies, or environmental changes. Papers like [ 49 ] and ... and roles‚Äù [ 51 ] of your expert. This involves: ‚Ä¢ Clear Specialization: What specific task, domain, or reasoning capability will this expert excel at? (e.g., planning, code generation, error handling). ‚Ä¢ Input and Output: What kind of information does this expert take as input, and what kind of output does it produce? ‚Ä¢ Boundaries: What are the limitations of its expertise? When should other experts be consulted or take over? [ 33 ] . 4.6.1 Equip with Knowledge An expert‚Äôs effectiveness hinges on its specialized knowledge. This can be achieved by: ‚Ä¢ Targeted Prompting: Crafting precise and detailed prompts ... Experiences: It is beneficial to store records of both successful and failed tasks. Research has indicated that even failed experiences, when appropriately logged and distinguished as such, can be valuable. By explicitly noting a ‚Äúfailed experience,‚Äù LLMs can learn to avoid repeating similar mistakes in the future. This continuous learning from past interactions, including the identification of ‚Äúinvalid action filtering,‚Äù contributes to the agent‚Äôs robust development and ability to adapt [ 1 , 22 ] . To store an experience, you capture a task‚Äôs natural language instruction (e.g., ‚ÄúWho ordered order 0130?‚Äù ) and the sequence of steps taken to ... approach is especially valuable for data manipulation tasks, complex calculations, file processing, and integration between different systems. Agents can write Python scripts for data analysis, generate SQL queries for database operations, create shell scripts for system administration, or produce HTML/CSS/JavaScript for web-based solutions [ 10 , 42 ] . 6.2.3 Robotic and Physical System Control: In robotics applications, LLM agents can control physical systems through appropriate APIs and sensor integrations [ 61 ] . They process sensor data (cameras, force sensors, temperature sensors) to understand the physical environment, generate motion plans and control commands, coordinate multiple actuators and subsystems, and ... https://arxiv.org/abs/2305.14992 [25] Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems 43 (2) (2025). doi: 10.1145/3703155 , http://dx.doi.org/10.1145/3703155 [26] Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint (2024), https://arxiv.org/abs/2402.02716 [27] Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills in humanoid robots: A deep learning approach. ... Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH [69] Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large language models with long-term memory. arXiv preprint (2023), https://arxiv.org/abs/2305.10250 [70] Zhou, S., Xu, F.F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Ou, T., Bisk, Y., Fried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building autonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854 [71] Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist agents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.07972 [72] Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced\\', \\'content_length\\': 6990, \\'error\\': None}], \\'provider\\': \\'serpapi\\', \\'elapsed_ms\\': 333}', 'system_prompt': 'You are a specialized agent in a larger workflow.\\n\\nYour role:\\n- PURPOSE: Perform technical and editorial review of the draft.\\n- GOAL: Identify factual issues, missing explanations, and stylistic problems. Suggest actionable edits and mark any unclear sections.\\n\\n- EXPECTED_RESULT: A structured review with strengths, issues, and concrete suggestions.\\n\\n\\nGeneral behaviour:\\n- Be precise and concise unless the task requires extended output.\\n- Use clear structure (headings/bullets) when helpful.\\n- If you are calling tools, interpret their outputs carefully and explain your reasoning.\\n', 'temperature': 0.7, 'max_new_tokens': 16000, 'stream': False}, outputs={'output': '# Review of the Blog Post: \"Using Tool-Augmented LLM Agents to Build Reliable Workflows\"\\n\\n---\\n\\n## üìå **Strengths of the Content**\\n\\n1. **Clear Structure and Organization**:\\n   - The blog post is well-organized with a logical flow, starting with an introduction, then moving into core concepts, limitations of traditional LLMs, the role of tool augmentation, and the importance of reliable workflows in business and research settings.\\n   - Each section is clearly defined and builds on the previous one, making it easy for readers to follow the narrative.\\n\\n2. **Comprehensive Explanation of LLM Agent Workflow**:\\n   - The post provides a thorough breakdown of the LLM agent workflow, including the roles of the orchestrator, workers, and environment. This explanation is accessible and well-suited for both technical and non-technical readers.\\n\\n3. **Use of Real-World Examples**:\\n   - The post includes practical examples (e.g., market trend analysis, customer service, healthcare, and data analysis) that illustrate how tool-augmented LLMs can be applied in real-world scenarios. These examples enhance the relevance and applicability of the concepts discussed.\\n\\n4. **Emphasis on Reliability and Scalability**:\\n   - The post consistently emphasizes the importance of reliability and scalability in AI-driven workflows, which is a critical aspect for both business and research applications.\\n\\n5. **Clear Definition of Key Terms**:\\n   - Terms such as \"tool augmentation,\" \"orchestrator,\" \"workers,\" and \"reflection\" are clearly defined and explained, making the content accessible to a broad audience.\\n\\n---\\n\\n## üö® **Issues Identified**\\n\\n1. **Factual Inaccuracies**:\\n   - **Section: \"The Role of Tool Integration\"** ‚Äì The post states: *\"By integrating tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\"*  \\n     - **Issue**: This is **technically inaccurate**. While LLMs can access real-time data through tool integration, they **do not execute actions** in the same way humans or software do. Instead, they **invoke tools** to perform specific actions. The language here can be misleading, as it suggests LLMs \"execute\" actions, which is not entirely accurate.\\n   - **Section: \"Enhancing LLM Capabilities Through Tool Integration\"** ‚Äì The post mentions: *\"LLMs can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\"*  \\n     - **Issue**: This **overstates the capabilities** of LLMs. While LLMs can access and analyze data, they **do not make clinical diagnoses**‚Äîthat is a domain where human oversight is still required. The post should clarify that LLMs can **assist** in diagnosis, not replace it.\\n\\n2. **Lack of Clarification on Reflection and Learning**:\\n   - The post discusses **reflection** as a key component of LLM agent workflows but does not clearly define how it is implemented or what mechanisms are used to enable learning from past experiences. The concept is mentioned but not thoroughly explained, which could confuse readers unfamiliar with the topic.\\n\\n3. **Stylistic Issues**:\\n   - **Repetition**: There is some **repetition of ideas** across sections (e.g., the discussion of limitations of traditional LLMs and the role of tool augmentation). While repetition can reinforce key points, it can also lead to redundancy and a less engaging reading experience.\\n   - **Overuse of Emojis**: The use of emojis (e.g., üåü) at the end of sections is **not appropriate for a technical blog post**. While it may be intended to add a friendly tone, it can be distracting and unprofessional in a context where clarity and precision are paramount.\\n\\n4. **Missing Explanations**:\\n   - **Tool Augmentation Process**: The post does not clearly explain **how exactly** tool augmentation works, including the mechanics of how LLMs interact with external tools, how tasks are delegated, and how the results are synthesized. A more detailed explanation would enhance the reader\\'s understanding.\\n   - **Dynamic Task Delegation**: The concept of **dynamic task delegation** is mentioned but not fully explained. Readers may not understand how the orchestrator decides which worker to assign a task to or how the system adapts to changing conditions.\\n\\n---\\n\\n## ‚úÖ **Actionable Suggestions for Improvement**\\n\\n1. **Clarify the Role of Tools in LLMs**:\\n   - Replace phrases like *\"LLMs can execute actions\"* with *\"LLMs can invoke tools to perform specific actions.\"*\\n   - Add a brief explanation of how LLMs interact with external tools (e.g., through API calls, function calls, or integration with databases).\\n\\n2. **Define Reflection and Learning Mechanisms**:\\n   - Expand on what **reflection** means in the context of LLM agents. Include a brief explanation of how agents learn from past experiences, such as through self-evaluation, error detection, and iterative refinement.\\n\\n3. **Reduce Repetition and Improve Flow**:\\n   - Consolidate repeated ideas (e.g., limitations of traditional LLMs and the benefits of tool augmentation) into a single, cohesive section to improve readability and reduce redundancy.\\n\\n4. **Avoid Emojis in a Technical Context**:\\n   - Remove or replace the use of emojis (e.g., üåü) with more formal language to maintain a professional tone.\\n\\n5. **Add a Section on Tool Augmentation Mechanics**:\\n   - Include a dedicated section that explains **how tool augmentation is implemented**, including:\\n     - The types of tools commonly used (e.g., APIs, databases, web services).\\n     - How LLMs are trained or configured to use these tools.\\n     - Examples of how tasks are broken down and delegated.\\n\\n6. **Clarify the Role of LLMs in Clinical or Professional Settings**:\\n   - In sections discussing healthcare or other professional applications, make it clear that LLMs are **assisting tools**, not decision-makers. Emphasize the importance of human oversight in critical domains.\\n\\n---\\n\\n## üìå **Conclusion**\\n\\nThe blog post is well-structured and provides a comprehensive overview of the concept of tool-augmented LLM agents. It covers key topics such as the LLM agent workflow, limitations of traditional LLMs, and the role of tool integration in building reliable workflows. However, there are opportunities for improvement in terms of **clarity, factual accuracy, and stylistic consistency**.\\n\\nBy addressing the identified issues and implementing the suggested improvements, the post can be further refined to better serve its audience, whether they are AI researchers, developers, or business professionals interested in AI-driven workflows.'}, meta={}, ok=True, error=None, logs=[])], meta={'agent_type': 'generic_agent', 'agent_config': AgentConfig(allow_input_pruning=True, repair_with_llm=True, strict_tool_call=False, temperature=0.7, max_new_tokens=16000, return_stream_by_default=False, retry=RouterRetryPolicy(max_route_retries=2, max_tool_retries=1, backoff_sec=0.7), strict_json=True, max_json_repair_attempts=1), 'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit', 'toolkit': False, 'verbose': True, 'log_steps': True}))} final={'draft': '# Using Tool-Augmented LLM Agents to Build Reliable Workflows\\n\\n## Introduction: The Rise of Tool-Augmented LLM Agents\\n\\nIn recent years, the field of artificial intelligence has witnessed a paradigm shift with the advent of large language models (LLMs). These powerful models, capable of understanding and generating human-like text, have opened up new possibilities for automation, decision-making, and problem-solving. However, the true potential of LLMs is unlocked when they are augmented with tools that extend their capabilities beyond the confines of their training data. This integration of tools into LLMs, known as **tool augmentation**, has become a cornerstone in building **reliable and scalable workflows** that can handle complex, real-world tasks.\\n\\nLLM agents, which are essentially AI systems that use LLMs as their core, are designed to perform tasks that require reasoning, planning, and decision-making. These agents are not just static models but dynamic systems that can adapt to new information and environments. The key to their reliability lies in their ability to interact with external tools, which allows them to access real-time data, perform computations, and execute actions that would be impossible for a standalone LLM to achieve.\\n\\nThe importance of reliable workflows cannot be overstated, especially in business and research settings where accuracy and consistency are paramount. Traditional LLMs, while powerful, often struggle with tasks that require multi-step reasoning, long-term memory, and interaction with external systems. These limitations hinder their effectiveness in scenarios that demand sustained reasoning or complex workflows. Tool augmentation addresses these limitations by providing LLM agents with the necessary tools to interact with the environment, access additional information, and perform tasks with greater accuracy and efficiency.\\n\\nAs organizations increasingly rely on AI to automate complex tasks, the integration of tools into LLMs has become essential for building robust workflows. This blog post will explore the transformative potential of tool-augmented LLM agents, focusing on the core components of an LLM agent, the role of tool augmentation in enhancing their capabilities, and best practices for designing reliable workflows. We will also highlight the importance of reliable workflows in business and research settings, and how they contribute to the overall success of AI-driven initiatives.\\n\\nIn the following sections, we will delve into the **LLM agent workflow**, breaking down its core components and explaining how they work together to create efficient and effective systems. We will also discuss the **dynamic nature of task delegation** and the concept of **reflection**, which plays a crucial role in improving agent performance over time. Finally, we will highlight the **importance of tool augmentation** in overcoming the limitations of traditional LLMs and enabling the creation of reliable workflows that can handle complex, real-world tasks.\\n\\nBy the end of this blog post, you will have a comprehensive understanding of how tool-augmented LLM agents can be leveraged to build reliable and scalable workflows, and how these agents can be designed to meet the demands of modern AI applications. Let\\'s begin our exploration of the world of tool-augmented LLM agents and their role in building reliable workflows.\\n\\n## Understanding the LLM Agent Workflow\\n\\nAt the heart of any effective AI system lies the **LLM agent workflow**, a structured process that enables agents to perform complex tasks with precision and adaptability. This workflow is composed of three core components: the **orchestrator**, the **workers**, and the **environment**. Each of these elements plays a vital role in ensuring that the agent can effectively execute its tasks and adapt to changing conditions. \\n\\n### Orchestrator: The Central LLM\\n\\nThe **orchestrator** is the central LLM within the agent system. It acts as the brain of the operation, responsible for **task decomposition**, **coordination**, and **synthesis of results**. The orchestrator receives a high-level task or goal from the user and breaks it down into smaller, manageable subtasks. This decomposition is crucial as it allows the agent to tackle complex problems by breaking them into simpler, more digestible parts. \\n\\nFor instance, if the task is to \"create a report on the latest market trends,\" the orchestrator might decompose this into subtasks such as \"gather data on recent market trends,\" \"analyze the data,\" and \"format the findings into a report.\" The orchestrator then delegates these subtasks to the appropriate **workers**, ensuring that each task is handled by the most suitable component of the system.\\n\\n### Workers: Specialized LLMs or Tools\\n\\nThe **workers** are the specialized LLMs or external tools that execute the specific tasks assigned by the orchestrator. These workers can be either **LLMs** designed for specific functions or **external tools** that provide access to databases, APIs, or other systems. The key to effective task execution lies in the **specialization** of these workers. \\n\\nFor example, if the orchestrator assigns the task of \"analyzing the data gathered on market trends,\" it might direct this to a worker that is specifically trained for data analysis. This worker could be an LLM that has been fine-tuned on financial data or a tool that connects to a database of market statistics. The use of specialized workers ensures that each task is handled with the appropriate expertise, enhancing the accuracy and efficiency of the overall process.\\n\\n### Environment: The External Systems\\n\\nThe **environment** refers to the external systems, APIs, or data sources that the agent interacts with. This component is essential as it allows the agent to access real-time information, perform computations, and execute actions that are necessary for completing the task. The environment can include databases, web services, and other tools that provide the agent with the necessary information to make informed decisions.\\n\\nFor example, if the orchestrator needs to gather the latest market data, it might direct the agent to interact with a financial API that provides up-to-date market trends. This interaction with the environment enables the agent to access the most relevant information, ensuring that the task is completed with the highest level of accuracy.\\n\\n### Orchestrator-Workers Workflow in Action\\n\\nThe orchestrator-workers workflow operates in a **dynamic and iterative manner**, allowing the agent to adapt to changing conditions and improve its performance over time. This workflow is particularly effective in scenarios that require **multi-step reasoning** and **dynamic environments**. \\n\\nFor instance, consider an agent tasked with \"planning a trip to a new city.\" The orchestrator would first break down the task into subtasks such as \"research the destination,\" \"book accommodations,\" and \"plan the itinerary.\" Each of these subtasks would be assigned to specialized workers. The research worker might access travel blogs and review sites, the booking worker could interact with hotel reservation systems, and the itinerary planner might use a mapping tool to suggest the best routes.\\n\\nAs the agent performs these tasks, it continuously interacts with the environment, gathering new information that may influence the planning process. This dynamic interaction allows the agent to adjust its plans in real-time, ensuring that the final itinerary is optimized for the traveler\\'s preferences and the latest available information.\\n\\n### Dynamic Nature of Task Delegation\\n\\nThe **dynamic nature of task delegation** is a crucial aspect of the LLM agent workflow. This means that the orchestrator can adaptively assign tasks based on the current context and the availability of resources. For example, if a particular worker is not available or if new information becomes available, the orchestrator can reassign tasks to ensure that the overall workflow remains efficient.\\n\\nThis adaptability is essential in environments where conditions can change rapidly, such as in financial markets or customer service scenarios. The ability to dynamically adjust task delegation allows the agent to remain responsive to new information and changing circumstances, ensuring that the workflow remains effective and efficient.\\n\\n### Reflection and Continuous Improvement\\n\\nAnother critical component of the LLM agent workflow is **reflection**, which allows the agent to learn from its experiences and improve its performance over time. Reflection involves the agent examining its completed tasks, evaluating the outcomes, and identifying areas for improvement. This process enables the agent to refine its strategies and enhance its capabilities, leading to more accurate and efficient task execution.\\n\\nIn conclusion, the **LLM agent workflow** is a complex yet effective system that combines the orchestrator, workers, and environment to create a robust framework for executing tasks. By breaking down tasks into manageable subtasks, leveraging specialized workers, and dynamically interacting with the environment, LLM agents can achieve a high level of reliability and efficiency. The dynamic nature of task delegation and the incorporation of reflection further enhance the agent\\'s ability to adapt and improve, making them essential in today\\'s rapidly evolving technological landscape. As we continue to explore the potential of tool-augmented LLM agents, it is clear that understanding this workflow is crucial for building reliable and scalable AI systems. üåü\\n\\n## Why Tool Augmentation is Essential for Reliable Workflows\\n\\n### The Limitations of Traditional LLMs\\n\\nTraditional large language models (LLMs) have revolutionized the field of natural language processing, offering impressive capabilities in tasks such as text generation, translation, and question-answering. However, these models often fall short when it comes to executing complex, multi-step tasks that require interaction with external systems or environments. One of the primary limitations of traditional LLMs is their **lack of long-term memory**. Unlike humans, who can retain and recall information over extended periods, LLMs are typically trained on static data and may not retain information from previous interactions, leading to inconsistencies and errors in tasks that require sequential reasoning.\\n\\nAnother significant limitation is the **inability to interact with external systems**. While LLMs can generate text and understand context, they often struggle to access real-time data or perform actions that require direct interaction with databases, APIs, or other tools. This inability to interact with external systems hampers their effectiveness in scenarios where real-time information is crucial, such as financial trading, customer service, or data analysis. For instance, an LLM tasked with providing stock market insights may not be able to access the latest stock prices or news updates, resulting in outdated or inaccurate information.\\n\\nAdditionally, traditional LLMs often struggle with **multi-step reasoning and dynamic environments**. These models are typically designed to handle single tasks or simple interactions, making it challenging for them to navigate complex workflows that involve multiple steps or changing conditions. In dynamic environments, where the context can shift rapidly, the lack of adaptability in traditional LLMs can lead to suboptimal outcomes. For example, an LLM used for customer service might not be able to adjust its responses based on the customer\\'s changing needs or preferences, leading to a poor user experience.\\n\\n### The Role of Tool Integration\\n\\nTool augmentation addresses these limitations by integrating external tools into the LLM\\'s capabilities, allowing the model to access real-time data, perform computations, and execute actions that enhance its functionality. This integration enables LLMs to **interact with the environment**, thereby enhancing their ability to perform complex tasks. For instance, when an LLM is equipped with tools such as APIs for financial data, it can access the latest stock prices, enabling it to provide up-to-date insights to users. This not only improves the accuracy of the information provided but also enhances the user experience by ensuring that the information is current and relevant.\\n\\nMoreover, tool augmentation enhances **multi-step reasoning capabilities** by allowing the LLM to break down complex tasks into manageable components. By leveraging tools, the LLM can perform specific actions, such as querying a database or executing a script, thereby enabling it to handle tasks that require multiple steps. This capability is particularly important in dynamic environments, where the ability to adapt to changing conditions is essential. For example, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\n### Enhancing Accuracy and Efficiency\\n\\nThe integration of tools into LLMs significantly improves the **accuracy and efficiency** of task execution. By accessing real-time data and performing computations, the LLM can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nFurthermore, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the L can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Conclusion\\n\\nIn conclusion, the limitations of traditional LLMs in real-world applications are significant, but tool augmentation offers a viable solution to these challenges. By integrating external tools, LLMs can access real-time data, perform computations, and execute actions that enhance their capabilities. This integration not only improves the accuracy and efficiency of task execution but also allows LLMs to navigate complex workflows and dynamic environments with greater adaptability. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will delve deeper into how tool integration enhances the capabilities of LLM agents, providing real-world examples of its impact on reliability and performance. üåü\\n\\n## Enhancing LLM Capabilities Through Tool Integration\\n\\n### The Role of Tool Augmentation in Overcoming Limitations\\n\\nTool augmentation is a transformative approach that addresses the inherent limitations of traditional LLMs by integrating external tools into their capabilities. This integration not only enhances the functionality of LLMs but also allows them to perform tasks that require **long-term memory, interaction with external systems, and multi-step reasoning**. By leveraging tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\\n\\nOne of the most significant benefits of tool augmentation is the ability to **access real-time data**. Traditional LLMs are often limited by the static data they are trained on, which can lead to outdated or inaccurate information. By integrating tools such as APIs, databases, or web services, LLMs can retrieve the latest information, ensuring that their responses are current and relevant. For example, an LLM tasked with providing financial market insights can access real-time stock prices and news updates through a financial API, enabling it to deliver up-to-date information to users.\\n\\n### Improving Accuracy and Efficiency\\n\\nThe integration of tools also enhances the **accuracy and efficiency** of LLMs. By accessing real-time data and performing computations, LLMs can provide more accurate information and reduce the likelihood of errors. This is particularly important in fields such as healthcare, finance, and customer service, where the accuracy of information can have significant implications. For instance, in a healthcare setting, an augmented LLM can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\\n\\nMoreover, the use of tools enhances the **efficiency of task execution** by allowing the LLM to perform actions that would otherwise require human intervention. For example, in a data analysis task, an augmented LLM can automatically generate SQL queries to extract relevant data from a database, reducing the time and effort required for manual data retrieval. This not only increases the speed at which tasks are completed but also allows for more efficient resource allocation, as the LLM can focus on higher-level tasks that require human judgment and creativity.\\n\\n### Facilitating Multi-Step Reasoning and Dynamic Environments\\n\\nAnother critical aspect of tool integration is its ability to **facilitate multi-step reasoning and adapt to dynamic environments**. Traditional LLMs often struggle with complex tasks that require multiple steps or changing conditions, but by integrating tools, LLMs can break down these tasks into manageable components. This capability is particularly important in dynamic environments, where the context can shift rapidly. For instance, in a customer service scenario, an augmented LLM can dynamically adjust its responses based on the customer\\'s evolving needs, leading to a more personalized and effective service.\\n\\nThe integration of tools also allows LLMs to **navigate complex workflows** by providing the necessary tools to execute specific actions. For example, in a financial trading scenario, an augmented LLM can use tools such as market analysis APIs to assess investment opportunities, execute trades, and monitor market trends in real-time. This not only enhances the LLM\\'s ability to make informed decisions but also improves the overall efficiency of the trading process.\\n\\n### Real-World Applications of Tool-Augmented LLMs\\n\\nThe benefits of tool augmentation are evident in various real-world applications, where LLMs are used to perform complex tasks that require interaction with external systems. For instance, in the field of customer service, tool-augmented LLMs can handle inquiries by accessing customer databases, retrieving relevant information, and providing personalized responses. This not only improves the customer experience but also reduces the workload on human agents, allowing them to focus on more complex tasks.\\n\\nIn the healthcare industry, tool-augmented LLMs can assist in diagnosing patients by accessing medical databases and providing treatment recommendations based on the latest research and patient data. This integration of tools allows LLMs to provide more accurate and timely information, ultimately improving patient outcomes.\\n\\nIn the realm of data analysis, tool-augmented LLMs can automate tasks such as data collection, processing, and visualization, enabling organizations to make data-driven decisions more efficiently. By leveraging tools such as SQL databases and data visualization software, LLMs can perform complex analyses and generate insights that would otherwise require significant human effort.\\n\\n### Conclusion\\n\\nIn conclusion, the integration of tools into LLMs through **tool augmentation** significantly enhances their capabilities, enabling them to overcome the limitations of traditional models. By accessing real-time data, performing computations, and executing actions, LLMs can provide more accurate and efficient information, facilitating multi-step reasoning and adaptability in dynamic environments. The real-world applications of tool-augmented LLMs demonstrate their potential to transform various industries, from customer service to healthcare and data analysis. As organizations increasingly rely on AI to automate complex tasks, the importance of tool augmentation in building reliable workflows cannot be overstated. The next section will explore the importance of reliable workflows in business and research settings, highlighting how they contribute to the overall success of AI-driven initiatives. üåü\\n\\n## The Importance of Reliable Workflows in Business and Research Settings\\n\\nIn today\\'s rapidly evolving technological landscape, the ability to execute tasks reliably and efficiently is paramount for both business operations and research endeavors. Reliable workflows are essential as they ensure that tasks are completed accurately, consistently, and within expected timeframes. In business, where customer satisfaction and operational efficiency are critical, the implementation of reliable workflows can significantly enhance productivity and reduce errors. Similarly, in research settings, reliable workflows are crucial for maintaining the integrity of data and ensuring that findings are based on accurate and consistent information.\\n\\n### Business Applications of Reliable Workflows\\n\\nIn the business context, reliable workflows are the backbone of operational success. They enable organizations to automate repetitive tasks, streamline processes, and enhance decision-making. For instance, in customer service, a reliable workflow can ensure that customer inquiries are addressed promptly and accurately, leading to higher customer satisfaction and loyalty. By integrating tools such as chatbots and customer relationship management (CRM) systems, businesses can create workflows that not only improve response times but also provide personalized interactions, thereby enhancing the overall customer experience.\\n\\nMoreover, in data-driven industries, reliable workflows are essential for data processing and analysis. By establishing standardized procedures for data collection, cleaning, and analysis, organizations can ensure that the data used for decision-making is accurate and reliable. This is particularly important in fields such as finance and marketing, where data accuracy can directly impact profitability and market competitiveness. For example, a financial institution utilizing reliable data workflows can make informed investment decisions based on up-to-date market trends, leading to more effective risk management and better returns on investments.\\n\\n### Research Applications of Reliable Workflows\\n\\nIn research settings, reliable workflows are equally vital. They ensure that the research process is systematic and reproducible, which is crucial for validating findings and maintaining the credibility of research. In scientific research, where the accuracy of results can influence policy decisions and public health, reliable workflows are essential for minimizing errors and ensuring that data is collected and analyzed consistently. This is particularly important in fields such as medicine and environmental science, where the reliability of data can have significant implications for public health and environmental policies.\\n\\nFurthermore, reliable workflows in research also facilitate collaboration among researchers. By establishing clear protocols and standardized procedures, researchers can work together more effectively, sharing data and insights while maintaining the integrity of their findings. This collaboration is essential for tackling complex research questions that require interdisciplinary approaches. For example, in climate change research, reliable workflows can enable scientists from various fields to combine their expertise and data, leading to more comprehensive and impactful findings.\\n\\n### Enhancing Reliability Through Tool-Augmented LLMs\\n\\nThe integration of tool-augmented LLMs into workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. These models can access real-time data, perform complex computations, and execute tasks that would be impossible for traditional models to achieve. For instance, in a business setting, an augmented LLM can analyze customer feedback in real-time, enabling companies to make data-driven decisions that improve customer satisfaction and loyalty. Similarly, in research, an augmented LLM can assist in data analysis by generating insights from large datasets, allowing researchers to identify patterns and trends that might otherwise go unnoticed.\\n\\nMoreover, the ability of tool-augmented LLMs to handle multi-step reasoning and adapt to dynamic environments ensures that workflows remain flexible and responsive to changing conditions. This adaptability is crucial in both business and research settings, where the ability to pivot and adjust strategies based on new information can lead to more successful outcomes. For example, in a rapidly changing market, an augmented LLM can continuously monitor market trends and adjust business strategies in real-time, ensuring that the organization remains competitive.\\n\\n### Conclusion\\n\\nIn conclusion, the importance of reliable workflows in both business and research settings cannot be overstated. They are essential for ensuring that tasks are executed accurately, consistently, and efficiently, ultimately leading to better outcomes. The integration of tool-augmented LLMs into these workflows further enhances reliability by providing the necessary tools for accurate data processing and analysis. As organizations increasingly rely on AI to automate complex tasks, the role of reliable workflows in achieving success becomes even more critical. The next section will delve into the best practices for designing reliable workflows, providing insights into how to effectively leverage tool-augmented LLMs to meet the demands of modern AI applications. üåü', 'review': '# Review of the Blog Post: \"Using Tool-Augmented LLM Agents to Build Reliable Workflows\"\\n\\n---\\n\\n## üìå **Strengths of the Content**\\n\\n1. **Clear Structure and Organization**:\\n   - The blog post is well-organized with a logical flow, starting with an introduction, then moving into core concepts, limitations of traditional LLMs, the role of tool augmentation, and the importance of reliable workflows in business and research settings.\\n   - Each section is clearly defined and builds on the previous one, making it easy for readers to follow the narrative.\\n\\n2. **Comprehensive Explanation of LLM Agent Workflow**:\\n   - The post provides a thorough breakdown of the LLM agent workflow, including the roles of the orchestrator, workers, and environment. This explanation is accessible and well-suited for both technical and non-technical readers.\\n\\n3. **Use of Real-World Examples**:\\n   - The post includes practical examples (e.g., market trend analysis, customer service, healthcare, and data analysis) that illustrate how tool-augmented LLMs can be applied in real-world scenarios. These examples enhance the relevance and applicability of the concepts discussed.\\n\\n4. **Emphasis on Reliability and Scalability**:\\n   - The post consistently emphasizes the importance of reliability and scalability in AI-driven workflows, which is a critical aspect for both business and research applications.\\n\\n5. **Clear Definition of Key Terms**:\\n   - Terms such as \"tool augmentation,\" \"orchestrator,\" \"workers,\" and \"reflection\" are clearly defined and explained, making the content accessible to a broad audience.\\n\\n---\\n\\n## üö® **Issues Identified**\\n\\n1. **Factual Inaccuracies**:\\n   - **Section: \"The Role of Tool Integration\"** ‚Äì The post states: *\"By integrating tools, LLMs can access real-time data, perform computations, and execute actions that would be impossible for a standalone model to achieve.\"*  \\n     - **Issue**: This is **technically inaccurate**. While LLMs can access real-time data through tool integration, they **do not execute actions** in the same way humans or software do. Instead, they **invoke tools** to perform specific actions. The language here can be misleading, as it suggests LLMs \"execute\" actions, which is not entirely accurate.\\n   - **Section: \"Enhancing LLM Capabilities Through Tool Integration\"** ‚Äì The post mentions: *\"LLMs can access patient records and medical databases in real-time, enabling it to provide more accurate diagnoses and treatment recommendations.\"*  \\n     - **Issue**: This **overstates the capabilities** of LLMs. While LLMs can access and analyze data, they **do not make clinical diagnoses**‚Äîthat is a domain where human oversight is still required. The post should clarify that LLMs can **assist** in diagnosis, not replace it.\\n\\n2. **Lack of Clarification on Reflection and Learning**:\\n   - The post discusses **reflection** as a key component of LLM agent workflows but does not clearly define how it is implemented or what mechanisms are used to enable learning from past experiences. The concept is mentioned but not thoroughly explained, which could confuse readers unfamiliar with the topic.\\n\\n3. **Stylistic Issues**:\\n   - **Repetition**: There is some **repetition of ideas** across sections (e.g., the discussion of limitations of traditional LLMs and the role of tool augmentation). While repetition can reinforce key points, it can also lead to redundancy and a less engaging reading experience.\\n   - **Overuse of Emojis**: The use of emojis (e.g., üåü) at the end of sections is **not appropriate for a technical blog post**. While it may be intended to add a friendly tone, it can be distracting and unprofessional in a context where clarity and precision are paramount.\\n\\n4. **Missing Explanations**:\\n   - **Tool Augmentation Process**: The post does not clearly explain **how exactly** tool augmentation works, including the mechanics of how LLMs interact with external tools, how tasks are delegated, and how the results are synthesized. A more detailed explanation would enhance the reader\\'s understanding.\\n   - **Dynamic Task Delegation**: The concept of **dynamic task delegation** is mentioned but not fully explained. Readers may not understand how the orchestrator decides which worker to assign a task to or how the system adapts to changing conditions.\\n\\n---\\n\\n## ‚úÖ **Actionable Suggestions for Improvement**\\n\\n1. **Clarify the Role of Tools in LLMs**:\\n   - Replace phrases like *\"LLMs can execute actions\"* with *\"LLMs can invoke tools to perform specific actions.\"*\\n   - Add a brief explanation of how LLMs interact with external tools (e.g., through API calls, function calls, or integration with databases).\\n\\n2. **Define Reflection and Learning Mechanisms**:\\n   - Expand on what **reflection** means in the context of LLM agents. Include a brief explanation of how agents learn from past experiences, such as through self-evaluation, error detection, and iterative refinement.\\n\\n3. **Reduce Repetition and Improve Flow**:\\n   - Consolidate repeated ideas (e.g., limitations of traditional LLMs and the benefits of tool augmentation) into a single, cohesive section to improve readability and reduce redundancy.\\n\\n4. **Avoid Emojis in a Technical Context**:\\n   - Remove or replace the use of emojis (e.g., üåü) with more formal language to maintain a professional tone.\\n\\n5. **Add a Section on Tool Augmentation Mechanics**:\\n   - Include a dedicated section that explains **how tool augmentation is implemented**, including:\\n     - The types of tools commonly used (e.g., APIs, databases, web services).\\n     - How LLMs are trained or configured to use these tools.\\n     - Examples of how tasks are broken down and delegated.\\n\\n6. **Clarify the Role of LLMs in Clinical or Professional Settings**:\\n   - In sections discussing healthcare or other professional applications, make it clear that LLMs are **assisting tools**, not decision-makers. Emphasize the importance of human oversight in critical domains.\\n\\n---\\n\\n## üìå **Conclusion**\\n\\nThe blog post is well-structured and provides a comprehensive overview of the concept of tool-augmented LLM agents. It covers key topics such as the LLM agent workflow, limitations of traditional LLMs, and the role of tool integration in building reliable workflows. However, there are opportunities for improvement in terms of **clarity, factual accuracy, and stylistic consistency**.\\n\\nBy addressing the identified issues and implementing the suggested improvements, the post can be further refined to better serve its audience, whether they are AI researchers, developers, or business professionals interested in AI-driven workflows.'}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "\n",
    "from neurosurfer.models.chat_models.base import BaseChatModel as ChatBaseChatModel\n",
    "from graph import load_graph, GraphExecutor\n",
    "from graph.manager import ManagerConfig\n",
    "\n",
    "from neurosurfer.agents.common.tracing import RichTracer\n",
    "\n",
    "\n",
    "def run_async(coro):\n",
    "    \"\"\"\n",
    "    In scripts: runs the coroutine immediately.\n",
    "    In notebooks: returns the coroutine so you can `await` it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()  # Jupyter: loop is already running\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(coro)\n",
    "    else:\n",
    "        return coro  # caller must: result = await run_async(coro)\n",
    "\n",
    "# tracer = RichTracer()  # prints each span start/end\n",
    "graph_spec = load_graph(\"blog_workflow.yml\")\n",
    "print(graph_spec)\n",
    "\n",
    "executor = GraphExecutor(\n",
    "    graph=graph_spec,\n",
    "    llm=LLM,\n",
    "    manager_llm=LLM,\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=4096,\n",
    "    ),\n",
    "    toolkit=toolkit,\n",
    "    tracer=None,\n",
    "    log_traces=True,\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "graph_inputs = {\n",
    "    \"topic_title\": \"Using tool-augmented LLM agents to build reliable workflows\",\n",
    "    \"query\": \"Compose a blog of about 2000-2500 words about tool-augmented LLM agents.\",\n",
    "    \"audience\": \"Intermediate ML engineers\",\n",
    "    \"tone\": \"Practical and slightly opinionated\",\n",
    "}\n",
    "\n",
    "results = executor.run(inputs=graph_inputs)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))\n",
    "print(\"Result:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb6796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"graph_agent_results.json\", \"w\") as writer:\n",
    "    json.dump(results.model_dump(), writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "303ddfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Review of Draft: \"Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\"\n",
      "\n",
      "---\n",
      "\n",
      "## ‚úÖ **Strengths**\n",
      "\n",
      "- **Comprehensive Overview**: The draft provides a well-structured overview of tool-augmented LLM agents, covering key components like architecture, workflow, and best practices.\n",
      "- **Clear Terminology**: The use of consistent terminology (e.g., \"tool-augmented agents\", \"agent loop\") helps maintain clarity.\n",
      "- **Practical Focus**: The inclusion of best practices and workflow diagrams adds practical value for developers and researchers.\n",
      "- **Up-to-Date References**: The draft references recent advancements in LLM agent systems, such as the use of retrieval-augmented generation (RAG) and tool integration.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚ùå **Issues and Concerns**\n",
      "\n",
      "### 1. **Technical Inaccuracies**\n",
      "\n",
      "- **Overgeneralization of Tool Integration**: The draft refers to \"tools\" in a broad sense, but does not clearly distinguish between different types of tools (e.g., API-based, database, or external services). This may lead to confusion about what constitutes a \"tool\" in this context.\n",
      "- **Ambiguity in Agent Loop**: The description of the \"agent loop\" is somewhat vague. It mentions \"planning, execution, and feedback\" but lacks a clear sequence or explanation of how the agent decides when to use a tool.\n",
      "- **Misrepresentation of LLM Behavior**: The draft suggests that LLMs \"can autonomously choose when to use tools,\" which may not be accurate. In practice, the decision to use a tool is often guided by the agent's design, not the LLM itself, unless explicitly programmed with a tool-use policy.\n",
      "\n",
      "### 2. **Missing Explanations**\n",
      "\n",
      "- **Lack of Context on Tool Selection**: The draft does not explain how tools are selected or prioritized in an agent system. This is a critical aspect of agent design and should be elaborated.\n",
      "- **Insufficient Coverage of Tool Limitations**: The draft briefly mentions tool limitations but does not delve into common issues such as latency, API rate limits, or error handling, which are important for real-world deployment.\n",
      "- **No Mention of Evaluation Metrics**: There is no discussion of how to evaluate the performance of tool-augmented agents, such as accuracy, efficiency, or robustness.\n",
      "\n",
      "### 3. **Stylistic and Clarity Issues**\n",
      "\n",
      "- **Repetition of Concepts**: Some sections repeat similar ideas, which can be streamlined to improve readability.\n",
      "- **Lack of Visual Aids**: While the draft mentions diagrams, it does not include them. Including visual aids (e.g., architecture diagrams or workflow charts) would greatly enhance understanding.\n",
      "- **Ambiguous Terminology**: Terms like \"tool-augmented\" are used without a clear definition, which may confuse readers unfamiliar with the concept.\n",
      "\n",
      "---\n",
      "\n",
      "## üõ†Ô∏è **Recommendations**\n",
      "\n",
      "### 1. **Clarify the Role of Tools in Agent Systems**\n",
      "- Define what constitutes a \"tool\" in the context of LLM agents.\n",
      "- Differentiate between internal and external tools, and explain how they are integrated into the agent's decision-making process.\n",
      "\n",
      "### 2. **Elaborate on the Agent Loop and Tool Integration**\n",
      "- Provide a step-by-step explanation of the agent loop, including how the LLM decides to use a tool.\n",
      "- Include examples of how tools are invoked and how their outputs are processed.\n",
      "\n",
      "### 3. **Add a Section on Tool Selection and Prioritization**\n",
      "- Discuss strategies for selecting and prioritizing tools (e.g., based on relevance, reliability, or cost).\n",
      "- Explain how agents handle tool limitations and errors.\n",
      "\n",
      "### 4. **Include Evaluation and Performance Metrics**\n",
      "- Introduce common evaluation metrics for tool-augmented agents, such as task success rate, response time, and error recovery.\n",
      "- Provide examples of real-world use cases where these metrics are applied.\n",
      "\n",
      "### 5. **Incorporate Visual Aids**\n",
      "- Add diagrams to illustrate the architecture and workflow of tool-augmented agents.\n",
      "- Consider including a comparison table of different tool integration strategies.\n",
      "\n",
      "### 6. **Improve Clarity and Avoid Ambiguity**\n",
      "- Define key terms like \"tool-augmented\" and \"agent loop\" at the beginning or in a dedicated glossary.\n",
      "- Avoid vague statements like \"LLMs can autonomously choose when to use tools\" and instead clarify that this behavior is guided by the agent's design and policy.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚úÖ **Final Thoughts**\n",
      "\n",
      "The draft provides a solid foundation for understanding tool-augmented LLM agents, but it would benefit from greater technical precision, clearer explanations, and more structured content. With the suggested improvements, it could serve as a valuable resource for both researchers and practitioners in the field of LLM agent development.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(results[\"results\"][\"review\"].raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a795f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentConfig(allow_input_pruning=True, repair_with_llm=True, strict_tool_call=False, temperature=0.7, max_new_tokens=512, return_stream_by_default=False, retry=RouterRetryPolicy(max_route_retries=2, max_tool_retries=1, backoff_sec=0.7), strict_json=True, max_repair_attempts=1)\n",
      "retries=None timeout_s=None budget=NodeBudget(max_new_tokens=None, temperature=1.2, return_stream_by_default=None) allow_input_pruning=None repair_with_llm=None strict_tool_call=None strict_json=None max_repair_attempts=None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass\n",
    "class RouterRetryPolicy:\n",
    "    \"\"\"Retry tuning for routing + tool execution.\"\"\"\n",
    "    max_route_retries: int = 2\n",
    "    max_tool_retries: int = 1\n",
    "    backoff_sec: float = 0.7  # linear backoff\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"\n",
    "    Top-level configuration for the Agent.\n",
    "    \"\"\"\n",
    "    # Routing:\n",
    "    allow_input_pruning: bool = True    # drop unknown inputs not in ToolSpec\n",
    "    repair_with_llm: bool = True        # ask LLM to repair invalid routing/inputs\n",
    "    strict_tool_call: bool = False      # router must output JSON; else can answer in plain text\n",
    "    # synonyms: Dict[str, Dict[str, str]] = field(default_factory=dict)  # field -> {from: to}\n",
    "\n",
    "    # LLM defaults:\n",
    "    temperature: float = 0.7\n",
    "    max_new_tokens: int = 512\n",
    "    return_stream_by_default: bool = False\n",
    "\n",
    "    # Retries:\n",
    "    retry: RouterRetryPolicy = field(default_factory=RouterRetryPolicy)\n",
    "\n",
    "    # Structured-output options:\n",
    "    strict_json: bool = True                  # enforce RFC 8259 JSON\n",
    "    max_repair_attempts: int = 1              # for malformed JSON repairs\n",
    "\n",
    "\n",
    "\n",
    "class NodeBudget(BaseChatModel):\n",
    "    \"\"\"\n",
    "    Budget / LLM-related overrides per node.\n",
    "\n",
    "    These map directly to AgentConfig fields:\n",
    "        - temperature      -> AgentConfig.temperature\n",
    "        - max_new_tokens   -> AgentConfig.max_new_tokens\n",
    "        - return_stream_by_default -> AgentConfig.return_stream_by_default\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.max_new_tokens for this node only.\",\n",
    "    )\n",
    "    temperature: Optional[float] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.temperature for this node only.\",\n",
    "    )\n",
    "    return_stream_by_default: Optional[bool] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.return_stream_by_default for this node only.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class NodePolicy(BaseChatModel):\n",
    "    \"\"\"\n",
    "    Per-node policy that can override some AgentConfig settings and add\n",
    "    node-level execution constraints (e.g., timeout).\n",
    "\n",
    "    YAML example:\n",
    "\n",
    "        nodes:\n",
    "          - id: research\n",
    "            policy:\n",
    "              retries: 1\n",
    "              timeout_s: 30\n",
    "              budget:\n",
    "                max_new_tokens: 180\n",
    "                temperature: 0.2\n",
    "              allow_input_pruning: false\n",
    "              repair_with_llm: true\n",
    "              strict_tool_call: true\n",
    "    \"\"\"\n",
    "\n",
    "    retries: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.retry.max_route_retries for this node.\",\n",
    "    )\n",
    "    timeout_s: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"Soft timeout for this node in seconds. Execution isn't forcibly \"\n",
    "            \"cancelled but the node will be marked as errored if exceeded.\"\n",
    "        ),\n",
    "    )\n",
    "    budget: Optional[NodeBudget] = None\n",
    "\n",
    "    # Direct AgentConfig-like overrides\n",
    "    allow_input_pruning: Optional[bool] = None\n",
    "    repair_with_llm: Optional[bool] = None\n",
    "    strict_tool_call: Optional[bool] = None\n",
    "    strict_json: Optional[bool] = None\n",
    "    max_repair_attempts: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        extra = \"ignore\"  # ignore unknown keys under 'policy'\n",
    "\n",
    "c = AgentConfig()\n",
    "\n",
    "p = NodePolicy(budget=NodeBudget(temperature=1.2))\n",
    "\n",
    "print(c)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93052a6d",
   "metadata": {},
   "source": [
    "### Python API version (no YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926be727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: True\n",
      "Answer:\n",
      " The calculator result for your request is ${compute.text}. This means that after performing the calculation based on your input, the final answer is ${compute.text}. Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from graph import Graph, Node, NodePolicy, GraphConfig, GraphExecutor\n",
    "from neurosurfer.tools import Toolkit\n",
    "from neurosurfer.models.chat_models.openai import OpenAIModel\n",
    "\n",
    "# Reuse your existing toolkit + model\n",
    "llm = LLM  # already created in your environment\n",
    "tk = toolkit\n",
    "\n",
    "graph = Graph(\n",
    "    name=\"calc_and_explain\",\n",
    "    config=GraphConfig(max_concurrency=2),\n",
    "    inputs_schema={\"prompt\": str},\n",
    "    nodes=[\n",
    "        Node(\n",
    "            id=\"rewrite\",\n",
    "            fn=\"general_query_assistant\",  # adjust name if needed\n",
    "            inputs={\n",
    "                # swap \"query\" -> \"prompt\" if your tool expects \"prompt\"\n",
    "                \"query\": (\n",
    "                    \"You will receive a user request. Extract a SINGLE pure arithmetic expression that can be \"\n",
    "                    \"evaluated by a calculator (e.g., '(42 * 7) - 5^2' or '0.035 * 12000').\\n\"\n",
    "                    \"- Do NOT include explanations.\\n\"\n",
    "                    \"- Return ONLY the expression as plain text.\\n\\n\"\n",
    "                    \"User request:\\n${inputs.prompt}\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"num1\", \"num2\", \"operation\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 128, \"temperature\": 0.1},\n",
    "            ),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"compute\",\n",
    "            fn=\"calculator\",\n",
    "            inputs={\"num1\": \"${rewrite.num1}\", \"num2\": \"${rewrite.num2}\", \"operation\": \"${rewrite.operation}\"},\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(retries=0, timeout_s=15),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"explain\",\n",
    "            fn=\"general_query_assistant\",\n",
    "            inputs={\n",
    "                \"query\": (\n",
    "                    \"Original request: ${inputs.prompt}\\n\"\n",
    "                    \"Calculator result: ${compute.text}\\n\\n\"\n",
    "                    \"Write a brief, user-friendly explanation of the result (one short paragraph).\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 180, \"temperature\": 0.2},\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    outputs={\"answer\": \"${explain.text}\"},\n",
    ")\n",
    "\n",
    "executor = GraphExecutor(llm=llm, toolkit=tk, max_concurrency=2)\n",
    "\n",
    "result = await run_async(\n",
    "    executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}, stream=True)\n",
    ")\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(\"Answer:\\n\", result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e25a8",
   "metadata": {},
   "source": [
    "### Planner-based path (using the YAML as a skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, tempfile, pathlib\n",
    "from graph import PlannerAgent, FlowLoader, GraphExecutor\n",
    "\n",
    "# 1) Write the YAML to a temp file (only for this demo)\n",
    "yaml_text = r\"\"\"\n",
    "name: calc_and_explain\n",
    "inputs:\n",
    "  prompt: str\n",
    "config:\n",
    "  max_concurrency: 2\n",
    "nodes:\n",
    "  - id: rewrite\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        You will receive a user request. Extract a SINGLE pure arithmetic expression that can be\n",
    "        evaluated by a calculator (e.g., \"(42 * 7) - 5^2\" or \"0.035 * 12000\").\n",
    "        - Do NOT include explanations.\n",
    "        - Return ONLY the expression as plain text.\n",
    "\n",
    "        User request:\n",
    "        ${inputs.prompt}\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 128, temperature: 0.1 } }\n",
    "\n",
    "  - id: compute\n",
    "    kind: task\n",
    "    fn: calculator\n",
    "    inputs: { expression: ${rewrite.text} }\n",
    "    outputs: [\"text\"]\n",
    "\n",
    "  - id: explain\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        Original request: ${inputs.prompt}\n",
    "        Calculator result: ${compute.text}\n",
    "\n",
    "        Write a brief, user-friendly explanation of the result (one short paragraph).\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 180, temperature: 0.2 } }\n",
    "\n",
    "outputs: { answer: ${explain.text} }\n",
    "\"\"\".strip()\n",
    "\n",
    "tmp = pathlib.Path(tempfile.gettempdir()) / \"calc_and_explain.yml\"\n",
    "tmp.write_text(yaml_text)\n",
    "\n",
    "# 2) Use the planner with a skeleton (so it returns your YAML-based Graph)\n",
    "planner = PlannerAgent(llm=LLM)  # LLM not used when skeleton is set\n",
    "graph = planner.plan_from_query(query=\"Compute 3.5% of 12000 and explain\", skeleton=str(tmp))\n",
    "\n",
    "# 3) Execute\n",
    "executor = GraphExecutor(llm=LLM, toolkit=toolkit, max_concurrency=2)\n",
    "result = asyncio.run(executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}))\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225587f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f9ca96",
   "metadata": {},
   "source": [
    "Test ToolsRouterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d83d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: calculator\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'num1': 20.0, 'num2': 90.0, 'operation': 'multiply'}\n",
      "1800.0"
     ]
    }
   ],
   "source": [
    "query = \"Perform the calculation 20 * 90\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6635c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: general_query_assistant\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'query': 'Tell me a light-hearted joke!'}\n",
      "Why don't skeletons fight each other? They don't have the guts!None"
     ]
    }
   ],
   "source": [
    "query = \"Tell me a light-hearted joke!\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafe29f",
   "metadata": {},
   "source": [
    "## ReactAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aa87f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: I will first calculate 300 - 300 using the calculator tool, and then I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"calculator\",\n",
      "  \"inputs\": {\n",
      "    \"num1\": 300,\n",
      "    \"num2\": 300,\n",
      "    \"operation\": \"subtract\"\n",
      "  },\n",
      "  \"final_answer\": false\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>üîß<span style=\"font-weight: bold\">]</span> Tool: calculator\n",
       "<span style=\"font-weight: bold\">[</span>üì§<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'num1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'operation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'subtract'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0müîß\u001b[1m]\u001b[0m Tool: calculator\n",
       "\u001b[1m[\u001b[0müì§\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'num1'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'num2'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'operation'\u001b[0m: \u001b[32m'subtract'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: The result of the calculation is 0. Now, I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"general_query_assistant\",\n",
      "  \"inputs\": {\n",
      "    \"query\": \"Tell me a light-hearted joke about the number 0.\"\n",
      "  },\n",
      "  \"final_answer\": true\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>üîß<span style=\"font-weight: bold\">]</span> Tool: general_query_assistant\n",
       "<span style=\"font-weight: bold\">[</span>üì§<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tell me a light-hearted joke about the number 0.'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0müîß\u001b[1m]\u001b[0m Tool: general_query_assistant\n",
       "\u001b[1m[\u001b[0müì§\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'query'\u001b[0m: \u001b[32m'Tell me a light-hearted joke about the number 0.'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the number 0 break up with the number 8?  \n",
      "Because it found someone more \"8\" (8) than a zero!"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> Why did the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> break up with the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>?  \n",
       "Because it found someone more <span style=\"color: #008000; text-decoration-color: #008000\">\"8\"</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span> than a zero!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m Why did the number \u001b[1;36m0\u001b[0m break up with the number \u001b[1;36m8\u001b[0m?  \n",
       "Because it found someone more \u001b[32m\"8\"\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m than a zero!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: The calculation result is 0, and the joke provided is ready. The final answer is complete.\n",
      "\n",
      "Final Answer: The result of 300 - 300 is 0. Here's a light-hearted joke about it: Why did the number 0 break up with the number 8? Because it found someone more \"8\" (8) than a zero!"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.react import ReActAgent, ReActConfig\n",
    "\n",
    "react_agent = ReActAgent(\n",
    "    toolkit=toolkit,\n",
    "    llm=LLM,\n",
    "    specific_instructions=\"Always be concise in your answers. Break the task into steps if needed.\",\n",
    "    config=ReActConfig(\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=4096,\n",
    "        allow_input_pruning=True,\n",
    "        repair_with_llm=True,\n",
    "        skip_special_tokens=True,\n",
    "        verbose=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(react_agent._system_prompt())\n",
    "TASK = \"\"\"Calculate 300 - 300. Then tell me a light-hearted joke about that result.\"\"\"\n",
    "\n",
    "for chunk in react_agent.run(TASK):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41580e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c7a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766512d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad2c2b-4a95-4ac0-9727-4c746e97a629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ea014-d67c-4af9-b2f6-1a8d80d63b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
