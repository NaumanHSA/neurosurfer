{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b35214-7a1f-403c-9a7a-b42e481ab431",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go up one directory from `b/` to project root\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affc4a2e-d532-4dee-8b50-cab72fd229c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë                                                                  ‚ïë\n",
      "‚ïë ‚ñì‚ñì‚ñì‚ñì‚ñì   ‚ñì‚ñì‚ñì‚ñì                                  ‚ñì‚ñì‚ñì                ‚ïë\n",
      "‚ïë  ‚ñì‚ñì ‚ñì‚ñì   ‚ñì‚ñì  ‚ñì‚ñì‚ñì‚ñì ‚ñì  ‚ñì ‚ñì ‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì ‚ñì  ‚ñì ‚ñì ‚ñì  ‚ñì   ‚ñì‚ñì‚ñì‚ñì ‚ñì ‚ñì       ‚ïë\n",
      "‚ïë  ‚ñì‚ñì  ‚ñì‚ñì  ‚ñì‚ñì  ‚ñì‚ñÅ‚ñÅ‚ñì ‚ñì  ‚ñì ‚ñì‚ñì‚ñè ‚ñì  ‚ñì ‚ñì‚ñÅ  ‚ñì  ‚ñì ‚ñì‚ñì‚ñè ‚ñì‚ñì‚ñì  ‚ñì‚ñÅ‚ñÅ‚ñì ‚ñì‚ñì        ‚ïë\n",
      "‚ïë  ‚ñì‚ñì   ‚ñì‚ñì ‚ñì‚ñì  ‚ñì    ‚ñì  ‚ñì ‚ñì   ‚ñì  ‚ñì   ‚ñì ‚ñì  ‚ñì ‚ñì    ‚ñì   ‚ñì    ‚ñì         ‚ïë\n",
      "‚ïë ‚ñì‚ñì‚ñì‚ñì   ‚ñì‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì   ‚ñì‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì ‚ñì‚ñì‚ñì‚ñì ‚ñì    ‚ñì   ‚ñì‚ñì‚ñì‚ñì ‚ñì         ‚ïë\n",
      "‚ïë ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ‚ïë\n",
      "‚ïë Orchestrate Agents - RAG - SQL Tools - Multi-LLM - FastAPI Ready ‚ïë\n",
      "‚ïë Faster builds, clearer flows, production-first                   ‚ïë\n",
      "‚ïë                                                                  ‚ïë\n",
      "‚ïë Version: 0.1.3 | Python: 3.11.13                                 ‚ïë\n",
      "‚ïë OS: Linux 6.14.0-35-generic (x86_64)                             ‚ïë\n",
      "‚ïë Torch: 2.7.1+cu126   CUDA: yes (12.6)                            ‚ïë\n",
      "‚ïë MPS: no (built: False)                                           ‚ïë\n",
      "‚ïë Transformers: 4.51.3   SentEmb: 5.1.0                            ‚ïë\n",
      "‚ïë Accelerate: 1.10.1   bnb: 0.47.0                                 ‚ïë\n",
      "‚ïë Unsloth: 2025.8.10                                               ‚ïë\n",
      "‚ïë                                                                  ‚ïë\n",
      "‚ïë Detected CUDA devices: NVIDIA GeForce RTX 3080 Ti                ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-20 10:03:01\u001b[0m | \u001b[96mconfig.py:<module>\u001b[0m | PyTorch version 2.7.1+cu126 available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomi/anaconda3/envs/LLMs/lib/python3.11/importlib/__init__.py:126: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 11-20 10:03:02 [__init__.py:241] Automatically detected platform cuda.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-20 10:03:04\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Initializing Transformers model.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-20 10:03:04\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Model is already quantized. Ignoring load_in_4bit=True.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-20 10:03:05\u001b[0m | \u001b[96mmodeling.py:get_balanced_memory\u001b[0m | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-20 10:03:14\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Transformers model initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from neurosurfer.models.chat_models.transformers import TransformersModel\n",
    "from neurosurfer import config \n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "DEFAULT_TRANSFORMERS_MODEL_PARAMS = dict({\n",
    "    \"model_name\": \"/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"max_seq_length\": 16_000,\n",
    "    \"load_in_4bit\": True,\n",
    "    \"enable_thinking\": False,  # main_gpu interpretation\n",
    "    \"verbose\": False\n",
    "})\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "LLM = TransformersModel(\n",
    "    **DEFAULT_TRANSFORMERS_MODEL_PARAMS,\n",
    "    stop_words=[\"Observation:\"],\n",
    "    logger = logging.getLogger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ff5798-3ed2-4b38-86cd-2498ca0e57be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?  \n",
      "Because they don't have the *guts*! üòÑ"
     ]
    }
   ],
   "source": [
    "# streaming response example\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "system_prompt = \"You are a joker.\"\n",
    "user_prompt = \"\"\"Tell me a short and light-hearted joke.\"\"\"\n",
    "\n",
    "stream_response = LLM.ask(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "md_display = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream_response:\n",
    "    chunk = chunk.choices[0].delta.content or \"\"\n",
    "    print(chunk, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808255b3",
   "metadata": {},
   "source": [
    "### Agent Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3030e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Response:\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m876s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m877s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "AI, or Artificial Intelligence, is the simulation of human intelligence in machines that are programmed to think, learn, and perform tasks typically requiring human cognition.\n"
     ]
    }
   ],
   "source": [
    "# agent normal response\n",
    "from neurosurfer.agents import Agent, AgentConfig\n",
    "# from neurosurfer.tracing import RichTracer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    strict_tool_call=True,\n",
    "    return_stream_by_default=True,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=4096,\n",
    ")\n",
    "agent = Agent(llm=LLM, config=agent_config, log_traces=True)\n",
    "\n",
    "# normal response\n",
    "print(\"Normal Response:\")\n",
    "agent_response = agent.run(user_prompt=\"What is AI (one line)?\", stream=False)\n",
    "# print(agent_response.response)\n",
    "\n",
    "# # streaming response\n",
    "# print(\"\\n\\nStreaming Response:\")\n",
    "# for c in agent.run(user_prompt=\"What are top 3 applications of AI (one line)?\").response:\n",
    "#     print(c, flush=True, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d91b3b",
   "metadata": {},
   "source": [
    "**Structured Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344ffe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-20 10:03:24\u001b[0m | \u001b[96magent.py:run\u001b[0m     | `output_schema` provided with `stream=True`; forcing non-streaming structured output.\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m5.\u001b[0m\u001b[2m446s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m5.\u001b[0m\u001b[2m447s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Structured Response:\n",
      "{\n",
      "  \"definition\": \"Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding.\",\n",
      "  \"history\": \"The concept of AI was first introduced in the 1950s. Early developments included the creation of the first AI programs and the establishment of AI as a formal academic discipline. Over the decades, advancements in computing power, data availability, and algorithmic techniques have significantly propelled AI forward.\",\n",
      "  \"modern_frameworks\": \"Modern frameworks such as TensorFlow, PyTorch, and Keras have revolutionized the development and deployment of AI models, making it more accessible and efficient for researchers and developers.\",\n",
      "  \"applications\": [\n",
      "    {\n",
      "      \"title\": \"Healthcare\",\n",
      "      \"description\": \"AI is used in healthcare for diagnostics, personalized treatment plans, and drug discovery.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Finance\",\n",
      "      \"description\": \"AI is applied in finance for fraud detection, algorithmic trading, and risk management.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Autonomous Vehicles\",\n",
      "      \"description\": \"AI powers self-driving cars through computer vision, sensor fusion, and decision-making algorithms.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Structured Response examples\n",
    "class AIApplication(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "class AI(BaseModel):\n",
    "    definition: str\n",
    "    history: str\n",
    "    modern_frameworks: str\n",
    "    applications: list[AIApplication]\n",
    "\n",
    "user_query = \"What is AI and list 3 of its top application, and 3 concerns.\"\n",
    "agent_response = agent.run(user_prompt=user_query, output_schema=AI)\n",
    "\n",
    "print(\"\\n\\nStructured Response:\")\n",
    "print(agent_response.response.json_obj)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b1381",
   "metadata": {},
   "source": [
    "## RAG wiring so the agent ‚Äúunderstands‚Äù the Neurosurf codebase\n",
    "\n",
    "You‚Äôll ingest the repo once, then run a retriever to answer code questions. The Planner can call the retriever first to form a precise implementation plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5bf38-1a5b-4ad1-be5f-b5073dbeaaf0",
   "metadata": {},
   "source": [
    "### FileReader and Chunker Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35db287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-20 10:08:56\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-20 10:08:56\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-20 10:08:56\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  6.19it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  9.84it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 15.34it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 16.06it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 17.19it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 15.54it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 17.52it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 15.66it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 16.29it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 13.16it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 15.19it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 18.30it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 16.97it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 16.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok',\n",
       " 'sources': 141,\n",
       " 'chunks': 889,\n",
       " 'unique_chunks': 889,\n",
       " 'added': 889,\n",
       " 'finished_at': 1763618939.3266816,\n",
       " 'accepted_sources': 1,\n",
       " 'total_docs_in_collection': 889}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from neurosurfer.vectorstores.chroma import ChromaVectorStore\n",
    "from neurosurfer.models.embedders.sentence_transformer import SentenceTransformerEmbedder\n",
    "from neurosurfer.agents.rag.chunker import Chunker\n",
    "from neurosurfer.agents.rag.filereader import FileReader\n",
    "from neurosurfer.agents.rag import RAGAgent, RAGAgentConfig, RAGIngestorConfig\n",
    "\n",
    "chunker = Chunker()\n",
    "file_reader = FileReader()\n",
    "embedder = SentenceTransformerEmbedder(\"intfloat/e5-small-v2\")\n",
    "\n",
    "rag_agent = RAGAgent(\n",
    "    llm=LLM,\n",
    "    embedder=embedder,\n",
    "    file_reader=file_reader,\n",
    "    chunker=chunker,\n",
    "    config=RAGAgentConfig(\n",
    "        top_k=5,\n",
    "        fixed_max_new_tokens=1024,\n",
    "        clear_collection_on_init=True\n",
    "    ),\n",
    "    ingestor_config=RAGIngestorConfig(\n",
    "        batch_size=64,\n",
    "        max_workers=4,\n",
    "        deduplicate=True,\n",
    "        normalize_embeddings=True,\n",
    "        default_metadata=None,\n",
    "        tmp_dir=\"./rag-storage\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "dir_path = \"../neurosurfer\"\n",
    "summary = rag_agent.ingest(sources=dir_path)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd1627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, get_args\n",
    "from neurosurfer.agents.rag.config import RetrievalMode\n",
    "\n",
    "def test(retrieval_mode: Optional[RetrievalMode] = None):\n",
    "    print(type(retrieval_mode))\n",
    "    print(retrieval_mode not in get_args(RetrievalMode))\n",
    "\n",
    "test(retrieval_mode=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "671e81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ smart\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_289190/3078909743.py\", line 1, in <module>\n",
      "    retrival_results = rag_agent.retrieve(user_query=\"Explain how graph agent is initialized\", retrieval_mode=\"smart\")\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/agent.py\", line 235, in retrieve\n",
      "    raise ValueError(\"Retrieval mode must be one of: [classic, smart]\")\n",
      "ValueError: Retrieval mode must be one of: [classic, smart]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/nomi/anaconda3/envs/LLMs/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "retrival_results = rag_agent.retrieve(user_query=\"Explain how graph agent is initialized\", retrieval_mode=\"smart\")\n",
    "print(retrival_results.context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991e188",
   "metadata": {},
   "source": [
    "**Server RAG Orchestrator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d61982-ac42-46b7-8a6b-bc3ed2248907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:55\u001b[0m | \u001b[96mdb.py:init_db\u001b[0m    | Database initialized successfully in sqlite:////home/nomi/.cache/Neurosurfer/app-storage/app.db\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96mposthog.py:__init__\u001b[0m | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of users left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of files left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of threads left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of messages left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:56\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of documents left: 0\n"
     ]
    }
   ],
   "source": [
    "# scripts/index_repo_for_rag.py\n",
    "from pathlib import Path\n",
    "from neurosurfer.vectorstores.chroma import ChromaVectorStore\n",
    "from neurosurfer.models.embedders.sentence_transformer import SentenceTransformerEmbedder\n",
    "from neurosurfer.server.services.rag.orchestrator import RAGOrchestrator\n",
    "\n",
    "try:\n",
    "    from neurosurfer.server.db.db import init_db\n",
    "    init_db()\n",
    "except Exception as _e:\n",
    "    print('DB init warning:', _e)\n",
    "    \n",
    "embedder = SentenceTransformerEmbedder(\"intfloat/e5-small-v2\")\n",
    "# vs = ChromaVectorStore(collection_name=\"neurosurf-repo\")\n",
    "RAG = RAGOrchestrator(\n",
    "    embedder=embedder,\n",
    "    gate_llm=LLM,\n",
    "    top_k=10,\n",
    "    verbose=False,\n",
    "    logger=LOGGER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1ba6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:59\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of users left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:59\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of files left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:59\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of threads left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:59\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of messages left: 0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:59\u001b[0m | \u001b[96morchestrator.py:_reset_db\u001b[0m | Number of documents left: 0\n",
      "[Init] ChromaVectorStore initialized with collection: nm_u1_t1\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:16:59\u001b[0m | \u001b[96mingestor.py:_ingest_single_file\u001b[0m | [RAGIngest] Handling file: weather_tool.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e53a73551b24b9fa6af5ec86cd55273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247a5ee7f9c849b3b759a64465e21cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-19 23:17:02\u001b[0m | \u001b[96m2334187976.py:<module>\u001b[0m | [RAG] used context (top_sim=0.000)\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "import base64\n",
    "import os\n",
    "\n",
    "actor_id = 1\n",
    "thread_id = 1\n",
    "user_query = \"Explain the weather tool?\"\n",
    "\n",
    "file_path = \"weather_tool.py\"\n",
    "\n",
    "# os.path.exists(file_path)\n",
    "\n",
    "files: List[Dict[str, Any]] = [{\n",
    "    \"name\": file_path,\n",
    "    \"content\": base64.b64encode(open(file_path, \"rb\").read()).decode(\"utf-8\"),\n",
    "    \"type\": \"text/x-python\",\n",
    "}]\n",
    "\n",
    "# reset db\n",
    "RAG._reset_db()\n",
    "\n",
    "rag_res = RAG.apply(\n",
    "    actor_id=actor_id,\n",
    "    thread_id=thread_id,\n",
    "    user_query=user_query,\n",
    "    files=files,\n",
    ")\n",
    "user_query = rag_res.augmented_query\n",
    "if rag_res.used:\n",
    "    LOGGER.info(f\"[RAG] used context (top_sim={rag_res.meta.get('top_similarity', 0):.3f})\")\n",
    "else:\n",
    "    LOGGER.info(f\"[RAG] no context (reason={rag_res.meta.get('reason')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe57e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGResult(used=True, augmented_query='Explain the key concepts and main functionality of the WeatherToolTool class defined in weather_tool.py.\\n\\n[CONTEXT]\\nSource: weather_tool.py\\nfrom neurosurfer.tools.tool_spec import ToolSpec, ToolParam, ToolReturn\\nfrom neurosurfer.tools.base_tool import BaseTool\\nclass WeatherToolTool(BaseTool):\\n    spec = ToolSpec(\\n        name=\"weather_tool\",\\n        description=\"Fetches current weather data for a given location\",\\n        when_to_use=\"When you need to retrieve current weather information\",\\n        inputs=[\\n            ToolParam(name=\"location\", type=\"str\", description=\"The location to check the weather for\", required=True)\\n        ],\\n        outputs=[\\n            ToolReturn(name=\"weather_data\", type=\"dict\", description=\"Dictionary containing current weather data\")\\n        ]\\n    )\\n    def __call__(self, location: str) -> dict:\\n        if not isinstance(location, str):\\n            raise ValueError(\"Location must be a string\")\\n        # Simulate fetching weather data (deterministic, no external calls)\\n        weather_data = {\\n            \"location\": location,\\n            \"temperature\": \"22¬∞C\",\\n            \"condition\": \"Sunny\",\\n            \"humidity\": \"65%\",\\n            \"wind_speed\": \"10 km/h\"\\n        }\\n\\n---\\n\\nSource: weather_tool.py\\nfrom neurosurfer.tools.tool_spec import ToolSpec, ToolParam, ToolReturn\\nfrom neurosurfer.tools.base_tool import BaseTool\\nclass WeatherToolTool(BaseTool):\\n    spec = ToolSpec(\\n        name=\"weather_tool\",\\n        description=\"Fetches current weather data for a given location\",\\n        when_to_use=\"When you need to retrieve current weather information\",\\n        inputs=[\\n            ToolParam(name=\"location\", type=\"str\", description=\"The location to check the weather for\", required=True)\\n        ],\\n        outputs=[\\n            ToolReturn(name=\"weather_data\", type=\"dict\", description=\"Dictionary containing current weather data\")\\n        ]\\n    )\\n    def __call__(self, location: str) -> dict:\\n        if not isinstance(location, str):\\n            raise ValueError(\"Location must be a string\")\\n        # Simulate fetching weather data (deterministic, no external calls)\\n        weather_data = {\\n            \"location\": location,\\n            \"temperature\": \"22¬∞C\",\\n            \"condition\": \"Sunny\",\\n            \"humidity\": \"65%\",\\n            \"wind_speed\": \"10 km/h\"\\n        }\\n\\n---\\n\\nSource: weather_tool.py\\n            \"humidity\": \"65%\",\\n            \"wind_speed\": \"10 km/h\"\\n        }\\n        return weather_data\\n\\n---\\n\\nSource: weather_tool.py\\n            \"humidity\": \"65%\",\\n            \"wind_speed\": \"10 km/h\"\\n        }\\n        return weather_data\\n[/CONTEXT]', meta={'used': True, 'reason': 'ok', 'gate': {'rag': True, 'related_files': ['weather_tool.py'], 'optimized_query': 'Explain the key concepts and main functionality of the WeatherToolTool class defined in weather_tool.py.', 'raw_response': '{\\n  \"rag\": true,\\n  \"related_files\": [\"weather_tool.py\"],\\n  \"optimized_query\": \"Explain the key concepts and main functionality of the WeatherToolTool class defined in weather_tool.py.\"\\n}', 'reason': None}})\n",
      "\n",
      "Explain the key concepts and main functionality of the WeatherToolTool class defined in weather_tool.py.\n",
      "\n",
      "[CONTEXT]\n",
      "Source: weather_tool.py\n",
      "from neurosurfer.tools.tool_spec import ToolSpec, ToolParam, ToolReturn\n",
      "from neurosurfer.tools.base_tool import BaseTool\n",
      "class WeatherToolTool(BaseTool):\n",
      "    spec = ToolSpec(\n",
      "        name=\"weather_tool\",\n",
      "        description=\"Fetches current weather data for a given location\",\n",
      "        when_to_use=\"When you need to retrieve current weather information\",\n",
      "        inputs=[\n",
      "            ToolParam(name=\"location\", type=\"str\", description=\"The location to check the weather for\", required=True)\n",
      "        ],\n",
      "        outputs=[\n",
      "            ToolReturn(name=\"weather_data\", type=\"dict\", description=\"Dictionary containing current weather data\")\n",
      "        ]\n",
      "    )\n",
      "    def __call__(self, location: str) -> dict:\n",
      "        if not isinstance(location, str):\n",
      "            raise ValueError(\"Location must be a string\")\n",
      "        # Simulate fetching weather data (deterministic, no external calls)\n",
      "        weather_data = {\n",
      "            \"location\": location,\n",
      "            \"temperature\": \"22¬∞C\",\n",
      "            \"condition\": \"Sunny\",\n",
      "            \"humidity\": \"65%\",\n",
      "            \"wind_speed\": \"10 km/h\"\n",
      "        }\n",
      "\n",
      "---\n",
      "\n",
      "Source: weather_tool.py\n",
      "from neurosurfer.tools.tool_spec import ToolSpec, ToolParam, ToolReturn\n",
      "from neurosurfer.tools.base_tool import BaseTool\n",
      "class WeatherToolTool(BaseTool):\n",
      "    spec = ToolSpec(\n",
      "        name=\"weather_tool\",\n",
      "        description=\"Fetches current weather data for a given location\",\n",
      "        when_to_use=\"When you need to retrieve current weather information\",\n",
      "        inputs=[\n",
      "            ToolParam(name=\"location\", type=\"str\", description=\"The location to check the weather for\", required=True)\n",
      "        ],\n",
      "        outputs=[\n",
      "            ToolReturn(name=\"weather_data\", type=\"dict\", description=\"Dictionary containing current weather data\")\n",
      "        ]\n",
      "    )\n",
      "    def __call__(self, location: str) -> dict:\n",
      "        if not isinstance(location, str):\n",
      "            raise ValueError(\"Location must be a string\")\n",
      "        # Simulate fetching weather data (deterministic, no external calls)\n",
      "        weather_data = {\n",
      "            \"location\": location,\n",
      "            \"temperature\": \"22¬∞C\",\n",
      "            \"condition\": \"Sunny\",\n",
      "            \"humidity\": \"65%\",\n",
      "            \"wind_speed\": \"10 km/h\"\n",
      "        }\n",
      "\n",
      "---\n",
      "\n",
      "Source: weather_tool.py\n",
      "            \"humidity\": \"65%\",\n",
      "            \"wind_speed\": \"10 km/h\"\n",
      "        }\n",
      "        return weather_data\n",
      "\n",
      "---\n",
      "\n",
      "Source: weather_tool.py\n",
      "            \"humidity\": \"65%\",\n",
      "            \"wind_speed\": \"10 km/h\"\n",
      "        }\n",
      "        return weather_data\n",
      "[/CONTEXT]\n"
     ]
    }
   ],
   "source": [
    "print(rag_res)\n",
    "\n",
    "print()\n",
    "print(rag_res.augmented_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f3be3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `WeatherToolTool` class in `weather_tool.py` is a custom tool designed to fetch and return current weather data for a given location. It is built using a base class `BaseTool` and follows a structured specification using `ToolSpec`, `ToolParam`, and `ToolReturn`. Here's a breakdown of its key concepts and main functionality:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Class Definition**\n",
      "- **Class Name:** `WeatherToolTool`\n",
      "- **Inherits From:** `BaseTool` (a base class for all tools in the `neurosurger` framework)\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Tool Specification (`ToolSpec`)**\n",
      "- **Purpose:** Defines metadata about the tool.\n",
      "- **Key Parameters:**\n",
      "  - **`name`:** `\"weather_tool\"` ‚Äî The name of the tool.\n",
      "  - **`description`:** `\"Fetches current weather data for a given location\"` ‚Äî A brief description of what the tool does.\n",
      "  - **`when_to_use`:** `\"When you need to retrieve current weather information\"` ‚Äî Indicates the appropriate use case.\n",
      "  - **`inputs`:** A list of input parameters:\n",
      "    - **`location`** (type: `str`, required: `True`) ‚Äî The location for which to fetch weather data.\n",
      "  - **`outputs`:** A list of output parameters:\n",
      "    - **`weather_data`** (type: `dict`) ‚Äî A dictionary containing current weather information.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Main Functionality**\n",
      "- **`__call__` Method:**\n",
      "  - **Purpose:** Executes the tool's main logic when called.\n",
      "  - **Parameters:**\n",
      "    - `location` (str): The location to check the weather for.\n",
      "  - **Validation:**\n",
      "    - Ensures the input `location` is a string; otherwise, raises a `ValueError`.\n",
      "  - **Simulated Weather Data:**\n",
      "    - Constructs a dictionary `weather_data` with the following keys:\n",
      "      - `\"location\"`: The input location.\n",
      "      - `\"temperature\"`: `\"22¬∞C\"`\n",
      "      - `\"condition\"`: `\"Sunny\"`\n",
      "      - `\"humidity\"`: `\"65%\"`\n",
      "      - `\"wind_speed\"`: `\"10 km/h\"`\n",
      "    - Returns this dictionary as the result.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Key Characteristics**\n",
      "- **Deterministic:** The tool does not make external API calls; it simulates weather data for demonstration purposes.\n",
      "- **Reusability:** Designed to be integrated into a larger system (e.g., a chatbot or application) that uses tools to retrieve information.\n",
      "- **Structured:** Uses a consistent format for inputs and outputs, making it compatible with the `neurosurfer` framework.\n",
      "\n",
      "---\n",
      "\n",
      "### **Summary**\n",
      "The `WeatherToolTool` class is a simple, reusable tool that simulates fetching current weather data for a given location. It leverages a structured specification to define inputs and outputs and provides a deterministic response, making it ideal for demonstration or integration into larger systems."
     ]
    }
   ],
   "source": [
    "for chunk in LLM.ask(\n",
    "    user_prompt=rag_res.augmented_query,\n",
    "    system_prompt=\"You are a helpful assistant. Provide your answers in a clear and concise manner.\",\n",
    "    chat_history=[],\n",
    "    stream=True,\n",
    "):\n",
    "    chunk = chunk.choices[0].delta.content or \"\"\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4c8c2",
   "metadata": {},
   "source": [
    "## Graph AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec7eb2",
   "metadata": {},
   "source": [
    "### YAML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e3d42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key:  f443633b...\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-18 14:44:24\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:35\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:35\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:35\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:40\u001b[0m | \u001b[96m_common.py:_log_backoff\u001b[0m | Backing off send_request(...) for 0.8s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))\n"
     ]
    }
   ],
   "source": [
    "# test web search tool\n",
    "from neurosurfer.tools.websearch import WebSearchTool, WebSearchConfig\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "\n",
    "api_key = os.getenv(\"SERPAPI_KEY\", \"API Key not found...\")\n",
    "print(\"API Key: \", f\"{api_key[:8]}...\")\n",
    "\n",
    "web_search_tool = WebSearchTool(\n",
    "    config=WebSearchConfig(\n",
    "        engine=\"serpapi\",\n",
    "        engine_kwargs={\"api_key\": api_key},\n",
    "        max_results=3,\n",
    "        enable_crawl=True,\n",
    "        max_crawl_results=2,\n",
    "        content_words_limit=2000,\n",
    "        content_limit_strategy=\"distributive\",\n",
    "        summarize=False,\n",
    "        top_k=10,\n",
    "    ),\n",
    "    llm=LLM,\n",
    ")\n",
    "\n",
    "# searches = web_search_tool(query=\"Importance of sleep in health.\")\n",
    "# print(searches)\n",
    "\n",
    "toolkit = Toolkit(tools=[web_search_tool])\n",
    "# print(toolkit.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346487b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Importance of sleep in health.',\n",
       " 'summary': \"Top 3 results out of ~988,000,000 results for: 'Importance of sleep in health.'\\n1. How Sleep Works - Why Is Sleep Important? - NHLBI - NIH ‚Äî https://www.nhlbi.nih.gov/health/sleep/why-sleep-important\\n2. Better sleep: Why it's important for your health and tips to ... ‚Äî https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03\\n3. Sleep is essential to health - Journal of Clinical Sleep Medicine ‚Äî https://jcsm.aasm.org/doi/10.5664/jcsm.9476\",\n",
       " 'provider': 'serpapi',\n",
       " 'elapsed_ms': 3004,\n",
       " 'rag_content': 'Source: 355e311e80b4be26:cc35f490\\nlth Sleep has become a precious commodity ‚Äì we love it and need it, but rarely get enough of it. Busy schedules, kids, anxiety and technology can all get in the way of a good night sleep. Getting enough sleep can play an important role in your weight, emotional wellbeing, blood pressure, diabetes, mental and physical performance, and more. Remember that adults aren\\'t the only ones who need good sleep. It\\'s also critical that children get even more sleep than adults. Why is sleep important for health? The three pillars of health are nutrition, physical exercise, and sleep. All three of these are connected. For example, if you don\\'t sleep well, you may not eat well. People get food cravings when they haven\\'t slept well, and they often crave a food with lots of carbohydrates (carbs) like a cookie. And when you are tired, the last thing you want to do is go to the gym. People who are fully functioning pay attention to all three. They must all be working together for better health. Here are\\n\\n---\\n\\nSource: 1569daa75eb865f1:cc35f490\\nBack To How Sleep Works Why Is Sleep Important? 0 How Sleep Works MENU Home Health Topics < Back To How Sleep Works Why Is Sleep Important? How Sleep Works Your Sleep/Wake Cycle Sleep Phases and Stages Why Is Sleep Important? How Much Sleep Is Enough? MORE INFORMATION Fact Sheets and Handouts Research How Sleep Works How Sleep Works Why Is Sleep Important? Language switcher English Espa√±ol IN THIS ARTICLE View More View Less Sleep plays a vital role in good health and well-being throughout your life. The way you feel while you are awake depends in part on what happens while you are sleeping. During sleep, your body is working to support healthy brain function and maintain your physical health. In children and teens, sleep also helps support growth and development. Getting inadequate sleep over time can raise your risk for chronic (long-term) health problems. It can also affect how well you think, react, work, learn, and get along with others. Learn how sleep affects your heart and circ\\n\\n---\\n\\nSource: 4bd421ad2e29abac:cc35f490\\nBetter sleep: Why it‚Äôs important for your health and tips to sleep soundly | Cultivating Health | UC Davis Health search Search all UC Davis health Main Menu add menu Main Menu close Main Menu Main Menu remove UC Davis Health Home Patients & Visitors Services & Specialties Health Care Professionals Schools & Programs Research News About UC Davis Health Giving Careers search Search √ó Search all UC Davis Health Search All UC Davis Health Search Search enhanced by Google close Search all UC Davis Health Search All UC Davis Health Search Search enhanced by Google Skip to main content Cultivating Health Show menu menu Menu Cancer Care Children\\'s Health Fitness Heart Health Mental Health All Articles notifications Subscribe Mental Health MARCH 15, 2023 Better sleep: Why it‚Äôs important for your health and tips to sleep soundly By Cultivating Health Sleep has become a precious commodity ‚Äì we love it and need it, but rarely get enough of it. Busy schedules, kids, anxiety and technology can all\\n\\n---\\n\\nSource: 91de3a34d7fa00e2:cc35f490\\nant to do is go to the gym. People who are fully functioning pay attention to all three. They must all be working together for better health. Here are some other health benefits of sleep: promotes growth helps heart health supports weight management helps combat germs and keep your immune system strong reduces risk of injury increases attention span boosts memory and learning Find out if melatonin is safe, its side effects and if it helps you sleep How much sleep should adults get? Studies show that adults should get seven to eight hours a night for good health. Some people insist that they can get away with four or five hours of sleep. While these so-called \"short sleepers\" do exist, they are a very small percentage of the population. The rest of the self-identified \"short sleepers\" are mostly staying alert by drinking coffee or other caffeinated drinks. Not getting enough sleep can raise the risk of health consequences. However, getting enough sleep isn\\'t just about the number of hou\\n\\n---\\n\\nSource: e388173c38819c5e:cc35f490\\nrm) health problems. It can also affect how well you think, react, work, learn, and get along with others. Learn how sleep affects your heart and circulatory system, metabolism , respiratory system, and immune system and how much sleep is enough. BROCHURE This brochure describes the differences between the types of sleep needed to feel awake and to be healthy and offers tips for getting a good night‚Äôs sleep. View the brochure Heart and circulatory system When you fall asleep and enter non-REM sleep , your blood pressure and heart rate fall. During sleep, your parasympathetic system controls your body, and your heart does not work as hard as it does when you are awake. During REM sleep and when waking, your sympathetic system is activated, increasing your heart rate and blood pressure to the usual levels when you are awake and relaxed. A sharp increase in blood pressure and heart rate upon waking has been linked to angina, or chest pain, and heart attacks . People who do not sleep enoug\\n\\n---\\n\\nSource: 527693a794d92a2b:cc35f490\\nffeinated drinks. Not getting enough sleep can raise the risk of health consequences. However, getting enough sleep isn\\'t just about the number of hours you\\'re asleep. It\\'s also about the quality of sleep and that you stay on a regular schedule so that you feel rested when you wake up. Learn about anxiety symptoms and when to know if you need help How much sleep should children get? According to the U.S. Department of Health and Human Services , these are the recommended number of hours of sleep based on a child\\'s age: Newborns: 14-17 hours a day Babies: 12-16 hours a day (including naps) Toddlers: 11-14 hours a day (including naps) Preschoolers: 10-13 hours a day (including naps) School-aged children: 9-12 hours each night Teenagers: 8-10 hours each night What are some health risks of not getting enough sleep? Not enough sleep or routinely getting broken sleep is linked with seven of the 15 leading causes of death in the U.S. These include: Heart disease Cancerous tumors Diseases rela\\n\\n---\\n\\nSource: f5deaa2fd34dff22:cc35f490\\nuctive pulmonary disease (COPD) . Asthma symptoms are usually worse during early morning sleep. Likewise, breathing problems in people who have lung diseases such as COPD can become worse during sleep. Sleep also affects different parts of your immune system, which become more active at different times of day. For example, when you sleep, a particular type of immune cell works harder. That is why people who do not sleep enough may be more likely to get colds and other infections. FACT SHEET Sleep Fact Sheet Learn some sleep terms and find out about treatments that can help with sleep apnea. View the fact sheet Problems with thinking and memory Sleep helps with learning and the formation of long-term memories. Not getting enough sleep or enough high-quality sleep can lead to problems focusing on tasks and thinking clearly. Read our Sleep Deprivation and Deficiency page for more information on how lack of sleep affects performance of daily activities, including driving and schoolwork. Bo\\n\\n---\\n\\nSource: baa9ae9e26cf11b5:cc35f490\\nHow Sleep Works - Why Is Sleep Important? | NHLBI, NIH Skip to main content An official website of the United States government Here‚Äôs how you know Here‚Äôs how you know Official websites use .gov A .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPS A lock ( A locked padlock ) or https:// means you‚Äôve safely connected to the .gov website. Share sensitive information only on official, secure websites. Search Query: Health Topics All Health Topics A-Z Asthma Heart-Healthy Living High Blood Pressure Sickle Cell Disease Sleep Apnea Calculate Your BMI Health Education Education Programs and Initiatives The Heart Truth¬Æ Learn More Breathe Better¬Æ Blood Diseases & Disorders Education Program Publications and Resources Research Clinical Trials and Studies Research Focus Areas Blood Disorders and Blood Safety Sleep Science and Sleep Disorders Lung Diseases Health Disparities Heart and Vascular Diseases Precision Medicine Activities Obe\\n\\n---\\n\\nSource: dbd50916457b69e1:cc35f490\\n, laptop, etc.) in an area of the house other than the bedrooms. Sleep in a dark room because light stimulates our brains. Use an alarm clock rather than your smartphone or tablet as a wakeup device. Keep room temperatures on the cooler side ‚Äì ideally low to mid-60s. Aim for a consistent bedtime routine and sleep schedule to help your body stay on a regular track. Find a good time for you to go to sleep every night and wake up at the same time every morning. It\\'s also important to keep that same schedule even on the weekends. Find out about social media\\'s impact on our mental health and tips to use it safely What happens to your brain when you don\\'t get enough sleep? Sleep deprivation affects your ability to remember, concentrate, and make good decisions. Your reaction time is also reduced. A sleep-deprived driver has the same poor response time as someone who is legally drunk. Not getting enough sleep makes us more emotionally unstable. Lack of sleep can cause you to have very strong\\n\\n---\\n\\nSource: 10685d511e3aaad8:cc35f490\\nse time as someone who is legally drunk. Not getting enough sleep makes us more emotionally unstable. Lack of sleep can cause you to have very strong emotions, such as extreme sadness or anger. Does sleep play a role in Alzheimer\\'s disease? One thing that connects almost all mental and nervous system disorders is some level of wake and sleep disruption. Health experts know that treating sleep disruptions can help stabilize neurologic disorders. But left untreated, sleep disruption may contribute to the progression of disease. One example is Alzheimer\\'s disease . We know that sleep is disrupted in the early stages of the disease. If we could address that early on, perhaps the progression of the disease could be delayed. Patrick M. Fuller , a neuroscientist who studies how the brain regulates sleeping and waking, contributed and reviewed this article. Fuller is a professor in UC Davis Health\\'s Department of Neurological Surgery and vice chair for research. Explore related topics Mental H',\n",
       " 'llm_summary': 'Sleep is crucial for overall health and well-being, playing a vital role in physical health, mental function, emotional stability, and immune system support (source: https://www.nhlbi.nih.gov/health/sleep/why-sleep-important). \\n\\n**Key Points:**\\n- Sleep supports brain function, including memory consolidation and learning (source: https://jcsm.aasm.org/doi/10.5664/jcsm.9476).\\n- It helps regulate bodily functions such as heart health, blood pressure, and metabolism (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- Chronic sleep deprivation is linked to an increased risk of chronic diseases, including heart disease, diabetes, and weakened immune function (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- Adults are recommended to get 7‚Äì8 hours of sleep per night, while children and teens require more (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n\\n**Caveats:**\\n- The quality of sleep is as important as the quantity. Poor sleep quality can have similar negative effects as insufficient sleep (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- Some individuals, known as \"short sleepers,\" may function with less sleep, but this is rare and not recommended for most people (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- There is some debate about the exact impact of sleep on conditions like Alzheimer\\'s disease, with some studies suggesting a potential link between sleep disruption and disease progression (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches.results\n",
    "# # print(searches.results[\"rag_content\"])\n",
    "# print(searches.results[\"llm_summary\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3dbe3",
   "metadata": {},
   "source": [
    "**GrpahAgent from YML file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf1ccb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-18 14:58:05\u001b[0m | \u001b[96mutils.py:normalize_and_validate_graph_inputs\u001b[0m | Ignoring extra inputs not declared in graph spec: audience, tone\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:58:05\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m249s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33müß† Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mresearch\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: web_search\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models'\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m079s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-18 14:58:09\u001b[0m | \u001b[96mingestor.py:ingest\u001b[0m | Some sources were skipped as unsupported: [None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 16.04it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 53.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:58:09\u001b[0m | \u001b[96magent.py:retrieve\u001b[0m | [RAGRetriever] Retrieved 10 chunks\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'web_search'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models'\u001b[0m\u001b[1;32m, 'summary\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m933s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m014s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mresearch\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m ‚ñ∂ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m ‚óÄ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m790s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\n",
      "\u001b[1;4;31mError executing node outline: CUDA out of memory. Tried to allocate \u001b[0m\u001b[1;4;31m158.00\u001b[0m\u001b[1;4;31m MiB. \u001b[0m\n",
      "\u001b[1;4;31mGPU \u001b[0m\u001b[1;4;31m0\u001b[0m\u001b[1;4;31m has a total capacity of \u001b[0m\u001b[1;4;31m11.61\u001b[0m\u001b[1;4;31m GiB of which \u001b[0m\u001b[1;4;31m120.00\u001b[0m\u001b[1;4;31m MiB is free. Including \u001b[0m\n",
      "\u001b[1;4;31mnon-PyTorch memory, this process has \u001b[0m\u001b[1;4;31m10.70\u001b[0m\u001b[1;4;31m GiB memory in use. Of the allocated \u001b[0m\n",
      "\u001b[1;4;31mmemory \u001b[0m\u001b[1;4;31m9.91\u001b[0m\u001b[1;4;31m GiB is allocated by PyTorch, and \u001b[0m\u001b[1;4;31m484.27\u001b[0m\u001b[1;4;31m MiB is reserved by PyTorch \u001b[0m\n",
      "\u001b[1;4;31mbut unallocated. If reserved but unallocated memory is large try setting \u001b[0m\n",
      "\u001b[1;4;31mPYTORCH_CUDA_ALLOC_CONF\u001b[0m\u001b[1;4;31m=\u001b[0m\u001b[1;4;31mexpandable_segments\u001b[0m\u001b[1;4;31m:\u001b[0m\u001b[1;3;4;31mTrue\u001b[0m\u001b[1;4;31m to avoid fragmentation.  See \u001b[0m\n",
      "\u001b[1;4;31mdocumentation for Memory Management  \u001b[0m\n",
      "\u001b[1;4;31m(\u001b[0m\u001b[1;4;31mhttps://pytorch.org/docs/stable/notes/cuda.html#environment-variables\u001b[0m\u001b[1;4;31m)\u001b[0m\n",
      "\u001b[1;4;33mReturning partial results from executed nodes\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:58:10\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node research output to exports/research_20251118_145807.json\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "from neurosurfer.agents.graph import GraphAgent, ManagerConfig\n",
    "\n",
    "graph_agent = GraphAgent(\n",
    "    llm=LLM,\n",
    "    graph_yaml=\"blog_workflow.yml\",\n",
    "    toolkit=toolkit,\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=4096,\n",
    "    ),\n",
    "    manager_llm=LLM,\n",
    "    log_traces=True\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "graph_inputs = {\n",
    "    \"topic_title\": \"The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models\",\n",
    "    \"query\": \"Compose a 2000-2500 word blog on why tool-routing layers matter more than scaling LLM size, covering practical design patterns, examples, and tradeoffs.\",\n",
    "    \"audience\": \"Intermediate ML engineers\",\n",
    "    \"tone\": \"Practical and slightly opinionated\",\n",
    "}\n",
    "\n",
    "results = graph_agent.run(inputs=graph_inputs)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205b51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cb6796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"graph_agent_results.json\", \"w\") as writer:\n",
    "    json.dump(results.model_dump(), writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "303ddfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Review of Draft: \"Understanding Tool-Augmented LLM Agents: Architecture, Workflow, and Best Practices\"\n",
      "\n",
      "---\n",
      "\n",
      "## ‚úÖ **Strengths**\n",
      "\n",
      "- **Comprehensive Overview**: The draft provides a well-structured overview of tool-augmented LLM agents, covering key components like architecture, workflow, and best practices.\n",
      "- **Clear Terminology**: The use of consistent terminology (e.g., \"tool-augmented agents\", \"agent loop\") helps maintain clarity.\n",
      "- **Practical Focus**: The inclusion of best practices and workflow diagrams adds practical value for developers and researchers.\n",
      "- **Up-to-Date References**: The draft references recent advancements in LLM agent systems, such as the use of retrieval-augmented generation (RAG) and tool integration.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚ùå **Issues and Concerns**\n",
      "\n",
      "### 1. **Technical Inaccuracies**\n",
      "\n",
      "- **Overgeneralization of Tool Integration**: The draft refers to \"tools\" in a broad sense, but does not clearly distinguish between different types of tools (e.g., API-based, database, or external services). This may lead to confusion about what constitutes a \"tool\" in this context.\n",
      "- **Ambiguity in Agent Loop**: The description of the \"agent loop\" is somewhat vague. It mentions \"planning, execution, and feedback\" but lacks a clear sequence or explanation of how the agent decides when to use a tool.\n",
      "- **Misrepresentation of LLM Behavior**: The draft suggests that LLMs \"can autonomously choose when to use tools,\" which may not be accurate. In practice, the decision to use a tool is often guided by the agent's design, not the LLM itself, unless explicitly programmed with a tool-use policy.\n",
      "\n",
      "### 2. **Missing Explanations**\n",
      "\n",
      "- **Lack of Context on Tool Selection**: The draft does not explain how tools are selected or prioritized in an agent system. This is a critical aspect of agent design and should be elaborated.\n",
      "- **Insufficient Coverage of Tool Limitations**: The draft briefly mentions tool limitations but does not delve into common issues such as latency, API rate limits, or error handling, which are important for real-world deployment.\n",
      "- **No Mention of Evaluation Metrics**: There is no discussion of how to evaluate the performance of tool-augmented agents, such as accuracy, efficiency, or robustness.\n",
      "\n",
      "### 3. **Stylistic and Clarity Issues**\n",
      "\n",
      "- **Repetition of Concepts**: Some sections repeat similar ideas, which can be streamlined to improve readability.\n",
      "- **Lack of Visual Aids**: While the draft mentions diagrams, it does not include them. Including visual aids (e.g., architecture diagrams or workflow charts) would greatly enhance understanding.\n",
      "- **Ambiguous Terminology**: Terms like \"tool-augmented\" are used without a clear definition, which may confuse readers unfamiliar with the concept.\n",
      "\n",
      "---\n",
      "\n",
      "## üõ†Ô∏è **Recommendations**\n",
      "\n",
      "### 1. **Clarify the Role of Tools in Agent Systems**\n",
      "- Define what constitutes a \"tool\" in the context of LLM agents.\n",
      "- Differentiate between internal and external tools, and explain how they are integrated into the agent's decision-making process.\n",
      "\n",
      "### 2. **Elaborate on the Agent Loop and Tool Integration**\n",
      "- Provide a step-by-step explanation of the agent loop, including how the LLM decides to use a tool.\n",
      "- Include examples of how tools are invoked and how their outputs are processed.\n",
      "\n",
      "### 3. **Add a Section on Tool Selection and Prioritization**\n",
      "- Discuss strategies for selecting and prioritizing tools (e.g., based on relevance, reliability, or cost).\n",
      "- Explain how agents handle tool limitations and errors.\n",
      "\n",
      "### 4. **Include Evaluation and Performance Metrics**\n",
      "- Introduce common evaluation metrics for tool-augmented agents, such as task success rate, response time, and error recovery.\n",
      "- Provide examples of real-world use cases where these metrics are applied.\n",
      "\n",
      "### 5. **Incorporate Visual Aids**\n",
      "- Add diagrams to illustrate the architecture and workflow of tool-augmented agents.\n",
      "- Consider including a comparison table of different tool integration strategies.\n",
      "\n",
      "### 6. **Improve Clarity and Avoid Ambiguity**\n",
      "- Define key terms like \"tool-augmented\" and \"agent loop\" at the beginning or in a dedicated glossary.\n",
      "- Avoid vague statements like \"LLMs can autonomously choose when to use tools\" and instead clarify that this behavior is guided by the agent's design and policy.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚úÖ **Final Thoughts**\n",
      "\n",
      "The draft provides a solid foundation for understanding tool-augmented LLM agents, but it would benefit from greater technical precision, clearer explanations, and more structured content. With the suggested improvements, it could serve as a valuable resource for both researchers and practitioners in the field of LLM agent development.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(results[\"results\"][\"review\"].raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a795f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentConfig(allow_input_pruning=True, repair_with_llm=True, strict_tool_call=False, temperature=0.7, max_new_tokens=512, return_stream_by_default=False, retry=RouterRetryPolicy(max_route_retries=2, max_tool_retries=1, backoff_sec=0.7), strict_json=True, max_repair_attempts=1)\n",
      "retries=None timeout_s=None budget=NodeBudget(max_new_tokens=None, temperature=1.2, return_stream_by_default=None) allow_input_pruning=None repair_with_llm=None strict_tool_call=None strict_json=None max_repair_attempts=None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass\n",
    "class RouterRetryPolicy:\n",
    "    \"\"\"Retry tuning for routing + tool execution.\"\"\"\n",
    "    max_route_retries: int = 2\n",
    "    max_tool_retries: int = 1\n",
    "    backoff_sec: float = 0.7  # linear backoff\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"\n",
    "    Top-level configuration for the Agent.\n",
    "    \"\"\"\n",
    "    # Routing:\n",
    "    allow_input_pruning: bool = True    # drop unknown inputs not in ToolSpec\n",
    "    repair_with_llm: bool = True        # ask LLM to repair invalid routing/inputs\n",
    "    strict_tool_call: bool = False      # router must output JSON; else can answer in plain text\n",
    "    # synonyms: Dict[str, Dict[str, str]] = field(default_factory=dict)  # field -> {from: to}\n",
    "\n",
    "    # LLM defaults:\n",
    "    temperature: float = 0.7\n",
    "    max_new_tokens: int = 512\n",
    "    return_stream_by_default: bool = False\n",
    "\n",
    "    # Retries:\n",
    "    retry: RouterRetryPolicy = field(default_factory=RouterRetryPolicy)\n",
    "\n",
    "    # Structured-output options:\n",
    "    strict_json: bool = True                  # enforce RFC 8259 JSON\n",
    "    max_repair_attempts: int = 1              # for malformed JSON repairs\n",
    "\n",
    "\n",
    "\n",
    "class NodeBudget(BaseChatModel):\n",
    "    \"\"\"\n",
    "    Budget / LLM-related overrides per node.\n",
    "\n",
    "    These map directly to AgentConfig fields:\n",
    "        - temperature      -> AgentConfig.temperature\n",
    "        - max_new_tokens   -> AgentConfig.max_new_tokens\n",
    "        - return_stream_by_default -> AgentConfig.return_stream_by_default\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.max_new_tokens for this node only.\",\n",
    "    )\n",
    "    temperature: Optional[float] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.temperature for this node only.\",\n",
    "    )\n",
    "    return_stream_by_default: Optional[bool] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.return_stream_by_default for this node only.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class NodePolicy(BaseChatModel):\n",
    "    \"\"\"\n",
    "    Per-node policy that can override some AgentConfig settings and add\n",
    "    node-level execution constraints (e.g., timeout).\n",
    "\n",
    "    YAML example:\n",
    "\n",
    "        nodes:\n",
    "          - id: research\n",
    "            policy:\n",
    "              retries: 1\n",
    "              timeout_s: 30\n",
    "              budget:\n",
    "                max_new_tokens: 180\n",
    "                temperature: 0.2\n",
    "              allow_input_pruning: false\n",
    "              repair_with_llm: true\n",
    "              strict_tool_call: true\n",
    "    \"\"\"\n",
    "\n",
    "    retries: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.retry.max_route_retries for this node.\",\n",
    "    )\n",
    "    timeout_s: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"Soft timeout for this node in seconds. Execution isn't forcibly \"\n",
    "            \"cancelled but the node will be marked as errored if exceeded.\"\n",
    "        ),\n",
    "    )\n",
    "    budget: Optional[NodeBudget] = None\n",
    "\n",
    "    # Direct AgentConfig-like overrides\n",
    "    allow_input_pruning: Optional[bool] = None\n",
    "    repair_with_llm: Optional[bool] = None\n",
    "    strict_tool_call: Optional[bool] = None\n",
    "    strict_json: Optional[bool] = None\n",
    "    max_repair_attempts: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        extra = \"ignore\"  # ignore unknown keys under 'policy'\n",
    "\n",
    "c = AgentConfig()\n",
    "\n",
    "p = NodePolicy(budget=NodeBudget(temperature=1.2))\n",
    "\n",
    "print(c)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93052a6d",
   "metadata": {},
   "source": [
    "### Python API version (no YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926be727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: True\n",
      "Answer:\n",
      " The calculator result for your request is ${compute.text}. This means that after performing the calculation based on your input, the final answer is ${compute.text}. Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from graph import Graph, Node, NodePolicy, GraphConfig, GraphExecutor\n",
    "from neurosurfer.tools import Toolkit\n",
    "from neurosurfer.models.chat_models.openai import OpenAIModel\n",
    "\n",
    "# Reuse your existing toolkit + model\n",
    "llm = LLM  # already created in your environment\n",
    "tk = toolkit\n",
    "\n",
    "graph = Graph(\n",
    "    name=\"calc_and_explain\",\n",
    "    config=GraphConfig(max_concurrency=2),\n",
    "    inputs_schema={\"prompt\": str},\n",
    "    nodes=[\n",
    "        Node(\n",
    "            id=\"rewrite\",\n",
    "            fn=\"general_query_assistant\",  # adjust name if needed\n",
    "            inputs={\n",
    "                # swap \"query\" -> \"prompt\" if your tool expects \"prompt\"\n",
    "                \"query\": (\n",
    "                    \"You will receive a user request. Extract a SINGLE pure arithmetic expression that can be \"\n",
    "                    \"evaluated by a calculator (e.g., '(42 * 7) - 5^2' or '0.035 * 12000').\\n\"\n",
    "                    \"- Do NOT include explanations.\\n\"\n",
    "                    \"- Return ONLY the expression as plain text.\\n\\n\"\n",
    "                    \"User request:\\n${inputs.prompt}\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"num1\", \"num2\", \"operation\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 128, \"temperature\": 0.1},\n",
    "            ),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"compute\",\n",
    "            fn=\"calculator\",\n",
    "            inputs={\"num1\": \"${rewrite.num1}\", \"num2\": \"${rewrite.num2}\", \"operation\": \"${rewrite.operation}\"},\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(retries=0, timeout_s=15),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"explain\",\n",
    "            fn=\"general_query_assistant\",\n",
    "            inputs={\n",
    "                \"query\": (\n",
    "                    \"Original request: ${inputs.prompt}\\n\"\n",
    "                    \"Calculator result: ${compute.text}\\n\\n\"\n",
    "                    \"Write a brief, user-friendly explanation of the result (one short paragraph).\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 180, \"temperature\": 0.2},\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    outputs={\"answer\": \"${explain.text}\"},\n",
    ")\n",
    "\n",
    "executor = GraphExecutor(llm=llm, toolkit=tk, max_concurrency=2)\n",
    "\n",
    "result = await run_async(\n",
    "    executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}, stream=True)\n",
    ")\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(\"Answer:\\n\", result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e25a8",
   "metadata": {},
   "source": [
    "### Planner-based path (using the YAML as a skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, tempfile, pathlib\n",
    "from graph import PlannerAgent, FlowLoader, GraphExecutor\n",
    "\n",
    "# 1) Write the YAML to a temp file (only for this demo)\n",
    "yaml_text = r\"\"\"\n",
    "name: calc_and_explain\n",
    "inputs:\n",
    "  prompt: str\n",
    "config:\n",
    "  max_concurrency: 2\n",
    "nodes:\n",
    "  - id: rewrite\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        You will receive a user request. Extract a SINGLE pure arithmetic expression that can be\n",
    "        evaluated by a calculator (e.g., \"(42 * 7) - 5^2\" or \"0.035 * 12000\").\n",
    "        - Do NOT include explanations.\n",
    "        - Return ONLY the expression as plain text.\n",
    "\n",
    "        User request:\n",
    "        ${inputs.prompt}\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 128, temperature: 0.1 } }\n",
    "\n",
    "  - id: compute\n",
    "    kind: task\n",
    "    fn: calculator\n",
    "    inputs: { expression: ${rewrite.text} }\n",
    "    outputs: [\"text\"]\n",
    "\n",
    "  - id: explain\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        Original request: ${inputs.prompt}\n",
    "        Calculator result: ${compute.text}\n",
    "\n",
    "        Write a brief, user-friendly explanation of the result (one short paragraph).\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 180, temperature: 0.2 } }\n",
    "\n",
    "outputs: { answer: ${explain.text} }\n",
    "\"\"\".strip()\n",
    "\n",
    "tmp = pathlib.Path(tempfile.gettempdir()) / \"calc_and_explain.yml\"\n",
    "tmp.write_text(yaml_text)\n",
    "\n",
    "# 2) Use the planner with a skeleton (so it returns your YAML-based Graph)\n",
    "planner = PlannerAgent(llm=LLM)  # LLM not used when skeleton is set\n",
    "graph = planner.plan_from_query(query=\"Compute 3.5% of 12000 and explain\", skeleton=str(tmp))\n",
    "\n",
    "# 3) Execute\n",
    "executor = GraphExecutor(llm=LLM, toolkit=toolkit, max_concurrency=2)\n",
    "result = asyncio.run(executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}))\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225587f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f9ca96",
   "metadata": {},
   "source": [
    "Test ToolsRouterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d83d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: calculator\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'num1': 20.0, 'num2': 90.0, 'operation': 'multiply'}\n",
      "1800.0"
     ]
    }
   ],
   "source": [
    "query = \"Perform the calculation 20 * 90\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6635c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: general_query_assistant\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'query': 'Tell me a light-hearted joke!'}\n",
      "Why don't skeletons fight each other? They don't have the guts!None"
     ]
    }
   ],
   "source": [
    "query = \"Tell me a light-hearted joke!\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafe29f",
   "metadata": {},
   "source": [
    "## ReactAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aa87f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: I will first calculate 300 - 300 using the calculator tool, and then I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"calculator\",\n",
      "  \"inputs\": {\n",
      "    \"num1\": 300,\n",
      "    \"num2\": 300,\n",
      "    \"operation\": \"subtract\"\n",
      "  },\n",
      "  \"final_answer\": false\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>üîß<span style=\"font-weight: bold\">]</span> Tool: calculator\n",
       "<span style=\"font-weight: bold\">[</span>üì§<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'num1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'operation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'subtract'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0müîß\u001b[1m]\u001b[0m Tool: calculator\n",
       "\u001b[1m[\u001b[0müì§\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'num1'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'num2'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'operation'\u001b[0m: \u001b[32m'subtract'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: The result of the calculation is 0. Now, I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"general_query_assistant\",\n",
      "  \"inputs\": {\n",
      "    \"query\": \"Tell me a light-hearted joke about the number 0.\"\n",
      "  },\n",
      "  \"final_answer\": true\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>üîß<span style=\"font-weight: bold\">]</span> Tool: general_query_assistant\n",
       "<span style=\"font-weight: bold\">[</span>üì§<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tell me a light-hearted joke about the number 0.'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0müîß\u001b[1m]\u001b[0m Tool: general_query_assistant\n",
       "\u001b[1m[\u001b[0müì§\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'query'\u001b[0m: \u001b[32m'Tell me a light-hearted joke about the number 0.'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the number 0 break up with the number 8?  \n",
      "Because it found someone more \"8\" (8) than a zero!"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> Why did the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> break up with the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>?  \n",
       "Because it found someone more <span style=\"color: #008000; text-decoration-color: #008000\">\"8\"</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span> than a zero!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m Why did the number \u001b[1;36m0\u001b[0m break up with the number \u001b[1;36m8\u001b[0m?  \n",
       "Because it found someone more \u001b[32m\"8\"\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m than a zero!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[üß†] Chain of Thoughts...\n",
      "Thought: The calculation result is 0, and the joke provided is ready. The final answer is complete.\n",
      "\n",
      "Final Answer: The result of 300 - 300 is 0. Here's a light-hearted joke about it: Why did the number 0 break up with the number 8? Because it found someone more \"8\" (8) than a zero!"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.react import ReActAgent, ReActConfig\n",
    "\n",
    "react_agent = ReActAgent(\n",
    "    toolkit=toolkit,\n",
    "    llm=LLM,\n",
    "    specific_instructions=\"Always be concise in your answers. Break the task into steps if needed.\",\n",
    "    config=ReActConfig(\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=4096,\n",
    "        allow_input_pruning=True,\n",
    "        repair_with_llm=True,\n",
    "        skip_special_tokens=True,\n",
    "        verbose=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(react_agent._system_prompt())\n",
    "TASK = \"\"\"Calculate 300 - 300. Then tell me a light-hearted joke about that result.\"\"\"\n",
    "\n",
    "for chunk in react_agent.run(TASK):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41580e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c7a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766512d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad2c2b-4a95-4ac0-9727-4c746e97a629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ea014-d67c-4af9-b2f6-1a8d80d63b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
