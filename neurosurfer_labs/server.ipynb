{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b35214-7a1f-403c-9a7a-b42e481ab431",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Go up one directory from `b/` to project root\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affc4a2e-d532-4dee-8b50-cab72fd229c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                                                                  â•‘\n",
      "â•‘ â–“â–“â–“â–“â–“   â–“â–“â–“â–“                                  â–“â–“â–“                â•‘\n",
      "â•‘  â–“â–“ â–“â–“   â–“â–“  â–“â–“â–“â–“ â–“  â–“ â–“ â–“ â–“â–“â–“â–“ â–“â–“â–“ â–“  â–“ â–“ â–“  â–“   â–“â–“â–“â–“ â–“ â–“       â•‘\n",
      "â•‘  â–“â–“  â–“â–“  â–“â–“  â–“â–â–â–“ â–“  â–“ â–“â–“â– â–“  â–“ â–“â–  â–“  â–“ â–“â–“â– â–“â–“â–“  â–“â–â–â–“ â–“â–“        â•‘\n",
      "â•‘  â–“â–“   â–“â–“ â–“â–“  â–“    â–“  â–“ â–“   â–“  â–“   â–“ â–“  â–“ â–“    â–“   â–“    â–“         â•‘\n",
      "â•‘ â–“â–“â–“â–“   â–“â–“â–“â–“â–“ â–“â–“â–“â–“ â–“â–“â–“â–“ â–“   â–“â–“â–“â–“ â–“â–“â–“ â–“â–“â–“â–“ â–“    â–“   â–“â–“â–“â–“ â–“         â•‘\n",
      "â•‘ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ â•‘\n",
      "â•‘ Orchestrate Agents - RAG - SQL Tools - Multi-LLM - FastAPI Ready â•‘\n",
      "â•‘ Faster builds, clearer flows, production-first                   â•‘\n",
      "â•‘                                                                  â•‘\n",
      "â•‘ Version: 0.1.0 | Python: 3.12.12                                 â•‘\n",
      "â•‘ OS: Linux 6.17.0-7-generic (x86_64)                              â•‘\n",
      "â•‘ Torch: 2.8.0   CUDA: yes (12.8)                                  â•‘\n",
      "â•‘ MPS: no (built: False)                                           â•‘\n",
      "â•‘ Transformers: 4.56.2   SentEmb: 5.1.1                            â•‘\n",
      "â•‘ Accelerate: 1.10.1   bnb: 0.48.1                                 â•‘\n",
      "â•‘ Unsloth: 2025.10.5                                               â•‘\n",
      "â•‘                                                                  â•‘\n",
      "â•‘ Detected CUDA devices: NVIDIA GeForce RTX 5080                   â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomi/micromamba/envs/LLMs/lib/python3.12/importlib/__init__.py:90: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "#### Unsloth: `hf_xet==1.1.10` and `ipykernel>6.30.1` breaks progress bars. Disabling for now in XET.\n",
      "#### Unsloth: To re-enable progress bars, please downgrade to `ipykernel==6.30.1` or wait for a fix to\n",
      "https://github.com/huggingface/xet-core/issues/526\n",
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Unsloth: Xformers does not work in RTX 50X, Blackwell GPUs as of yet. Please build from source via\n",
      "```\n",
      "pip install ninja\n",
      "pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers\n",
      "```\n",
      "\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-04 23:23:59\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Initializing Transformers model.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-12-04 23:23:59\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Model is already quantized. Ignoring load_in_4bit=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-04 23:24:00\u001b[0m | \u001b[96mmodeling.py:get_balanced_memory\u001b[0m | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b1aab925da4468b58b59c4a32217a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-04 23:24:04\u001b[0m | \u001b[96mtransformers.py:init_model\u001b[0m | Transformers model initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from neurosurfer.models.chat_models.transformers import TransformersModel\n",
    "from neurosurfer.models.chat_models.unsloth import UnslothModel\n",
    "from neurosurfer import config \n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# falcon-7b-instruct\n",
    "# \"model_name\": \"/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "# \"model_name\": \"/home/nomi/workspace/Model_Weights/falcon-7b-instruct\",\n",
    "\n",
    "DEFAULT_TRANSFORMERS_MODEL_PARAMS = dict({\n",
    "    \"model_name\": \"/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"max_seq_length\": 4096,\n",
    "    \"load_in_4bit\": True,\n",
    "    \"enable_thinking\": False,\n",
    "    \"reasoning_effort\": \"low\",\n",
    "    \"add_special_tokens\": False,\n",
    "    \"verbose\": False\n",
    "})\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "LLM = TransformersModel(\n",
    "    **DEFAULT_TRANSFORMERS_MODEL_PARAMS,\n",
    "    stop_words=[\"Observation:\"],\n",
    "    logger = logging.getLogger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ff5798-3ed2-4b38-86cd-2498ca0e57be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?  \n",
      "Because they donâ€™t have the *guts*! ðŸ˜„"
     ]
    }
   ],
   "source": [
    "# streaming response example\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "system_prompt = \"\"\"You are a joke teller\"\"\"\n",
    "user_prompt = \"\"\"Tell me a short and light-hearted joke.\"\"\"\n",
    "\n",
    "stream_response = LLM.ask(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# print(stream_response.choices[0].message.content)\n",
    "md_display = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream_response:\n",
    "    chunk = chunk.choices[0].delta.content or \"\"\n",
    "    print(chunk, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808255b3",
   "metadata": {},
   "source": [
    "## Agent Test\n",
    "\n",
    "**Normal Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3030e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Response:\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m698s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m701s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "AI, or Artificial Intelligence, is the simulation of human intelligence in machines that are programmed to think, learn, and perform tasks typically requiring human cognition.\n"
     ]
    }
   ],
   "source": [
    "# agent normal response\n",
    "from neurosurfer.agents import Agent, AgentConfig\n",
    "# from neurosurfer.tracing import RichTracer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    strict_tool_call=True,\n",
    "    return_stream_by_default=True,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=4096,\n",
    ")\n",
    "agent = Agent(llm=LLM, config=agent_config, log_traces=True)\n",
    "\n",
    "# normal response\n",
    "print(\"Normal Response:\")\n",
    "agent_response = agent.run(user_prompt=\"What is AI (one line)?\", stream=False)\n",
    "# print(agent_response.response)\n",
    "\n",
    "# # streaming response\n",
    "# print(\"\\n\\nStreaming Response:\")\n",
    "# for c in agent.run(user_prompt=\"What are top 3 applications of AI (one line)?\").response:\n",
    "#     print(c, flush=True, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d91b3b",
   "metadata": {},
   "source": [
    "**Structured Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344ffe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-12-04 23:24:20\u001b[0m | \u001b[96magent.py:run\u001b[0m     | `output_schema` provided with `stream=True`; forcing non-streaming structured output.\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.structured_call.first_pass'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m148s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m161s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Structured Response:\n",
      "{\n",
      "  \"definition\": \"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and make decisions.\",\n",
      "  \"history\": \"The concept of AI dates back to the 1950s, with the term 'artificial intelligence' coined in 1956. Early research focused on creating machines that could perform tasks requiring human intelligence, such as problem-solving and language understanding.\",\n",
      "  \"modern_frameworks\": \"Modern frameworks like TensorFlow, PyTorch, and Keras have revolutionized AI development by providing scalable tools for building and deploying machine learning models.\",\n",
      "  \"applications\": [\n",
      "    {\n",
      "      \"title\": \"Healthcare\",\n",
      "      \"description\": \"AI is used for disease diagnosis, drug discovery, and personalized treatment plans.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Finance\",\n",
      "      \"description\": \"AI is used for fraud detection, algorithmic trading, and risk management.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Autonomous Vehicles\",\n",
      "      \"description\": \"AI powers self-driving cars through computer vision and real-time decision-making.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Structured Response examples\n",
    "class AIApplication(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "class AI(BaseModel):\n",
    "    definition: str\n",
    "    history: str\n",
    "    modern_frameworks: str\n",
    "    applications: list[AIApplication]\n",
    "\n",
    "user_query = \"What is AI and list 3 of its top application, and 3 concerns.\"\n",
    "agent_response = agent.run(user_prompt=user_query, output_schema=AI)\n",
    "\n",
    "print(\"\\n\\nStructured Response:\")\n",
    "print(agent_response.response.json_obj)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe4f0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_id': 2,\n",
       " 'kind': 'llm.call',\n",
       " 'label': 'agent.structured_call.first_pass',\n",
       " 'node_id': None,\n",
       " 'agent_id': 'main_agent',\n",
       " 'started_at': 1764876260.2168481,\n",
       " 'duration_ms': 4148,\n",
       " 'inputs': {'schema': 'AI',\n",
       "  'system_prompt_len': 52,\n",
       "  'user_prompt_len': 61,\n",
       "  'user_prompt': 'What is AI and list 3 of its top application, and 3 concerns.',\n",
       "  'system_prompt': \"You are a precise and rule-abiding assistant.  \\nYour task is to produce only a single valid JSON object following the schema below.\\n\\nStructured Output Contract:\\n- Output only JSON â€” no markdown, code fences, or explanations.  \\n- JSON must be strictly valid (RFC 8259): use double quotes for all keys and string values.  \\n- Do not include extra keys or any text outside the JSON object.  \\n- All required fields must be present, even if empty.  \\n- Arrays must contain at least one object when applicable.  \\n- The JSON must be a single complete object (not pretty-printed, no trailing commas).  \\n- Failure to comply with this structure means your response is invalid.\\n\\nExpected JSON Structure:\\n{'$defs': {'AIApplication': {'properties': {'title': {'title': 'Title', 'type': 'string'}, 'description': {'title': 'Description', 'type': 'string'}}, 'required': ['title', 'description'], 'title': 'AIApplication', 'type': 'object'}}, 'properties': {'definition': {'title': 'Definition', 'type': 'string'}, 'history': {'title': 'History', 'type': 'string'}, 'modern_frameworks': {'title': 'Modern Frameworks', 'type': 'string'}, 'applications': {'items': {'$ref': '#/$defs/AIApplication'}, 'title': 'Applications', 'type': 'array'}}, 'required': ['definition', 'history', 'modern_frameworks', 'applications'], 'title': 'AI', 'type': 'object'}\\n\\nNow generate your response strictly following this contract.\\n\",\n",
       "  'temperature': 0.7,\n",
       "  'max_new_tokens': 4096,\n",
       "  'stream': False},\n",
       " 'outputs': {'model_response': '{\"definition\":\"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and make decisions.\",\"history\":\"The concept of AI dates back to the 1950s, with the term \\'artificial intelligence\\' coined in 1956. Early research focused on creating machines that could perform tasks requiring human intelligence, such as problem-solving and language understanding.\",\"modern_frameworks\":\"Modern frameworks like TensorFlow, PyTorch, and Keras have revolutionized AI development by providing scalable tools for building and deploying machine learning models.\",\"applications\":[{\"title\":\"Healthcare\",\"description\":\"AI is used for disease diagnosis, drug discovery, and personalized treatment plans.\"},{\"title\":\"Finance\",\"description\":\"AI is used for fraud detection, algorithmic trading, and risk management.\"},{\"title\":\"Autonomous Vehicles\",\"description\":\"AI powers self-driving cars through computer vision and real-time decision-making.\"}]}',\n",
       "  'model_response_len': 995},\n",
       " 'meta': {},\n",
       " 'ok': True,\n",
       " 'error': None,\n",
       " 'logs': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_response.traces.steps[1].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf48079",
   "metadata": {},
   "source": [
    "**Tool Calling Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440e9634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-03 09:36:07\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: python_execute\n",
      "Agent with choice between tools and plain text:\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: python_execute\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'task'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Compute the determinant of a 50x50 matrix where each entry A\u001b[0m\u001b[1;3;32m is given by \u001b[0m\u001b[1;3;32m(\u001b[0m\u001b[1;3;32mi*j\u001b[0m\u001b[1;3;32m)\u001b[0m\u001b[1;3;32m % 7 + sin\u001b[0m\u001b[1;3;32m(\u001b[0m\u001b[1;3;32mi\u001b[0m\u001b[1;3;32m)\u001b[0m\u001b[1;3;32m.'\u001b[0m\u001b[1;3;32m}\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m406s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'python_execute'\u001b[0m\u001b[1;32m Tool Return: Here are the results from executing Python code for your task:\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\u001b[1;32m0.0\u001b[0m\n",
      "        \u001b[1;32mINFO: \u001b[0m\n",
      "        \u001b[1;32mINFO: Python code used:\u001b[0m\n",
      "        \u001b[1;32mINFO: ```python\u001b[0m\n",
      "        \u001b[1;32mINFO: imp\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m284s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'main_agent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m691s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmain_agent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "ToolCallResponse(selected_tool='python_execute', inputs={'task': 'Compute the determinant of a 50x50 matrix where each entry A[i][j] is given by (i*j) % 7 + sin(i).'}, returns='Here are the results from executing Python code for your task:\\n\\n0.0\\n\\nPython code used:\\n```python\\nimport numpy as np\\n\\n# Create the 50x50 matrix\\nmatrix = np.zeros((50, 50))\\nfor i in range(50):\\n    for j in range(50):\\n        matrix[i, j] = (i * j) % 7 + np.sin(i)\\n\\n# Compute the determinant\\ndeterminant = np.linalg.det(matrix)\\n\\nresult = determinant\\n```', final=False, extras={'generated_plots': [], 'python_last_result_summary': {'value': {'kind': 'float64', 'value': np.float64(0.0)}, 'description': 'Primitive result from the last python_execute call.', 'visible_to_llm': True}, 'python_last_code': {'value': 'import numpy as np\\n\\n# Create the 50x50 matrix\\nmatrix = np.zeros((50, 50))\\nfor i in range(50):\\n    for j in range(50):\\n        matrix[i, j] = (i * j) % 7 + np.sin(i)\\n\\n# Compute the determinant\\ndeterminant = np.linalg.det(matrix)\\n\\nresult = determinant', 'description': 'Python code used in the last python_execute call.', 'visible_to_llm': False}})\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.agent import Agent\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "from neurosurfer.tools.code_execution.python_exec_tool import PythonExecTool\n",
    "\n",
    "\n",
    "py_exec_tool = PythonExecTool(llm=LLM)\n",
    "toolkit = Toolkit(tools=[py_exec_tool])\n",
    "\n",
    "# print(\"Tool description:\")\n",
    "# print(py_exec_tool.get_tool_description())\n",
    "# print()\n",
    "\n",
    "agent = Agent(llm=LLM, toolkit=toolkit, log_traces=True)\n",
    "\n",
    "print(\"Agent with choice between tools and plain text:\")\n",
    "user_prompt = \"\"\"Using the Python tool, compute the determinant of this 50x50 matrix whose entries follow the rule A[i][j] = (i*j) % 7 + sin(i). Return only the final numeric determinant\"\"\"\n",
    "agent_response = agent.run(user_prompt=user_prompt, strict_tool_call=True, stream=False)\n",
    "\n",
    "# for chunk in agent_response.response.returns:\n",
    "#     pass\n",
    "\n",
    "print(agent_response.response)\n",
    "\n",
    "# print(\"\\n\\nAgent with strict tool call:\")\n",
    "# agent_response = agent.run(user_prompt=\"What is one forth of a 100?\", strict_tool_call=True)\n",
    "# print(agent_response.response)\n",
    "\n",
    "\n",
    "# for chunk in agent_response.response.returns:\n",
    "#     print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6233130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': {'kind': 'float64', 'value': np.float64(0.0)}, 'description': 'Primitive result from the last python_execute call.', 'visible_to_llm': True}\n"
     ]
    }
   ],
   "source": [
    "# print(agent_response.response.extras['python_last_code']['value'])\n",
    "print(agent_response.response.extras['python_last_result_summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4063c3",
   "metadata": {},
   "source": [
    "**Let's solve this problem using CodeAgent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9ca58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc2311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-03 09:40:15\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: python_execute\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mCodeAgent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90minspect \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90m'Student \u001b[0m\u001b[3;90mDegree \u001b[0m\u001b[3;90mCollege \u001b[0m\u001b[3;90mData.csv' \u001b[0m\u001b[3;90mfile \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90munderstand \u001b[0m\u001b[3;90mits \u001b[0m\u001b[3;90mstructure \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mcontents \u001b[0m\u001b[3;90mbefore \u001b[0m\u001b[3;90mperforming \u001b[0m\u001b[3;90many \u001b[0m\u001b[3;90mcomputations. \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mwill \u001b[0m\u001b[3;90mstart \u001b[0m\u001b[3;90mby \u001b[0m\u001b[3;90mloading \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mdisplaying \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfirst \u001b[0m\u001b[3;90mfew \u001b[0m\u001b[3;90mrows \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90midentify \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mcolumn \u001b[0m\u001b[3;90mnames \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mtypes.\u001b[0m\n",
      "        \n",
      "        \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"python_execute\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"task\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Load \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90m'Student \u001b[0m\u001b[3;90mDegree \u001b[0m\u001b[3;90mCollege \u001b[0m\u001b[3;90mData.csv' \u001b[0m\u001b[3;90mfile \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mdisplay \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfirst \u001b[0m\u001b[3;90mfew \u001b[0m\u001b[3;90mrows \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90minspect \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mstructure.\"\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "        \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: python_execute\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: python_execute, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'task'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"Load the 'Student Degree College Data.csv' file and display the first few rows to inspect the data structure.\"\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: Here are the results from executing Python code for your task:\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\n",
      "            \u001b[1;32mINFO: |   form_no | name            | category   | minority   | gender   |   hs_total |   hs\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m410s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m4.\u001b[0m\u001b[2m709s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mNow \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mhave \u001b[0m\u001b[3;90minspected \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdata, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mask \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mquestion \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mrequires \u001b[0m\u001b[3;90musing \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mPython \u001b[0m\u001b[3;90mtool \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mcompute \u001b[0m\u001b[3;90msome \u001b[0m\u001b[3;90mstatistics \u001b[0m\u001b[3;90mor \u001b[0m\u001b[3;90manalyze \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mfurther. \u001b[0m\u001b[3;90mFor \u001b[0m\u001b[3;90mexample, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mcould \u001b[0m\u001b[3;90mcalculate \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90maverage \u001b[0m\u001b[3;90mmarks \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mfirst \u001b[0m\u001b[3;90mchoice \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90msecond \u001b[0m\u001b[3;90mchoice \u001b[0m\u001b[3;90msubjects, \u001b[0m\u001b[3;90mor \u001b[0m\u001b[3;90mfind \u001b[0m\u001b[3;90mout \u001b[0m\u001b[3;90mhow \u001b[0m\u001b[3;90mmany \u001b[0m\u001b[3;90mstudents \u001b[0m\u001b[3;90mbelong \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90meach \u001b[0m\u001b[3;90mcategory.\u001b[0m\n",
      "        \n",
      "        \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"python_execute\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"task\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Calculate \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90maverage \u001b[0m\u001b[3;90mmarks \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mfirst \u001b[0m\u001b[3;90mchoice \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90msecond \u001b[0m\u001b[3;90mchoice \u001b[0m\u001b[3;90msubjects \u001b[0m\u001b[3;90mfrom \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90m'Student \u001b[0m\u001b[3;90mDegree \u001b[0m\u001b[3;90mCollege \u001b[0m\u001b[3;90mData.csv' \u001b[0m\u001b[3;90mfile.\"\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[3;90m\"python_last_result_summary\"\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "        \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: python_execute\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: python_execute, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'task'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"Calculate the average marks for first choice and second choice subjects from the 'Student Degree College Data.csv' file.\"\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: Here are the results from executing Python code for your task:\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m{\u001b[0m\n",
      "            \u001b[1;32mINFO:   \u001b[0m\u001b[1;32m\"average_first_choice_marks\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m46.24324324324324\u001b[0m\u001b[1;32m,\u001b[0m\n",
      "            \u001b[1;32mINFO:   \u001b[0m\u001b[1;32m\"average_second_choice_marks\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m739s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m6.\u001b[0m\u001b[2m642s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mThe \u001b[0m\u001b[3;90maverage \u001b[0m\u001b[3;90mmarks \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mfirst \u001b[0m\u001b[3;90mchoice \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90msecond \u001b[0m\u001b[3;90mchoice \u001b[0m\u001b[3;90msubjects \u001b[0m\u001b[3;90mhave \u001b[0m\u001b[3;90mbeen \u001b[0m\u001b[3;90mcalculated. \u001b[0m\u001b[3;90mNow, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mcan \u001b[0m\u001b[3;90mprovide \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfinal \u001b[0m\u001b[3;90manswer \u001b[0m\u001b[3;90mbased \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mthese \u001b[0m\u001b[3;90mresults.\u001b[0m\n",
      "        \n",
      "        \u001b[1;32mFinal Response:\u001b[0m\n",
      "        \u001b[1;37mThe \u001b[0m\u001b[1;37maverage \u001b[0m\u001b[1;37mmarks \u001b[0m\u001b[1;37mfor \u001b[0m\u001b[1;37mfirst \u001b[0m\u001b[1;37mchoice \u001b[0m\u001b[1;37msubjects \u001b[0m\u001b[1;37mare \u001b[0m\u001b[1;37m46.24\u001b[0m\u001b[1;37m, \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37mthe \u001b[0m\u001b[1;37maverage \u001b[0m\u001b[1;37mmarks \u001b[0m\u001b[1;37mfor \u001b[0m\u001b[1;37msecond \u001b[0m\u001b[1;37mchoice \u001b[0m\u001b[1;37msubjects \u001b[0m\u001b[1;37mare \u001b[0m\u001b[1;37m45.76\u001b[0m\u001b[1;37m.\u001b[0m        \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m591s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'CodeAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m13.\u001b[0m\u001b[2m944s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mCodeAgent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.code.agent import CodeAgent\n",
    "\n",
    "code_agent = CodeAgent(llm=LLM, log_traces=True)\n",
    "\n",
    "files_context = {\n",
    "    \"Student Degree College Data.csv\": {\n",
    "        \"path\": \"/home/nomi/Downloads/archive/Student Degree College Data.csv\",\n",
    "        \"mime\": \"text/csv\",\n",
    "        \"size\": 422368,\n",
    "    }\n",
    "}\n",
    "\n",
    "# code_agent.set_persistent_memory(files_context=files_context)\n",
    "# mem_injected = code_agent.memory.resolve_keys(['files_context'])\n",
    "# print(mem_injected)\n",
    "\n",
    "# query = \"Using the uploaded 'Student Degree College Data.csv', get me a report explaining the data in very details.\"\n",
    "# query = \"Use the python tool to generate a line plot of y = x^3 âˆ’ 4x + 1 for x in the range âˆ’10 to 10. Return the image.\"\n",
    "# query = \"Using python, generate an Excel file with two sheets: (1) primes up to 5000 and (2) Fibonacci numbers up to 100,000. Provide the file for download.\"\n",
    "query = \"First, analyze the uploaded 'Student Degree College Data.csv' file. Based on the data, ask yourself a question that must make use of the Python tool.\"\n",
    "resp = code_agent.run(\n",
    "    query=query,\n",
    "    files_context=files_context,\n",
    "    workdir=None,    # take current working directory\n",
    "    post_process=\"none\",   # optional\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "# print(resp.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a8af006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_agent.memory.get_persistent(key=\"files_context\")\n",
    "# code_agent.memory.llm_visible_summary()\n",
    "\n",
    "# code_agent.memory.get_ephemeral(key=\"python_last_result_summary\")\n",
    "\n",
    "# print(resp.traces.steps[4].outputs['memory_update']['python_last_code']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f7fe40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "\n",
      "# Load the CSV file\n",
      "file_path = files[\"Student Degree College Data.csv\"][\"path\"]\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Calculate the average marks for first and second choice subjects\n",
      "average_first_choice = df['first_choice_marks'].mean()\n",
      "average_second_choice = df['second_choice_marks'].mean()\n",
      "\n",
      "result = {\n",
      "    \"average_first_choice_marks\": average_first_choice,\n",
      "    \"average_second_choice_marks\": average_second_choice\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp.traces.steps[4].model_dump()\n",
    "\n",
    "# print()\n",
    "\n",
    "# print(resp.traces.steps[4].outputs['tool_return'])\n",
    "print(resp.traces.steps[4].outputs['memory_update']['python_last_code']['value'])\n",
    "\n",
    "# resp.traces.model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6603dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf83e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: Student Degree College Data.csv\n",
      "Attached_to_current_message: no\n",
      "Summary:\n",
      "This file is about a dataset containing information on students' academic records, including their personal details, high school performance, and choices of subjects and streams. The data includes fields such as form number, name, category, gender, total marks, passing year, and subject preferences. \n",
      "\n",
      "Keywords: student records, academic performance, subject choices, high school data, form number, category\n",
      "\n",
      "\n",
      "Filename: rag_agent.md\n",
      "Attached_to_current_message: no\n",
      "Summary:\n",
      "This file is about the RAGRetrieverAgent module, which provides a modular retrieval system for Retrieval-Augmented Generation. It supports various vector stores, embedders, and LLMs, and includes tools for retrieving, formatting, and trimming context to fit model token limits. The module also offers utilities for file picking and best practices for efficient retrieval and generation.\n",
      "\n",
      "Keywords: RAGRetrieverAgent, Retrieval-Augmented Generation, vector store, embedder, LLM, context trimming\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from neurosurfer.server.db.db import SessionLocal\n",
    "from neurosurfer.server.db.models import NSFile\n",
    "import re\n",
    "\n",
    "ALLOWED_NAME = re.compile(r\"[^a-zA-Z0-9._-]+\")\n",
    "\n",
    "def _collection_for(user_id: int, thread_id: int) -> str:\n",
    "    return _safe_collection_name(f\"ns_vdb_u{user_id}_t{thread_id}\")\n",
    "\n",
    "def _safe_collection_name(s: str) -> str:\n",
    "    s = ALLOWED_NAME.sub(\"_\", s).strip(\"._-\")\n",
    "    return s or \"ns_vdb_default\"\n",
    "\n",
    "\n",
    "user_id = 1\n",
    "thread_id = 21\n",
    "message_id = 1\n",
    "collection_name = _collection_for(user_id, thread_id)\n",
    "\n",
    "db = SessionLocal()\n",
    "files = (\n",
    "    db.query(NSFile)\n",
    "    .filter(\n",
    "        NSFile.user_id == user_id,\n",
    "        NSFile.thread_id == thread_id,\n",
    "        NSFile.collection == collection_name,\n",
    "        NSFile.ingested == True\n",
    "    )\n",
    "    .all()\n",
    ")\n",
    "files_block_lines: List[str] = []\n",
    "for f in files:\n",
    "    flag = \"yes\" if message_id and f.message_id == message_id else \"no\"\n",
    "    files_block_lines.append(\n",
    "        f\"Filename: {f.filename}\\n\"\n",
    "        f\"Attached_to_current_message: {flag}\\n\"\n",
    "        f\"Summary:\\n{f.summary or '(no summary)'}\\n\"\n",
    "    )\n",
    "files_block = \"\\n\\n\".join(files_block_lines)\n",
    "\n",
    "print(files_block)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8246d3c",
   "metadata": {},
   "source": [
    "## SERVER SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "785a9ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mapp.py:__init__\u001b[0m  | Default embedder: intfloat/e5-large-v2 successfully initialized. Replace it by calling app.register_model(model: BaseEmbedder)\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mdb.py:init_db\u001b[0m    | Database initialized successfully in sqlite:////home/nomi/.cache/Neurosurfer/app-storage/app.db\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mapp.py:register_model\u001b[0m | LLM /home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit successfully registered.\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96morchestrator.py:__init__\u001b[0m | Number of documents left: 0\n",
      "Code Agent Cofig:\n",
      "CodeAgentConfig(mode='analysis_only', temperature=0.7, max_new_tokens=2000, allow_input_pruning=True, repair_with_llm=True, retry=RetryPolicy(max_parse_retries=2, max_tool_errors=2, backoff_sec=0.8), skip_special_tokens=False, return_stream_by_default=False, log_internal_thoughts=True, return_internal_thoughts=False, agent_name='CodeAgent', enable_post_processing=False, default_workdir=None, encourage_multistep_planning=True, default_return_raw=False)\n",
      "\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: python_execute\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: code_agent_run\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: rag_retriever\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: final_answer_summarize\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mapp.py:register_model\u001b[0m | RAG service successfully initialized...\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing default collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96morchestrator.py:__init__\u001b[0m | Number of documents left: 0\n",
      "Code Agent Cofig:\n",
      "CodeAgentConfig(mode='analysis_only', temperature=0.7, max_new_tokens=2000, allow_input_pruning=True, repair_with_llm=True, retry=RetryPolicy(max_parse_retries=2, max_tool_errors=2, backoff_sec=0.8), skip_special_tokens=False, return_stream_by_default=False, log_internal_thoughts=True, return_internal_thoughts=False, agent_name='CodeAgent', enable_post_processing=False, default_workdir=None, encourage_multistep_planning=True, default_return_raw=False)\n",
      "\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: python_execute\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: code_agent_run\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: rag_retriever\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-12-05 00:04:50\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: final_answer_summarize\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.server.app import NeurosurferApp\n",
    "from neurosurfer.config import config\n",
    "\n",
    "# Create app instance\n",
    "ns = NeurosurferApp(\n",
    "    app_name=\"Neurosurfer API\",\n",
    "    api_keys=[],\n",
    "    enable_docs=True,\n",
    "    cors_origins=[\"*\"],\n",
    "    host=\"0.0.0.0\",\n",
    "    port=8000,\n",
    "    reload=config.app.reload,\n",
    "    log_level=config.app.logs_level,\n",
    "    workers=config.app.workers\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "ns.register_model(\n",
    "    model=LLM,\n",
    "    family=\"llama\",\n",
    "    provider=\"Unsloth\",\n",
    "    description=\"Proxy to Llama\"\n",
    ")\n",
    "\n",
    "# Initialize RAG\n",
    "ns._init_rag(embedder=ns._embedder, llm=ns._llm)\n",
    "\n",
    "# Initialize agent\n",
    "ns._init_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bba0ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Context:\n",
      "{'agents_index.md': {'path': '/home/nomi/.cache/Neurosurfer/app-storage/ns_users_1/ns_threads_1_1/files/file_f8e989535617405e8ce5d6a12daaa97d.md', 'mime': 'text/markdown', 'size': 5956}}\n",
      "\n",
      "User Prompt for Agent:\n",
      "# User query:\n",
      "Check what this file is about? Give me detailed answer, not just summary.\n",
      "\n",
      "# Uploaded files for this thread (with summaries):\n",
      "Filename: agents_index.md\n",
      "Attached_to_current_message: no\n",
      "Summary:\n",
      "This file is about AI agents that can reason, use tools, and solve complex tasks, with a focus on three specific agents: ReActAgent for general reasoning, SQLAgent for database analytics, and RAGRetrieverAgent for document Q&A. It explains their purposes, use cases, and provides code examples for quick start.\n",
      "\n",
      "Keywords: AI agents, ReActAgent, SQLAgent, RAGRetrieverAgent, tool routing, document Q&A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mMainChatAgent\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'MainChatAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'MainChatAgent'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mThe \u001b[0m\u001b[3;90muser \u001b[0m\u001b[3;90mwants \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mdetailed \u001b[0m\u001b[3;90manalysis \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfile \u001b[0m\u001b[3;90m\"agents_index.md\"\u001b[0m\u001b[3;90m. \u001b[0m\u001b[3;90mSince \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfile's \u001b[0m\u001b[3;90msummary \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90malready \u001b[0m\u001b[3;90mprovided, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mcan \u001b[0m\u001b[3;90muse \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfinal \u001b[0m\u001b[3;90manswer \u001b[0m\u001b[3;90mtool \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mpresent \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mdetailed \u001b[0m\u001b[3;90mexplanation \u001b[0m\u001b[3;90mbased \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90msummary.\u001b[0m\n",
      "        \n",
      "        \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"final_answer_summarize\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"text\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"The \u001b[0m\u001b[3;90mfile \u001b[0m\u001b[3;90m'agents_index.md'\u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90mprovides \u001b[0m\u001b[3;90man \u001b[0m\u001b[3;90min-depth \u001b[0m\u001b[3;90mexploration \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mAI \u001b[0m\u001b[3;90magents, \u001b[0m\u001b[3;90mspecifically \u001b[0m\u001b[3;90mfocusing \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mthree \u001b[0m\u001b[3;90mkey \u001b[0m\u001b[3;90magents: \u001b[0m\u001b[3;90mReActAgent, \u001b[0m\u001b[3;90mSQLAgent, \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mRAGRetrieverAgent. \u001b[0m\u001b[3;90mHere \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mdetailed \u001b[0m\u001b[3;90mbreakdown:\\n\\n1. \u001b[0m\u001b[3;90m**ReActAgent**: \u001b[0m\u001b[3;90mThis \u001b[0m\u001b[3;90magent \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90mdesigned \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mgeneral \u001b[0m\u001b[3;90mreasoning \u001b[0m\u001b[3;90mtasks. \u001b[0m\u001b[3;90mIt \u001b[0m\u001b[3;90mcombines \u001b[0m\u001b[3;90mreasoning \u001b[0m\u001b[3;90msteps \u001b[0m\u001b[3;90mwith \u001b[0m\u001b[3;90maction \u001b[0m\u001b[3;90mexecution, \u001b[0m\u001b[3;90mallowing \u001b[0m\u001b[3;90mit \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90msolve \u001b[0m\u001b[3;90mcomplex \u001b[0m\u001b[3;90mproblems \u001b[0m\u001b[3;90mby \u001b[0m\u001b[3;90mbreaking \u001b[0m\u001b[3;90mthem \u001b[0m\u001b[3;90mdown \u001b[0m\u001b[3;90minto \u001b[0m\u001b[3;90msmaller, \u001b[0m\u001b[3;90mmanageable \u001b[0m\u001b[3;90msteps. \u001b[0m\u001b[3;90mIt \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90museful \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mtasks \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mrequire \u001b[0m\u001b[3;90mlogical \u001b[0m\u001b[3;90mdeduction, \u001b[0m\u001b[3;90mplanning, \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mdecision-making.\\n\\n2. \u001b[0m\u001b[3;90m**SQLAgent**: \u001b[0m\u001b[3;90mThis \u001b[0m\u001b[3;90magent \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90mtailored \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mdatabase \u001b[0m\u001b[3;90manalytics. \u001b[0m\u001b[3;90mIt \u001b[0m\u001b[3;90menables \u001b[0m\u001b[3;90musers \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mquery \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90manalyze \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mstored \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90mrelational \u001b[0m\u001b[3;90mdatabases. \u001b[0m\u001b[3;90mIt \u001b[0m\u001b[3;90msupports \u001b[0m\u001b[3;90mSQL \u001b[0m\u001b[3;90msyntax \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mcan \u001b[0m\u001b[3;90mperform \u001b[0m\u001b[3;90moperations \u001b[0m\u001b[3;90msuch \u001b[0m\u001b[3;90mas \u001b[0m\u001b[3;90mdata \u001b[0m\u001b[3;90mretrieval, \u001b[0m\u001b[3;90maggregation, \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mfiltering, \u001b[0m\u001b[3;90mmaking \u001b[0m\u001b[3;90mit \u001b[0m\u001b[3;90mideal \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mdata-driven \u001b[0m\u001b[3;90mdecision-making.\\n\\n3. \u001b[0m\u001b[3;90m**RAGRetrieverAgent**: \u001b[0m\u001b[3;90mThis \u001b[0m\u001b[3;90magent \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90mfocused \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mdocument \u001b[0m\u001b[3;90mQ&A. \u001b[0m\u001b[3;90mIt \u001b[0m\u001b[3;90mleverages \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mretrieval \u001b[0m\u001b[3;90mmechanism \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mfetch \u001b[0m\u001b[3;90mrelevant \u001b[0m\u001b[3;90minformation \u001b[0m\u001b[3;90mfrom \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mcollection \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mdocuments, \u001b[0m\u001b[3;90mallowing \u001b[0m\u001b[3;90musers \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mask \u001b[0m\u001b[3;90mquestions \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mreceive \u001b[0m\u001b[3;90manswers \u001b[0m\u001b[3;90mbased \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mcontent \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdocuments. \u001b[0m\u001b[3;90mIt \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90mparticularly \u001b[0m\u001b[3;90museful \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mtasks \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mrequire \u001b[0m\u001b[3;90mcontextual \u001b[0m\u001b[3;90munderstanding \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90minformation \u001b[0m\u001b[3;90mretrieval \u001b[0m\u001b[3;90mfrom \u001b[0m\u001b[3;90mlarge \u001b[0m\u001b[3;90mdocument \u001b[0m\u001b[3;90msets.\\n\\nThe \u001b[0m\u001b[3;90mfile \u001b[0m\u001b[3;90malso \u001b[0m\u001b[3;90mdiscusses \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mconcept \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mtool \u001b[0m\u001b[3;90mrouting, \u001b[0m\u001b[3;90mwhich \u001b[0m\u001b[3;90minvolves \u001b[0m\u001b[3;90mselecting \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mappropriate \u001b[0m\u001b[3;90magent \u001b[0m\u001b[3;90mbased \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mspecific \u001b[0m\u001b[3;90mtask \u001b[0m\u001b[3;90mrequirements. \u001b[0m\u001b[3;90mThis \u001b[0m\u001b[3;90mensures \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90meach \u001b[0m\u001b[3;90mtask \u001b[0m\u001b[3;90mis \u001b[0m\u001b[3;90mhandled \u001b[0m\u001b[3;90mby \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mmost \u001b[0m\u001b[3;90msuitable \u001b[0m\u001b[3;90magent, \u001b[0m\u001b[3;90moptimizing \u001b[0m\u001b[3;90mefficiency \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90maccuracy.\\n\\nOverall, \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfile \u001b[0m\u001b[3;90mserves \u001b[0m\u001b[3;90mas \u001b[0m\u001b[3;90ma \u001b[0m\u001b[3;90mcomprehensive \u001b[0m\u001b[3;90mguide \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90munderstanding \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mutilizing \u001b[0m\u001b[3;90mthese \u001b[0m\u001b[3;90mAI \u001b[0m\u001b[3;90magents \u001b[0m\u001b[3;90mfor \u001b[0m\u001b[3;90mvarious \u001b[0m\u001b[3;90mapplications, \u001b[0m\u001b[3;90memphasizing \u001b[0m\u001b[3;90mtheir \u001b[0m\u001b[3;90munique \u001b[0m\u001b[3;90mcapabilities \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90muse \u001b[0m\u001b[3;90mcases.\"\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"memory_keys\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m[\u001b[0m\u001b[1;3;90m]\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mtrue\u001b[0m\n",
      "        \u001b[1;3;90m}\u001b[0m"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ReActConfig' object has no attribute 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     16\u001b[39m has_files_message = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     18\u001b[39m agent_return = ns.run_agent(\n\u001b[32m     19\u001b[39m     user_id=user_id,\n\u001b[32m     20\u001b[39m     thread_id=thread_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     has_files_message=has_files_message,\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43magent_return\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# chunk = chunk.choices[0].delta.content or \"\"\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# print(chunk, end=\"\", flush=True)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/neurosurfer/neurosurfer/agents/react/agent.py:74\u001b[39m, in \u001b[36m_run_loop\u001b[39m\u001b[34m(self, query, temperature, max_new_tokens, stream, specific_instructions)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/neurosurfer/neurosurfer/agents/react/agent.py:376\u001b[39m, in \u001b[36m_decide_tool_call\u001b[39m\u001b[34m(self, response, user_query, history)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err:\n\u001b[32m    374\u001b[39m     \u001b[38;5;66;03m# Missing required or bad types -> try repair\u001b[39;00m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.repair_with_llm:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._repair_action(user_query, history, error_message=\u001b[38;5;28mstr\u001b[39m(err))\n\u001b[32m    377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dropped \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.verbose:\n",
      "\u001b[31mAttributeError\u001b[39m: 'ReActConfig' object has no attribute 'verbose'"
     ]
    }
   ],
   "source": [
    "# test the server\n",
    "# Prepare inputs\n",
    "\n",
    "user_query = \"Check what this file is about? Give me detailed answer, not just summary.\"\n",
    "# Minimal chat history excluding system messages, max 10\n",
    "# num_recent = 10\n",
    "# conversation_messages = args.messages.converstaion\n",
    "# chat_history = conversation_messages[-num_recent:-1]\n",
    "\n",
    "# Model call (stream or non-stream handled by router)\n",
    "# kwargs = {\"temperature\": args.temperature, \"max_new_tokens\": args.max_tokens}\n",
    "\n",
    "user_id = 1\n",
    "thread_id = 1\n",
    "message_id = 1\n",
    "has_files_message = False\n",
    "\n",
    "agent_return = ns.run_agent(\n",
    "    user_id=user_id,\n",
    "    thread_id=thread_id,\n",
    "    message_id=message_id,\n",
    "    user_query=user_query,\n",
    "    has_files_message=has_files_message,\n",
    ")\n",
    "\n",
    "for chunk in agent_return.response:\n",
    "    ...\n",
    "    # chunk = chunk.choices[0].delta.content or \"\"\n",
    "    # print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399835cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools:\n",
      "Tool Name: `code_agent_run`\n",
      "Description: Use the CodeAgent to answer questions that require Python-based analysis or computation over uploaded files (e.g. CSV, text, etc.). The CodeAgent can inspect file structure, compute statistics, create plots, and return summarized results.\n",
      "When to use: Use this tool whenever the query clearly needs precise computation or data manipulation that is hard to do in your head, especially when the user has uploaded structured data (CSV, tables, logs). Examples: counting rows, aggregating metrics, computing correlations, or generating plots from uploaded files. Do NOT use this tool for general Q&A that does not depend on code or files.\n",
      "Tool Inputs:\n",
      "- `query`: string (required) â€” Natural-language description of what the CodeAgent should do. You can mention uploaded files by name and describe the analysis or computation needed.\n",
      "- `files_hint`: array (optional) â€” Optional list of filenames that are especially relevant. If omitted, the runtime may pass all available files_context.\n",
      "Tool Return: string â€” A human-readable answer produced by the CodeAgent. In delegate_final mode: the full user-facing answer. In analysis_only mode: a log of tool execution steps plus a short final snippet from the CodeAgent. Structured extras (e.g. internal tool_calls) are attached in ToolResponse.extras['code_agent_tool_calls'].\n",
      "\n",
      "Tool Name: `rag_retriever`\n",
      "Description: Retrieve relevant context from the user's uploaded files using a vector store and a routing (gate) model. This tool decides whether RAG is needed, which files to use, and how broad the retrieval should be.\n",
      "When to use: Use this tool whenever the user's question clearly depends on, or might depend on, the content of uploaded files (PDFs, CSVs, docs, etc.). For example: 'summarize the attached PDF', 'compare the two reports I uploaded', or 'based on the CSV I sent, what is the average score per subject?'. If the question is purely general and does not rely on the files, you should NOT call this tool.\n",
      "Tool Inputs:\n",
      "- `query`: string (required) â€” The user's natural-language question.\n",
      "Tool Return: string â€” Retrieved textual context wrapped in [RAG CONTEXT] tags, or a short diagnostic message if RAG was not used or no context was found.\n",
      "\n",
      "Tool Name: `final_answer_summarize`\n",
      "Description: Generate the final user-facing answer from the accumulated history of thoughts and tool results. This tool does NOT call further tools; it only writes a clear answer in the requested language and length.\n",
      "When to use: Always use this tool as the final step, after all necessary tools have been run and you have their results in the history. Do NOT use this tool for intermediate reasoning.\n",
      "Tool Inputs: None (The tool doesn't take any inputs)\n",
      "Tool Return: string â€” The final, user-facing answer text, written in the requested language and approximate length.\n"
     ]
    }
   ],
   "source": [
    "# print(ns._agent.toolkit.get_tools_description())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b3d829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_return.traces.model_dump()\n",
    "# print(agent_return.traces.steps[0].inputs['scratchpad'])\n",
    "\n",
    "from neurosurfer.agents.react import ToolCall\n",
    "\n",
    "# tool_calls = [ToolCall(tool='python_execute', inputs={'task': \"Load the 'Student Degree College Data.csv' file and display the first few rows to inspect the structure.\"}, final_answer=False, memory_keys=[], rationale=None, output='Here are the results from executing Python code for your task:\\n\\n|   form_no | name            | category   | minority   | gender   |   hs_total |   hs_pass_year | first_choice_sub   |   first_choice_marks | second_choice_sub   |   second_choice_marks | first_choice_stream   | second_choice_stream   |\\n|----------:|:----------------|:-----------|:-----------|:---------|-----------:|---------------:|:-------------------|---------------------:|:--------------------|----------------------:|:----------------------|:-----------------------|\\n|   1801371 | Susmita Bhowmik | UR         | NO         | F        |        381 |           2018 | Mathematics        |                   80 | Mathematics         |                    80 | Physical Science      | Physical Science       |\\n|   1803096 | Ankur Das       | SC         | NO         | M        |        262 |           2018 | Education          |                   61 | Bengali             |                    58 | Arts                  | Arts                   |\\n|   1801287 | Rashmita Tanti  | UR         | NO         | M        |        278 |           2018 | Human Physiology   |                   74 | Botany              |                    74 | Bio Science           | Bio Science            |\\n|   1803173 | Sanjib Ghosh    | UR         | NO         | M        |        194 |           2018 | nan                |                    0 | nan                 |                     0 | Arts                  | Arts                   |\\n|   1801077 | Swarupa Pal     | UR         | NO         | F        |        320 |           2015 | nan                |                    0 | nan                 |                     0 | Bio Science           | Bio Science            |'), ToolCall(tool='python_execute', inputs={'task': \"Find the grades of Paheli Bhaumik from the 'Student Degree College Data.csv' file.\"}, final_answer=False, memory_keys=['python_last_result_summary'], rationale=None, output='Here are the results from executing Python code for your task:\\n\\n[\\n  93,\\n  93\\n]')]\n",
    "# tool_calls[1].__dict__\n",
    "    \n",
    "# print(agent_return.tool_calls[0].__dict__['output'])\n",
    "\n",
    "import json\n",
    "with open('agent_return.json', 'w') as f:\n",
    "    json.dump(agent_return.traces.model_dump(), f)\n",
    "# agent_return.traces.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3778857",
   "metadata": {},
   "source": [
    "## ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14e4e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 09:46:19\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: calculator\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 09:46:19\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: city_info\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "# CityInfoTool\n",
    "class CityInfoTool(BaseTool):\n",
    "    \"\"\"\n",
    "    Simple read-only city info DB so the ReAct agent has something non-trivial to reason about.\n",
    "    \"\"\"\n",
    "    spec = ToolSpec(\n",
    "        name=\"city_info\",\n",
    "        description=\"Look up basic information about a city (population and timezone).\",\n",
    "        when_to_use=\"Use this tool when you need factual info about a city such as population or timezone.\",\n",
    "        inputs=[\n",
    "            ToolParam(name=\"city\", type=\"string\", description=\"City name, e.g. 'Paris', 'Tokyo'.\", required=True),\n",
    "        ],\n",
    "        returns=ToolReturn(type=\"string\", description=\"A short JSON-formatted string with fields like population_millions and timezone.\"),\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # tiny in-memory DB\n",
    "        self._db = {\n",
    "            \"paris\": {\n",
    "                \"population_millions\": 2.1,\n",
    "                \"timezone\": \"Europe/Paris\",\n",
    "            },\n",
    "            \"tokyo\": {\n",
    "                \"population_millions\": 13.9,\n",
    "                \"timezone\": \"Asia/Tokyo\",\n",
    "            },\n",
    "            \"dubai\": {\n",
    "                \"population_millions\": 3.6,\n",
    "                \"timezone\": \"Asia/Dubai\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def __call__(self, city: str) -> ToolResponse:\n",
    "        city_key = city.strip().lower()\n",
    "        info = self._db.get(city_key)\n",
    "        if not info:\n",
    "            result = f'{{\"city\": \"{city}\", \"error\": \"unknown city\"}}'\n",
    "        else:\n",
    "            result = json.dumps({\"city\": city_key, **info})\n",
    "\n",
    "        return ToolResponse(\n",
    "            results=result,\n",
    "            final_answer=False,  # ReAct can decide what to do next\n",
    "            extras={},          # you can stash anything here into memory if you want\n",
    "        )\n",
    "\n",
    "\n",
    "calculator_tool = CalculatorTool()\n",
    "city_info_tool = CityInfoTool()\n",
    "\n",
    "toolkit = Toolkit(tools=[calculator_tool, city_info_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d5c099e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mreact_agent_main\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mlook \u001b[0m\u001b[3;90mup \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mParis \u001b[0m\u001b[3;90mand \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mfirst \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mcompute \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdifference.\u001b[0m\n",
      "        \n",
      "        \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"city_info\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"city\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Paris\"\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "        \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: city_info\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: city_info, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'city'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Paris'\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m\"city\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"paris\"\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"population_millions\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m2.1\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"timezone\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"Europe/Paris\"\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m001s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m729s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mneed \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mlook \u001b[0m\u001b[3;90mup \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mnext \u001b[0m\u001b[3;90mto \u001b[0m\u001b[3;90mcompute \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdifference.\u001b[0m\n",
      "        \n",
      "        \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"city_info\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"city\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"Tokyo\"\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "        \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: city_info\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: city_info, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'city'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'Tokyo'\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m\"city\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"tokyo\"\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"population_millions\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m13.9\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m\"timezone\"\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m\"Asia/Tokyo\"\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m001s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m716s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mNow \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mhave \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulations \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mboth \u001b[0m\u001b[3;90mcities, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mcan \u001b[0m\u001b[3;90mcompute \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mdifference \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90mtheir \u001b[0m\u001b[3;90mpopulations.\u001b[0m\n",
      "        \n",
      "        \u001b[3;90mAction: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"tool\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"calculator\"\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"inputs\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m{\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"num1\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m13.9\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"num2\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[1;3;90m2.1\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m   \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"operation\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90m\"subtract\"\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[1;3;90m}\u001b[0m\u001b[3;90m,\u001b[0m\n",
      "        \u001b[3;90m \u001b[0m\u001b[3;90m \u001b[0m\u001b[3;90m\"final_answer\"\u001b[0m\u001b[3;90m: \u001b[0m\u001b[3;90mfalse\u001b[0m\n",
      "        \u001b[1;3;90m}\u001b[0m        \n",
      "        \u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Selected: calculator\u001b[0m\n",
      "\u001b[2m         â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Executing Tool: calculator, Attempt: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ“¤\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'num1'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m13.9\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'num2'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m2.1\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'operation'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'subtract'\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "            \u001b[1;32mINFO: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mðŸ”§\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Tool Result: \u001b[0m\u001b[1;32m11.8\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m         â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m7\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m001s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "        \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m294s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\n",
      "        \u001b[3;90mThought: \u001b[0m\u001b[3;90mNow \u001b[0m\u001b[3;90mthat \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mhave \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mpopulation \u001b[0m\u001b[3;90mdifference, \u001b[0m\u001b[3;90mI \u001b[0m\u001b[3;90mcan \u001b[0m\u001b[3;90mprovide \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mfinal \u001b[0m\u001b[3;90mrecommendation \u001b[0m\u001b[3;90mbased \u001b[0m\u001b[3;90mon \u001b[0m\u001b[3;90mthe \u001b[0m\u001b[3;90mnumber \u001b[0m\u001b[3;90mof \u001b[0m\u001b[3;90mmillions \u001b[0m\u001b[3;90mmore \u001b[0m\u001b[3;90mpeople \u001b[0m\u001b[3;90mliving \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90mTokyo \u001b[0m\u001b[3;90mthan \u001b[0m\u001b[3;90min \u001b[0m\u001b[3;90mParis.\u001b[0m\n",
      "        \n",
      "        \u001b[1;32mFinal Response:\u001b[0m\n",
      "        \u001b[1;37mBased \u001b[0m\u001b[1;37mon \u001b[0m\u001b[1;37mthe \u001b[0m\u001b[1;37mpopulation \u001b[0m\u001b[1;37mdata, \u001b[0m\u001b[1;37mTokyo \u001b[0m\u001b[1;37mhas \u001b[0m\u001b[1;37mapproximately \u001b[0m\u001b[1;37m11.8\u001b[0m\u001b[1;37m \u001b[0m\u001b[1;37mmillion \u001b[0m\u001b[1;37mmore \u001b[0m\u001b[1;37mpeople \u001b[0m\u001b[1;37mthan \u001b[0m\u001b[1;37mParis. \u001b[0m\u001b[1;37mGiven \u001b[0m\u001b[1;37mthis \u001b[0m\u001b[1;37msignificant \u001b[0m\u001b[1;37mdifference \u001b[0m\u001b[1;37min \u001b[0m\u001b[1;37mpopulation, \u001b[0m\u001b[1;37mif \u001b[0m\u001b[1;37myou're \u001b[0m\u001b[1;37mlooking \u001b[0m\u001b[1;37mfor \u001b[0m\u001b[1;37ma \u001b[0m\u001b[1;37mvibrant, \u001b[0m\u001b[1;37mbustling \u001b[0m\u001b[1;37mcity \u001b[0m\u001b[1;37mexperience \u001b[0m\u001b[1;37mwith \u001b[0m\u001b[1;37ma \u001b[0m\u001b[1;37mlarge \u001b[0m\u001b[1;37mpopulation, \u001b[0m\u001b[1;37mTokyo \u001b[0m\u001b[1;37mwould \u001b[0m\u001b[1;37mbe \u001b[0m\u001b[1;37man \u001b[0m\u001b[1;37mexcellent \u001b[0m\u001b[1;37mchoice. \u001b[0m\u001b[1;37mHowever, \u001b[0m\u001b[1;37mif \u001b[0m\u001b[1;37myou \u001b[0m\u001b[1;37mprefer \u001b[0m\u001b[1;37ma \u001b[0m\u001b[1;37mmore \u001b[0m\u001b[1;37mintimate \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37mculturally \u001b[0m\u001b[1;37mrich \u001b[0m\u001b[1;37matmosphere, \u001b[0m\u001b[1;37mParis \u001b[0m\u001b[1;37mwould \u001b[0m\u001b[1;37mbe \u001b[0m\u001b[1;37ma \u001b[0m\u001b[1;37mwonderful \u001b[0m\u001b[1;37moption. \u001b[0m\u001b[1;37mUltimately, \u001b[0m\u001b[1;37mthe \u001b[0m\u001b[1;37mchoice \u001b[0m\u001b[1;37mdepends \u001b[0m\u001b[1;37mon \u001b[0m\u001b[1;37myour \u001b[0m\u001b[1;37mpersonal \u001b[0m\u001b[1;37mpreferences \u001b[0m\u001b[1;37mfor \u001b[0m\u001b[1;37mcity \u001b[0m\u001b[1;37msize \u001b[0m\u001b[1;37mand \u001b[0m\u001b[1;37mambiance. \u001b[0m\u001b[1;37mEnjoy \u001b[0m\u001b[1;37myour \u001b[0m\u001b[1;37mdecision!\u001b[0m        \n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m8\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.loop.reason_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m672s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.react_agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent_main'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'react_agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m9.\u001b[0m\u001b[2m412s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mreact_agent_main\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.react.agent import ReActAgent, ReActConfig\n",
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "\n",
    "\n",
    "react_config = ReActConfig(\n",
    "    skip_special_tokens=True,\n",
    "    max_new_tokens=4096,\n",
    "    temperature=0.7,\n",
    "    log_internal_thoughts=True,\n",
    ")\n",
    "\n",
    "react_agent = ReActAgent(\n",
    "    id=\"react_agent_main\",\n",
    "    llm=LLM,\n",
    "    toolkit=toolkit,\n",
    "    config=react_config,\n",
    "    log_traces=True,\n",
    ")\n",
    "\n",
    "query = (\n",
    "    \"I'm deciding between visiting Paris or Tokyo. \"\n",
    "    \"Use your tools to: \"\n",
    "    \"1) look up the population of each city in millions, \"\n",
    "    \"2) compute how many millions more people live in Tokyo than in Paris, \"\n",
    "    \"3) then give me a final recommendation in natural language using that number.\"\n",
    ")\n",
    "\n",
    "res = react_agent.run(query=query, stream=False)\n",
    "\n",
    "\n",
    "# # For streaming Response\n",
    "# res = react_agent.run(query=query, stream=True)\n",
    "# for chunk in res.response: \n",
    "#     # print(chunk, end=\"\", flush=True)\n",
    "#     pass\n",
    "\n",
    "# traces\n",
    "# trace_dict = res.traces.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b1381",
   "metadata": {},
   "source": [
    "## RAG wiring so the agent â€œunderstandsâ€ the Neurosurf codebase\n",
    "\n",
    "Youâ€™ll ingest the repo once, then run a retriever to answer code questions. The Planner can call the retriever first to form a precise implementation plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5bf38-1a5b-4ad1-be5f-b5073dbeaaf0",
   "metadata": {},
   "source": [
    "### FileReader and Chunker Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a35db287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scripts/index_repo_for_rag.py\n",
    "# from pathlib import Path\n",
    "# from neurosurfer.vectorstores.chroma import ChromaVectorStore\n",
    "# from neurosurfer.models.embedders.sentence_transformer import SentenceTransformerEmbedder\n",
    "# from neurosurfer.agents.rag.chunker import Chunker\n",
    "# from neurosurfer.agents.rag.filereader import FileReader\n",
    "# from neurosurfer.agents.rag import RAGAgent, RAGAgentConfig, RAGIngestorConfig\n",
    "\n",
    "# chunker = Chunker()\n",
    "# file_reader = FileReader()\n",
    "\n",
    "# embedder = SentenceTransformerEmbedder(\"intfloat/e5-small-v2\")\n",
    "\n",
    "# rag_agent = RAGAgent(\n",
    "#     llm=LLM,\n",
    "#     embedder=embedder,\n",
    "#     file_reader=file_reader,\n",
    "#     chunker=chunker,\n",
    "#     config=RAGAgentConfig(\n",
    "#         top_k=5,\n",
    "#         fixed_max_new_tokens=1024,\n",
    "#         clear_collection_on_init=True\n",
    "#     ),\n",
    "#     ingestor_config=RAGIngestorConfig(\n",
    "#         batch_size=64,\n",
    "#         max_workers=4,\n",
    "#         deduplicate=True,\n",
    "#         normalize_embeddings=True,\n",
    "#         default_metadata=None,\n",
    "#         tmp_dir=\"./rag-storage\",\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# dir_path = \"../neurosurfer\"\n",
    "# summary = rag_agent.ingest(sources=dir_path)\n",
    "\n",
    "# summary\n",
    "\n",
    "# retrival_results = rag_agent.retrieve(user_query=\"Explain how graph agent is initialized\", top_k=10)\n",
    "\n",
    "# print(\"max_new_tokens\", retrival_results.max_new_tokens)\n",
    "# print()\n",
    "# print(retrival_results.context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d61982-ac42-46b7-8a6b-bc3ed2248907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # scripts/index_repo_for_rag.py\n",
    "# from pathlib import Path\n",
    "# from neurosurfer.rag.ingestor import RAGIngestor\n",
    "# from neurosurfer.rag.chunker import Chunker\n",
    "# from neurosurfer.rag.filereader import FileReader\n",
    "# from neurosurfer.vectorstores.chroma import ChromaVectorStore\n",
    "# from neurosurfer.models.embedders.sentence_transformer import SentenceTransformerEmbedder\n",
    "\n",
    "# embedder = SentenceTransformerEmbedder(\"intfloat/e5-small-v2\")\n",
    "# vs = ChromaVectorStore(collection_name=\"neurosurf-repo\")\n",
    "# ing = RAGIngestor(\n",
    "#     embedder=embedder,\n",
    "#     vector_store=vs, \n",
    "#     chunker=Chunker(), \n",
    "#     file_reader=FileReader(),\n",
    "#     default_metadata={\"collection\": \"neurosurf\"}\n",
    "# )\n",
    "\n",
    "# root_dir = Path(os.getcwd()).parent.joinpath(\"neurosurfer\")\n",
    "# ing.add_directory(root_dir)  # the repo root\n",
    "# print(ing.build())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4c8c2",
   "metadata": {},
   "source": [
    "## Graph AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec7eb2",
   "metadata": {},
   "source": [
    "### YAML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e3d42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key:  f443633b...\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-18 14:44:24\u001b[0m | \u001b[96magent.py:__init__\u001b[0m | No vectorstore provided to RAGAgent, using default ChromaVectorStore. Initializing collection `neurosurfer-rag-agent`\n",
      "[Init] ChromaVectorStore initialized with collection: neurosurfer-rag-agent\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:35\u001b[0m | \u001b[96mSentenceTransformer.py:__init__\u001b[0m | Use pytorch device_name: cuda:0\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:35\u001b[0m | \u001b[96msentence_transformer.py:__init__\u001b[0m | SentenceTransformer embedding model initialized.\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:35\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:44:40\u001b[0m | \u001b[96m_common.py:_log_backoff\u001b[0m | Backing off send_request(...) for 0.8s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))\n"
     ]
    }
   ],
   "source": [
    "# test web search tool\n",
    "from neurosurfer.tools.websearch import WebSearchTool, WebSearchConfig\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "\n",
    "api_key = os.getenv(\"SERPAPI_KEY\", \"API Key not found...\")\n",
    "print(\"API Key: \", f\"{api_key[:8]}...\")\n",
    "\n",
    "web_search_tool = WebSearchTool(\n",
    "    config=WebSearchConfig(\n",
    "        engine=\"serpapi\",\n",
    "        engine_kwargs={\"api_key\": api_key},\n",
    "        max_results=3,\n",
    "        enable_crawl=True,\n",
    "        max_crawl_results=2,\n",
    "        content_words_limit=2000,\n",
    "        content_limit_strategy=\"distributive\",\n",
    "        summarize=False,\n",
    "        top_k=10,\n",
    "    ),\n",
    "    llm=LLM,\n",
    ")\n",
    "\n",
    "# searches = web_search_tool(query=\"Importance of sleep in health.\")\n",
    "# print(searches)\n",
    "\n",
    "toolkit = Toolkit(tools=[web_search_tool])\n",
    "# print(toolkit.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346487b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Importance of sleep in health.',\n",
       " 'summary': \"Top 3 results out of ~988,000,000 results for: 'Importance of sleep in health.'\\n1. How Sleep Works - Why Is Sleep Important? - NHLBI - NIH â€” https://www.nhlbi.nih.gov/health/sleep/why-sleep-important\\n2. Better sleep: Why it's important for your health and tips to ... â€” https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03\\n3. Sleep is essential to health - Journal of Clinical Sleep Medicine â€” https://jcsm.aasm.org/doi/10.5664/jcsm.9476\",\n",
       " 'provider': 'serpapi',\n",
       " 'elapsed_ms': 3004,\n",
       " 'rag_content': 'Source: 355e311e80b4be26:cc35f490\\nlth Sleep has become a precious commodity â€“ we love it and need it, but rarely get enough of it. Busy schedules, kids, anxiety and technology can all get in the way of a good night sleep. Getting enough sleep can play an important role in your weight, emotional wellbeing, blood pressure, diabetes, mental and physical performance, and more. Remember that adults aren\\'t the only ones who need good sleep. It\\'s also critical that children get even more sleep than adults. Why is sleep important for health? The three pillars of health are nutrition, physical exercise, and sleep. All three of these are connected. For example, if you don\\'t sleep well, you may not eat well. People get food cravings when they haven\\'t slept well, and they often crave a food with lots of carbohydrates (carbs) like a cookie. And when you are tired, the last thing you want to do is go to the gym. People who are fully functioning pay attention to all three. They must all be working together for better health. Here are\\n\\n---\\n\\nSource: 1569daa75eb865f1:cc35f490\\nBack To How Sleep Works Why Is Sleep Important? 0 How Sleep Works MENU Home Health Topics < Back To How Sleep Works Why Is Sleep Important? How Sleep Works Your Sleep/Wake Cycle Sleep Phases and Stages Why Is Sleep Important? How Much Sleep Is Enough? MORE INFORMATION Fact Sheets and Handouts Research How Sleep Works How Sleep Works Why Is Sleep Important? Language switcher English EspaÃ±ol IN THIS ARTICLE View More View Less Sleep plays a vital role in good health and well-being throughout your life. The way you feel while you are awake depends in part on what happens while you are sleeping. During sleep, your body is working to support healthy brain function and maintain your physical health. In children and teens, sleep also helps support growth and development. Getting inadequate sleep over time can raise your risk for chronic (long-term) health problems. It can also affect how well you think, react, work, learn, and get along with others. Learn how sleep affects your heart and circ\\n\\n---\\n\\nSource: 4bd421ad2e29abac:cc35f490\\nBetter sleep: Why itâ€™s important for your health and tips to sleep soundly | Cultivating Health | UC Davis Health search Search all UC Davis health Main Menu add menu Main Menu close Main Menu Main Menu remove UC Davis Health Home Patients & Visitors Services & Specialties Health Care Professionals Schools & Programs Research News About UC Davis Health Giving Careers search Search Ã— Search all UC Davis Health Search All UC Davis Health Search Search enhanced by Google close Search all UC Davis Health Search All UC Davis Health Search Search enhanced by Google Skip to main content Cultivating Health Show menu menu Menu Cancer Care Children\\'s Health Fitness Heart Health Mental Health All Articles notifications Subscribe Mental Health MARCH 15, 2023 Better sleep: Why itâ€™s important for your health and tips to sleep soundly By Cultivating Health Sleep has become a precious commodity â€“ we love it and need it, but rarely get enough of it. Busy schedules, kids, anxiety and technology can all\\n\\n---\\n\\nSource: 91de3a34d7fa00e2:cc35f490\\nant to do is go to the gym. People who are fully functioning pay attention to all three. They must all be working together for better health. Here are some other health benefits of sleep: promotes growth helps heart health supports weight management helps combat germs and keep your immune system strong reduces risk of injury increases attention span boosts memory and learning Find out if melatonin is safe, its side effects and if it helps you sleep How much sleep should adults get? Studies show that adults should get seven to eight hours a night for good health. Some people insist that they can get away with four or five hours of sleep. While these so-called \"short sleepers\" do exist, they are a very small percentage of the population. The rest of the self-identified \"short sleepers\" are mostly staying alert by drinking coffee or other caffeinated drinks. Not getting enough sleep can raise the risk of health consequences. However, getting enough sleep isn\\'t just about the number of hou\\n\\n---\\n\\nSource: e388173c38819c5e:cc35f490\\nrm) health problems. It can also affect how well you think, react, work, learn, and get along with others. Learn how sleep affects your heart and circulatory system, metabolism , respiratory system, and immune system and how much sleep is enough. BROCHURE This brochure describes the differences between the types of sleep needed to feel awake and to be healthy and offers tips for getting a good nightâ€™s sleep. View the brochure Heart and circulatory system When you fall asleep and enter non-REM sleep , your blood pressure and heart rate fall. During sleep, your parasympathetic system controls your body, and your heart does not work as hard as it does when you are awake. During REM sleep and when waking, your sympathetic system is activated, increasing your heart rate and blood pressure to the usual levels when you are awake and relaxed. A sharp increase in blood pressure and heart rate upon waking has been linked to angina, or chest pain, and heart attacks . People who do not sleep enoug\\n\\n---\\n\\nSource: 527693a794d92a2b:cc35f490\\nffeinated drinks. Not getting enough sleep can raise the risk of health consequences. However, getting enough sleep isn\\'t just about the number of hours you\\'re asleep. It\\'s also about the quality of sleep and that you stay on a regular schedule so that you feel rested when you wake up. Learn about anxiety symptoms and when to know if you need help How much sleep should children get? According to the U.S. Department of Health and Human Services , these are the recommended number of hours of sleep based on a child\\'s age: Newborns: 14-17 hours a day Babies: 12-16 hours a day (including naps) Toddlers: 11-14 hours a day (including naps) Preschoolers: 10-13 hours a day (including naps) School-aged children: 9-12 hours each night Teenagers: 8-10 hours each night What are some health risks of not getting enough sleep? Not enough sleep or routinely getting broken sleep is linked with seven of the 15 leading causes of death in the U.S. These include: Heart disease Cancerous tumors Diseases rela\\n\\n---\\n\\nSource: f5deaa2fd34dff22:cc35f490\\nuctive pulmonary disease (COPD) . Asthma symptoms are usually worse during early morning sleep. Likewise, breathing problems in people who have lung diseases such as COPD can become worse during sleep. Sleep also affects different parts of your immune system, which become more active at different times of day. For example, when you sleep, a particular type of immune cell works harder. That is why people who do not sleep enough may be more likely to get colds and other infections. FACT SHEET Sleep Fact Sheet Learn some sleep terms and find out about treatments that can help with sleep apnea. View the fact sheet Problems with thinking and memory Sleep helps with learning and the formation of long-term memories. Not getting enough sleep or enough high-quality sleep can lead to problems focusing on tasks and thinking clearly. Read our Sleep Deprivation and Deficiency page for more information on how lack of sleep affects performance of daily activities, including driving and schoolwork. Bo\\n\\n---\\n\\nSource: baa9ae9e26cf11b5:cc35f490\\nHow Sleep Works - Why Is Sleep Important? | NHLBI, NIH Skip to main content An official website of the United States government Hereâ€™s how you know Hereâ€™s how you know Official websites use .gov A .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPS A lock ( A locked padlock ) or https:// means youâ€™ve safely connected to the .gov website. Share sensitive information only on official, secure websites. Search Query: Health Topics All Health Topics A-Z Asthma Heart-Healthy Living High Blood Pressure Sickle Cell Disease Sleep Apnea Calculate Your BMI Health Education Education Programs and Initiatives The Heart TruthÂ® Learn More Breathe BetterÂ® Blood Diseases & Disorders Education Program Publications and Resources Research Clinical Trials and Studies Research Focus Areas Blood Disorders and Blood Safety Sleep Science and Sleep Disorders Lung Diseases Health Disparities Heart and Vascular Diseases Precision Medicine Activities Obe\\n\\n---\\n\\nSource: dbd50916457b69e1:cc35f490\\n, laptop, etc.) in an area of the house other than the bedrooms. Sleep in a dark room because light stimulates our brains. Use an alarm clock rather than your smartphone or tablet as a wakeup device. Keep room temperatures on the cooler side â€“ ideally low to mid-60s. Aim for a consistent bedtime routine and sleep schedule to help your body stay on a regular track. Find a good time for you to go to sleep every night and wake up at the same time every morning. It\\'s also important to keep that same schedule even on the weekends. Find out about social media\\'s impact on our mental health and tips to use it safely What happens to your brain when you don\\'t get enough sleep? Sleep deprivation affects your ability to remember, concentrate, and make good decisions. Your reaction time is also reduced. A sleep-deprived driver has the same poor response time as someone who is legally drunk. Not getting enough sleep makes us more emotionally unstable. Lack of sleep can cause you to have very strong\\n\\n---\\n\\nSource: 10685d511e3aaad8:cc35f490\\nse time as someone who is legally drunk. Not getting enough sleep makes us more emotionally unstable. Lack of sleep can cause you to have very strong emotions, such as extreme sadness or anger. Does sleep play a role in Alzheimer\\'s disease? One thing that connects almost all mental and nervous system disorders is some level of wake and sleep disruption. Health experts know that treating sleep disruptions can help stabilize neurologic disorders. But left untreated, sleep disruption may contribute to the progression of disease. One example is Alzheimer\\'s disease . We know that sleep is disrupted in the early stages of the disease. If we could address that early on, perhaps the progression of the disease could be delayed. Patrick M. Fuller , a neuroscientist who studies how the brain regulates sleeping and waking, contributed and reviewed this article. Fuller is a professor in UC Davis Health\\'s Department of Neurological Surgery and vice chair for research. Explore related topics Mental H',\n",
       " 'llm_summary': 'Sleep is crucial for overall health and well-being, playing a vital role in physical health, mental function, emotional stability, and immune system support (source: https://www.nhlbi.nih.gov/health/sleep/why-sleep-important). \\n\\n**Key Points:**\\n- Sleep supports brain function, including memory consolidation and learning (source: https://jcsm.aasm.org/doi/10.5664/jcsm.9476).\\n- It helps regulate bodily functions such as heart health, blood pressure, and metabolism (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- Chronic sleep deprivation is linked to an increased risk of chronic diseases, including heart disease, diabetes, and weakened immune function (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- Adults are recommended to get 7â€“8 hours of sleep per night, while children and teens require more (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n\\n**Caveats:**\\n- The quality of sleep is as important as the quantity. Poor sleep quality can have similar negative effects as insufficient sleep (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- Some individuals, known as \"short sleepers,\" may function with less sleep, but this is rare and not recommended for most people (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).\\n- There is some debate about the exact impact of sleep on conditions like Alzheimer\\'s disease, with some studies suggesting a potential link between sleep disruption and disease progression (source: https://health.ucdavis.edu/blog/cultivating-health/better-sleep-why-its-important-for-your-health-and-tips-to-sleep-soundly/2023/03).'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches.results\n",
    "# # print(searches.results[\"rag_content\"])\n",
    "# print(searches.results[\"llm_summary\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3dbe3",
   "metadata": {},
   "source": [
    "**GrpahAgent from YML file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf1ccb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-18 14:58:05\u001b[0m | \u001b[96mutils.py:normalize_and_validate_graph_inputs\u001b[0m | Ignoring extra inputs not declared in graph spec: audience, tone\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:58:05\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: web_search\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m249s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mresearch\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: web_search\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models'\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m079s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-18 14:58:09\u001b[0m | \u001b[96mingestor.py:ingest\u001b[0m | Some sources were skipped as unsupported: [None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.04it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 53.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:58:09\u001b[0m | \u001b[96magent.py:retrieve\u001b[0m | [RAGRetriever] Retrieved 10 chunks\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'web_search'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'query'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models'\u001b[0m\u001b[1;32m, 'summary\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m933s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'research'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m014s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mresearch\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m790s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;92mTrue\u001b[0m\n",
      "\u001b[1;4;31mError executing node outline: CUDA out of memory. Tried to allocate \u001b[0m\u001b[1;4;31m158.00\u001b[0m\u001b[1;4;31m MiB. \u001b[0m\n",
      "\u001b[1;4;31mGPU \u001b[0m\u001b[1;4;31m0\u001b[0m\u001b[1;4;31m has a total capacity of \u001b[0m\u001b[1;4;31m11.61\u001b[0m\u001b[1;4;31m GiB of which \u001b[0m\u001b[1;4;31m120.00\u001b[0m\u001b[1;4;31m MiB is free. Including \u001b[0m\n",
      "\u001b[1;4;31mnon-PyTorch memory, this process has \u001b[0m\u001b[1;4;31m10.70\u001b[0m\u001b[1;4;31m GiB memory in use. Of the allocated \u001b[0m\n",
      "\u001b[1;4;31mmemory \u001b[0m\u001b[1;4;31m9.91\u001b[0m\u001b[1;4;31m GiB is allocated by PyTorch, and \u001b[0m\u001b[1;4;31m484.27\u001b[0m\u001b[1;4;31m MiB is reserved by PyTorch \u001b[0m\n",
      "\u001b[1;4;31mbut unallocated. If reserved but unallocated memory is large try setting \u001b[0m\n",
      "\u001b[1;4;31mPYTORCH_CUDA_ALLOC_CONF\u001b[0m\u001b[1;4;31m=\u001b[0m\u001b[1;4;31mexpandable_segments\u001b[0m\u001b[1;4;31m:\u001b[0m\u001b[1;3;4;31mTrue\u001b[0m\u001b[1;4;31m to avoid fragmentation.  See \u001b[0m\n",
      "\u001b[1;4;31mdocumentation for Memory Management  \u001b[0m\n",
      "\u001b[1;4;31m(\u001b[0m\u001b[1;4;31mhttps://pytorch.org/docs/stable/notes/cuda.html#environment-variables\u001b[0m\u001b[1;4;31m)\u001b[0m\n",
      "\u001b[1;4;33mReturning partial results from executed nodes\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-18 14:58:10\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node research output to exports/research_20251118_145807.json\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "from neurosurfer.agents.graph import GraphAgent, ManagerConfig\n",
    "\n",
    "graph_agent = GraphAgent(\n",
    "    llm=LLM,\n",
    "    graph_yaml=\"blog_workflow.yml\",\n",
    "    toolkit=toolkit,\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=4096,\n",
    "    ),\n",
    "    manager_llm=LLM,\n",
    "    log_traces=True\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "graph_inputs = {\n",
    "    \"topic_title\": \"The Missing Middle Layer: Why LLM Systems Need Tool Routers, Not Bigger Models\",\n",
    "    \"query\": \"Compose a 2000-2500 word blog on why tool-routing layers matter more than scaling LLM size, covering practical design patterns, examples, and tradeoffs.\",\n",
    "    \"audience\": \"Intermediate ML engineers\",\n",
    "    \"tone\": \"Practical and slightly opinionated\",\n",
    "}\n",
    "\n",
    "results = graph_agent.run(inputs=graph_inputs)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1205b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"graph_agent_results.json\", \"w\") as writer:\n",
    "#     json.dump(results.model_dump(), writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59defcd4",
   "metadata": {},
   "source": [
    "## Docs Gen Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6cb6796c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:42:37\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: directory_scan\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:42:37\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: code_symbol_index\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:42:37\u001b[0m | \u001b[96mdir_scanning.py:__call__\u001b[0m | DirectoryScanTool scanning project_root=/home/nomi/workspace/neurosurfer/neurosurfer docs_root=None max_depth=None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_root': '/home/nomi/workspace/neurosurfer/neurosurfer',\n",
       " 'docs_root': None,\n",
       " 'python_files': [{'path': 'version.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/version.py',\n",
       "   'module': 'neurosurfer.version',\n",
       "   'package': 'neurosurfer'},\n",
       "  {'path': 'config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/config.py',\n",
       "   'module': 'neurosurfer.config',\n",
       "   'package': 'neurosurfer'},\n",
       "  {'path': 'diagnostics.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/diagnostics.py',\n",
       "   'module': 'neurosurfer.diagnostics',\n",
       "   'package': 'neurosurfer'},\n",
       "  {'path': 'logger.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/logger.py',\n",
       "   'module': 'neurosurfer.logger',\n",
       "   'package': 'neurosurfer'},\n",
       "  {'path': '__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/__init__.py',\n",
       "   'module': 'neurosurfer.__init__',\n",
       "   'package': 'neurosurfer'},\n",
       "  {'path': 'db/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/db/__init__.py',\n",
       "   'module': 'neurosurfer.db.__init__',\n",
       "   'package': 'neurosurfer.db'},\n",
       "  {'path': 'db/sql_database.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/db/sql_database.py',\n",
       "   'module': 'neurosurfer.db.sql_database',\n",
       "   'package': 'neurosurfer.db'},\n",
       "  {'path': 'db/sql_schema_store.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/db/sql_schema_store.py',\n",
       "   'module': 'neurosurfer.db.sql_schema_store',\n",
       "   'package': 'neurosurfer.db'},\n",
       "  {'path': 'examples/quickstart_app.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/examples/quickstart_app.py',\n",
       "   'module': 'neurosurfer.examples.quickstart_app',\n",
       "   'package': 'neurosurfer.examples'},\n",
       "  {'path': 'vectorstores/in_memory_store.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/in_memory_store.py',\n",
       "   'module': 'neurosurfer.vectorstores.in_memory_store',\n",
       "   'package': 'neurosurfer.vectorstores'},\n",
       "  {'path': 'vectorstores/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/base.py',\n",
       "   'module': 'neurosurfer.vectorstores.base',\n",
       "   'package': 'neurosurfer.vectorstores'},\n",
       "  {'path': 'vectorstores/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/__init__.py',\n",
       "   'module': 'neurosurfer.vectorstores.__init__',\n",
       "   'package': 'neurosurfer.vectorstores'},\n",
       "  {'path': 'vectorstores/chroma.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/chroma.py',\n",
       "   'module': 'neurosurfer.vectorstores.chroma',\n",
       "   'package': 'neurosurfer.vectorstores'},\n",
       "  {'path': 'utils/helper.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/helper.py',\n",
       "   'module': 'neurosurfer.utils.helper',\n",
       "   'package': 'neurosurfer.utils'},\n",
       "  {'path': 'utils/response_wrappers.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/response_wrappers.py',\n",
       "   'module': 'neurosurfer.utils.response_wrappers',\n",
       "   'package': 'neurosurfer.utils'},\n",
       "  {'path': 'utils/prompts.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/prompts.py',\n",
       "   'module': 'neurosurfer.utils.prompts',\n",
       "   'package': 'neurosurfer.utils'},\n",
       "  {'path': 'utils/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/__init__.py',\n",
       "   'module': 'neurosurfer.utils.__init__',\n",
       "   'package': 'neurosurfer.utils'},\n",
       "  {'path': 'tracing/step_context.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/step_context.py',\n",
       "   'module': 'neurosurfer.tracing.step_context',\n",
       "   'package': 'neurosurfer.tracing'},\n",
       "  {'path': 'tracing/models.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/models.py',\n",
       "   'module': 'neurosurfer.tracing.models',\n",
       "   'package': 'neurosurfer.tracing'},\n",
       "  {'path': 'tracing/span.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/span.py',\n",
       "   'module': 'neurosurfer.tracing.span',\n",
       "   'package': 'neurosurfer.tracing'},\n",
       "  {'path': 'tracing/tracer.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/tracer.py',\n",
       "   'module': 'neurosurfer.tracing.tracer',\n",
       "   'package': 'neurosurfer.tracing'},\n",
       "  {'path': 'tracing/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/__init__.py',\n",
       "   'module': 'neurosurfer.tracing.__init__',\n",
       "   'package': 'neurosurfer.tracing'},\n",
       "  {'path': 'models/embedders/sentence_transformer.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/sentence_transformer.py',\n",
       "   'module': 'neurosurfer.models.embedders.sentence_transformer',\n",
       "   'package': 'neurosurfer.models.embedders'},\n",
       "  {'path': 'models/embedders/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/base.py',\n",
       "   'module': 'neurosurfer.models.embedders.base',\n",
       "   'package': 'neurosurfer.models.embedders'},\n",
       "  {'path': 'models/embedders/llamacpp.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/llamacpp.py',\n",
       "   'module': 'neurosurfer.models.embedders.llamacpp',\n",
       "   'package': 'neurosurfer.models.embedders'},\n",
       "  {'path': 'models/embedders/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/__init__.py',\n",
       "   'module': 'neurosurfer.models.embedders.__init__',\n",
       "   'package': 'neurosurfer.models.embedders'},\n",
       "  {'path': 'models/chat_models/transformers.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/transformers.py',\n",
       "   'module': 'neurosurfer.models.chat_models.transformers',\n",
       "   'package': 'neurosurfer.models.chat_models'},\n",
       "  {'path': 'models/chat_models/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/base.py',\n",
       "   'module': 'neurosurfer.models.chat_models.base',\n",
       "   'package': 'neurosurfer.models.chat_models'},\n",
       "  {'path': 'models/chat_models/unsloth.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/unsloth.py',\n",
       "   'module': 'neurosurfer.models.chat_models.unsloth',\n",
       "   'package': 'neurosurfer.models.chat_models'},\n",
       "  {'path': 'models/chat_models/llamacpp.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/llamacpp.py',\n",
       "   'module': 'neurosurfer.models.chat_models.llamacpp',\n",
       "   'package': 'neurosurfer.models.chat_models'},\n",
       "  {'path': 'models/chat_models/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/__init__.py',\n",
       "   'module': 'neurosurfer.models.chat_models.__init__',\n",
       "   'package': 'neurosurfer.models.chat_models'},\n",
       "  {'path': 'models/chat_models/openai.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/openai.py',\n",
       "   'module': 'neurosurfer.models.chat_models.openai',\n",
       "   'package': 'neurosurfer.models.chat_models'},\n",
       "  {'path': 'runtime/checks.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/runtime/checks.py',\n",
       "   'module': 'neurosurfer.runtime.checks',\n",
       "   'package': 'neurosurfer.runtime'},\n",
       "  {'path': 'runtime/paths.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/runtime/paths.py',\n",
       "   'module': 'neurosurfer.runtime.paths',\n",
       "   'package': 'neurosurfer.runtime'},\n",
       "  {'path': 'server/reset.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/reset.py',\n",
       "   'module': 'neurosurfer.server.reset',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/models_registry.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/models_registry.py',\n",
       "   'module': 'neurosurfer.server.models_registry',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/utils.py',\n",
       "   'module': 'neurosurfer.server.utils',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/runtime.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/runtime.py',\n",
       "   'module': 'neurosurfer.server.runtime',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/config.py',\n",
       "   'module': 'neurosurfer.server.config',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/app.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/app.py',\n",
       "   'module': 'neurosurfer.server.app',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/security.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/security.py',\n",
       "   'module': 'neurosurfer.server.security',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/gunicorn.conf.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/gunicorn.conf.py',\n",
       "   'module': 'neurosurfer.server.gunicorn.conf',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/__init__.py',\n",
       "   'module': 'neurosurfer.server.__init__',\n",
       "   'package': 'neurosurfer.server'},\n",
       "  {'path': 'server/db/models.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/db/models.py',\n",
       "   'module': 'neurosurfer.server.db.models',\n",
       "   'package': 'neurosurfer.server.db'},\n",
       "  {'path': 'server/db/db.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/db/db.py',\n",
       "   'module': 'neurosurfer.server.db.db',\n",
       "   'package': 'neurosurfer.server.db'},\n",
       "  {'path': 'server/db/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/db/__init__.py',\n",
       "   'module': 'neurosurfer.server.db.__init__',\n",
       "   'package': 'neurosurfer.server.db'},\n",
       "  {'path': 'server/services/follow_up_questions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/follow_up_questions.py',\n",
       "   'module': 'neurosurfer.server.services.follow_up_questions',\n",
       "   'package': 'neurosurfer.server.services'},\n",
       "  {'path': 'server/services/rag/metadata_filter.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/metadata_filter.py',\n",
       "   'module': 'neurosurfer.server.services.rag.metadata_filter',\n",
       "   'package': 'neurosurfer.server.services.rag'},\n",
       "  {'path': 'server/services/rag/models.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/models.py',\n",
       "   'module': 'neurosurfer.server.services.rag.models',\n",
       "   'package': 'neurosurfer.server.services.rag'},\n",
       "  {'path': 'server/services/rag/ingestor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/ingestor.py',\n",
       "   'module': 'neurosurfer.server.services.rag.ingestor',\n",
       "   'package': 'neurosurfer.server.services.rag'},\n",
       "  {'path': 'server/services/rag/summarizer.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/summarizer.py',\n",
       "   'module': 'neurosurfer.server.services.rag.summarizer',\n",
       "   'package': 'neurosurfer.server.services.rag'},\n",
       "  {'path': 'server/services/rag/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/__init__.py',\n",
       "   'module': 'neurosurfer.server.services.rag.__init__',\n",
       "   'package': 'neurosurfer.server.services.rag'},\n",
       "  {'path': 'server/services/rag/orchestrator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/orchestrator.py',\n",
       "   'module': 'neurosurfer.server.services.rag.orchestrator',\n",
       "   'package': 'neurosurfer.server.services.rag'},\n",
       "  {'path': 'server/services/rag/gate.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/gate.py',\n",
       "   'module': 'neurosurfer.server.services.rag.gate',\n",
       "   'package': 'neurosurfer.server.services.rag'},\n",
       "  {'path': 'server/schemas/model_response.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/model_response.py',\n",
       "   'module': 'neurosurfer.server.schemas.model_response',\n",
       "   'package': 'neurosurfer.server.schemas'},\n",
       "  {'path': 'server/schemas/chats.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/chats.py',\n",
       "   'module': 'neurosurfer.server.schemas.chats',\n",
       "   'package': 'neurosurfer.server.schemas'},\n",
       "  {'path': 'server/schemas/completions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/completions.py',\n",
       "   'module': 'neurosurfer.server.schemas.completions',\n",
       "   'package': 'neurosurfer.server.schemas'},\n",
       "  {'path': 'server/schemas/model_registry.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/model_registry.py',\n",
       "   'module': 'neurosurfer.server.schemas.model_registry',\n",
       "   'package': 'neurosurfer.server.schemas'},\n",
       "  {'path': 'server/schemas/auth.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/auth.py',\n",
       "   'module': 'neurosurfer.server.schemas.auth',\n",
       "   'package': 'neurosurfer.server.schemas'},\n",
       "  {'path': 'server/schemas/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/__init__.py',\n",
       "   'module': 'neurosurfer.server.schemas.__init__',\n",
       "   'package': 'neurosurfer.server.schemas'},\n",
       "  {'path': 'server/api/api_chat_completions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_chat_completions.py',\n",
       "   'module': 'neurosurfer.server.api.api_chat_completions',\n",
       "   'package': 'neurosurfer.server.api'},\n",
       "  {'path': 'server/api/api_files.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_files.py',\n",
       "   'module': 'neurosurfer.server.api.api_files',\n",
       "   'package': 'neurosurfer.server.api'},\n",
       "  {'path': 'server/api/api_chats.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_chats.py',\n",
       "   'module': 'neurosurfer.server.api.api_chats',\n",
       "   'package': 'neurosurfer.server.api'},\n",
       "  {'path': 'server/api/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/__init__.py',\n",
       "   'module': 'neurosurfer.server.api.__init__',\n",
       "   'package': 'neurosurfer.server.api'},\n",
       "  {'path': 'server/api/api_auth.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_auth.py',\n",
       "   'module': 'neurosurfer.server.api.api_auth',\n",
       "   'package': 'neurosurfer.server.api'},\n",
       "  {'path': 'tools/toolkit.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/toolkit.py',\n",
       "   'module': 'neurosurfer.tools.toolkit',\n",
       "   'package': 'neurosurfer.tools'},\n",
       "  {'path': 'tools/base_tool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/base_tool.py',\n",
       "   'module': 'neurosurfer.tools.base_tool',\n",
       "   'package': 'neurosurfer.tools'},\n",
       "  {'path': 'tools/tool_spec.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/tool_spec.py',\n",
       "   'module': 'neurosurfer.tools.tool_spec',\n",
       "   'package': 'neurosurfer.tools'},\n",
       "  {'path': 'tools/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/__init__.py',\n",
       "   'module': 'neurosurfer.tools.__init__',\n",
       "   'package': 'neurosurfer.tools'},\n",
       "  {'path': 'tools/mermaid/erd_diagram_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/mermaid/erd_diagram_generator.py',\n",
       "   'module': 'neurosurfer.tools.mermaid.erd_diagram_generator',\n",
       "   'package': 'neurosurfer.tools.mermaid'},\n",
       "  {'path': 'tools/mermaid/mermaid_diagram_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/mermaid/mermaid_diagram_generator.py',\n",
       "   'module': 'neurosurfer.tools.mermaid.mermaid_diagram_generator',\n",
       "   'package': 'neurosurfer.tools.mermaid'},\n",
       "  {'path': 'tools/common/general_query_assistant.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/common/general_query_assistant.py',\n",
       "   'module': 'neurosurfer.tools.common.general_query_assistant',\n",
       "   'package': 'neurosurfer.tools.common'},\n",
       "  {'path': 'tools/common/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/common/__init__.py',\n",
       "   'module': 'neurosurfer.tools.common.__init__',\n",
       "   'package': 'neurosurfer.tools.common'},\n",
       "  {'path': 'tools/sql/final_answer_formatter.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/final_answer_formatter.py',\n",
       "   'module': 'neurosurfer.tools.sql.final_answer_formatter',\n",
       "   'package': 'neurosurfer.tools.sql'},\n",
       "  {'path': 'tools/sql/sql_executor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/sql_executor.py',\n",
       "   'module': 'neurosurfer.tools.sql.sql_executor',\n",
       "   'package': 'neurosurfer.tools.sql'},\n",
       "  {'path': 'tools/sql/db_insights_tool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/db_insights_tool.py',\n",
       "   'module': 'neurosurfer.tools.sql.db_insights_tool',\n",
       "   'package': 'neurosurfer.tools.sql'},\n",
       "  {'path': 'tools/sql/relevant_tables_schema_retriever.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/relevant_tables_schema_retriever.py',\n",
       "   'module': 'neurosurfer.tools.sql.relevant_tables_schema_retriever',\n",
       "   'package': 'neurosurfer.tools.sql'},\n",
       "  {'path': 'tools/sql/sql_query_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/sql_query_generator.py',\n",
       "   'module': 'neurosurfer.tools.sql.sql_query_generator',\n",
       "   'package': 'neurosurfer.tools.sql'},\n",
       "  {'path': 'tools/sql/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/__init__.py',\n",
       "   'module': 'neurosurfer.tools.sql.__init__',\n",
       "   'package': 'neurosurfer.tools.sql'},\n",
       "  {'path': 'tools/rag/docs_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/rag/docs_generator.py',\n",
       "   'module': 'neurosurfer.tools.rag.docs_generator',\n",
       "   'package': 'neurosurfer.tools.rag'},\n",
       "  {'path': 'tools/rag/simple_query_assitant.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/rag/simple_query_assitant.py',\n",
       "   'module': 'neurosurfer.tools.rag.simple_query_assitant',\n",
       "   'package': 'neurosurfer.tools.rag'},\n",
       "  {'path': 'tools/websearch/extractor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/extractor.py',\n",
       "   'module': 'neurosurfer.tools.websearch.extractor',\n",
       "   'package': 'neurosurfer.tools.websearch'},\n",
       "  {'path': 'tools/websearch/tool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/tool.py',\n",
       "   'module': 'neurosurfer.tools.websearch.tool',\n",
       "   'package': 'neurosurfer.tools.websearch'},\n",
       "  {'path': 'tools/websearch/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/utils.py',\n",
       "   'module': 'neurosurfer.tools.websearch.utils',\n",
       "   'package': 'neurosurfer.tools.websearch'},\n",
       "  {'path': 'tools/websearch/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/config.py',\n",
       "   'module': 'neurosurfer.tools.websearch.config',\n",
       "   'package': 'neurosurfer.tools.websearch'},\n",
       "  {'path': 'tools/websearch/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/templates.py',\n",
       "   'module': 'neurosurfer.tools.websearch.templates',\n",
       "   'package': 'neurosurfer.tools.websearch'},\n",
       "  {'path': 'tools/websearch/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/__init__.py',\n",
       "   'module': 'neurosurfer.tools.websearch.__init__',\n",
       "   'package': 'neurosurfer.tools.websearch'},\n",
       "  {'path': 'tools/websearch/rag.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/rag.py',\n",
       "   'module': 'neurosurfer.tools.websearch.rag',\n",
       "   'package': 'neurosurfer.tools.websearch'},\n",
       "  {'path': 'tools/websearch/engines/serpapi.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/engines/serpapi.py',\n",
       "   'module': 'neurosurfer.tools.websearch.engines.serpapi',\n",
       "   'package': 'neurosurfer.tools.websearch.engines'},\n",
       "  {'path': 'tools/websearch/engines/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/engines/base.py',\n",
       "   'module': 'neurosurfer.tools.websearch.engines.base',\n",
       "   'package': 'neurosurfer.tools.websearch.engines'},\n",
       "  {'path': 'tools/websearch/engines/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/engines/__init__.py',\n",
       "   'module': 'neurosurfer.tools.websearch.engines.__init__',\n",
       "   'package': 'neurosurfer.tools.websearch.engines'},\n",
       "  {'path': 'agents/tools_router_agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/tools_router_agent.py',\n",
       "   'module': 'neurosurfer.agents.tools_router_agent',\n",
       "   'package': 'neurosurfer.agents'},\n",
       "  {'path': 'agents/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/__init__.py',\n",
       "   'module': 'neurosurfer.agents.__init__',\n",
       "   'package': 'neurosurfer.agents'},\n",
       "  {'path': 'agents/sql_agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/sql_agent.py',\n",
       "   'module': 'neurosurfer.agents.sql_agent',\n",
       "   'package': 'neurosurfer.agents'},\n",
       "  {'path': 'agents/common/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/common/utils.py',\n",
       "   'module': 'neurosurfer.agents.common.utils',\n",
       "   'package': 'neurosurfer.agents.common'},\n",
       "  {'path': 'agents/rag/ingestor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/ingestor.py',\n",
       "   'module': 'neurosurfer.agents.rag.ingestor',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/picker.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/picker.py',\n",
       "   'module': 'neurosurfer.agents.rag.picker',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/constants.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/constants.py',\n",
       "   'module': 'neurosurfer.agents.rag.constants',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/config.py',\n",
       "   'module': 'neurosurfer.agents.rag.config',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/chunker.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/chunker.py',\n",
       "   'module': 'neurosurfer.agents.rag.chunker',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/context_builder.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/context_builder.py',\n",
       "   'module': 'neurosurfer.agents.rag.context_builder',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/templates.py',\n",
       "   'module': 'neurosurfer.agents.rag.templates',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/agent.py',\n",
       "   'module': 'neurosurfer.agents.rag.agent',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/__init__.py',\n",
       "   'module': 'neurosurfer.agents.rag.__init__',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/token_utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/token_utils.py',\n",
       "   'module': 'neurosurfer.agents.rag.token_utils',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/rag/filereader.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/filereader.py',\n",
       "   'module': 'neurosurfer.agents.rag.filereader',\n",
       "   'package': 'neurosurfer.agents.rag'},\n",
       "  {'path': 'agents/react/memory.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/memory.py',\n",
       "   'module': 'neurosurfer.agents.react.memory',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/types.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/types.py',\n",
       "   'module': 'neurosurfer.agents.react.types',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/history.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/history.py',\n",
       "   'module': 'neurosurfer.agents.react.history',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/retry.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/retry.py',\n",
       "   'module': 'neurosurfer.agents.react.retry',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/config.py',\n",
       "   'module': 'neurosurfer.agents.react.config',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/parser.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/parser.py',\n",
       "   'module': 'neurosurfer.agents.react.parser',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/base.py',\n",
       "   'module': 'neurosurfer.agents.react.base',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/scratchpad.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/scratchpad.py',\n",
       "   'module': 'neurosurfer.agents.react.scratchpad',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/agent.py',\n",
       "   'module': 'neurosurfer.agents.react.agent',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/exceptions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/exceptions.py',\n",
       "   'module': 'neurosurfer.agents.react.exceptions',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/react/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/__init__.py',\n",
       "   'module': 'neurosurfer.agents.react.__init__',\n",
       "   'package': 'neurosurfer.agents.react'},\n",
       "  {'path': 'agents/graph/loader.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/loader.py',\n",
       "   'module': 'neurosurfer.agents.graph.loader',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/manager.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/manager.py',\n",
       "   'module': 'neurosurfer.agents.graph.manager',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/utils.py',\n",
       "   'module': 'neurosurfer.agents.graph.utils',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/schema.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/schema.py',\n",
       "   'module': 'neurosurfer.agents.graph.schema',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/export.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/export.py',\n",
       "   'module': 'neurosurfer.agents.graph.export',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/errors.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/errors.py',\n",
       "   'module': 'neurosurfer.agents.graph.errors',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/executor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/executor.py',\n",
       "   'module': 'neurosurfer.agents.graph.executor',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/templates.py',\n",
       "   'module': 'neurosurfer.agents.graph.templates',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/agent.py',\n",
       "   'module': 'neurosurfer.agents.graph.agent',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/model_pool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/model_pool.py',\n",
       "   'module': 'neurosurfer.agents.graph.model_pool',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/__init__.py',\n",
       "   'module': 'neurosurfer.agents.graph.__init__',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/graph/artifacts.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/artifacts.py',\n",
       "   'module': 'neurosurfer.agents.graph.artifacts',\n",
       "   'package': 'neurosurfer.agents.graph'},\n",
       "  {'path': 'agents/agent/responses.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/responses.py',\n",
       "   'module': 'neurosurfer.agents.agent.responses',\n",
       "   'package': 'neurosurfer.agents.agent'},\n",
       "  {'path': 'agents/agent/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/config.py',\n",
       "   'module': 'neurosurfer.agents.agent.config',\n",
       "   'package': 'neurosurfer.agents.agent'},\n",
       "  {'path': 'agents/agent/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/templates.py',\n",
       "   'module': 'neurosurfer.agents.agent.templates',\n",
       "   'package': 'neurosurfer.agents.agent'},\n",
       "  {'path': 'agents/agent/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/agent.py',\n",
       "   'module': 'neurosurfer.agents.agent.agent',\n",
       "   'package': 'neurosurfer.agents.agent'},\n",
       "  {'path': 'agents/agent/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/__init__.py',\n",
       "   'module': 'neurosurfer.agents.agent.__init__',\n",
       "   'package': 'neurosurfer.agents.agent'},\n",
       "  {'path': 'agents/agent/schema_utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/schema_utils.py',\n",
       "   'module': 'neurosurfer.agents.agent.schema_utils',\n",
       "   'package': 'neurosurfer.agents.agent'},\n",
       "  {'path': 'cli/processes.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/processes.py',\n",
       "   'module': 'neurosurfer.cli.processes',\n",
       "   'package': 'neurosurfer.cli'},\n",
       "  {'path': 'cli/serve.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/serve.py',\n",
       "   'module': 'neurosurfer.cli.serve',\n",
       "   'package': 'neurosurfer.cli'},\n",
       "  {'path': 'cli/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/utils.py',\n",
       "   'module': 'neurosurfer.cli.utils',\n",
       "   'package': 'neurosurfer.cli'},\n",
       "  {'path': 'cli/main.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/main.py',\n",
       "   'module': 'neurosurfer.cli.main',\n",
       "   'package': 'neurosurfer.cli'},\n",
       "  {'path': 'cli/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/__init__.py',\n",
       "   'module': 'neurosurfer.cli.__init__',\n",
       "   'package': 'neurosurfer.cli'}],\n",
       " 'doc_files': [],\n",
       " 'packages': ['neurosurfer',\n",
       "  'neurosurfer.agents',\n",
       "  'neurosurfer.agents.agent',\n",
       "  'neurosurfer.agents.common',\n",
       "  'neurosurfer.agents.graph',\n",
       "  'neurosurfer.agents.rag',\n",
       "  'neurosurfer.agents.react',\n",
       "  'neurosurfer.cli',\n",
       "  'neurosurfer.db',\n",
       "  'neurosurfer.examples',\n",
       "  'neurosurfer.models.chat_models',\n",
       "  'neurosurfer.models.embedders',\n",
       "  'neurosurfer.runtime',\n",
       "  'neurosurfer.server',\n",
       "  'neurosurfer.server.api',\n",
       "  'neurosurfer.server.db',\n",
       "  'neurosurfer.server.schemas',\n",
       "  'neurosurfer.server.services',\n",
       "  'neurosurfer.server.services.rag',\n",
       "  'neurosurfer.tools',\n",
       "  'neurosurfer.tools.common',\n",
       "  'neurosurfer.tools.mermaid',\n",
       "  'neurosurfer.tools.rag',\n",
       "  'neurosurfer.tools.sql',\n",
       "  'neurosurfer.tools.websearch',\n",
       "  'neurosurfer.tools.websearch.engines',\n",
       "  'neurosurfer.tracing',\n",
       "  'neurosurfer.utils',\n",
       "  'neurosurfer.vectorstores'],\n",
       " 'modules': ['neurosurfer.__init__',\n",
       "  'neurosurfer.agents.__init__',\n",
       "  'neurosurfer.agents.agent.__init__',\n",
       "  'neurosurfer.agents.agent.agent',\n",
       "  'neurosurfer.agents.agent.config',\n",
       "  'neurosurfer.agents.agent.responses',\n",
       "  'neurosurfer.agents.agent.schema_utils',\n",
       "  'neurosurfer.agents.agent.templates',\n",
       "  'neurosurfer.agents.common.utils',\n",
       "  'neurosurfer.agents.graph.__init__',\n",
       "  'neurosurfer.agents.graph.agent',\n",
       "  'neurosurfer.agents.graph.artifacts',\n",
       "  'neurosurfer.agents.graph.errors',\n",
       "  'neurosurfer.agents.graph.executor',\n",
       "  'neurosurfer.agents.graph.export',\n",
       "  'neurosurfer.agents.graph.loader',\n",
       "  'neurosurfer.agents.graph.manager',\n",
       "  'neurosurfer.agents.graph.model_pool',\n",
       "  'neurosurfer.agents.graph.schema',\n",
       "  'neurosurfer.agents.graph.templates',\n",
       "  'neurosurfer.agents.graph.utils',\n",
       "  'neurosurfer.agents.rag.__init__',\n",
       "  'neurosurfer.agents.rag.agent',\n",
       "  'neurosurfer.agents.rag.chunker',\n",
       "  'neurosurfer.agents.rag.config',\n",
       "  'neurosurfer.agents.rag.constants',\n",
       "  'neurosurfer.agents.rag.context_builder',\n",
       "  'neurosurfer.agents.rag.filereader',\n",
       "  'neurosurfer.agents.rag.ingestor',\n",
       "  'neurosurfer.agents.rag.picker',\n",
       "  'neurosurfer.agents.rag.templates',\n",
       "  'neurosurfer.agents.rag.token_utils',\n",
       "  'neurosurfer.agents.react.__init__',\n",
       "  'neurosurfer.agents.react.agent',\n",
       "  'neurosurfer.agents.react.base',\n",
       "  'neurosurfer.agents.react.config',\n",
       "  'neurosurfer.agents.react.exceptions',\n",
       "  'neurosurfer.agents.react.history',\n",
       "  'neurosurfer.agents.react.memory',\n",
       "  'neurosurfer.agents.react.parser',\n",
       "  'neurosurfer.agents.react.retry',\n",
       "  'neurosurfer.agents.react.scratchpad',\n",
       "  'neurosurfer.agents.react.types',\n",
       "  'neurosurfer.agents.sql_agent',\n",
       "  'neurosurfer.agents.tools_router_agent',\n",
       "  'neurosurfer.cli.__init__',\n",
       "  'neurosurfer.cli.main',\n",
       "  'neurosurfer.cli.processes',\n",
       "  'neurosurfer.cli.serve',\n",
       "  'neurosurfer.cli.utils',\n",
       "  'neurosurfer.config',\n",
       "  'neurosurfer.db.__init__',\n",
       "  'neurosurfer.db.sql_database',\n",
       "  'neurosurfer.db.sql_schema_store',\n",
       "  'neurosurfer.diagnostics',\n",
       "  'neurosurfer.examples.quickstart_app',\n",
       "  'neurosurfer.logger',\n",
       "  'neurosurfer.models.chat_models.__init__',\n",
       "  'neurosurfer.models.chat_models.base',\n",
       "  'neurosurfer.models.chat_models.llamacpp',\n",
       "  'neurosurfer.models.chat_models.openai',\n",
       "  'neurosurfer.models.chat_models.transformers',\n",
       "  'neurosurfer.models.chat_models.unsloth',\n",
       "  'neurosurfer.models.embedders.__init__',\n",
       "  'neurosurfer.models.embedders.base',\n",
       "  'neurosurfer.models.embedders.llamacpp',\n",
       "  'neurosurfer.models.embedders.sentence_transformer',\n",
       "  'neurosurfer.runtime.checks',\n",
       "  'neurosurfer.runtime.paths',\n",
       "  'neurosurfer.server.__init__',\n",
       "  'neurosurfer.server.api.__init__',\n",
       "  'neurosurfer.server.api.api_auth',\n",
       "  'neurosurfer.server.api.api_chat_completions',\n",
       "  'neurosurfer.server.api.api_chats',\n",
       "  'neurosurfer.server.api.api_files',\n",
       "  'neurosurfer.server.app',\n",
       "  'neurosurfer.server.config',\n",
       "  'neurosurfer.server.db.__init__',\n",
       "  'neurosurfer.server.db.db',\n",
       "  'neurosurfer.server.db.models',\n",
       "  'neurosurfer.server.gunicorn.conf',\n",
       "  'neurosurfer.server.models_registry',\n",
       "  'neurosurfer.server.reset',\n",
       "  'neurosurfer.server.runtime',\n",
       "  'neurosurfer.server.schemas.__init__',\n",
       "  'neurosurfer.server.schemas.auth',\n",
       "  'neurosurfer.server.schemas.chats',\n",
       "  'neurosurfer.server.schemas.completions',\n",
       "  'neurosurfer.server.schemas.model_registry',\n",
       "  'neurosurfer.server.schemas.model_response',\n",
       "  'neurosurfer.server.security',\n",
       "  'neurosurfer.server.services.follow_up_questions',\n",
       "  'neurosurfer.server.services.rag.__init__',\n",
       "  'neurosurfer.server.services.rag.gate',\n",
       "  'neurosurfer.server.services.rag.ingestor',\n",
       "  'neurosurfer.server.services.rag.metadata_filter',\n",
       "  'neurosurfer.server.services.rag.models',\n",
       "  'neurosurfer.server.services.rag.orchestrator',\n",
       "  'neurosurfer.server.services.rag.summarizer',\n",
       "  'neurosurfer.server.utils',\n",
       "  'neurosurfer.tools.__init__',\n",
       "  'neurosurfer.tools.base_tool',\n",
       "  'neurosurfer.tools.common.__init__',\n",
       "  'neurosurfer.tools.common.general_query_assistant',\n",
       "  'neurosurfer.tools.mermaid.erd_diagram_generator',\n",
       "  'neurosurfer.tools.mermaid.mermaid_diagram_generator',\n",
       "  'neurosurfer.tools.rag.docs_generator',\n",
       "  'neurosurfer.tools.rag.simple_query_assitant',\n",
       "  'neurosurfer.tools.sql.__init__',\n",
       "  'neurosurfer.tools.sql.db_insights_tool',\n",
       "  'neurosurfer.tools.sql.final_answer_formatter',\n",
       "  'neurosurfer.tools.sql.relevant_tables_schema_retriever',\n",
       "  'neurosurfer.tools.sql.sql_executor',\n",
       "  'neurosurfer.tools.sql.sql_query_generator',\n",
       "  'neurosurfer.tools.tool_spec',\n",
       "  'neurosurfer.tools.toolkit',\n",
       "  'neurosurfer.tools.websearch.__init__',\n",
       "  'neurosurfer.tools.websearch.config',\n",
       "  'neurosurfer.tools.websearch.engines.__init__',\n",
       "  'neurosurfer.tools.websearch.engines.base',\n",
       "  'neurosurfer.tools.websearch.engines.serpapi',\n",
       "  'neurosurfer.tools.websearch.extractor',\n",
       "  'neurosurfer.tools.websearch.rag',\n",
       "  'neurosurfer.tools.websearch.templates',\n",
       "  'neurosurfer.tools.websearch.tool',\n",
       "  'neurosurfer.tools.websearch.utils',\n",
       "  'neurosurfer.tracing.__init__',\n",
       "  'neurosurfer.tracing.models',\n",
       "  'neurosurfer.tracing.span',\n",
       "  'neurosurfer.tracing.step_context',\n",
       "  'neurosurfer.tracing.tracer',\n",
       "  'neurosurfer.utils.__init__',\n",
       "  'neurosurfer.utils.helper',\n",
       "  'neurosurfer.utils.prompts',\n",
       "  'neurosurfer.utils.response_wrappers',\n",
       "  'neurosurfer.vectorstores.__init__',\n",
       "  'neurosurfer.vectorstores.base',\n",
       "  'neurosurfer.vectorstores.chroma',\n",
       "  'neurosurfer.vectorstores.in_memory_store',\n",
       "  'neurosurfer.version'],\n",
       " 'summary': {'python_file_count': 140,\n",
       "  'doc_file_count': 0,\n",
       "  'package_count': 29,\n",
       "  'module_count': 140}}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neurosurfer_labs.tools.doc_gen.dir_scanning import DirectoryScanTool\n",
    "from neurosurfer_labs.tools.doc_gen.code_symbol_index import CodeSymbolIndexTool\n",
    "from neurosurfer.tools.toolkit import Toolkit\n",
    "\n",
    "root_dir = \"../neurosurfer\"\n",
    "dir_scan_tool = DirectoryScanTool()\n",
    "code_index_tool = CodeSymbolIndexTool()\n",
    "\n",
    "toolkit = Toolkit(tools=[dir_scan_tool, code_index_tool])\n",
    "\n",
    "params = {\n",
    "    \"project_root\": root_dir,\n",
    "    \"docs_root\": \"docs\",\n",
    "}\n",
    "\n",
    "scan_results = dir_scan_tool(project_root=root_dir)\n",
    "scan_results.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "303ddfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modules': {'neurosurfer.version': {'path': 'version.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/version.py',\n",
       "   'package': 'neurosurfer',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.config': {'path': 'config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/config.py',\n",
       "   'package': 'neurosurfer',\n",
       "   'classes': [{'name': 'BaseModelConfig',\n",
       "     'docstring': 'Base configuration shared across all model types.\\n\\nAll model configs inherit these common parameters.\\nCan be extended with model-specific settings.',\n",
       "     'methods': [{'name': 'to_dict',\n",
       "       'docstring': 'Convert config to dictionary for unpacking into model __init__.\\n\\nArgs:\\n    exclude_none: Exclude fields with None values\\n    \\nReturns:\\n    Dictionary of configuration parameters',\n",
       "       'args': ['self', 'exclude_none']}]},\n",
       "    {'name': 'AppConfig',\n",
       "     'docstring': 'General application configuration.\\n\\nManages application-level settings like versioning, networking,\\nfile paths, and runtime behavior.',\n",
       "     'methods': [{'name': 'get_dynamic_host_ip',\n",
       "       'docstring': 'Get interface IP dynamically',\n",
       "       'args': ['self']},\n",
       "      {'name': 'host_url',\n",
       "       'docstring': 'Construct full host URL',\n",
       "       'args': ['self']},\n",
       "      {'name': 'vector_store_path',\n",
       "       'docstring': 'Vector store storage path',\n",
       "       'args': ['self']},\n",
       "      {'name': 'database_url',\n",
       "       'docstring': 'SQLite database URL',\n",
       "       'args': ['self']}]},\n",
       "    {'name': 'DatabaseConfig',\n",
       "     'docstring': 'External database connection configuration.\\n\\nFor SQL Server or other external databases used by the SQL Agent.',\n",
       "     'methods': []},\n",
       "    {'name': 'ChunkerConfig',\n",
       "     'docstring': 'Configuration for the GenericCodeChunker.\\nControls chunking sizes, overlaps, and fallback behavior\\nfor both line-based (code-friendly) and char-based (generic text) splitting.',\n",
       "     'methods': []},\n",
       "    {'name': 'Config',\n",
       "     'docstring': 'Main configuration class aggregating all sub-configurations.\\n\\nThis is the primary entry point for all application configuration.\\nProvides structured access to app, database, model, and processing configs.\\n\\nUsage:\\n    # Initialize config (loads from .env automatically)\\n    config = Config()\\n    \\n    # Access app settings\\n    print(config.app.host_url)\\n    \\n    # Configure and instantiate a model\\n    config.model.unsloth.model_name = \"custom/model\"\\n    config.model.unsloth.max_seq_length = 16000\\n    model = UnslothModel(**config.model.unsloth.to_dict())\\n\\nAttributes:\\n    app: Application-level configuration\\n    database: External database configuration\\n    chunker: Chunker configuration',\n",
       "     'methods': [{'name': 'get_logger',\n",
       "       'docstring': 'Get a configured logger instance.\\n\\nArgs:\\n    name: Logger name (typically __name__)\\n    \\nReturns:\\n    Configured logger instance',\n",
       "       'args': ['self', 'name']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.diagnostics': {'path': 'diagnostics.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/diagnostics.py',\n",
       "   'package': 'neurosurfer',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'main', 'docstring': None, 'args': ['argv']}]},\n",
       "  'neurosurfer.logger': {'path': 'logger.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/logger.py',\n",
       "   'package': 'neurosurfer',\n",
       "   'classes': [{'name': 'ColorFormatter',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'format',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'record']}]}],\n",
       "   'functions': [{'name': 'configure_logging',\n",
       "     'docstring': None,\n",
       "     'args': []}]},\n",
       "  'neurosurfer.__init__': {'path': '__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/__init__.py',\n",
       "   'package': 'neurosurfer',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.db.__init__': {'path': 'db/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/db/__init__.py',\n",
       "   'package': 'neurosurfer.db',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.db.sql_database': {'path': 'db/sql_database.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/db/sql_database.py',\n",
       "   'package': 'neurosurfer.db',\n",
       "   'classes': [{'name': 'SQLDatabase',\n",
       "     'docstring': 'Production-grade SQLAlchemy database wrapper.\\n\\nThis class provides a high-level interface for database operations,\\nincluding schema introspection, query execution, and metadata caching.\\nIt\\'s designed for use with SQL agents and tools.\\n\\nFeatures:\\n    - Automatic schema introspection\\n    - Table filtering (include/ignore)\\n    - Sample data for context\\n    - Metadata caching for performance\\n    - View support\\n    - Safe query execution\\n\\nAttributes:\\n    _engine (Engine): SQLAlchemy engine\\n    _schema (Optional[str]): Database schema name\\n    _inspector: SQLAlchemy inspector\\n    _all_tables (set): All available tables\\n    _usable_tables (set): Filtered tables based on include/ignore\\n\\nExample:\\n    >>> db = SQLDatabase(\\n    ...     database_uri=\"sqlite:///mydb.db\",\\n    ...     include_tables=[\"users\", \"products\"],\\n    ...     sample_rows_in_table_info=3\\n    ... )\\n    >>> \\n    >>> # Get schema\\n    >>> schema_info = db.get_table_info()\\n    >>> \\n    >>> # Execute query\\n    >>> results = db.run(\"SELECT COUNT(*) FROM users\")\\n    >>> \\n    >>> # Get table names\\n    >>> tables = db.get_usable_table_names()',\n",
       "     'methods': [{'name': 'dialect',\n",
       "       'docstring': 'Return string representation of dialect to use.',\n",
       "       'args': ['self']},\n",
       "      {'name': 'get_usable_table_names',\n",
       "       'docstring': 'Get names of tables available.',\n",
       "       'args': ['self']},\n",
       "      {'name': 'get_table_info',\n",
       "       'docstring': 'Get information about specified tables.\\nFollows best practices as specified in: Rajkumar et al, 2022\\n(https://arxiv.org/abs/2204.00498)\\nIf `sample_rows_in_table_info`, the specified number of sample rows will be\\nappended to each table description. This can increase performance as\\ndemonstrated in the paper.',\n",
       "       'args': ['self', 'table_names']},\n",
       "      {'name': 'build_connection_string',\n",
       "       'docstring': None,\n",
       "       'args': ['server',\n",
       "        'database',\n",
       "        'username',\n",
       "        'password',\n",
       "        'driver',\n",
       "        'port',\n",
       "        'odbc_driver']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.db.sql_schema_store': {'path': 'db/sql_schema_store.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/db/sql_schema_store.py',\n",
       "   'package': 'neurosurfer.db',\n",
       "   'classes': [{'name': 'SQLSchemaStore',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'train',\n",
       "       'docstring': 'Trains the schema summarizer by extracting schema data and optionally generating LLM summaries.\\nsummarize:\\n    - False: Store raw schema only.\\n    - True: Add LLM-generated short summary with schema.\\nforce:\\n    - If True, flushes existing storage and retrains all tables.',\n",
       "       'args': ['self', 'summarize', 'force']},\n",
       "      {'name': 'summarize_schema__',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'table_name', 'schema']},\n",
       "      {'name': 'get_all_table_schemas', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'save_to_file', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'load_from_file', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'get_table_data', 'docstring': None, 'args': ['self', 'table']},\n",
       "      {'name': 'get_db_name', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'get_tables_count', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.examples.quickstart_app': {'path': 'examples/quickstart_app.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/examples/quickstart_app.py',\n",
       "   'package': 'neurosurfer.examples',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'cleanup',\n",
       "     'docstring': 'Clean up temporary files and directories on application shutdown.',\n",
       "     'args': []},\n",
       "    {'name': 'handler',\n",
       "     'docstring': 'Process chat completion requests with RAG-enhanced context.\\n\\nThis is the main chat handler that processes incoming chat requests, optionally\\nenhances them with relevant context from uploaded documents using RAG, and\\ngenerates responses using the configured language model.\\n\\nArgs:\\n    args (ChatHandlerModel): The chat handler model contains:\\n        - user_id: User/session identifier\\n        - thread_id: Session/thread identifier for context management\\n        - message_id: Message identifier for context management\\n        - has_files_message: Whether the message contains files\\n        - model: The model to use for generation, selected from the UI\\n        - messages: ChatHandlerMessages\\n            - user_query: Last user message\\n            - user_msgs: List of user messages\\n            - assistant_msgs: List of assistant messages\\n            - system_msgs: List of system messages\\n            - converstaion: List of conversation messages\\n        - temperature: Sampling temperature for response generation\\n        - max_tokens: Maximum tokens to generate in response\\n        - stream: Whether to stream the response\\n        - system_prompt: Optional system prompt for generation\\n        - tools: Optional list of tools to use for generation\\n        - tool_choice: Optional tool choice for generation\\n        - metadata: Optional metadata for generation\\n        - files: Optional list of uploaded files for context\\n\\nReturns:\\n    The AppResponseModel, which can be either:\\n        - Complete response object (non-streaming)\\n        - Streaming response generator (streaming mode)\\n\\nProcessing Flow:\\n    1. Extract user messages, system messages, and conversation history\\n    2. Apply RAG enhancement if files/context available for the thread\\n    3. Configure generation parameters (temperature, max_tokens)\\n    4. Call LLM with enhanced query and chat history\\n\\nRAG Enhancement:\\n    - Checks if RAG system is available and thread_id is provided\\n    - Applies document retrieval and context injection\\n    - Logs RAG usage statistics (similarity scores, usage decisions)\\n    - Falls back to original query if no relevant context found\\n\\nConfiguration:\\n    - Uses DEFAULT_SYSTEM_PROMPT if no system message provided\\n    - Applies temperature/max_tokens limits with fallbacks to config defaults\\n    - Maintains recent chat history (last 10 messages by default)\\n\\nNote:\\n    - Thread-based context allows for persistent conversations\\n    - File uploads are processed and converted to document chunks\\n    - Streaming responses are supported for real-time interaction\\n    - RAG context injection happens before LLM generation',\n",
       "     'args': ['args']},\n",
       "    {'name': 'create_app', 'docstring': None, 'args': []},\n",
       "    {'name': 'main', 'docstring': None, 'args': []}]},\n",
       "  'neurosurfer.vectorstores.in_memory_store': {'path': 'vectorstores/in_memory_store.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/in_memory_store.py',\n",
       "   'package': 'neurosurfer.vectorstores',\n",
       "   'classes': [{'name': 'InMemoryVectorStore',\n",
       "     'docstring': 'Minimal, production-friendly baseline. Replace with FAISS, PGVecto, Chroma, Milvus, etc.',\n",
       "     'methods': [{'name': 'add_documents',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'docs']},\n",
       "      {'name': 'similarity_search',\n",
       "       'docstring': None,\n",
       "       'args': ['self',\n",
       "        'query_embedding',\n",
       "        'top_k',\n",
       "        'metadata_filter',\n",
       "        'similarity_threshold']},\n",
       "      {'name': 'count', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'list_all_documents',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'metadata_filter']},\n",
       "      {'name': 'delete_collection', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'clear_collection', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.vectorstores.base': {'path': 'vectorstores/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/base.py',\n",
       "   'package': 'neurosurfer.vectorstores',\n",
       "   'classes': [{'name': 'Doc',\n",
       "     'docstring': 'Document data structure for vector stores.\\n\\nRepresents a single document with its text content, embedding vector,\\nand associated metadata. Used throughout Neurosurfer\\'s RAG and retrieval systems.\\n\\nAttributes:\\n    id (str): Unique identifier for the document\\n    text (str): The actual text content of the document\\n    embedding (Optional[List[float]]): Vector embedding of the text. None if not yet embedded.\\n    metadata (Dict[str, Any]): Additional metadata (e.g., filename, source, chunk_idx, etc.)\\n\\nExample:\\n    >>> doc = Doc(\\n    ...     id=\"doc_123\",\\n    ...     text=\"Machine learning is a subset of AI.\",\\n    ...     embedding=[0.1, 0.2, 0.3, ...],\\n    ...     metadata={\"source\": \"textbook.pdf\", \"page\": 42}\\n    ... )',\n",
       "     'methods': []},\n",
       "    {'name': 'BaseVectorDB',\n",
       "     'docstring': 'Abstract base class for all vector database implementations in Neurosurfer.\\n\\nThis class defines a unified interface for vector stores, enabling seamless\\nswitching between different backends (Chroma, in-memory, etc.) without\\nchanging application code.\\n\\nCore Operations:\\n    - add_documents(): Store documents with embeddings\\n    - similarity_search(): Find similar documents using vector similarity\\n    - list_all_documents(): Retrieve all documents (with optional filtering)\\n    - delete_documents(): Remove specific documents\\n    - clear_collection(): Remove all documents from collection\\n    - delete_collection(): Delete the entire collection\\n\\nAbstract Methods:\\n    All methods must be implemented by concrete vector store classes.\\n\\nExample:\\n    >>> class MyVectorDB(BaseVectorDB):\\n    ...     def add_documents(self, docs):\\n    ...         # Implementation\\n    ...         pass\\n    ...     # ... implement other methods\\n    >>> \\n    >>> vectordb = MyVectorDB()\\n    >>> vectordb.add_documents([doc1, doc2])\\n    >>> results = vectordb.similarity_search(query_embedding, top_k=5)',\n",
       "     'methods': [{'name': 'add_documents',\n",
       "       'docstring': 'Add documents with embeddings to the vector store.\\n\\nThis method stores documents along with their vector embeddings and metadata.\\nDocuments can be retrieved later using similarity_search().\\n\\nArgs:\\n    docs (List[Doc]): List of Doc objects to add. Each Doc must have:\\n        - id: Unique identifier\\n        - text: Document text content\\n        - embedding: Vector embedding (List[float])\\n        - metadata: Optional metadata dict\\n\\nRaises:\\n    NotImplementedError: If not implemented by subclass\\n\\nExample:\\n    >>> docs = [\\n    ...     Doc(id=\"1\", text=\"Hello\", embedding=[0.1, 0.2], metadata={\"source\": \"file.txt\"}),\\n    ...     Doc(id=\"2\", text=\"World\", embedding=[0.3, 0.4], metadata={\"source\": \"file.txt\"})\\n    ... ]\\n    >>> vectordb.add_documents(docs)',\n",
       "       'args': ['self', 'docs']},\n",
       "      {'name': 'similarity_search',\n",
       "       'docstring': 'Perform similarity search to find documents most similar to the query.\\n\\nUses vector similarity (typically cosine similarity) to find and rank\\ndocuments by their relevance to the query embedding.\\n\\nArgs:\\n    query_embedding (List[float]): Query vector to search for\\n    top_k (int): Maximum number of results to return. Default: 5\\n    metadata_filter (Optional[Dict[str, Any]]): Filter results by metadata.\\n        Only documents matching all key-value pairs are returned. Default: None\\n    similarity_threshold (Optional[float]): Minimum similarity score (0.0-1.0).\\n        Documents below this threshold are excluded. Default: None\\n\\nReturns:\\n    List[Tuple[Doc, float]]: List of (document, similarity_score) tuples,\\n        sorted by similarity in descending order (most similar first)\\n\\nRaises:\\n    NotImplementedError: If not implemented by subclass\\n\\nExample:\\n    >>> query_emb = embedder.embed(\"machine learning\")\\n    >>> results = vectordb.similarity_search(\\n    ...     query_embedding=query_emb,\\n    ...     top_k=10,\\n    ...     metadata_filter={\"category\": \"AI\"},\\n    ...     similarity_threshold=0.7\\n    ... )\\n    >>> for doc, score in results:\\n    ...     print(f\"Score: {score:.3f} - {doc.text[:50]}\")',\n",
       "       'args': ['self',\n",
       "        'query_embedding',\n",
       "        'top_k',\n",
       "        'metadata_filter',\n",
       "        'similarity_threshold']},\n",
       "      {'name': 'count',\n",
       "       'docstring': 'Get the total number of documents in the collection.\\n\\nReturns:\\n    int: Number of documents currently stored\\n\\nRaises:\\n    NotImplementedError: If not implemented by subclass\\n\\nExample:\\n    >>> count = vectordb.count()\\n    >>> print(f\"Collection contains {count} documents\")',\n",
       "       'args': ['self']},\n",
       "      {'name': 'list_all_documents',\n",
       "       'docstring': 'Retrieve all documents from the collection.\\n\\nArgs:\\n    metadata_filter (Optional[Dict[str, Any]]): Filter by metadata.\\n        Only documents matching all key-value pairs are returned. Default: None\\n\\nReturns:\\n    List[Doc]: List of all documents (or filtered subset)\\n\\nRaises:\\n    NotImplementedError: If not implemented by subclass\\n\\nExample:\\n    >>> # Get all documents\\n    >>> all_docs = vectordb.list_all_documents()\\n    >>> \\n    >>> # Get documents from specific source\\n    >>> filtered_docs = vectordb.list_all_documents(\\n    ...     metadata_filter={\"source\": \"manual.pdf\"}\\n    ... )',\n",
       "       'args': ['self', 'metadata_filter']},\n",
       "      {'name': 'delete_documents',\n",
       "       'docstring': 'Delete specific documents from the collection.\\n\\nArgs:\\n    docs (List[Doc]): List of documents to delete (matched by ID)\\n\\nRaises:\\n    NotImplementedError: If not implemented by subclass\\n\\nExample:\\n    >>> docs_to_delete = vectordb.list_all_documents(\\n    ...     metadata_filter={\"source\": \"old_file.txt\"}\\n    ... )\\n    >>> vectordb.delete_documents(docs_to_delete)',\n",
       "       'args': ['self', 'docs']},\n",
       "      {'name': 'delete_collection',\n",
       "       'docstring': 'Delete the entire collection permanently.\\n\\nThis removes the collection and all its documents from the vector store.\\nThe collection cannot be recovered after deletion.\\n\\nRaises:\\n    NotImplementedError: If not implemented by subclass\\n\\nExample:\\n    >>> vectordb.delete_collection()',\n",
       "       'args': ['self']},\n",
       "      {'name': 'clear_collection',\n",
       "       'docstring': 'Remove all documents from the collection.\\n\\nThis clears the collection but keeps it available for new documents.\\nTypically implemented by dropping and recreating the collection.\\n\\nRaises:\\n    NotImplementedError: If not implemented by subclass\\n\\nExample:\\n    >>> vectordb.clear_collection()\\n    >>> vectordb.count()  # Returns 0',\n",
       "       'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.vectorstores.__init__': {'path': 'vectorstores/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/__init__.py',\n",
       "   'package': 'neurosurfer.vectorstores',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.vectorstores.chroma': {'path': 'vectorstores/chroma.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/vectorstores/chroma.py',\n",
       "   'package': 'neurosurfer.vectorstores',\n",
       "   'classes': [{'name': 'ChromaVectorStore',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'add_documents',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'docs']},\n",
       "      {'name': 'similarity_search',\n",
       "       'docstring': None,\n",
       "       'args': ['self',\n",
       "        'query_embedding',\n",
       "        'top_k',\n",
       "        'metadata_filter',\n",
       "        'similarity_threshold']},\n",
       "      {'name': 'clear_collection', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'delete_documents', 'docstring': None, 'args': ['self', 'ids']},\n",
       "      {'name': 'delete_collection', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'count', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'list_all_documents',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'metadata_filter']}]}],\n",
       "   'functions': [{'name': 'DefaultEmbeddingFunction',\n",
       "     'docstring': None,\n",
       "     'args': []}]},\n",
       "  'neurosurfer.utils.helper': {'path': 'utils/helper.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/helper.py',\n",
       "   'package': 'neurosurfer.utils',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'get_uploaded_files',\n",
       "     'docstring': None,\n",
       "     'args': ['project_path', 'extensions', 'exclude_dirs']},\n",
       "    {'name': 'retrieve_filtered_chunks',\n",
       "     'docstring': None,\n",
       "     'args': ['keywords', 'query', 'vector_db', 'top_k']},\n",
       "    {'name': 'keywords_filter_chunks',\n",
       "     'docstring': None,\n",
       "     'args': ['keywords', 'docs']},\n",
       "    {'name': 'create_context', 'docstring': None, 'args': ['results']},\n",
       "    {'name': 'build_chat_context',\n",
       "     'docstring': 'Builds a formatted conversation context string from the last 10 chat history records.\\n\\nArgs:\\n    chat_history (list): List of dicts like {\"role\": \"user\" or \"assistant\", \"content\": \"...\"}\\n\\nReturns:\\n    str: Formatted context string.',\n",
       "     'args': ['chat_history', 'n_recent_chats']},\n",
       "    {'name': 'chat_completion_wrapper',\n",
       "     'docstring': None,\n",
       "     'args': ['call_id', 'model_name', 'content']},\n",
       "    {'name': 'get_text_only_history',\n",
       "     'docstring': None,\n",
       "     'args': ['chat_history', 'num_recent_chats']},\n",
       "    {'name': 'generate_folder_structure',\n",
       "     'docstring': 'Generate a tree-like folder structure.\\nSupports both directory paths and .zip files.\\nIf a zip is given, it is extracted to a temporary directory,\\nprocessed, and then deleted.',\n",
       "     'args': ['root_path', 'max_depth', 'exclude_dirs', 'supported_files']},\n",
       "    {'name': 'reconstruct_code_from_chunks',\n",
       "     'docstring': None,\n",
       "     'args': ['chunks', 'overlap_lines']},\n",
       "    {'name': 'is_prompt_like', 'docstring': None, 'args': ['text']},\n",
       "    {'name': 'mermaid_save_diagram',\n",
       "     'docstring': \"Save Mermaid diagram as an image using Mermaid CLI.\\nArgs:\\n    mermaid_code (str): Mermaid syntax code.\\n    output_path (str): File path to save the image.\\n    image_format (str): 'png' or 'svg'.\\n    background_color (str): Background color.\\n    scale (float): Scale multiplier.\",\n",
       "     'args': ['mermaid_code',\n",
       "      'output_path',\n",
       "      'image_format',\n",
       "      'background_color',\n",
       "      'scale',\n",
       "      'puppeteer_config_path',\n",
       "      'mmdc_path',\n",
       "      'logger']}]},\n",
       "  'neurosurfer.utils.response_wrappers': {'path': 'utils/response_wrappers.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/response_wrappers.py',\n",
       "   'package': 'neurosurfer.utils',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'chat_completion_response_wrapper',\n",
       "     'docstring': None,\n",
       "     'args': ['id', 'model', 'content', 'stream', 'finish_reason']}]},\n",
       "  'neurosurfer.utils.prompts': {'path': 'utils/prompts.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/prompts.py',\n",
       "   'package': 'neurosurfer.utils',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.utils.__init__': {'path': 'utils/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/utils/__init__.py',\n",
       "   'package': 'neurosurfer.utils',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tracing.step_context': {'path': 'tracing/step_context.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/step_context.py',\n",
       "   'package': 'neurosurfer.tracing',\n",
       "   'classes': [{'name': 'TraceStepContext',\n",
       "     'docstring': 'Context manager returned by Tracer.step().\\n\\n- On __enter__:\\n    * records start time\\n    * optionally logs a span \"â–¶ step.<kind>\"\\n- On __exit__:\\n    * sets duration_ms\\n    * sets ok/error\\n    * records a TraceStep via Tracer._record_step()\\n    * does NOT suppress exceptions',\n",
       "     'methods': [{'name': 'set_error',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'error']},\n",
       "      {'name': 'add_meta', 'docstring': None, 'args': ['self', '**kwargs']},\n",
       "      {'name': 'outputs',\n",
       "       'docstring': 'Add arbitrary key/value pairs to `outputs`.\\n\\nTypical usage:\\n    t.outputs(output=normalized_result)\\n    t.outputs(system_prompt=sys, user_prompt=usr)',\n",
       "       'args': ['self', '**kwargs']},\n",
       "      {'name': 'inputs',\n",
       "       'docstring': 'Add arbitrary key/value pairs to `inputs`.\\n\\nTypical usage:\\n    t.inputs(output=normalized_result)\\n    t.inputs(system_prompt=sys, user_prompt=usr)',\n",
       "       'args': ['self', '**kwargs']},\n",
       "      {'name': 'stream',\n",
       "       'docstring': 'Add an internal log line to this step.\\n\\n- Stored in the structured trace result (step.logs)\\n- Printed at the same indentation level as the step spans\\n  when `log_steps=True`.',\n",
       "       'args': ['self', 'message', 'type', '**data']},\n",
       "      {'name': 'log',\n",
       "       'docstring': 'Add an internal log line to this step.\\n\\n- Stored in the structured trace result (step.logs)\\n- Printed at the same indentation level as the step spans\\n  when `log_steps=True`.',\n",
       "       'args': ['self', 'message', 'type', 'type_keyword', '**data']},\n",
       "      {'name': 'start', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'is_closed', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'close', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tracing.models': {'path': 'tracing/models.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/models.py',\n",
       "   'package': 'neurosurfer.tracing',\n",
       "   'classes': [{'name': 'TraceLog',\n",
       "     'docstring': 'A single log entry inside a traced step.',\n",
       "     'methods': []},\n",
       "    {'name': 'TraceStep',\n",
       "     'docstring': 'One traced step in a workflow.\\n\\nFlexible enough to cover:\\n  - LLM calls\\n  - tool calls\\n  - any custom step\\n\\nYou decide how to populate `inputs`, `outputs`, and `meta`.',\n",
       "     'methods': []},\n",
       "    {'name': 'TraceResult',\n",
       "     'docstring': 'Structured tracing results for a single run.\\n\\nYou can attach this object directly to Agent / GraphExecutor outputs.',\n",
       "     'methods': [{'name': 'summary', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tracing.span': {'path': 'tracing/span.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/span.py',\n",
       "   'package': 'neurosurfer.tracing',\n",
       "   'classes': [{'name': 'SpanTracer',\n",
       "     'docstring': 'Low-level span tracer interface.\\n\\nThis is deliberately minimal: it just exposes a `span(name, attrs)` method\\nthat returns a context manager. Span tracers are used by higher-level\\ntracing utilities (e.g., Tracer) to emit human-readable logs.',\n",
       "     'methods': [{'name': 'span',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'name', 'attrs']}]},\n",
       "    {'name': 'ConsoleTracer',\n",
       "     'docstring': \"Span tracer that writes to stdout using `print`.\\n\\nExample line:\\n    [trace] â–¶ step.llm step_id=1 label='agent.llm.ask'\",\n",
       "     'methods': [{'name': 'span',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'name', 'attrs']}]},\n",
       "    {'name': 'LoggerTracer',\n",
       "     'docstring': 'Span tracer that writes to a Python `logging.Logger`.\\n\\nEach span line is logged at INFO level.',\n",
       "     'methods': [{'name': 'span',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'name', 'attrs']}]},\n",
       "    {'name': 'MemorySpanTracer',\n",
       "     'docstring': 'Span tracer that captures span events in-memory.\\n\\nMostly useful for tests or debugging.',\n",
       "     'methods': [{'name': 'span',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'name', 'attrs']}]},\n",
       "    {'name': 'NullSpanTracer',\n",
       "     'docstring': 'No-op span tracer.\\n\\nAll spans are ignored; useful when you want structured tracing\\nbut no human-readable logs.',\n",
       "     'methods': [{'name': 'span',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'name', 'attrs']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tracing.tracer': {'path': 'tracing/tracer.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/tracer.py',\n",
       "   'package': 'neurosurfer.tracing',\n",
       "   'classes': [{'name': 'TracerConfig',\n",
       "     'docstring': 'Configuration options for Tracer.\\n\\nAttributes:\\n    enabled:\\n        If False, `step(...)` becomes a no-op. Your code can always call it.\\n    log_steps:\\n        If True, each step prints human-readable spans via `span_tracer`.\\n    max_output_preview_chars:\\n        When you store large outputs in `t.add(...)`, you may choose to\\n        also store a shortened preview in `outputs[\"preview\"]`.\\n        This class itself doesn\\'t enforce truncation â€” it\\'s up to your\\n        usage â€” but the parameter is here for convenience / future use.',\n",
       "     'methods': []},\n",
       "    {'name': 'Tracer',\n",
       "     'docstring': 'Unified, simple tracing class for agents / graphs.\\n\\nUsage example inside an Agent:\\n\\n    class Agent:\\n        def __init__(..., enable_tracing: bool = False, log_tracing_steps: bool = False):\\n            self.tracer = Tracer(\\n                config=TracerConfig(\\n                    enabled=enable_tracing,\\n                    log_steps=log_tracing_steps,\\n                ),\\n                span_tracer=RichTracer() if log_tracing_steps else NullSpanTracer(),\\n                meta={\"agent_type\": \"generic_agent\"},\\n            )\\n\\n        def run(...):\\n            inputs = {...}\\n            with self.tracer.step(\\n                kind=\"llm\",\\n                label=\"agent.llm.ask\",\\n                inputs=inputs,\\n                node_id=context.get(\"node_id\"),\\n                agent_id=\"main_agent\",\\n            ) as t:\\n                res = self.llm.ask(**inputs)\\n                norm = normalize_tool_observation(res)\\n                t.add(output=norm, raw_response=res)\\n\\n            return AgentResult(\\n                ...,\\n                traces=self.tracer.results,\\n            )\\n\\nKey properties:\\n  - If `config.enabled=False`, `step(...)` returns a no-op context manager\\n    and no steps are recorded â€” your calling code doesn\\'t change.\\n  - Each step has:\\n      * auto-incremented step_id\\n      * timing (started_at, duration_ms)\\n      * ok/error (based on exceptions)\\n      * inputs/outputs/meta dicts\\n  - `results` returns a `TraceResult` Pydantic model.',\n",
       "     'methods': [{'name': 'meta',\n",
       "       'docstring': 'Metadata attached to the whole trace run (e.g. graph_name, run_id).',\n",
       "       'args': ['self']},\n",
       "      {'name': 'set_meta',\n",
       "       'docstring': 'Update global metadata for this tracer.',\n",
       "       'args': ['self', '**kwargs']},\n",
       "      {'name': 'results',\n",
       "       'docstring': 'Structured tracing results for this run.',\n",
       "       'args': ['self']},\n",
       "      {'name': 'reset', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tracing.__init__': {'path': 'tracing/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tracing/__init__.py',\n",
       "   'package': 'neurosurfer.tracing',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.embedders.sentence_transformer': {'path': 'models/embedders/sentence_transformer.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/sentence_transformer.py',\n",
       "   'package': 'neurosurfer.models.embedders',\n",
       "   'classes': [{'name': 'SentenceTransformerEmbedder',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'embed',\n",
       "       'docstring': None,\n",
       "       'args': ['self',\n",
       "        'query',\n",
       "        'convert_to_tensor',\n",
       "        'normalize_embeddings']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.embedders.base': {'path': 'models/embedders/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/base.py',\n",
       "   'package': 'neurosurfer.models.embedders',\n",
       "   'classes': [{'name': 'BaseEmbedder',\n",
       "     'docstring': 'Abstract base class for all embedding models in Neurosurfer.\\n\\nThis class provides a unified interface for generating text embeddings\\nfrom various backends. Embeddings are used for semantic search, RAG,\\nand similarity computations.\\n\\nAttributes:\\n    logger (logging.Logger): Logger instance for debugging\\n    model: The underlying embedding model instance (implementation-specific)\\n\\nAbstract Methods:\\n    embed(): Generate embeddings for single or multiple text inputs\\n\\nExample:\\n    >>> class MyEmbedder(BaseEmbedder):\\n    ...     def embed(self, query, **kwargs):\\n    ...         # Generate embeddings\\n    ...         return embeddings\\n    >>> \\n    >>> embedder = MyEmbedder()\\n    >>> embedding = embedder.embed(\"Hello world\")\\n    >>> embeddings = embedder.embed([\"Text 1\", \"Text 2\"])',\n",
       "     'methods': [{'name': 'embed',\n",
       "       'docstring': 'Generate embeddings for text input(s).\\n\\nThis method must be implemented by all concrete embedder classes.\\nIt should handle both single strings and lists of strings.\\n\\nArgs:\\n    query (Union[str, List[str]]): Single text string or list of text strings\\n    **kwargs: Additional embedder-specific parameters (e.g., normalize_embeddings)\\n\\nReturns:\\n    Union[List[float], List[List[float]]]:\\n        - If query is str: Returns List[float] (single embedding vector)\\n        - If query is List[str]: Returns List[List[float]] (list of embedding vectors)\\n\\nExample:\\n    >>> # Single text\\n    >>> embedding = embedder.embed(\"Hello world\")\\n    >>> len(embedding)  # e.g., 384 for all-MiniLM-L6-v2\\n    384\\n    \\n    >>> # Multiple texts\\n    >>> embeddings = embedder.embed([\"Text 1\", \"Text 2\"])\\n    >>> len(embeddings)\\n    2',\n",
       "       'args': ['self', 'query', '**kwargs']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.embedders.llamacpp': {'path': 'models/embedders/llamacpp.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/llamacpp.py',\n",
       "   'package': 'neurosurfer.models.embedders',\n",
       "   'classes': [{'name': 'LlamaCppEmbedder',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'embed',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'query', 'normalize_embeddings']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.embedders.__init__': {'path': 'models/embedders/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/embedders/__init__.py',\n",
       "   'package': 'neurosurfer.models.embedders',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.chat_models.transformers': {'path': 'models/chat_models/transformers.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/transformers.py',\n",
       "   'package': 'neurosurfer.models.chat_models',\n",
       "   'classes': [{'name': 'StopSignalCriteria',\n",
       "     'docstring': None,\n",
       "     'methods': []},\n",
       "    {'name': 'TransformersModel',\n",
       "     'docstring': 'HF Transformers local model - now returns Pydantic models',\n",
       "     'methods': [{'name': 'stop_generation',\n",
       "       'docstring': None,\n",
       "       'args': ['self']},\n",
       "      {'name': 'set_stop_words', 'docstring': None, 'args': ['self', 'stops']},\n",
       "      {'name': 'init_model',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'load_in_4bit', '**kwargs']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.chat_models.base': {'path': 'models/chat_models/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/base.py',\n",
       "   'package': 'neurosurfer.models.chat_models',\n",
       "   'classes': [{'name': 'BaseChatModel',\n",
       "     'docstring': 'Abstract base class for all chat models in Neurosurfer.\\n\\nThis class provides a unified interface for interacting with different LLM backends\\nwhile maintaining OpenAI-compatible response formats. All model implementations\\n(Transformers, Unsloth, vLLM, LlamaCpp, OpenAI) inherit from this class.\\n\\nAttributes:\\n    model_name (str): Identifier for the model (default: \"local-gpt\")\\n    verbose (bool): Enable verbose logging\\n    logger (logging.Logger): Logger instance for debugging\\n    call_id (str): Unique identifier for each generation call\\n    lock (Lock): Thread lock for concurrent access control\\n    model: The underlying model instance (implementation-specific)\\n    max_seq_length (int): Maximum context window size in tokens\\n\\nAbstract Methods:\\n    init_model(): Initialize the underlying model and tokenizer\\n    _call(): Perform non-streaming generation\\n    _stream(): Perform streaming generation\\n    stop_generation(): Stop ongoing generation\\n\\nExample:\\n    >>> class MyModel(BaseChatModel):\\n    ...     def init_model(self):\\n    ...         # Load model\\n    ...         pass\\n    ...     \\n    ...     def _call(self, user_prompt, system_prompt, **kwargs):\\n    ...         # Generate response\\n    ...         return self._final_nonstream_response(...)\\n    ...     \\n    ...     def _stream(self, user_prompt, system_prompt, **kwargs):\\n    ...         # Stream response\\n    ...         for token in tokens:\\n    ...             yield self._delta_chunk(...)\\n    ...         yield self._stop_chunk(...)',\n",
       "     'methods': [{'name': 'set_stop_signal',\n",
       "       'docstring': 'Set stop signal to halt generation',\n",
       "       'args': ['self']},\n",
       "      {'name': 'reset_stop_signal',\n",
       "       'docstring': 'Reset stop signal before new generation',\n",
       "       'args': ['self']},\n",
       "      {'name': 'init_model', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'ask',\n",
       "       'docstring': 'Main entry point for generating model responses.\\n\\nThis method provides a unified interface for both streaming and non-streaming\\ngeneration. It automatically routes to _call() or _stream() based on the\\nstream parameter.\\n\\nArgs:\\n    user_prompt (str): The user\\'s input message/question\\n    system_prompt (str): System-level instructions for the model.\\n        Default: \"You are a helpful assistant. Answer questions to the best of your ability.\"\\n    chat_history (List[dict]): Conversation history as list of message dicts.\\n        Each dict should have \\'role\\' and \\'content\\' keys. Default: []\\n    temperature (float): Sampling temperature (0.0-2.0). Lower = more deterministic,\\n        higher = more creative. Default: 0.7\\n    max_new_tokens (int): Maximum number of tokens to generate. Default: 2000\\n    stream (bool): Enable streaming response. Default: False\\n    **kwargs: Additional model-specific generation parameters\\n\\nReturns:\\n    LLM_RESPONSE_TYPE:\\n        - If stream=False: Returns ChatCompletionResponse (Pydantic model)\\n        - If stream=True: Returns Generator yielding ChatCompletionChunk objects\\n\\nExample:\\n    >>> # Non-streaming\\n    >>> response = model.ask(\"What is AI?\", temperature=0.5)\\n    >>> print(response.choices[0].message.content)\\n    \\n    >>> # Streaming\\n    >>> for chunk in model.ask(\"Explain quantum computing\", stream=True):\\n    ...     print(chunk.choices[0].delta.content, end=\"\")            ',\n",
       "       'args': ['self',\n",
       "        'user_prompt',\n",
       "        'system_prompt',\n",
       "        'chat_history',\n",
       "        'temperature',\n",
       "        'max_new_tokens',\n",
       "        'stream',\n",
       "        '**kwargs']},\n",
       "      {'name': 'stop_generation', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'silent', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.chat_models.unsloth': {'path': 'models/chat_models/unsloth.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/unsloth.py',\n",
       "   'package': 'neurosurfer.models.chat_models',\n",
       "   'classes': [{'name': 'StopSignalCriteria',\n",
       "     'docstring': 'Custom stopping criteria that checks a stop signal function',\n",
       "     'methods': []},\n",
       "    {'name': 'UnslothModel',\n",
       "     'docstring': 'Unsloth FastLanguageModel wrapper with Pydantic response models.\\n\\nFeatures:\\n- Returns ChatCompletionResponse for non-streaming\\n- Yields ChatCompletionChunk for streaming\\n- Thread-safe stop signal\\n- Stop words support (truncates before stop sequence)\\n- Optional thinking mode with <think> tag suppression\\n- Token usage tracking',\n",
       "     'methods': [{'name': 'init_model',\n",
       "       'docstring': 'Initialize Unsloth model with specified configuration',\n",
       "       'args': ['self', '**kwargs']},\n",
       "      {'name': 'set_stop_words',\n",
       "       'docstring': 'Update stop words list',\n",
       "       'args': ['self', 'stops']},\n",
       "      {'name': 'stop_generation',\n",
       "       'docstring': 'Signal the model to stop generation immediately.\\nThread-safe operation.',\n",
       "       'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.chat_models.llamacpp': {'path': 'models/chat_models/llamacpp.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/llamacpp.py',\n",
       "   'package': 'neurosurfer.models.chat_models',\n",
       "   'classes': [{'name': 'LlamaCppModel',\n",
       "     'docstring': 'llama.cpp model wrapper with Pydantic responses.\\n\\nFeatures:\\n- Supports both local GGUF files and HuggingFace repos\\n- Streaming and non-streaming completions\\n- Thread-safe generation\\n- Token usage tracking\\n- Stop signal support',\n",
       "     'methods': [{'name': 'init_model',\n",
       "       'docstring': 'Initialize llama.cpp model from local file or HuggingFace repo',\n",
       "       'args': ['self', '**kwargs']},\n",
       "      {'name': 'stop_generation',\n",
       "       'docstring': 'Signal to stop the current generation',\n",
       "       'args': ['self']},\n",
       "      {'name': 'set_stop_words',\n",
       "       'docstring': 'Update stop words list',\n",
       "       'args': ['self', 'stops']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.chat_models.__init__': {'path': 'models/chat_models/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/__init__.py',\n",
       "   'package': 'neurosurfer.models.chat_models',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.models.chat_models.openai': {'path': 'models/chat_models/openai.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/models/chat_models/openai.py',\n",
       "   'package': 'neurosurfer.models.chat_models',\n",
       "   'classes': [{'name': 'OpenAIModel',\n",
       "     'docstring': 'An OpenAI/compatible chat client implementing BaseChatModel with Pydantic responses.\\n\\nWorks with:\\n  â€¢ OpenAI Cloud (leave base_url=None, set a real api_key)\\n  â€¢ LM Studio local server (e.g., base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\\n  â€¢ vLLM OpenAI server (e.g., base_url=\"http://localhost:8000/v1\")\\n  â€¢ Ollama OpenAI compat (e.g., base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")',\n",
       "     'methods': [{'name': 'init_model', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'strip_reasoning_text',\n",
       "       'docstring': 'Remove reasoning blocks from text',\n",
       "       'args': ['self', 'text']},\n",
       "      {'name': 'stop_generation',\n",
       "       'docstring': 'Set stop signal to halt generation',\n",
       "       'args': ['self']},\n",
       "      {'name': 'set_stop_words',\n",
       "       'docstring': 'Update stop words list',\n",
       "       'args': ['self', 'stops']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.runtime.checks': {'path': 'runtime/checks.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/runtime/checks.py',\n",
       "   'package': 'neurosurfer.runtime',\n",
       "   'classes': [{'name': 'DeviceInfo', 'docstring': None, 'methods': []}],\n",
       "   'functions': [{'name': 'detect_devices', 'docstring': None, 'args': []},\n",
       "    {'name': 'banner', 'docstring': None, 'args': ['info']},\n",
       "    {'name': 'print_banner_once', 'docstring': None, 'args': []},\n",
       "    {'name': 'warn_optional_llm_stack',\n",
       "     'docstring': 'Soft-check: warn if the LLM stack is missing. Called on import.',\n",
       "     'args': []},\n",
       "    {'name': 'require',\n",
       "     'docstring': 'Import a module or raise a RuntimeError with a helpful install hint.\\nUse in your code paths that need optional frameworks.',\n",
       "     'args': ['module', 'feature', 'install_hint']},\n",
       "    {'name': 'assert_minimum_runtime',\n",
       "     'docstring': 'Ensure core LLM runtime deps are present; call early in LLM/model startup paths.\\nKeep this OUT of global import to avoid hard-failing lightweight installs.',\n",
       "     'args': []},\n",
       "    {'name': 'diagnostic_report', 'docstring': None, 'args': []}]},\n",
       "  'neurosurfer.runtime.paths': {'path': 'runtime/paths.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/runtime/paths.py',\n",
       "   'package': 'neurosurfer.runtime',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'get_cache_dir',\n",
       "     'docstring': 'Return the per-user cache directory for Neurosurfer, creating it if needed.\\nRespects NEUROSURF_CACHE_DIR if set; otherwise uses platform-specific defaults.\\nLinux:  ~/.cache/Neurosurfer\\nmacOS:  ~/Library/Caches/Neurosurfer\\nWindows: %LOCALAPPDATA%\\\\Neurosurfer\\\\Cache (per platformdirs)',\n",
       "     'args': ['create', 'suffix']}]},\n",
       "  'neurosurfer.server.reset': {'path': 'server/reset.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/reset.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'reset_db',\n",
       "     'docstring': 'Clear all chats and threads from the database. Only leave Users Information.',\n",
       "     'args': []}]},\n",
       "  'neurosurfer.server.models_registry': {'path': 'server/models_registry.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/models_registry.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [{'name': 'ModelInfo', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ModelRegistry',\n",
       "     'docstring': 'Registry for managing AI models and their metadata.\\n\\nThis class provides a centralized registry for tracking available models,\\ntheir capabilities, and metadata. Used by the server to validate model\\nrequests and provide model information to clients.\\n\\nAttributes:\\n    _models (Dict[str, ModelCard]): Internal registry mapping model IDs to model cards\\n\\nExample:\\n    >>> registry = ModelRegistry()\\n    >>> \\n    >>> # Add models\\n    >>> registry.add(\\n    ...     id=\"llama-3-8b\",\\n    ...     family=\"Llama\",\\n    ...     provider=\"Meta\",\\n    ...     context_length=8192,\\n    ...     description=\"Llama 3 8B parameter model\"\\n    ... )\\n    >>> \\n    >>> # Retrieve model info\\n    >>> model = registry.get(\"llama-3-8b\")\\n    >>> print(f\"{model.family} - {model.context_length} tokens\")\\n    Llama - 8192 tokens\\n    >>> \\n    >>> # Check availability\\n    >>> registry.exists(\"gpt-4\")\\n    False',\n",
       "     'methods': [{'name': 'add',\n",
       "       'docstring': 'Register a new model in the registry.\\n\\nArgs:\\n    id (str): Unique model identifier\\n    family (str): Model family/architecture. Default: \"Unknown\"\\n    provider (Optional[str]): Model provider (e.g., \"OpenAI\", \"Meta\"). Default: None\\n    context_length (int): Maximum context window size in tokens. Default: None\\n    description (Optional[str]): Human-readable model description. Default: None\\n\\nRaises:\\n    ValueError: If model ID is already registered\\n\\nExample:\\n    >>> registry.add(\\n    ...     id=\"gpt-3.5-turbo\",\\n    ...     family=\"GPT\",\\n    ...     provider=\"OpenAI\",\\n    ...     context_length=4096,\\n    ...     description=\"Fast and efficient GPT-3.5 model\"\\n    ... )',\n",
       "       'args': ['self', 'llm', 'family', 'provider', 'description']},\n",
       "      {'name': 'get_first_available',\n",
       "       'docstring': 'Retrieve the first available model from the registry.\\n\\nReturns:\\n    ModelInfo: First available model in the registry\\n\\nRaises:\\n    ValueError: If no models are registered\\n\\nExample:\\n    >>> model = registry.get_first_available()\\n    >>> print(model.model_card.id)\\n    gpt-4',\n",
       "       'args': ['self']},\n",
       "      {'name': 'get',\n",
       "       'docstring': 'Retrieve model card by ID.\\n\\nArgs:\\n    model_id (str): Model identifier to look up\\n\\nReturns:\\n    ModelCard: Model card containing model metadata\\n\\nRaises:\\n    KeyError: If model ID is not found in registry\\n\\nExample:\\n    >>> model = registry.get(\"gpt-4\")\\n    >>> print(model.context_length)\\n    8192',\n",
       "       'args': ['self', 'model_id']},\n",
       "      {'name': 'exists',\n",
       "       'docstring': 'Check if a model is registered.\\n\\nArgs:\\n    model_id (str): Model identifier to check\\n\\nReturns:\\n    bool: True if model exists in registry, False otherwise\\n\\nExample:\\n    >>> registry.exists(\"gpt-4\")\\n    True\\n    >>> registry.exists(\"unknown-model\")\\n    False',\n",
       "       'args': ['self', 'model_id']},\n",
       "      {'name': 'all',\n",
       "       'docstring': 'Get all registered models.\\n\\nReturns:\\n    Dict[str, ModelCard]: Dictionary mapping model IDs to model cards\\n\\nExample:\\n    >>> all_models = registry.all()\\n    >>> for model_id, model_card in all_models.items():\\n    ...     print(f\"{model_id}: {model_card.family}\")\\n    gpt-4: GPT\\n    llama-3-8b: Llama',\n",
       "       'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.utils': {'path': 'server/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/utils.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [{'name': 'ApplicationPaths',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'rag_storage_path',\n",
       "       'docstring': None,\n",
       "       'args': ['user_id', 'thread_id']},\n",
       "      {'name': 'user_storage_path', 'docstring': None, 'args': ['user_id']},\n",
       "      {'name': 'thread_storage_path',\n",
       "       'docstring': None,\n",
       "       'args': ['user_id', 'thread_id']},\n",
       "      {'name': 'thread_files_storage_path',\n",
       "       'docstring': None,\n",
       "       'args': ['user_id', 'thread_id']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.runtime': {'path': 'server/runtime.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/runtime.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [{'name': 'RequestContext',\n",
       "     'docstring': 'Container for request-specific runtime context.\\n\\nHolds metadata and control signals for a single request/operation,\\nenabling cancellation and context passing throughout the request lifecycle.\\n\\nAttributes:\\n    op_id (str): Unique operation identifier (e.g., \"op_a1b2c3d4e5f6\")\\n    stop_event (threading.Event): Event for signaling operation cancellation\\n    headers (dict): Request headers or additional metadata\\n\\nExample:\\n    >>> ctx = RequestContext(\\n    ...     op_id=\"op_123\",\\n    ...     stop_event=threading.Event(),\\n    ...     headers={\"user-agent\": \"client/1.0\"}\\n    ... )\\n    >>> \\n    >>> # Check if operation should stop\\n    >>> if ctx.stop_event.is_set():\\n    ...     return \"Operation cancelled\"',\n",
       "     'methods': []},\n",
       "    {'name': 'OperationManager',\n",
       "     'docstring': 'Manages operation lifecycle and cancellation signals.\\n\\nThis class provides centralized management of active operations,\\nallowing creation, cancellation, and cleanup of request contexts.\\nThread-safe for concurrent access.\\n\\nAttributes:\\n    _ops (Dict[str, threading.Event]): Mapping of operation IDs to stop events\\n\\nExample:\\n    >>> manager = OperationManager()\\n    >>> \\n    >>> # Create new operation\\n    >>> ctx = manager.create()\\n    >>> \\n    >>> # Stop from another thread\\n    >>> manager.stop(ctx.op_id)\\n    >>> \\n    >>> # Clean up\\n    >>> manager.done(ctx.op_id)',\n",
       "     'methods': [{'name': 'create',\n",
       "       'docstring': \"Create a new operation context with unique ID.\\n\\nGenerates a unique operation ID, creates a stop event, and\\nregisters the operation for lifecycle management.\\n\\nReturns:\\n    RequestContext: New request context with unique op_id and stop_event\\n\\nExample:\\n    >>> ctx = op_manager.create()\\n    >>> print(ctx.op_id)\\n    'op_a1b2c3d4e5f6'\\n    >>> ctx.stop_event.is_set()\\n    False\",\n",
       "       'args': ['self']},\n",
       "      {'name': 'stop',\n",
       "       'docstring': 'Signal an operation to stop.\\n\\nSets the stop event for the specified operation, allowing\\nthe operation to gracefully terminate.\\n\\nArgs:\\n    op_id (str): Operation ID to stop\\n\\nReturns:\\n    bool: True if operation was found and stopped, False if not found\\n\\nExample:\\n    >>> ctx = op_manager.create()\\n    >>> # ... operation running ...\\n    >>> success = op_manager.stop(ctx.op_id)\\n    >>> print(success)\\n    True\\n    >>> ctx.stop_event.is_set()\\n    True',\n",
       "       'args': ['self', 'op_id']},\n",
       "      {'name': 'done',\n",
       "       'docstring': \"Clean up a completed operation.\\n\\nRemoves the operation from the registry after completion.\\nSafe to call even if operation doesn't exist.\\n\\nArgs:\\n    op_id (str): Operation ID to clean up\\n\\nExample:\\n    >>> ctx = op_manager.create()\\n    >>> # ... operation completes ...\\n    >>> op_manager.done(ctx.op_id)\",\n",
       "       'args': ['self', 'op_id']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.config': {'path': 'server/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/config.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.app': {'path': 'server/app.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/app.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [{'name': 'NeurosurferApp',\n",
       "     'docstring': 'A comprehensive FastAPI-based application builder for AI-powered chat and API services.\\n\\nNeurosurferApp provides a simplicity-first approach to building AI applications with:\\n- Single chat handler registration via decorator or method\\n- Custom endpoint creation with one-line decorators\\n- Built-in authentication (API key or JWT-based)\\n- Database integration\\n- CORS support for cross-origin requests\\n- Automatic API documentation (Swagger/OpenAPI)\\n- Model registry for managing AI models\\n- Lifecycle management with startup/shutdown hooks\\n\\nThe app supports both simple API key authentication and full user authentication\\nwith JWT tokens. It includes built-in routes for health checks, model listings,\\nchat completions, and user management.\\n\\nKey Features:\\n- FastAPI-based with automatic OpenAPI documentation\\n- SQLAlchemy ORM for database operations\\n- Session middleware for CSRF protection\\n- Model registry for AI model management\\n- Flexible authentication (API key or JWT)\\n- CORS support for web applications\\n- Startup and shutdown lifecycle hooks\\n- Built-in routes for common operations\\n\\nExample:\\n    ```python\\n    from neurosurfer.server.app import NeurosurferApp\\n\\n    app = NeurosurferApp(api_key=\"your-api-key\")\\n\\n    @app.chat()\\n    def handle_chat(request, context):\\n        # Handle chat request and return response\\n        return {\"response\": \"Hello!\"}\\n\\n    if __name__ == \"__main__\":\\n        app.run()\\n    ```',\n",
       "     'methods': [{'name': 'register_model',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'model', 'provider', 'family', 'description']},\n",
       "      {'name': 'get_model', 'docstring': None, 'args': ['self', 'model_name']},\n",
       "      {'name': 'apply_rag',\n",
       "       'docstring': None,\n",
       "       'args': ['self',\n",
       "        'user_id',\n",
       "        'thread_id',\n",
       "        'message_id',\n",
       "        'user_query',\n",
       "        'has_files_message']},\n",
       "      {'name': 'require_api_key',\n",
       "       'docstring': 'Validate API key authentication for incoming requests.\\n\\nThis method checks if the request contains a valid API key in the Authorization header.\\nIf no API key is configured for the app, authentication is skipped.\\n\\nArgs:\\n    req (Request): The incoming FastAPI request object containing headers.\\n\\nRaises:\\n    HTTPException: If the API key is configured but missing or invalid, raises a 401\\n        Unauthorized exception with details about the authentication failure.\\n\\nNote:\\n    The expected format is: \"Bearer <api_key>\" in the Authorization header.\\n    If the API key is configured but the request doesn\\'t have a valid key,\\n    the request is rejected with a 401 status code.',\n",
       "       'args': ['self', 'req']},\n",
       "      {'name': 'require_auth',\n",
       "       'docstring': 'Authenticate requests using either API key or JWT-based user authentication.\\n\\nThis method implements a flexible authentication strategy that supports both:\\n1. API key authentication (for service-to-service communication)\\n2. JWT-based user authentication (for user sessions)\\n\\nThe method first checks for a valid API key if one is configured. If an API key\\nis provided and valid, the request is authenticated as a service/system caller.\\nOtherwise, it falls back to JWT-based user authentication.\\n\\nArgs:\\n    req (Request): The incoming FastAPI request object containing headers and state.\\n    response (Response): The FastAPI response object for potential cookie refresh.\\n    db (Session): SQLAlchemy database session for user authentication queries.\\n\\nRaises:\\n    HTTPException: If neither API key nor valid user authentication is provided,\\n        raises a 401 Unauthorized exception.\\n\\nNote:\\n    - API key format: \"Bearer <api_key>\" in Authorization header\\n    - For API key auth: sets req.state.user = None (indicates service caller)\\n    - For JWT auth: sets req.state.user to the authenticated user object\\n    - If API key is configured, it takes precedence over user authentication',\n",
       "       'args': ['self', 'req', 'response', 'db']},\n",
       "      {'name': 'on_startup',\n",
       "       'docstring': 'Register a function to be executed during application startup.\\n\\nThis decorator allows you to register callback functions that will be executed\\nwhen the FastAPI application starts up. The functions can be either synchronous\\nor asynchronous (coroutines).\\n\\nArgs:\\n    fn (Callable[[], Any]): A callable that takes no arguments and returns Any.\\n        Can be either a regular function or an async function (coroutine).\\n\\nReturns:\\n    Callable: The original function, allowing this to be used as a decorator.\\n\\nExample:\\n    ```python\\n    app = NeurosurferApp()\\n\\n    @app.on_startup\\n    def initialize_database():\\n        print(\"Setting up database connections...\")\\n\\n    @app.on_startup\\n    async def load_models():\\n        print(\"Loading AI models...\")\\n        await some_async_operation()\\n    ```\\n\\nNote:\\n    - Startup functions are executed in the order they are registered\\n    - Async functions are properly awaited during the startup process\\n    - These functions run before the server starts accepting requests',\n",
       "       'args': ['self', 'fn']},\n",
       "      {'name': 'on_shutdown',\n",
       "       'docstring': 'Register a function to be executed during application shutdown.\\n\\nThis decorator allows you to register callback functions that will be executed\\nwhen the FastAPI application shuts down gracefully. The functions can be either\\nsynchronous or asynchronous (coroutines).\\n\\nArgs:\\n    fn (Callable[[], Any]): A callable that takes no arguments and returns Any.\\n        Can be either a regular function or an async function (coroutine).\\n\\nReturns:\\n    Callable: The original function, allowing this to be used as a decorator.\\n\\nExample:\\n    ```python\\n    app = NeurosurferApp()\\n\\n    @app.on_shutdown\\n    def cleanup_resources():\\n        print(\"Cleaning up resources...\")\\n\\n    @app.on_shutdown\\n    async def save_state():\\n        print(\"Saving application state...\")\\n        await some_async_cleanup()\\n    ```\\n\\nNote:\\n    - Shutdown functions are executed in the order they are registered\\n    - Async functions are properly awaited during the shutdown process\\n    - These functions run after the server stops accepting requests\\n    - Useful for cleanup operations, saving state, or closing connections',\n",
       "       'args': ['self', 'fn']},\n",
       "      {'name': 'chat',\n",
       "       'docstring': 'Decorator to register the primary chat handler for the application.\\n\\nThis method serves as a decorator factory that allows you to register a single\\nchat handler function that will process all chat requests. The decorated function\\nwill be automatically integrated with the FastAPI routing system and will be\\naccessible via the chat completions API endpoints.\\n\\nThe decorator triggers the mounting of built-in routes including health checks,\\nmodel listings, and chat completion endpoints.\\n\\nReturns:\\n    Callable: A decorator function that registers the chat handler.\\n\\nExample:\\n    ```python\\n    app = NeurosurferApp()\\n    @app.chat()\\n    def handle_chat(request_data):\\n        # Process the chat request\\n        user_message = request_data.get(\"messages\", [{}])[-1].get(\"content\", \"\")\\n        # Generate response\\n        return {\\n            \"choices\": [{\\n                \"message\": {\\n                    \"role\": \"assistant\",\\n                    \"content\": f\"You said: {user_message}\"\\n                }\\n            }]\\n        }\\n\\n    # Alternative: async handler\\n    @app.chat()\\n    async def handle_chat_async(request_data):\\n        # Async processing\\n        response = await some_async_ai_call(request_data)\\n        return response\\n    ```\\n\\nNote:\\n    - Only one chat handler can be registered per application instance\\n    - The handler function should accept request data and return response data\\n    - Async handlers are supported and properly awaited\\n    - The decorator automatically mounts all necessary routes',\n",
       "       'args': ['self']},\n",
       "      {'name': 'endpoint',\n",
       "       'docstring': 'Create a decorator for registering custom API endpoints.\\n\\nThis method serves as a decorator factory that allows you to easily create custom\\nAPI endpoints with automatic request/response model validation, dependency injection,\\nand integration with FastAPI\\'s routing system.\\n\\nArgs:\\n    path (str): The URL path for the endpoint (e.g., \"/api/summarize\").\\n    method (str, optional): HTTP method for the endpoint. Must be one of:\\n        \"get\", \"post\", \"put\", \"patch\", \"delete\". Defaults to \"post\".\\n    request (Type[BaseModel], optional): Pydantic model class for request body validation.\\n        If provided, FastAPI will automatically parse and validate the request body.\\n        Defaults to None.\\n    response (Type[BaseModel], optional): Pydantic model class for response serialization.\\n        If provided, FastAPI will automatically serialize the response to match this model.\\n        Defaults to None.\\n    dependencies (list[Callable[..., Any]], optional): List of FastAPI dependency functions\\n        that will be executed before the endpoint handler. Useful for authentication,\\n        database sessions, etc. Defaults to None.\\n\\nReturns:\\n    Callable: A decorator function that registers the endpoint.\\n\\nExample:\\n    ```python\\n    from pydantic import BaseModel\\n\\n    class SummarizeRequest(BaseModel):\\n        text: str\\n        max_length: int = 100\\n\\n    class SummarizeResponse(BaseModel):\\n        summary: str\\n        original_length: int\\n        summary_length: int\\n\\n    app = NeurosurferApp()\\n\\n    @app.endpoint(\\n        \"/summarize\",\\n        method=\"post\",\\n        request=SummarizeRequest,\\n        response=SummarizeResponse\\n    )\\n    def summarize_text(data: SummarizeRequest):\\n        # data is automatically parsed and validated\\n        summary = summarize_function(data.text, data.max_length)\\n        return SummarizeResponse(\\n            summary=summary,\\n            original_length=len(data.text),\\n            summary_length=len(summary)\\n        )\\n\\n    # GET endpoint without request/response models\\n    @app.endpoint(\"/health\", method=\"get\")\\n    def custom_health():\\n        return {\"status\": \"custom health check\"}\\n    ```\\n\\nRaises:\\n    ValueError: If the provided HTTP method is not supported.\\n\\nNote:\\n    - The decorated function can access the request body via its first parameter\\n    - Request and response models provide automatic validation and serialization\\n    - Dependencies are executed before the endpoint handler runs\\n    - The endpoint is automatically registered with the main router',\n",
       "       'args': ['self',\n",
       "        'path',\n",
       "        'method',\n",
       "        'request',\n",
       "        'response',\n",
       "        'dependencies']},\n",
       "      {'name': 'run',\n",
       "       'docstring': 'Start the FastAPI application server using Uvicorn.\\n\\nThis method launches the configured FastAPI application using the Uvicorn ASGI server.\\nThe server will start with the configuration specified during initialization including\\nhost, port, reload settings, logging level, and worker processes.\\n\\nThe method handles server startup and graceful error handling. If the server fails\\nto start, it logs an error message with details about the failure.\\n\\nConfiguration used:\\n- host: Server bind address (from __init__)\\n- port: Server port number (from __init__)\\n- reload: Auto-reload during development (from __init__)\\n- log_level: Logging verbosity (from __init__)\\n- workers: Number of worker processes (from __init__)\\n\\nExample:\\n    ```python\\n    app = NeurosurferApp(port=9000, reload=True)\\n\\n    # Start the server\\n    app.run()\\n    ```\\n\\nNote:\\n    - This method blocks the current thread while the server is running\\n    - Use Ctrl+C or send SIGTERM to stop the server gracefully\\n    - In production, consider using a process manager like gunicorn\\n    - The method will not return until the server is stopped',\n",
       "       'args': ['self', 'host', 'port', 'reload', 'log_level', 'workers']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.security': {'path': 'server/security.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/security.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'get_db',\n",
       "     'docstring': 'Database session dependency for FastAPI.\\n\\nCreates a new database session for each request and ensures\\nit\\'s properly closed after the request completes.\\n\\nYields:\\n    Session: SQLAlchemy database session\\n\\nExample:\\n    >>> from fastapi import Depends\\n    >>> from neurosurfer.server.security import get_db\\n    >>> \\n    >>> @app.get(\"/users\")\\n    >>> def list_users(db: Session = Depends(get_db)):\\n    ...     return db.query(User).all()',\n",
       "     'args': []},\n",
       "    {'name': 'hash_password',\n",
       "     'docstring': 'Hash a password using bcrypt.\\n\\nArgs:\\n    password (str): Plain text password to hash\\n\\nReturns:\\n    str: Bcrypt hashed password\\n\\nExample:\\n    >>> hashed = hash_password(\"my-secure-password\")\\n    >>> print(hashed[:7])\\n    \\'$2b$12$\\'',\n",
       "     'args': ['password']},\n",
       "    {'name': 'verify_password',\n",
       "     'docstring': 'Verify a password against its hash.\\n\\nArgs:\\n    plain (str): Plain text password to verify\\n    hashed (str): Bcrypt hashed password to compare against\\n\\nReturns:\\n    bool: True if password matches, False otherwise\\n\\nExample:\\n    >>> hashed = hash_password(\"password123\")\\n    >>> verify_password(\"password123\", hashed)\\n    True\\n    >>> verify_password(\"wrong-password\", hashed)\\n    False',\n",
       "     'args': ['plain', 'hashed']},\n",
       "    {'name': 'create_access_token',\n",
       "     'docstring': 'Create a JWT access token.\\n\\nGenerates a signed JWT token with expiration time. The \\'sub\\' (subject)\\nfield is automatically converted to string if present.\\n\\nArgs:\\n    data (dict): Token payload data (typically {\"sub\": user_id})\\n    expires_minutes (Optional[int]): Token expiration in minutes.\\n        Default: ACCESS_TOKEN_EXPIRE_MINUTES from config\\n\\nReturns:\\n    str: Encoded JWT token\\n\\nExample:\\n    >>> token = create_access_token({\"sub\": \"user123\"})\\n    >>> print(token[:20])\\n    \\'eyJhbGciOiJIUzI1NiIs\\'\\n    >>> \\n    >>> # Custom expiration\\n    >>> short_token = create_access_token({\"sub\": \"user123\"}, expires_minutes=15)',\n",
       "     'args': ['data', 'expires_minutes']},\n",
       "    {'name': 'decode_token',\n",
       "     'docstring': 'Decode and validate a JWT token.\\n\\nArgs:\\n    token (str): JWT token to decode\\n\\nReturns:\\n    dict: Decoded token payload\\n\\nRaises:\\n    JWTError: If token is invalid or expired\\n\\nExample:\\n    >>> token = create_access_token({\"sub\": \"user123\"})\\n    >>> payload = decode_token(token)\\n    >>> print(payload[\"sub\"])\\n    \\'user123\\'',\n",
       "     'args': ['token']},\n",
       "    {'name': 'set_login_cookie',\n",
       "     'docstring': 'Set authentication cookie in response.\\n\\nConfigures a secure HttpOnly cookie with the JWT token,\\nusing settings from config (secure, samesite, max_age).\\n\\nArgs:\\n    response (Response): FastAPI response object\\n    token (str): JWT token to store in cookie\\n\\nExample:\\n    >>> from fastapi import Response\\n    >>> response = Response()\\n    >>> token = create_access_token({\"sub\": \"user123\"})\\n    >>> set_login_cookie(response, token)',\n",
       "     'args': ['response', 'token']},\n",
       "    {'name': 'clear_login_cookie',\n",
       "     'docstring': 'Clear authentication cookie from response.\\n\\nRemoves the authentication cookie, effectively logging out the user.\\n\\nArgs:\\n    response (Response): FastAPI response object\\n\\nExample:\\n    >>> from fastapi import Response\\n    >>> response = Response()\\n    >>> clear_login_cookie(response)',\n",
       "     'args': ['response']},\n",
       "    {'name': 'get_current_user',\n",
       "     'docstring': 'FastAPI dependency for getting the current authenticated user.\\n\\nExtracts and validates the JWT token from request headers or cookies,\\nretrieves the user from database, and implements sliding session refresh\\n(automatically extends token if expiring soon).\\n\\nArgs:\\n    request (Request): FastAPI request object\\n    response (Response): FastAPI response object (for token refresh)\\n    db (Session): Database session (injected via Depends)\\n\\nReturns:\\n    User: Authenticated user object from database\\n\\nRaises:\\n    HTTPException: 401 if not authenticated or token invalid\\n    HTTPException: 404 if user not found in database\\n\\nExample:\\n    >>> from fastapi import Depends\\n    >>> from neurosurfer.server.security import get_current_user\\n    >>> \\n    >>> @app.get(\"/me\")\\n    >>> def get_profile(user = Depends(get_current_user)):\\n    ...     return {\"username\": user.username, \"email\": user.email}',\n",
       "     'args': ['request', 'response', 'db']},\n",
       "    {'name': 'resolve_actor_id', 'docstring': None, 'args': ['req', 'user']}]},\n",
       "  'neurosurfer.server.gunicorn.conf': {'path': 'server/gunicorn.conf.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/gunicorn.conf.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.__init__': {'path': 'server/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/__init__.py',\n",
       "   'package': 'neurosurfer.server',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.db.models': {'path': 'server/db/models.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/db/models.py',\n",
       "   'package': 'neurosurfer.server.db',\n",
       "   'classes': [{'name': 'User',\n",
       "     'docstring': 'User account model.\\n\\nRepresents a registered user with authentication credentials.\\nUsers can have multiple chat threads and files.\\n\\nAttributes:\\n    id (int): Primary key\\n    email (str): Unique email address (indexed)\\n    full_name (str | None): Optional full name\\n    hashed_password (str): Bcrypt hashed password\\n    created_at (datetime): Account creation timestamp\\n    threads (list[ChatThread]): User\\'s chat threads (cascade delete)\\n\\nIndexes:\\n    - email (unique)\\n    - id (primary key)\\n\\nExample:\\n    >>> user = User(\\n    ...     email=\"user@example.com\",\\n    ...     full_name=\"John Doe\",\\n    ...     hashed_password=hash_password(\"password\")\\n    ... )',\n",
       "     'methods': []},\n",
       "    {'name': 'ChatThread',\n",
       "     'docstring': 'Chat thread (conversation) model.\\n\\nRepresents a conversation thread containing multiple messages.\\nEach thread belongs to a user and can have associated files.\\n\\nAttributes:\\n    id (int): Primary key\\n    user_id (int): Foreign key to User (indexed)\\n    title (str | None): Thread title (auto-generated from first message)\\n    created_at (datetime): Thread creation timestamp\\n    updated_at (datetime): Last update timestamp (auto-updated)\\n    user (User): Thread owner\\n    messages (list[Message]): Messages in this thread (cascade delete, ordered by created_at)\\n    files (list[NSFile]): Files attached to this thread (cascade delete)\\n\\nIndexes:\\n    - id (primary key)\\n    - user_id\\n    - (user_id, created_at) composite index\\n\\nExample:\\n    >>> thread = ChatThread(\\n    ...     user_id=1,\\n    ...     title=\"Discussion about AI\"\\n    ... )',\n",
       "     'methods': []},\n",
       "    {'name': 'Message',\n",
       "     'docstring': 'Chat message model.\\n\\nRepresents a single message within a chat thread.\\nMessages have a role (user, assistant, system, tool) and content.\\n\\nAttributes:\\n    id (int): Primary key\\n    thread_id (int): Foreign key to ChatThread (indexed)\\n    role (str): Message role (user | assistant | system | tool)\\n    content (str): Message text content\\n    model_name (str | None): Model used to generate this message (if assistant)\\n    created_at (datetime): Message creation timestamp\\n    thread (ChatThread): Parent thread\\n\\nIndexes:\\n    - id (primary key)\\n    - thread_id\\n    - (thread_id, created_at) composite index\\n\\nExample:\\n    >>> message = Message(\\n    ...     thread_id=1,\\n    ...     role=\"user\",\\n    ...     content=\"Hello, how are you?\"\\n    ... )',\n",
       "     'methods': []},\n",
       "    {'name': 'NSFile',\n",
       "     'docstring': 'File attachment model.\\n\\nRepresents a file uploaded by a user and associated with a chat thread.\\nFiles are ingested into vector stores for RAG functionality.\\n\\nAttributes:\\n    id (str): Primary key (file ID)\\n    user_id (int): Foreign key to User (indexed)\\n    thread_id (int): Foreign key to ChatThread (indexed)\\n    filename (str): Original filename\\n    stored_path (str): Path where file is stored (may be removed after ingest)\\n    mime (str | None): MIME type (e.g., \"application/pdf\")\\n    size (int | None): File size in bytes\\n    collection (str): Vector store collection name for this file\\n    created_at (datetime): Upload timestamp\\n    thread (ChatThread): Parent thread\\n\\nIndexes:\\n    - id (primary key)\\n    - user_id\\n    - thread_id\\n\\nExample:\\n    >>> file = NSFile(\\n    ...     id=\"file_abc123\",\\n    ...     user_id=1,\\n    ...     thread_id=1,\\n    ...     filename=\"document.pdf\",\\n    ...     stored_path=\"/uploads/document.pdf\",\\n    ...     mime=\"application/pdf\",\\n    ...     size=1024000,\\n    ...     collection=\"nm_u1_t1\"\\n    ... )',\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.db.db': {'path': 'server/db/db.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/db/db.py',\n",
       "   'package': 'neurosurfer.server.db',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'init_db',\n",
       "     'docstring': \"Initialize database tables.\\n\\nCreates all tables defined in models if they don't exist.\\nThis function should be called once during application startup.\\n\\nExample:\\n    >>> from neurosurfer.server.db.db import init_db\\n    >>> init_db()\\n    Database initialized successfully...\",\n",
       "     'args': []}]},\n",
       "  'neurosurfer.server.db.__init__': {'path': 'server/db/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/db/__init__.py',\n",
       "   'package': 'neurosurfer.server.db',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.services.follow_up_questions': {'path': 'server/services/follow_up_questions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/follow_up_questions.py',\n",
       "   'package': 'neurosurfer.server.services',\n",
       "   'classes': [{'name': 'FollowUpQuestions',\n",
       "     'docstring': \"Service to generate and parse follow-up questions from an existing LLM.\\nThe LLM must support a 'ask(user_prompt, system_prompt, chat_history, stream=False, **kwargs)' call.\",\n",
       "     'methods': [{'name': 'set_llm',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'llm']},\n",
       "      {'name': 'generate',\n",
       "       'docstring': \"- messages: list of {'role': 'system'|'user'|'assistant', 'content': str}\\nReturns a list of up to 3 questions.\",\n",
       "       'args': ['self', 'messages']}]}],\n",
       "   'functions': [{'name': 'robust_parse_followups',\n",
       "     'docstring': None,\n",
       "     'args': ['raw']}]},\n",
       "  'neurosurfer.server.services.rag.metadata_filter': {'path': 'server/services/rag/metadata_filter.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/metadata_filter.py',\n",
       "   'package': 'neurosurfer.server.services.rag',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'build_metadata_filter_from_related_files',\n",
       "     'docstring': \"Map gate LLM's related_files (filenames) to NSFile IDs,\\nthen build a metadata_filter suitable for the vectorstore.\",\n",
       "     'args': ['db', 'user_id', 'thread_id', 'collection', 'related_files']}]},\n",
       "  'neurosurfer.server.services.rag.models': {'path': 'server/services/rag/models.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/models.py',\n",
       "   'package': 'neurosurfer.server.services.rag',\n",
       "   'classes': [{'name': 'RAGResult',\n",
       "     'docstring': 'Outcome of a RAG orchestration step.',\n",
       "     'methods': []},\n",
       "    {'name': 'GateDecision',\n",
       "     'docstring': 'Result from the RAG routing (gate) LLM.',\n",
       "     'methods': [{'name': 'from_dict',\n",
       "       'docstring': None,\n",
       "       'args': ['cls', 'data']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.services.rag.ingestor': {'path': 'server/services/rag/ingestor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/ingestor.py',\n",
       "   'package': 'neurosurfer.server.services.rag',\n",
       "   'classes': [{'name': 'FileIngestor',\n",
       "     'docstring': 'RAG File Ingestor\\n\\nTakes already-persisted NSFile records (one per physical file on disk)\\nand ingests them into the vectorstore.\\n\\nIt assumes:\\n  - Files are already stored on disk at nsfile.stored_path\\n  - Zips have already been expanded at the API layer (one NSFile per\\n    extracted inner file)',\n",
       "     'methods': [{'name': 'ingest_files',\n",
       "       'docstring': 'Ingest existing NSFile rows into the vectorstore.\\n\\nArgs:\\n    db: SQLAlchemy session\\n    user_id, thread_id: scope sanity-checks\\n    collection_name: vectorstore collection name\\n    files: NSFile records to ingest (e.g. new files for the last message)\\n    reset_state: passed only to the first ingest call\\nReturns:\\n    List of ingestion summaries.',\n",
       "       'args': ['self',\n",
       "        'db',\n",
       "        'user_id',\n",
       "        'thread_id',\n",
       "        'collection_name',\n",
       "        'files',\n",
       "        'reset_state']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.services.rag.summarizer': {'path': 'server/services/rag/summarizer.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/summarizer.py',\n",
       "   'package': 'neurosurfer.server.services.rag',\n",
       "   'classes': [{'name': 'FileSummarizer',\n",
       "     'docstring': 'Responsible for turning file content into a short textual summary,\\nused by the routing LLM (gate) and stored in NSFile.summary.',\n",
       "     'methods': [{'name': 'summarize_path',\n",
       "       'docstring': \"Build a summary for the file at `path` using actual content if possible.\\n\\n- Reads via RAGAgent's FileReader.\\n- Samples text (start/middle/end) with a budget.\\n- Uses LLM if available:\\n    - zip member -> ~2 sentences\\n    - single file -> ~1 short paragraph\",\n",
       "       'args': ['self', 'path', 'is_zip_member']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.services.rag.__init__': {'path': 'server/services/rag/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/__init__.py',\n",
       "   'package': 'neurosurfer.server.services.rag',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.services.rag.orchestrator': {'path': 'server/services/rag/orchestrator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/orchestrator.py',\n",
       "   'package': 'neurosurfer.server.services.rag',\n",
       "   'classes': [{'name': 'RAGOrchestrator',\n",
       "     'docstring': 'Thin coordinator that wires:\\n  - File ingestion (SQL + vectorstore)\\n  - File summaries\\n  - RAG routing (gate LLM)\\n  - Retrieval via RAGAgent',\n",
       "     'methods': [{'name': 'apply',\n",
       "       'docstring': 'Main entry point.\\n- user_id, thread_id: scope for both SQL and vectorstore collection\\n- user_query: latest user message text\\n- files: base64-encoded upload metadata from request (if any)',\n",
       "       'args': ['self',\n",
       "        'user_id',\n",
       "        'thread_id',\n",
       "        'user_query',\n",
       "        'message_id',\n",
       "        'has_files_message']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.services.rag.gate': {'path': 'server/services/rag/gate.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/services/rag/gate.py',\n",
       "   'package': 'neurosurfer.server.services.rag',\n",
       "   'classes': [{'name': 'RAGGate',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'decide',\n",
       "       'docstring': 'Decide whether to use RAG, which files are relevant, and the retrieval scope.\\n\\nBehavior:\\n- If there are files attached to the current message:\\n    - They are ALWAYS included in related_files (pinned).\\n    - If there are other files in the thread and a gate LLM is configured,\\n      we ask the LLM to select any additional relevant files from the rest.\\n- If there are no message_files:\\n    - We fall back to normal gate behavior over all thread files.',\n",
       "       'args': ['self',\n",
       "        'db',\n",
       "        'user_id',\n",
       "        'thread_id',\n",
       "        'collection',\n",
       "        'user_query',\n",
       "        'message_files']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.schemas.model_response': {'path': 'server/schemas/model_response.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/model_response.py',\n",
       "   'package': 'neurosurfer.server.schemas',\n",
       "   'classes': [{'name': 'ChoiceMessage',\n",
       "     'docstring': 'Message in a non-streaming completion response',\n",
       "     'methods': []},\n",
       "    {'name': 'Choice',\n",
       "     'docstring': 'Choice in a non-streaming completion response',\n",
       "     'methods': []},\n",
       "    {'name': 'Usage', 'docstring': 'Token usage information', 'methods': []},\n",
       "    {'name': 'ChatCompletionResponse',\n",
       "     'docstring': 'Complete non-streaming chat completion response',\n",
       "     'methods': []},\n",
       "    {'name': 'DeltaContent',\n",
       "     'docstring': 'Delta content for streaming chunks',\n",
       "     'methods': []},\n",
       "    {'name': 'StreamChoice',\n",
       "     'docstring': 'Choice in a streaming chunk',\n",
       "     'methods': []},\n",
       "    {'name': 'ChatCompletionChunk',\n",
       "     'docstring': 'Streaming chunk response',\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.schemas.chats': {'path': 'server/schemas/chats.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/chats.py',\n",
       "   'package': 'neurosurfer.server.schemas',\n",
       "   'classes': [{'name': 'Chat', 'docstring': None, 'methods': []},\n",
       "    {'name': 'UploadedFileIn', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ChatMessageIn', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ChatFileOut', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ChatMessageOut', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.schemas.completions': {'path': 'server/schemas/completions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/completions.py',\n",
       "   'package': 'neurosurfer.server.schemas',\n",
       "   'classes': [{'name': 'ToolDefFunction', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ToolDef', 'docstring': None, 'methods': []},\n",
       "    {'name': 'FileContent', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ChatCompletionRequest', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ChatHandlerMessages', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ChatHandlerModel', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.schemas.model_registry': {'path': 'server/schemas/model_registry.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/model_registry.py',\n",
       "   'package': 'neurosurfer.server.schemas',\n",
       "   'classes': [{'name': 'ModelCard',\n",
       "     'docstring': 'Represents one registered model.',\n",
       "     'methods': []},\n",
       "    {'name': 'ModelList', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.schemas.auth': {'path': 'server/schemas/auth.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/auth.py',\n",
       "   'package': 'neurosurfer.server.schemas',\n",
       "   'classes': [{'name': 'User', 'docstring': None, 'methods': []},\n",
       "    {'name': 'LoginRequest', 'docstring': None, 'methods': []},\n",
       "    {'name': 'LoginResponse', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.schemas.__init__': {'path': 'server/schemas/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/schemas/__init__.py',\n",
       "   'package': 'neurosurfer.server.schemas',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.api.api_chat_completions': {'path': 'server/api/api_chat_completions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_chat_completions.py',\n",
       "   'package': 'neurosurfer.server.api',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'make_chat_response',\n",
       "     'docstring': 'Create OpenAI-compatible chat completion response from plain text.\\n\\nHelper function to wrap simple text responses in the proper Pydantic model format.\\n\\nArgs:\\n    op_id (str): Operation/request ID\\n    model (str): Model identifier\\n    text (str): Response text content\\n\\nReturns:\\n    ChatCompletionResponse: Formatted response with usage stats\\n\\nExample:\\n    >>> response = make_chat_response(\"op_123\", \"gpt-4\", \"Hello!\")\\n    >>> print(response.choices[0].message.content)\\n    \\'Hello!\\'',\n",
       "     'args': ['op_id', 'model', 'text']},\n",
       "    {'name': 'chat_completion_router',\n",
       "     'docstring': 'Create FastAPI router for chat completion endpoints.\\n\\nFactory function that creates a router with the /chat/completions endpoint,\\nconfigured with the provided chat handler and model registry.\\n\\nArgs:\\n    _chat_handler: Custom chat handler function (sync or async)\\n    model_registry (ModelRegistry): Registry of available models\\n\\nReturns:\\n    APIRouter: Configured FastAPI router\\n\\nExample:\\n    >>> def my_handler(request, context):\\n    ...     return \"Response\"\\n    >>> router = chat_completion_router(my_handler, registry)\\n    >>> app.include_router(router)',\n",
       "     'args': ['_chat_handler', 'model_registry']}]},\n",
       "  'neurosurfer.server.api.api_files': {'path': 'server/api/api_files.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_files.py',\n",
       "   'package': 'neurosurfer.server.api',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'download_file',\n",
       "     'docstring': 'Download a file that belongs to the current user.\\n\\n- Ensures the file exists\\n- Ensures it belongs to this user\\n- Streams the file with correct filename + mime type',\n",
       "     'args': ['file_id', 'db', 'user']}]},\n",
       "  'neurosurfer.server.api.api_chats': {'path': 'server/api/api_chats.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_chats.py',\n",
       "   'package': 'neurosurfer.server.api',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'thread_to_chat',\n",
       "     'docstring': 'Convert ChatThread model to Chat schema.\\n\\nArgs:\\n    th (ChatThread): Database chat thread model\\n\\nReturns:\\n    Chat: API chat schema',\n",
       "     'args': ['th']},\n",
       "    {'name': 'list_threads',\n",
       "     'docstring': 'List all chat threads for the current user.\\n\\nReturns threads ordered by most recent activity (last message timestamp).\\nIncludes message count and timestamps for each thread.\\n\\nArgs:\\n    db (Session): Database session\\n    user (User): Current authenticated user\\n\\nReturns:\\n    List[Chat]: List of chat threads with metadata\\n\\nExample:\\n    >>> GET /chats\\n    >>> # Returns: [{\"id\": \"1\", \"title\": \"Chat 1\", \"messagesCount\": 5, ...}]',\n",
       "     'args': ['db', 'user']},\n",
       "    {'name': 'create_thread',\n",
       "     'docstring': 'Create a new chat thread.\\n\\nArgs:\\n    data (dict): Thread data (optional title)\\n    db (Session): Database session\\n    user (User): Current authenticated user\\n\\nReturns:\\n    Chat: Created chat thread\\n\\nExample:\\n    >>> POST /chats\\n    >>> {\"title\": \"My New Chat\"}\\n    >>> # Returns: {\"id\": \"1\", \"title\": \"My New Chat\", ...}',\n",
       "     'args': ['data', 'db', 'user']},\n",
       "    {'name': 'get_thread',\n",
       "     'docstring': 'Get a specific chat thread.\\n\\nArgs:\\n    chat_id (int): Chat thread ID\\n    db (Session): Database session\\n    user (User): Current authenticated user\\n\\nReturns:\\n    Chat: Chat thread details\\n\\nRaises:\\n    HTTPException: 404 if chat not found or doesn\\'t belong to user\\n\\nExample:\\n    >>> GET /chats/1\\n    >>> # Returns: {\"id\": \"1\", \"title\": \"My Chat\", ...}',\n",
       "     'args': ['chat_id', 'db', 'user']},\n",
       "    {'name': 'list_messages',\n",
       "     'docstring': 'List all messages in a chat thread.\\n\\nReturns messages ordered chronologically (oldest first).\\n\\nArgs:\\n    chat_id (int): Chat thread ID\\n    db (Session): Database session\\n    user (User): Current authenticated user\\n\\nReturns:\\n    List[ChatMessageOut]: List of messages in the thread\\n\\nRaises:\\n    HTTPException: 404 if chat not found or doesn\\'t belong to user\\n\\nExample:\\n    >>> GET /chats/1/messages\\n    >>> # Returns: [{\"id\": 1, \"role\": \"user\", \"content\": \"Hi\", ...}]',\n",
       "     'args': ['chat_id', 'db', 'user']},\n",
       "    {'name': 'append_message',\n",
       "     'docstring': None,\n",
       "     'args': ['chat_id', 'body', 'db', 'user']},\n",
       "    {'name': 'delete_thread',\n",
       "     'docstring': None,\n",
       "     'args': ['chat_id', 'db', 'user']},\n",
       "    {'name': 'update_thread',\n",
       "     'docstring': None,\n",
       "     'args': ['chat_id', 'data', 'db', 'user']}]},\n",
       "  'neurosurfer.server.api.__init__': {'path': 'server/api/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/__init__.py',\n",
       "   'package': 'neurosurfer.server.api',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.server.api.api_auth': {'path': 'server/api/api_auth.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/server/api/api_auth.py',\n",
       "   'package': 'neurosurfer.server.api',\n",
       "   'classes': [{'name': 'RegisterBody',\n",
       "     'docstring': 'Request body for user registration.',\n",
       "     'methods': []},\n",
       "    {'name': 'LoginBody',\n",
       "     'docstring': 'Request body for user login.',\n",
       "     'methods': []},\n",
       "    {'name': 'DeleteBody',\n",
       "     'docstring': 'Request body for account deletion (requires password confirmation).',\n",
       "     'methods': []}],\n",
       "   'functions': [{'name': 'user_to_schema',\n",
       "     'docstring': 'Convert database User model to API schema.\\n\\nArgs:\\n    u (User): Database user model\\n\\nReturns:\\n    UserSchema: API user schema with id, name, and email',\n",
       "     'args': ['u']},\n",
       "    {'name': 'register',\n",
       "     'docstring': 'Register a new user account.\\n\\nCreates a new user with hashed password and generates an authentication token.\\nEmail must be unique.\\n\\nArgs:\\n    body (RegisterBody): Registration data (email, password, optional full_name)\\n    response (Response): FastAPI response object\\n    db (Session): Database session\\n\\nReturns:\\n    UserSchema: Created user information\\n\\nRaises:\\n    HTTPException: 400 if email already registered\\n\\nExample:\\n    >>> POST /auth/register\\n    >>> {\"email\": \"user@example.com\", \"password\": \"pass123\", \"full_name\": \"John\"}\\n    >>> # Returns: {\"id\": \"1\", \"name\": \"John\", \"email\": \"user@example.com\"}',\n",
       "     'args': ['body', 'response', 'db']},\n",
       "    {'name': 'login',\n",
       "     'docstring': 'Authenticate user and create session.\\n\\nValidates credentials and creates JWT token stored in secure cookie.\\n\\nArgs:\\n    body (LoginBody): Login credentials (email, password)\\n    response (Response): FastAPI response object (for setting cookie)\\n    db (Session): Database session\\n\\nReturns:\\n    LoginResponse: Authentication token and user information\\n\\nRaises:\\n    HTTPException: 401 if user not found or password invalid\\n\\nExample:\\n    >>> POST /auth/login\\n    >>> {\"email\": \"user@example.com\", \"password\": \"pass123\"}\\n    >>> # Returns: {\"token\": \"eyJ...\", \"user\": {...}}',\n",
       "     'args': ['body', 'response', 'db']},\n",
       "    {'name': 'logout',\n",
       "     'docstring': 'Logout user by clearing authentication cookie.\\n\\nArgs:\\n    response (Response): FastAPI response object\\n\\nReturns:\\n    dict: Success confirmation\\n\\nExample:\\n    >>> POST /auth/logout\\n    >>> # Returns: {\"ok\": true}',\n",
       "     'args': ['response']},\n",
       "    {'name': 'me',\n",
       "     'docstring': 'Get current authenticated user profile.\\n\\nArgs:\\n    user (User): Current user (injected via dependency)\\n\\nReturns:\\n    UserSchema: Current user information\\n\\nRaises:\\n    HTTPException: 401 if not authenticated\\n\\nExample:\\n    >>> GET /auth/me\\n    >>> # Headers: Authorization: Bearer <token>\\n    >>> # Returns: {\"id\": \"1\", \"name\": \"John\", \"email\": \"user@example.com\"}',\n",
       "     'args': ['user']},\n",
       "    {'name': 'delete_account',\n",
       "     'docstring': 'Delete user account and all associated data.\\n\\nRequires password confirmation. Deletes all chat threads, messages,\\nand the user account. This operation is irreversible.\\n\\nArgs:\\n    body (DeleteBody): Password confirmation\\n    user (User): Current user (injected via dependency)\\n    db (Session): Database session\\n\\nReturns:\\n    UserSchema: Deleted user information\\n\\nRaises:\\n    HTTPException: 401 if password is incorrect\\n\\nExample:\\n    >>> POST /auth/delete_account\\n    >>> {\"password\": \"pass123\"}\\n    >>> # Returns: {\"id\": \"1\", \"name\": \"John\", \"email\": \"user@example.com\"}',\n",
       "     'args': ['body', 'user', 'db']}]},\n",
       "  'neurosurfer.tools.toolkit': {'path': 'tools/toolkit.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/toolkit.py',\n",
       "   'package': 'neurosurfer.tools',\n",
       "   'classes': [{'name': 'Toolkit',\n",
       "     'docstring': 'Tool registry and manager for agents.\\n\\nThis class manages a collection of tools, providing registration,\\nvalidation, and description generation capabilities. Agents use\\nthe Toolkit to discover and invoke available tools.\\n\\nAttributes:\\n    logger (logging.Logger): Logger instance\\n    registry (Dict[str, BaseTool]): Mapping of tool names to tool instances\\n    specs (Dict[str, ToolSpec]): Mapping of tool names to tool specifications\\n\\nExample:\\n    >>> toolkit = Toolkit()\\n    >>> \\n    >>> # Register tools\\n    >>> toolkit.register_tool(MyTool())\\n    >>> toolkit.register_tool(AnotherTool())\\n    >>> \\n    >>> # Get formatted descriptions\\n    >>> desc = toolkit.get_tools_description()\\n    >>> \\n    >>> # Access tools\\n    >>> tool = toolkit.registry[\"my_tool\"]\\n    >>> response = tool(param=\"value\")',\n",
       "     'methods': [{'name': 'register_tool',\n",
       "       'docstring': 'Register a tool in the toolkit.\\n\\nValidates the tool type and ensures no duplicate registrations.\\nOnce registered, the tool becomes available to agents.\\n\\nArgs:\\n    tool (BaseTool): Tool instance to register\\n\\nRaises:\\n    TypeError: If tool is not a BaseTool subclass\\n    ValueError: If tool name is already registered\\n\\nExample:\\n    >>> from neurosurfer.tools.sql import SQLQueryTool\\n    >>> toolkit = Toolkit()\\n    >>> toolkit.register_tool(SQLQueryTool())\\n    Registered tool: sql_query',\n",
       "       'args': ['self', 'tool']},\n",
       "      {'name': 'get_tools_description',\n",
       "       'docstring': \"Generate formatted descriptions of all registered tools.\\n\\nCreates a markdown-formatted string describing each tool's:\\n- Name and description\\n- When to use it\\n- Input parameters (with types and requirements)\\n- Return type and description\\n\\nThis description is used by agents to understand available tools.\\nReturns:\\n    str: Formatted tool descriptions in markdown\\n\\nExample:\\n    >>> toolkit = Toolkit()\\n    >>> toolkit.register_tool(MyTool())\\n    >>> desc = toolkit.get_tools_description()\\n    >>> print(desc)\\n    Available tools:\\n    Tool Name: <tool_name>\\n    Description: <tool_description>\\n    When to use: <when_to_use>\\n    Tool Inputs:\\n    - <input_name>: <input_type> (<required/optional>) â€” <input_description>\\n      ...\\n    Tool Return: <return_type> â€” <return_description>\\n    \",\n",
       "       'args': ['self']},\n",
       "      {'name': 'build_tool_args',\n",
       "       'docstring': 'Merge LLM-provided args with system/graph-provided args\\nbased on ToolParam.llm flag and optional bindings.',\n",
       "       'args': ['tool_spec', 'llm_args', 'context', 'bindings']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.base_tool': {'path': 'tools/base_tool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/base_tool.py',\n",
       "   'package': 'neurosurfer.tools',\n",
       "   'classes': [{'name': 'ToolResponse',\n",
       "     'docstring': 'Structured response from tool execution.\\n\\nThis dataclass encapsulates the output of a tool, including whether it\\nrepresents a final answer, the results, and any extra data\\nto pass to subsequent tool calls.\\n\\nAttributes:\\n    final_answer (bool): If True, the results should be treated as the\\n        final answer to the user\\'s query (no further tool calls needed)\\n    results (Union[str, Generator]): The tool\\'s output. Can be a string\\n        or a generator for streaming responses (ChatCompletionChunk style)\\n    extras (dict): Additional data to store in agent memory for subsequent\\n        tool calls. Default: {}\\n\\nExample:\\n    >>> # Simple tool response\\n    >>> response = ToolResponse(\\n    ...     final_answer=False,\\n    ...     results=\"Found 3 matching records\",\\n    ...     extras={\"record_ids\": [1, 2, 3]}\\n    ... )\\n    >>> \\n    >>> # Final answer response\\n    >>> response = ToolResponse(\\n    ...     final_answer=True,\\n    ...     results=\"The answer is 42\"\\n    ... )',\n",
       "     'methods': []},\n",
       "    {'name': 'BaseTool',\n",
       "     'docstring': 'Abstract base class for all tools in Neurosurfer.\\n\\nTools extend agent capabilities by providing specific functionalities.\\nEach tool must define a ToolSpec that describes its name, description,\\nand input parameters. The spec is used by agents to understand how to\\ninvoke the tool.\\n\\nAttributes:\\n    spec (ToolSpec): Tool specification defining name, description, and inputs\\n\\nAbstract Methods:\\n    __call__(): Execute the tool with provided inputs\\n\\nExample:\\n    >>> from neurosurfer.tools import BaseTool, ToolResponse\\n    >>> from neurosurfer.tools.tool_spec import ToolSpec, InputParam\\n    >>> \\n    >>> class MyTool(BaseTool):\\n    ...     spec = ToolSpec(\\n    ...         name=\"my_tool\",\\n    ...         description=\"Does something useful\",\\n    ...         inputs=[\\n    ...             InputParam(name=\"query\", type=\"string\", description=\"Input query\", required=True)\\n    ...         ]\\n    ...     )\\n    ...     \\n    ...     def __call__(self, query: str, **kwargs):\\n    ...         result = f\"Processed: {query}\"\\n    ...         return ToolResponse(final_answer=False, results=result)\\n    >>> \\n    >>> tool = MyTool()\\n    >>> response = tool(query=\"test\")',\n",
       "     'methods': [{'name': 'get_tool_description',\n",
       "       'docstring': \"Generate a formatted description of the tool. This description is used by the agent to understand the tool.\\nThis description doesn't include the params which are not generated by the LLM, so the LLM knows only the params\\nit should generate.\\n\\nReturns:\\n    str: Formatted tool description in markdown\",\n",
       "       'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.tool_spec': {'path': 'tools/tool_spec.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/tool_spec.py',\n",
       "   'package': 'neurosurfer.tools',\n",
       "   'classes': [{'name': 'ToolParam',\n",
       "     'docstring': 'Specification for a tool input parameter.\\n\\nDefines the name, type, description, and requirement status of a\\nsingle tool parameter. Used for validation and documentation.\\n\\nAttributes:\\n    name (str): Parameter name\\n    type (str): Parameter type (string, integer, number, boolean, array, object)\\n    description (str): Human-readable description of the parameter\\n    required (bool): Whether the parameter is required. Default: True\\n\\nExample:\\n    >>> param = ToolParam(\\n    ...     name=\"query\",\\n    ...     type=\"string\",\\n    ...     description=\"SQL query to execute\",\\n    ...     required=True\\n    ... )',\n",
       "     'methods': []},\n",
       "    {'name': 'ToolReturn',\n",
       "     'docstring': 'Specification for a tool\\'s return value.\\n\\nDefines the type and description of what a tool returns.\\n\\nAttributes:\\n    type (str): Return type (string, integer, number, boolean, array, object)\\n    description (str): Human-readable description of the return value\\n\\nExample:\\n    >>> ret = ToolReturn(\\n    ...     type=\"object\",\\n    ...     description=\"Query results as a dictionary\"\\n    ... )',\n",
       "     'methods': []},\n",
       "    {'name': 'ToolSpec',\n",
       "     'docstring': 'Complete specification for a tool.\\n\\nDefines all metadata needed for a tool: name, description, usage guidelines,\\ninput parameters, and return type. Used for validation, documentation, and\\nagent understanding.\\n\\nAttributes:\\n    name (str): Unique tool identifier\\n    description (str): Brief description of what the tool does\\n    when_to_use (str): Guidelines for when to use this tool\\n    inputs (List[ToolParam]): List of input parameter specifications\\n    returns (ToolReturn): Return value specification\\n\\nMethods:\\n    validate(): Validate the specification\\n    to_json(): Convert to JSON-serializable dict\\n    check_inputs(): Validate and sanitize runtime inputs\\n\\nExample:\\n    >>> spec = ToolSpec(\\n    ...     name=\"web_search\",\\n    ...     description=\"Search the web for information\",\\n    ...     when_to_use=\"When you need current information from the internet\",\\n    ...     inputs=[\\n    ...         ToolParam(name=\"query\", type=\"string\", description=\"Search query\", required=True),\\n    ...         ToolParam(name=\"max_results\", type=\"integer\", description=\"Max results\", required=False)\\n    ...     ],\\n    ...     returns=ToolReturn(type=\"array\", description=\"List of search results\")\\n    ... )\\n    >>> spec.validate()\\n    >>> inputs = spec.check_inputs({\"query\": \"AI news\"})',\n",
       "     'methods': [{'name': 'validate',\n",
       "       'docstring': 'Validate the tool specification.\\n\\nChecks that:\\n- Name, description, and when_to_use are non-empty\\n- At least one input parameter is defined\\n- All parameter types are supported\\n- Parameter names are unique\\n- Return type is supported\\n\\nRaises:\\n    ValueError: If validation fails\\n\\nExample:\\n    >>> spec = ToolSpec(...)\\n    >>> spec.validate()  # Raises ValueError if invalid',\n",
       "       'args': ['self']},\n",
       "      {'name': 'to_json',\n",
       "       'docstring': 'Convert specification to JSON-serializable dictionary.\\n\\nReturns:\\n    Dict[str, Any]: Dictionary representation of the spec\\n\\nExample:\\n    >>> spec = ToolSpec(...)\\n    >>> json_data = spec.to_json()\\n    >>> print(json_data[\"name\"])\\n    \\'my_tool\\'',\n",
       "       'args': ['self']},\n",
       "      {'name': 'parse_inputs', 'docstring': None, 'args': ['self', 'raw']},\n",
       "      {'name': 'check_inputs',\n",
       "       'docstring': 'Validate and sanitize runtime inputs against the specification.\\n\\nPerforms strict validation:\\n- Ensures all required parameters are present\\n- Rejects extra/unknown parameters\\n- Validates parameter types\\n\\nArgs:\\n    raw (Dict[str, Any]): Raw input dictionary from LLM or user\\n    relax (bool): If True, relaxes validation (e.g. only check passed parameters)\\n\\nReturns:\\n    Dict[str, Any]: Validated input dictionary (same as input if valid)\\n\\nRaises:\\n    ValueError: If validation fails (missing required, wrong type, extra params)\\n\\nExample:\\n    >>> spec = ToolSpec(\\n    ...     inputs=[ToolParam(name=\"x\", type=\"number\", description=\"X\", required=True)],\\n    ...     ...\\n    ... )\\n    >>> validated = spec.check_inputs({\"x\": 42})\\n    >>> # Raises ValueError:\\n    >>> spec.check_inputs({\"x\": \"not a number\"})\\n    >>> spec.check_inputs({\"y\": 42})  # Missing required \\'x\\'\\n    >>> spec.check_inputs({\"x\": 42, \"z\": 10})  # Extra param \\'z\\'',\n",
       "       'args': ['self', 'raw', 'relax']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.__init__': {'path': 'tools/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/__init__.py',\n",
       "   'package': 'neurosurfer.tools',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.mermaid.erd_diagram_generator': {'path': 'tools/mermaid/erd_diagram_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/mermaid/erd_diagram_generator.py',\n",
       "   'package': 'neurosurfer.tools.mermaid',\n",
       "   'classes': [{'name': 'ERDDiagramGenerator',\n",
       "     'docstring': None,\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.mermaid.mermaid_diagram_generator': {'path': 'tools/mermaid/mermaid_diagram_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/mermaid/mermaid_diagram_generator.py',\n",
       "   'package': 'neurosurfer.tools.mermaid',\n",
       "   'classes': [{'name': 'MermaidDiagramGenerator',\n",
       "     'docstring': None,\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.common.general_query_assistant': {'path': 'tools/common/general_query_assistant.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/common/general_query_assistant.py',\n",
       "   'package': 'neurosurfer.tools.common',\n",
       "   'classes': [{'name': 'GeneralQueryAssistantTool',\n",
       "     'docstring': None,\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.common.__init__': {'path': 'tools/common/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/common/__init__.py',\n",
       "   'package': 'neurosurfer.tools.common',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.sql.final_answer_formatter': {'path': 'tools/sql/final_answer_formatter.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/final_answer_formatter.py',\n",
       "   'package': 'neurosurfer.tools.sql',\n",
       "   'classes': [{'name': 'FinalAnswerFormatter',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'preprocess_sql_results_for_llm',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'user_query', 'db_results']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.sql.sql_executor': {'path': 'tools/sql/sql_executor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/sql_executor.py',\n",
       "   'package': 'neurosurfer.tools.sql',\n",
       "   'classes': [{'name': 'SQLExecutor',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'get_results_with_columns',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'query']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.sql.db_insights_tool': {'path': 'tools/sql/db_insights_tool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/db_insights_tool.py',\n",
       "   'package': 'neurosurfer.tools.sql',\n",
       "   'classes': [{'name': 'DBInsightsTool',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'get_tables_summaries__',\n",
       "       'docstring': None,\n",
       "       'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.sql.relevant_tables_schema_retriever': {'path': 'tools/sql/relevant_tables_schema_retriever.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/relevant_tables_schema_retriever.py',\n",
       "   'package': 'neurosurfer.tools.sql',\n",
       "   'classes': [{'name': 'RelevantTableSchemaFinderLLM',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'get_tables_summaries__',\n",
       "       'docstring': None,\n",
       "       'args': ['self']},\n",
       "      {'name': 'get_table_schema',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'tables']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.sql.sql_query_generator': {'path': 'tools/sql/sql_query_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/sql_query_generator.py',\n",
       "   'package': 'neurosurfer.tools.sql',\n",
       "   'classes': [{'name': 'SQLQueryGenerator',\n",
       "     'docstring': None,\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.sql.__init__': {'path': 'tools/sql/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/sql/__init__.py',\n",
       "   'package': 'neurosurfer.tools.sql',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.rag.docs_generator': {'path': 'tools/rag/docs_generator.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/rag/docs_generator.py',\n",
       "   'package': 'neurosurfer.tools.rag',\n",
       "   'classes': [{'name': 'DocsGenerator',\n",
       "     'docstring': 'Generates a full project documentation by iterating fixed sections and synthesizing each one with RAG context.\\nThe tool streams a single merged Markdown document (grand doc).\\n\\nPurpose:\\n  Create a high-level documentation template using a fixed section list and the project\\'s folder structure,\\n  avoiding large single-prompt context windows by generating section-wise.\\n\\nInputs:\\n  - query (str): Optional short description/instruction for the doc generation run (e.g., style hints).\\n    All other runtime options come via **kwargs.\\n\\nCommon kwargs:\\n  - folder_structure (str): The textual tree of the project directories/files. Recommended.\\n  - sections (List[str]): Ordered list of section titles to generate. Defaults to the hybrid template.\\n  - section_instructions (Dict[str, str]): Extra hints per section title.\\n  - chat_history (List[Dict]): Prior conversation turns if you track them.\\n  - top_k (int): Retrieval depth (default 10).\\n  - temperature (float): LLM sampling temperature (default 0.3).\\n  - max_new_tokens (int): Cap per-section generation (default 700).\\n  - prepend_title (bool): Whether to start doc with \"# Project Documentation\" (default True).\\n  - doc_title (str): Custom H1 title if prepend_title is True (default \"Project Documentation\").',\n",
       "     'methods': [{'name': 'plan_docs',\n",
       "       'docstring': 'Returns a mapping: {section_title: instructions}',\n",
       "       'args': ['self',\n",
       "        'user_query',\n",
       "        'folder_structure',\n",
       "        'temperature',\n",
       "        'max_new_tokens',\n",
       "        'verbose',\n",
       "        'extra_hl_query',\n",
       "        'candidate_pool_size',\n",
       "        'n_files',\n",
       "        'max_total_chunks']},\n",
       "      {'name': 'build_high_level_queries',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'extra_query']},\n",
       "      {'name': 'diverse_pick',\n",
       "       'docstring': 'Two-pass selector:\\n1) satisfy per_file_min for as many files as possible\\n2) fill remaining by score order, respecting per_file_cap',\n",
       "       'args': ['self',\n",
       "        'hits',\n",
       "        'k',\n",
       "        'file_key',\n",
       "        'per_file_min',\n",
       "        'per_file_cap']},\n",
       "      {'name': 'select_high_level_context',\n",
       "       'docstring': None,\n",
       "       'args': ['self',\n",
       "        'extra_query',\n",
       "        'candidate_pool_size',\n",
       "        'n_files',\n",
       "        'max_total_chunks',\n",
       "        'per_file_min',\n",
       "        'per_file_cap',\n",
       "        'overfetch_factor',\n",
       "        'file_key',\n",
       "        'max_chars_per_chunk']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.rag.simple_query_assitant': {'path': 'tools/rag/simple_query_assitant.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/rag/simple_query_assitant.py',\n",
       "   'package': 'neurosurfer.tools.rag',\n",
       "   'classes': [{'name': 'RagSimpleAnswerTool',\n",
       "     'docstring': None,\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.websearch.extractor': {'path': 'tools/websearch/extractor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/extractor.py',\n",
       "   'package': 'neurosurfer.tools.websearch',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'get_domain',\n",
       "     'docstring': \"Extract normalized domain from URL (netloc without leading 'www.').\",\n",
       "     'args': ['url']},\n",
       "    {'name': 'html_to_text',\n",
       "     'docstring': 'Convert HTML to cleaned plain text using BeautifulSoup.\\n\\nUses domain-specific selectors from `domain_content_config` when possible,\\nfalling back to generic extraction otherwise.',\n",
       "     'args': ['html', 'url', 'domain_content_config']}]},\n",
       "  'neurosurfer.tools.websearch.tool': {'path': 'tools/websearch/tool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/tool.py',\n",
       "   'package': 'neurosurfer.tools.websearch',\n",
       "   'classes': [{'name': 'WebSearchTool',\n",
       "     'docstring': 'Unified web search + optional crawl + optional LLM summarization.\\n\\nThis tool:\\n  1. Uses a pluggable engine (SerpAPI now; Tavily, etc. later) to get SERP results.\\n  2. Optionally crawls the top results, with smart domain-specific extraction.\\n  3. Optionally asks an LLM to create a long, refined summary of the results.\\n\\nParameters common across engines:\\n  - engine: which backend to use (\"serpapi\", ...)\\n  - engine_kwargs: dict with engine-specific config (api_key, endpoint, ...)\\n  - max_results, location, gl: SERP-level knobs\\n  - enable_crawl, max_crawl_results, max_concurrent_crawls, etc.\\n  - domain_content_config, preferred_domains: smarter content extraction\\n  - llm: optional LLM instance for summarization',\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.websearch.utils': {'path': 'tools/websearch/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/utils.py',\n",
       "   'package': 'neurosurfer.tools.websearch',\n",
       "   'classes': [{'name': 'WebSearchResult',\n",
       "     'docstring': 'Final normalized result, ready for LLM use.\\n\\nCombines:\\n  - engine-level info (title, url, snippet, score)\\n  - optional crawled content and length\\n  - crawl error, if any',\n",
       "     'methods': []}],\n",
       "   'functions': [{'name': 'build_results_with_crawl',\n",
       "     'docstring': 'Crawl top N results in parallel and return WebSearchResult list\\nin the original SERP order.\\n\\nIf preferred_domains are configured, we first try to crawl those. If none\\nare found, we fall back to the usual top-N.',\n",
       "     'args': ['config', 'engine_results']},\n",
       "    {'name': 'build_result_from_engine_result',\n",
       "     'docstring': None,\n",
       "     'args': ['config', 'item', 'crawl']},\n",
       "    {'name': 'crawl_url',\n",
       "     'docstring': 'Fetch page content and extract clean text.\\n\\nReturns a dict:\\n    {\\n        \"content\": str | None,\\n        \"error\": str | None,\\n    }',\n",
       "     'args': ['url', 'config']},\n",
       "    {'name': 'is_preferred_domain',\n",
       "     'docstring': None,\n",
       "     'args': ['url', 'preferred_domains']},\n",
       "    {'name': 'limit_content_length',\n",
       "     'docstring': 'Truncate `content` to at most `max_words` words using a given strategy.\\n\\nStrategies\\n----------\\n- \"first\":       Keep the first `max_words` words.\\n- \"last\":        Keep the last `max_words` words.\\n- \"middle\":      Keep a centered window of `max_words` words.\\n- \"head_tail\":   Split budget between start and end, join with \"...\".\\n- \"distributive\":Pick several short chunks distributed across the text,\\n                 joined with \"...\".',\n",
       "     'args': ['content',\n",
       "      'max_words',\n",
       "      'strategy',\n",
       "      'distributive_segment_size']},\n",
       "    {'name': 'summarize_with_llm',\n",
       "     'docstring': 'Use the configured LLM to produce a long, detailed summary of the search results.',\n",
       "     'args': ['llm', 'results_dict']}]},\n",
       "  'neurosurfer.tools.websearch.config': {'path': 'tools/websearch/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/config.py',\n",
       "   'package': 'neurosurfer.tools.websearch',\n",
       "   'classes': [{'name': 'WebSearchConfig', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.websearch.templates': {'path': 'tools/websearch/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/templates.py',\n",
       "   'package': 'neurosurfer.tools.websearch',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.websearch.__init__': {'path': 'tools/websearch/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/__init__.py',\n",
       "   'package': 'neurosurfer.tools.websearch',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.websearch.rag': {'path': 'tools/websearch/rag.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/rag.py',\n",
       "   'package': 'neurosurfer.tools.websearch',\n",
       "   'classes': [{'name': 'WebSearchRAGResult',\n",
       "     'docstring': 'Return payload from RAG refinement of web search results.',\n",
       "     'methods': []}],\n",
       "   'functions': [{'name': 'run_web_rag',\n",
       "     'docstring': 'RAG-style refinement over normalized web search results.\\n\\n- Re-scores each result embedding vs. the query embedding.\\n- Selects top_k results.\\n- Builds a single concatenated context string and trims it to\\n  `max_context_tokens`.\\n- Optionally runs an LLM summarization over that context.\\n\\nThis is *ephemeral RAG* â€” no persistent vectorstore, just in-memory\\nembeddings for the current tool call.',\n",
       "     'args': ['query', 'results', 'llm', 'embedder', 'config']},\n",
       "    {'name': 'run_web_rag_on_results_dict',\n",
       "     'docstring': 'Convenience wrapper when you already have the full `results_dict`\\nproduced by WebSearchTool.',\n",
       "     'args': ['results_dict', 'llm', 'embedder', 'config']}]},\n",
       "  'neurosurfer.tools.websearch.engines.serpapi': {'path': 'tools/websearch/engines/serpapi.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/engines/serpapi.py',\n",
       "   'package': 'neurosurfer.tools.websearch.engines',\n",
       "   'classes': [{'name': 'SerpApiEngine',\n",
       "     'docstring': 'SerpAPI-backed implementation of SearchEngine (Google engine).',\n",
       "     'methods': [{'name': 'search',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'query', 'hl', 'max_results', 'location', 'gl']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.websearch.engines.base': {'path': 'tools/websearch/engines/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/engines/base.py',\n",
       "   'package': 'neurosurfer.tools.websearch.engines',\n",
       "   'classes': [{'name': 'EngineResult',\n",
       "     'docstring': 'One normalized result item from a search engine.\\n\\nEngines should populate at least:\\n  - title\\n  - url\\n  - snippet\\n\\nOptional:\\n  - score (relevance, rank, etc.)',\n",
       "     'methods': []},\n",
       "    {'name': 'EngineSearchMeta',\n",
       "     'docstring': 'Metadata about a search engine call.\\n\\ntotal_results:\\n    Estimated total results (if available).\\nprovider:\\n    Name/identifier of the provider (e.g. \"serpapi\", \"tavily\").\\nextra:\\n    Engine-specific metadata.',\n",
       "     'methods': []},\n",
       "    {'name': 'SearchEngine',\n",
       "     'docstring': 'Abstract base class for web search engines.\\n\\nConcrete engines (SerpApiEngine, TavilyEngine, etc.) must implement\\nthe `search()` method and expose a `name` attribute.',\n",
       "     'methods': [{'name': 'search',\n",
       "       'docstring': 'Execute a search and return:\\n\\n    (results, meta, raw)\\n\\nwhere:\\n  - results: list[EngineResult]\\n  - meta: EngineSearchMeta\\n  - raw: engine-specific raw payload (dict or any JSON-like object)',\n",
       "       'args': ['self', 'query', 'hl', 'max_results', 'location', 'gl']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.tools.websearch.engines.__init__': {'path': 'tools/websearch/engines/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/tools/websearch/engines/__init__.py',\n",
       "   'package': 'neurosurfer.tools.websearch.engines',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.tools_router_agent': {'path': 'agents/tools_router_agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/tools_router_agent.py',\n",
       "   'package': 'neurosurfer.agents',\n",
       "   'classes': [{'name': 'RouterRetryPolicy', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ToolsRouterConfig', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ToolAndInputsModel', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ToolsRouterAgent',\n",
       "     'docstring': \"Minimal, production-ready tools router:\\n  1) Uses LLM to select exactly one tool + inputs (strict JSON).\\n  2) Validates inputs against the tool's ToolSpec (prunes unknowns if enabled).\\n  3) Executes the tool, proxying streaming or returning a string.\\n  4) Retries routing and tool execution with backoff (bounded).\",\n",
       "     'methods': [{'name': 'run',\n",
       "       'docstring': 'Decide a tool with the LLM (JSON: {\"tool\": \"...\", \"inputs\": {...}}),\\nvalidate/repair inputs, and execute that tool.\\n- If stream=True (default from config), returns a Generator[str].\\n- If stream=False, returns a str.\\nExtra **kwargs are forwarded into the tool call (merged with inputs).',\n",
       "       'args': ['self',\n",
       "        'user_query',\n",
       "        'chat_history',\n",
       "        'execute_tool',\n",
       "        'strict_tool_call',\n",
       "        'stream',\n",
       "        'temperature',\n",
       "        'max_new_tokens',\n",
       "        '**kwargs']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.__init__': {'path': 'agents/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/__init__.py',\n",
       "   'package': 'neurosurfer.agents',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.sql_agent': {'path': 'agents/sql_agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/sql_agent.py',\n",
       "   'package': 'neurosurfer.agents',\n",
       "   'classes': [{'name': 'SQLAgent',\n",
       "     'docstring': 'SQL-aware ReActAgent with DB connection, schema cache, and SQL tools pre-wired.\\n\\nExample:\\n    >>> llm = TransformersModel(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")\\n    >>> agent = SQLAgent(llm=llm, db_uri=\"sqlite:///my.db\", sample_rows_in_table_info=3)\\n    >>> for chunk in agent.run(\"How many users registered last month?\"):\\n    ...     print(chunk, end=\"\")',\n",
       "     'methods': [{'name': 'train',\n",
       "       'docstring': 'Warm up schema cache (optionally summarize). This yields progress strings.',\n",
       "       'args': ['self', 'summarize', 'force']},\n",
       "      {'name': 'is_trained',\n",
       "       'docstring': 'True if we have at least one cached schema summary.',\n",
       "       'args': ['self']},\n",
       "      {'name': 'register_tool',\n",
       "       'docstring': 'Register an extra tool and refresh the parent toolkit reference.',\n",
       "       'args': ['self', 'tool']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.common.utils': {'path': 'agents/common/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/common/utils.py',\n",
       "   'package': 'neurosurfer.agents.common',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'stream_text_from_response',\n",
       "     'docstring': None,\n",
       "     'args': ['resp']},\n",
       "    {'name': 'nonstream_text_from_response',\n",
       "     'docstring': None,\n",
       "     'args': ['resp']},\n",
       "    {'name': 'normalize_response',\n",
       "     'docstring': 'For tool responses, normalize into either a string or a generator[str].',\n",
       "     'args': ['results']},\n",
       "    {'name': 'extract_and_repair_json',\n",
       "     'docstring': 'Extract and parse the first valid JSON object from arbitrary text (e.g., LLM output).\\n\\nHandles:\\n- Markdown code fences (```json ... ```)\\n- Extraneous text before/after JSON\\n- Nested braces {...}\\n- Incomplete or malformed chunks (best-effort parsing)\\n\\nReturns:\\n    dict if successful, otherwise None.',\n",
       "     'args': ['text', 'return_dict']},\n",
       "    {'name': 'rprint', 'docstring': None, 'args': ['msg', 'color', 'rich']}]},\n",
       "  'neurosurfer.agents.rag.ingestor': {'path': 'agents/rag/ingestor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/ingestor.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [{'name': 'RAGIngestor',\n",
       "     'docstring': 'Production-grade RAG document ingestor.\\n\\nThis class orchestrates the complete document ingestion pipeline:\\nreading, chunking, embedding, deduplication, and vector storage.\\n\\nIt supports multiple input sources and provides progress tracking,\\ncancellation, and parallel processing capabilities.\\n\\nAttributes:\\n    embedder (BaseEmbedder): Embedding model for generating vectors\\n    vs (BaseVectorDB): Vector store for document storage\\n    reader (FileReader): File reader for various formats\\n    chunker (Chunker): Document chunker\\n    log (logging.Logger): Logger instance\\n    progress_cb (Optional[ProgressCallback]): Progress callback function\\n    cancel_event (threading.Event): Event for cancellation\\n    batch_size (int): Batch size for embedding generation\\n    max_workers (int): Max parallel workers for processing\\n    deduplicate (bool): Enable content-based deduplication\\n    normalize_embeddings (bool): Normalize embedding vectors\\n\\nExample:\\n    >>> ingestor = RAGIngestor(\\n    ...     embedder=embedder,\\n    ...     vectorstore=vectorstore,\\n    ...     batch_size=64,\\n    ...     progress_cb=lambda p: print(f\"Progress: {p[\\'percent\\']:.1f}%\")\\n    ... )\\n    >>> \\n    >>> # Add multiple sources\\n    >>> ingestor.add_files([\"./docs\", \"./code\"])\\n    >>> ingestor.add_text(\"Custom content\", metadata={\"source\": \"manual\"})\\n    >>> \\n    >>> # Ingest all\\n    >>> stats = ingestor.ingest()\\n    >>> print(f\"Ingested {stats[\\'chunks_added\\']} chunks\")',\n",
       "     'methods': [{'name': 'set_vectorstore',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'vectorstore']},\n",
       "      {'name': 'add_files',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'paths', 'include_exts', 'root', 'extra_metadata']},\n",
       "      {'name': 'add_directory',\n",
       "       'docstring': None,\n",
       "       'args': ['self',\n",
       "        'directory',\n",
       "        'include_exts',\n",
       "        'exclude_dirs',\n",
       "        'extra_metadata']},\n",
       "      {'name': 'add_texts',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'texts', 'base_id', 'metadatas']},\n",
       "      {'name': 'add_urls',\n",
       "       'docstring': 'Pass a custom fetcher to keep this offline-friendly. Example fetcher can use requests/bs4.',\n",
       "       'args': ['self', 'urls', 'fetcher', 'extra_metadata']},\n",
       "      {'name': 'add_git_folder',\n",
       "       'docstring': 'Index an already-cloned repo folder (avoids adding .git, node_modules, etc.).',\n",
       "       'args': ['self', 'repo_root', 'include_exts', 'extra_metadata']},\n",
       "      {'name': 'add_zipfile',\n",
       "       'docstring': \"Extract a single .zip into a temporary folder, index its contents using add_directory,\\nthen delete the temp folder. Adds {'source_zip': <zip filename>} to each doc's metadata.\",\n",
       "       'args': ['self',\n",
       "        'zip_path',\n",
       "        'include_exts',\n",
       "        'exclude_dirs',\n",
       "        'extra_metadata']},\n",
       "      {'name': 'ingest',\n",
       "       'docstring': 'Unified high-level ingestion wrapper.\\n\\nThis method accepts a mix of paths, URLs, and raw text, routes them to the\\nappropriate add_* methods, and then runs the full pipeline via `build()`.\\n\\nSupported source forms:\\n    - File path (string or Path)\\n    - Directory path (string or Path)\\n    - .zip archive (string or Path)\\n    - Git repo folder (directory containing a .git subfolder)\\n    - URL string (starting with http:// or https://)\\n    - Raw text string (everything else)\\n\\nParameters\\n----------\\nsources:\\n    A single source or iterable of sources. Each element can be:\\n    - str\\n    - pathlib.Path\\nurl_fetcher:\\n    Optional callable used by `add_urls`. Signature: (url: str) -> Optional[str].\\ninclude_exts:\\n    Allowed file extensions for file/directory/zip ingestion. Defaults to\\n    `supported_file_types`.\\nextra_metadata:\\n    Extra metadata merged into each queued document\\'s metadata.\\nreset_state:\\n    If True, clears previous queue and seen-hash set before processing.\\n\\nReturns\\n-------\\nDict[str, Any]\\n    A summary dictionary, typically the result of `build()`. On error, returns:\\n        {\\n            \"status\": \"error\",\\n            \"error\": \"<message>\",\\n            \"unsupported\": [...optional list of unsupported items...]\\n        }',\n",
       "       'args': ['self',\n",
       "        'sources',\n",
       "        'url_fetcher',\n",
       "        'include_exts',\n",
       "        'extra_metadata',\n",
       "        'reset_state']},\n",
       "      {'name': 'build',\n",
       "       'docstring': 'Execute the ingestion:\\n  - chunk queued sources\\n  - dedupe by chunk hash\\n  - embed in batches\\n  - write to vector store\\nReturns a summary dict.',\n",
       "       'args': ['self']},\n",
       "      {'name': 'embed_query', 'docstring': None, 'args': ['self', 'text']},\n",
       "      {'name': 'search',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'text', 'top_k']}]}],\n",
       "   'functions': [{'name': 'sha256_text',\n",
       "     'docstring': 'Generate SHA256 hash of text string.',\n",
       "     'args': ['s']},\n",
       "    {'name': 'now_ts', 'docstring': 'Get current timestamp.', 'args': []}]},\n",
       "  'neurosurfer.agents.rag.picker': {'path': 'agents/rag/picker.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/picker.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'pick_files_by_grouped_chunk_hits',\n",
       "     'docstring': 'Broad similarity search -> aggregate by file -> top-N.\\nUseful for large codebases to decide focus files.',\n",
       "     'args': ['embedder',\n",
       "      'vector_db',\n",
       "      'section_query',\n",
       "      'candidate_pool_size',\n",
       "      'n_files',\n",
       "      'file_key']}]},\n",
       "  'neurosurfer.agents.rag.constants': {'path': 'agents/rag/constants.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/constants.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.config': {'path': 'agents/rag/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/config.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [{'name': 'RetrieveResult', 'docstring': None, 'methods': []},\n",
       "    {'name': 'RetrievalPlan',\n",
       "     'docstring': 'Plan for how much to retrieve and how to shape the context.\\n\\nThis is intentionally simple and can be created by:\\n  - RAGGate (UI layer) or\\n  - RAGAgent itself via an internal LLM call.',\n",
       "     'methods': []},\n",
       "    {'name': 'RAGIngestorConfig', 'docstring': None, 'methods': []},\n",
       "    {'name': 'RAGAgentConfig', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.chunker': {'path': 'agents/rag/chunker.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/chunker.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [{'name': 'CustomChunkHandler',\n",
       "     'docstring': None,\n",
       "     'methods': []},\n",
       "    {'name': 'Chunker',\n",
       "     'docstring': 'Extensible document chunker with pluggable strategy registry for different file types.\\n\\nThis class provides intelligent document chunking for RAG (Retrieval-Augmented Generation)\\nsystems with support for multiple file formats and customizable chunking strategies.\\n\\nKey Features:\\n    - Pluggable strategy system for different file types (Python, JavaScript, JSON, Markdown, etc.)\\n    - Line-based chunking for code (preserves structure and context)\\n    - Character-based chunking for prose and generic text\\n    - Configurable overlap between chunks to maintain context\\n    - Comment-aware filtering to exclude comment-only blocks\\n    - Blacklist patterns for excluding unwanted file types\\n    - AST-based chunking for Python code with structural awareness\\n    - Custom handler system for specialized chunking logic\\n    - Router system for dynamic strategy selection\\n    - Comprehensive error handling and fallback mechanisms\\n\\nThe chunker follows a priority-based strategy selection:\\n1. Explicit custom handlers (callable or registered name)\\n2. Router function results\\n3. File extension mappings to custom handlers\\n4. Built-in strategies by file extension\\n5. Heuristic fallback (line-based for code, character-based for prose)\\n\\nArgs:\\n    config: ChunkerConfig instance controlling chunking behavior.\\n           Uses default configuration if not provided.\\n\\nExample:\\n    >>> config = ChunkerConfig(fallback_chunk_size=30, overlap_lines=5)\\n    >>> chunker = Chunker(config)\\n    >>>\\n    >>> # Chunk Python code with structural awareness\\n    >>> chunks = chunker.chunk(python_code, file_path=\"script.py\")\\n    >>>\\n    >>> # Register custom strategy for specific file types\\n    >>> def my_strategy(text, file_path):\\n    ...     return text.split(\"\\\\n\\\\n\")\\n    >>> chunker.register([\".custom\"], my_strategy)',\n",
       "     'methods': [{'name': 'register',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'exts', 'fn']},\n",
       "      {'name': 'set_logger', 'docstring': None, 'args': ['self', 'logger_fn']},\n",
       "      {'name': 'register_custom',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'name', 'handler']},\n",
       "      {'name': 'unregister_custom',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'name']},\n",
       "      {'name': 'list_custom_handlers', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'use_custom_for_ext',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'exts', 'handler_name']},\n",
       "      {'name': 'clear_custom_for_ext',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'exts']},\n",
       "      {'name': 'set_router',\n",
       "       'docstring': 'router(file_path, text) -> handler_name or None\\nCalled before strategies and fallbacks. Return a registered name or None.',\n",
       "       'args': ['self', 'router']},\n",
       "      {'name': 'list_ext_mappings', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'chunk',\n",
       "       'docstring': 'Chunk text into smaller pieces using a priority-based strategy selection.\\n\\nThe method uses the following priority order:\\n1. Explicit custom handler (callable or registered name)\\n2. Router function result pointing to registered custom handler\\n3. File extension mapping to custom handler\\n4. Built-in strategy registry by file extension\\n5. Heuristic fallback (line-based for code-like content, char-based for prose)\\n\\nArgs:\\n    text: The text content to be chunked\\n    source_id: Optional identifier for the source document (currently unused)\\n    file_path: Optional file path to determine file type and apply blacklist filtering\\n    k: Minimum word count threshold - if text has fewer words, returns as single chunk\\n    custom: Optional custom chunking handler (either registered name or callable)\\n\\nReturns:\\n    List of text chunks. Returns empty list if text is empty, file should be skipped,\\n    or no valid chunks can be generated.\\n\\nRaises:\\n    No exceptions raised - all errors are logged and handled gracefully with fallbacks.',\n",
       "       'args': ['self', 'text', 'source_id', 'file_path', 'k', 'custom']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.context_builder': {'path': 'agents/rag/context_builder.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/context_builder.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [{'name': 'ContextBuilder',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'build',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'docs']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.templates': {'path': 'agents/rag/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/templates.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.agent': {'path': 'agents/rag/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/agent.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [{'name': 'RAGAgent',\n",
       "     'docstring': 'Retrieval core for RAG pipelines. VectorDB- and embedder-agnostic.\\nAdds a convenient `run(...)` that makes a full LLM call with the retrieved context.',\n",
       "     'methods': [{'name': 'set_collection',\n",
       "       'docstring': 'Call this method to set a new collection for ingesting and retrieving documents.',\n",
       "       'args': ['self', 'collection_name', 'clear_collection_on_init']},\n",
       "      {'name': 'ingest',\n",
       "       'docstring': 'Unified high-level ingestion wrapper.\\n\\nThis method accepts a mix of paths, URLs, and raw text, routes them to the\\nappropriate add_* methods, and then runs the full pipeline via `build()`.\\n\\nSupported source forms:\\n    - File path (string or Path)\\n    - Directory path (string or Path)\\n    - .zip archive (string or Path)\\n    - Git repo folder (directory containing a .git subfolder)\\n    - URL string (starting with http:// or https://)\\n    - Raw text string (everything else)\\n\\nParameters\\n----------\\nsources:\\n    A single source or iterable of sources. Each element can be:\\n    - str\\n    - pathlib.Path\\nurl_fetcher:\\n    Optional callable used by `add_urls`. Signature: (url: str) -> Optional[str].\\ninclude_exts:\\n    Allowed file extensions for file/directory/zip ingestion. Defaults to\\n    `supported_file_types`.\\nextra_metadata:\\n    Extra metadata merged into each queued document\\'s metadata.\\nreset_state:\\n    If True, clears previous queue and seen-hash set before processing.\\n\\nReturns\\n-------\\nDict[str, Any]\\n    A summary dictionary, typically the result of `build()`. On error, returns:\\n        {\\n            \"status\": \"error\",\\n            \"error\": \"<message>\",\\n            \"unsupported\": [...optional list of unsupported items...]\\n        }',\n",
       "       'args': ['self',\n",
       "        'sources',\n",
       "        'url_fetcher',\n",
       "        'include_exts',\n",
       "        'extra_metadata',\n",
       "        'reset_state']},\n",
       "      {'name': 'retrieve',\n",
       "       'docstring': \"Public interface for retrieving documents from the vectorstore.\\n\\nArgs:\\n    user_query: The user's query string.\\n    top_k: Optional number of documents to retrieve.\\n    metadata_filter: Optional metadata filter for the search.\\n    similarity_threshold: Optional similarity threshold for the search.\\n\\nReturns:\\n    RetrieveResult: The result of the retrieval process.\",\n",
       "       'args': ['self',\n",
       "        'user_query',\n",
       "        'top_k',\n",
       "        'metadata_filter',\n",
       "        'similarity_threshold',\n",
       "        'retrieval_mode',\n",
       "        'retrieval_scope',\n",
       "        'retrieval_plan']},\n",
       "      {'name': 'run',\n",
       "       'docstring': \"Public interface for running the RAG pipeline.\\n\\nArgs:\\n    user_query: The user's query string.\\n    system_prompt: Optional system prompt for the LLM.\\n    chat_history: Optional chat history for the LLM.\\n    stream: Whether to stream the response.\\n    top_k: Optional number of documents to retrieve.\\n    metadata_filter: Optional metadata filter for the search.\\n    similarity_threshold: Optional similarity threshold for the search.\\n    temperature: Optional temperature for the LLM.\\n    **llm_kwargs: Additional keyword arguments for the LLM.\\nReturns:\\n    LLM_RESPONSE_TYPE:\\n        - If stream=False: Returns ChatCompletionResponse (Pydantic model)\\n        - If stream=True: Returns Generator yielding ChatCompletionChunk objects\\nRaises:\\n    ValueError: If vectorstore or embedder is not provided.\\n    ValueError: If LLM is not provided.\",\n",
       "       'args': ['self',\n",
       "        'user_query',\n",
       "        'system_prompt',\n",
       "        'chat_history',\n",
       "        'top_k',\n",
       "        'metadata_filter',\n",
       "        'similarity_threshold',\n",
       "        'temperature',\n",
       "        'stream',\n",
       "        '**llm_kwargs']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.__init__': {'path': 'agents/rag/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/__init__.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.token_utils': {'path': 'agents/rag/token_utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/token_utils.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [{'name': 'TokenCounter',\n",
       "     'docstring': 'Vendor-agnostic token utilities.\\n- If llm.tokenizer is present (HF or similar), use it.\\n- Else, try tiktoken if available (OpenAI-like approximation).\\n- Else, fall back to char-based heuristic (chars_per_token).',\n",
       "     'methods': [{'name': 'count',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'text']},\n",
       "      {'name': 'trim_to_tokens',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'text', 'max_tokens']},\n",
       "      {'name': 'apply_chat_template',\n",
       "       'docstring': 'Try llm.tokenizer.apply_chat_template; else naive concatenation.',\n",
       "       'args': ['self', 'messages']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.rag.filereader': {'path': 'agents/rag/filereader.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/rag/filereader.py',\n",
       "   'package': 'neurosurfer.agents.rag',\n",
       "   'classes': [{'name': 'FileReader',\n",
       "     'docstring': 'Unified file reader for multiple formats.\\n\\nThis class provides a single interface for reading various file types\\ninto plain text. It automatically detects the file type by extension\\nand applies the appropriate reader method.\\n\\nAttributes:\\n    supported_types (dict): Mapping of file extensions to reader functions\\n\\nExample:\\n    >>> reader = FileReader()\\n    >>> \\n    >>> # Read different file types\\n    >>> pdf_text = reader.read(\"report.pdf\")\\n    >>> excel_text = reader.read(\"data.xlsx\")\\n    >>> code_text = reader.read(\"script.py\")\\n    >>> \\n    >>> # Check supported types\\n    >>> print(reader.supported_types.keys())',\n",
       "     'methods': [{'name': 'read',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'file_path']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.memory': {'path': 'agents/react/memory.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/memory.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'EphemeralMemory',\n",
       "     'docstring': 'Short-lived scratch memory for passing small items between steps.\\nCleared after each tool execution (by agent).',\n",
       "     'methods': [{'name': 'set',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'key', 'val']},\n",
       "      {'name': 'items', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'clear', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.types': {'path': 'agents/react/types.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/types.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'ToolCall', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ReactAgentResponse', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.history': {'path': 'agents/react/history.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/history.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'History',\n",
       "     'docstring': 'A simple list of strings appended in the loop.\\nEach entry is typically a block like:\\n  - Thought: ...\\n  - Action: {...}\\n  - results: ...',\n",
       "     'methods': [{'name': 'append',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'line']},\n",
       "      {'name': 'as_text', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'to_prompt',\n",
       "       'docstring': 'Render the previous reasoning steps as a readable history.\\n\\nWe emphasize that these are *past* steps so the model is\\nless tempted to repeat them verbatim.',\n",
       "       'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.retry': {'path': 'agents/react/retry.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/retry.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'RetryPolicy',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'sleep',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'attempt']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.config': {'path': 'agents/react/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/config.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'ReActConfig', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.parser': {'path': 'agents/react/parser.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/parser.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'ToolCallParser',\n",
       "     'docstring': 'Extracts and normalizes a tool call from an LLM message.\\n- tolerant to fenced blocks\\n- tolerant to trailing commas and missing braces\\n- returns ToolCall',\n",
       "     'methods': [{'name': 'extract',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'text']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.base': {'path': 'agents/react/base.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/base.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'AgentDelimiters', 'docstring': None, 'methods': []},\n",
       "    {'name': 'BaseAgent',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'stop_generation',\n",
       "       'docstring': None,\n",
       "       'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.scratchpad': {'path': 'agents/react/scratchpad.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/scratchpad.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.agent': {'path': 'agents/react/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/agent.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'ReActAgent',\n",
       "     'docstring': 'Production-ready ReAct Agent with:\\n- tolerant Action parsing\\n- input sanitization vs ToolSpec (drop extras or repair)\\n- bounded retries on parse & tool errors\\n- reusable base class & utilities',\n",
       "     'methods': [{'name': 'run',\n",
       "       'docstring': 'Run the ReAct agent.\\n\\n- If stream=True: returns ReactAgentResponse with a Generator[str]\\n  that yields tokens as they are produced.\\n- If stream=False: returns ReactAgentResponse with the full string\\n  (we still use streaming under the hood, but we buffer it).',\n",
       "       'args': ['self',\n",
       "        'query',\n",
       "        'stream',\n",
       "        'temperature',\n",
       "        'max_new_tokens',\n",
       "        'specific_instructions',\n",
       "        'context',\n",
       "        '_route_extra_instructions',\n",
       "        'reset_tracer']},\n",
       "      {'name': 'stop_generation', 'docstring': None, 'args': ['self']},\n",
       "      {'name': 'update_toolkit',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'toolkit']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.exceptions': {'path': 'agents/react/exceptions.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/exceptions.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [{'name': 'ToolCallParseError',\n",
       "     'docstring': None,\n",
       "     'methods': []},\n",
       "    {'name': 'ToolExecutionError', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.react.__init__': {'path': 'agents/react/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/react/__init__.py',\n",
       "   'package': 'neurosurfer.agents.react',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.loader': {'path': 'agents/graph/loader.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/loader.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'load_graph_from_dict',\n",
       "     'docstring': 'Load a Graph from a raw dict, with:\\n  - Unknown keys warned and ignored\\n  - Detailed error messages on schema violations\\n  - Semantic validation of outputs / depends_on / DAG structure',\n",
       "     'args': ['data']},\n",
       "    {'name': 'load_graph',\n",
       "     'docstring': 'Load a Graph from a YAML or JSON file.\\n\\nFeatures:\\n  - YAML/JSON parse errors are reported with filename and cause.\\n  - Unknown keys are warned and ignored (top-level + per-node).\\n  - Schema errors show precise locations (e.g., nodes[1].id).\\n  - Semantic errors (unknown outputs, bad depends_on, cycles) are reported\\n    via GraphConfigurationError with clear messages.\\n\\nExample:\\n    spec = load_graph(\"flows/blog_workflow.yaml\")',\n",
       "     'args': ['path']}]},\n",
       "  'neurosurfer.agents.graph.manager': {'path': 'agents/graph/manager.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/manager.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [{'name': 'ManagerConfig', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ManagerAgent',\n",
       "     'docstring': \"LLM-based manager that composes the `user_prompt` for each node's Agent.\\n\\nIt does NOT execute tools or call the underlying Agents itself;\\nit only crafts prompts based on:\\n  - Node spec (purpose / goal / expected_result / tools)\\n  - Original graph inputs\\n  - Dependency results\\n  - Previous node result\",\n",
       "     'methods': [{'name': 'compose_user_prompt',\n",
       "       'docstring': 'Compose the next `user_prompt` for the given node.\\n\\nReturns a plain string to pass into `Agent.run(...)`.',\n",
       "       'args': ['self',\n",
       "        'node',\n",
       "        'graph_inputs',\n",
       "        'dependency_results',\n",
       "        'previous_result',\n",
       "        'temperature',\n",
       "        'max_new_tokens']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.utils': {'path': 'agents/graph/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/utils.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'get_from_ctx',\n",
       "     'docstring': 'Resolve a dotted path like \"nodes.research.summary\" or \"inputs.topic\".\\nSupports nested dicts and simple list indices.',\n",
       "     'args': ['ctx', 'path']},\n",
       "    {'name': 'render_template',\n",
       "     'docstring': 'Very small templating helper.\\nReplaces `{{ path.to.value }}` with a value looked up via `get_from_ctx`.\\nIf lookup fails, leaves the placeholder untouched.',\n",
       "     'args': ['text', 'ctx']},\n",
       "    {'name': 'topo_sort',\n",
       "     'docstring': 'Topologically sort nodes based on their `depends_on` list.\\nRaises GraphConfigurationError on cycles or unknown dependencies.',\n",
       "     'args': ['nodes']},\n",
       "    {'name': 'import_string',\n",
       "     'docstring': 'Import an object from a \"module:attr\" or \"module.attr\" path.\\nExample:\\n    \"myproj.schemas.Answer\" -> myproj.schemas.Answer',\n",
       "     'args': ['path']},\n",
       "    {'name': 'normalize_and_validate_graph_inputs',\n",
       "     'docstring': 'Enforce graph-level input spec if declared.\\n\\n- If `graph.inputs` is empty:\\n    - dict -> used as-is\\n    - anything else -> wrapped as `{\"query\": inputs}`\\n- If `graph.inputs` is non-empty:\\n    - inputs must be a dict\\n    - missing required keys -> GraphConfigurationError\\n    - extra keys -> warned and ignored\\n    - values are cast according to GraphInput.type',\n",
       "     'args': ['graph', 'inputs']}]},\n",
       "  'neurosurfer.agents.graph.schema': {'path': 'agents/graph/schema.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/schema.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [{'name': 'NodeMode', 'docstring': None, 'methods': []},\n",
       "    {'name': 'GraphInput',\n",
       "     'docstring': 'Specification for a top-level graph input.\\n\\nNormalized form:\\n  name: str\\n  type: str     (string|integer|float|boolean|object|array, or synonyms)\\n  required: bool\\n  description: Optional[str]',\n",
       "     'methods': []},\n",
       "    {'name': 'NodePolicy',\n",
       "     'docstring': 'Per-node policy that can override some AgentConfig settings and add\\nnode-level execution constraints (e.g., timeout).\\n\\nYAML example:\\n    nodes:\\n      - id: research\\n        policy:\\n          retries: 1\\n          timeout_s: 30\\n          max_new_tokens: 180\\n          temperature: 0.2\\n          allow_input_pruning: false\\n          repair_with_llm: true\\n          strict_tool_call: true',\n",
       "     'methods': []},\n",
       "    {'name': 'GraphNode', 'docstring': None, 'methods': []},\n",
       "    {'name': 'Graph',\n",
       "     'docstring': None,\n",
       "     'methods': [{'name': 'node_map', 'docstring': None, 'args': ['self']}]},\n",
       "    {'name': 'NodeExecutionResult', 'docstring': None, 'methods': []},\n",
       "    {'name': 'GraphExecutionResult', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.export': {'path': 'agents/graph/export.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/export.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'export',\n",
       "     'docstring': 'Export node results to disk for nodes that have `export=True`.\\n\\nRules:\\n- If node.export_path is a file (has extension) -> use that exact file.\\n- If node.export_path is a directory / bare path -> write\\n    `{node_id}_{timestamp}.ext` inside it.\\n- If node.export_path is not set -> write into `export_base_dir`\\n    (or `base_dir` override) as `{node_id}_{timestamp}.ext`.\\n\\nContent:\\n- If structured_output is present -> JSON by default.\\n- Else if tool_call_output is present -> JSON by default.\\n- Else -> raw_output as Markdown by default.\\n\\nIf the final path has `.json`, will always write JSON.\\nIf `.md` / `.txt`, will write Markdown (embedding JSON if needed).',\n",
       "     'args': ['graph_results', 'export_base_dir']},\n",
       "    {'name': 'export_single_node',\n",
       "     'docstring': None,\n",
       "     'args': ['node', 'result', 'base_dir']},\n",
       "    {'name': 'resolve_export_path',\n",
       "     'docstring': 'Decide where to write the file for a node.',\n",
       "     'args': ['node', 'started_at', 'base_dir', 'default_ext']},\n",
       "    {'name': 'build_json_payload',\n",
       "     'docstring': 'Build a JSON-friendly representation of the node result.',\n",
       "     'args': ['node', 'result', 'content_kind']},\n",
       "    {'name': 'build_markdown_payload',\n",
       "     'docstring': 'Build a Markdown representation of the node result.',\n",
       "     'args': ['node', 'result', 'content_kind']}]},\n",
       "  'neurosurfer.agents.graph.errors': {'path': 'agents/graph/errors.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/errors.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [{'name': 'GraphError',\n",
       "     'docstring': 'Base exception for graph-related issues.',\n",
       "     'methods': []},\n",
       "    {'name': 'GraphConfigurationError',\n",
       "     'docstring': 'Invalid graph spec, missing tools, cycles, etc.',\n",
       "     'methods': []},\n",
       "    {'name': 'GraphExecutionError',\n",
       "     'docstring': 'Errors that occur during graph execution.',\n",
       "     'methods': []},\n",
       "    {'name': 'NodeExecutionError',\n",
       "     'docstring': 'A single node failed in an unexpected way.',\n",
       "     'methods': []},\n",
       "    {'name': 'ValidationError', 'docstring': None, 'methods': []},\n",
       "    {'name': 'PlanningError', 'docstring': None, 'methods': []},\n",
       "    {'name': 'NodeError', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.executor': {'path': 'agents/graph/executor.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/executor.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [{'name': 'GraphExecutor',\n",
       "     'docstring': 'Execute a `Graph` DAG using:\\n  - A single shared `llm` (BaseChatModel) for all nodes by default.\\n  - A single shared `Toolkit` (all tools), with per-node subsets based on YAML.\\n  - A `ManagerAgent` (by default using the same `llm`) to compose inter-node prompts.\\n\\nUsers only need:\\n  - YAML flow (Graph)\\n  - `llm` instance\\n  - `toolkit` instance\\n\\nFeatures:\\n  - Per-node policy (NodePolicy) allowing AgentConfig-like overrides:\\n      * budget: max_new_tokens, temperature, return_stream_by_default\\n      * retries: override AgentConfig.retry.max_route_retries\\n      * timeout_s: soft node-level timeout flag\\n      * toggles: allow_input_pruning, repair_with_llm, strict_tool_call, etc.\\n  - Top-level graph inputs (`Graph.inputs`) that:\\n      * validate runtime `inputs`\\n      * cast values to expected types\\n      * can be interpolated into node prompts via `{input_name}`.',\n",
       "     'methods': [{'name': 'run',\n",
       "       'docstring': 'Execute the entire graph once.\\n\\nParameters\\n----------\\ninputs:\\n    Runtime inputs to the graph.\\n\\n    If the graph declares `inputs` in YAML:\\n      - Must be a mapping (dict)\\n      - Validated and cast according to GraphInput\\n      - Extra keys are warned and ignored\\n\\n    If the graph does NOT declare `inputs`:\\n      - If `inputs` is a dict, it\\'s used as-is\\n      - Otherwise, it\\'s wrapped as: {\"query\": inputs}\\nmanager_temperature:\\n    Temperature used for ManagerAgent when composing prompts.\\nmanager_max_new_tokens:\\n    Max new tokens for ManagerAgent responses.\\n\\nReturns\\n-------\\nGraphExecutionResult\\n    Contains the graph spec, all node results, and the final outputs.',\n",
       "       'args': ['self',\n",
       "        'inputs',\n",
       "        'manager_temperature',\n",
       "        'manager_max_new_tokens']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.templates': {'path': 'agents/graph/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/templates.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.agent': {'path': 'agents/graph/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/agent.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [{'name': 'GraphAgent',\n",
       "     'docstring': 'High-level agent wrapper around `GraphExecutor`.\\n\\nUsers can think of this as:\\n  - \"Use a normal Agent for single-step reasoning\"\\n  - \"Use GraphAgent when you want a DAG/flow of Agents\"\\n\\nTypical usage\\n-------------\\n    agent = GraphAgent(\\n        graph_yaml=\"blog_workflow.yml\",\\n        llm=LLM,\\n        toolkit=toolkit,\\n    )\\n\\n    result = agent.run(\\n        inputs={\\n            \"topic_title\": \"...\",\\n            \"query\": \"...\",\\n            \"audience\": \"...\",\\n            \"tone\": \"...\",\\n        }\\n    )',\n",
       "     'methods': [{'name': 'run',\n",
       "       'docstring': 'Execute the graph once with the given inputs.\\n\\nParameters\\n----------\\ninputs:\\n    Runtime inputs to the graph (dict or scalar). Delegated to\\n    `normalize_and_validate_graph_inputs` inside GraphExecutor.\\nmanager_temperature:\\n    Optional override for ManagerAgent temperature.\\nmanager_max_new_tokens:\\n    Optional override for ManagerAgent max_new_tokens.\\n\\nReturns\\n-------\\nGraphExecutionResult\\n    Contains the graph spec, all node results, and the final outputs.',\n",
       "       'args': ['self',\n",
       "        'inputs',\n",
       "        'manager_temperature',\n",
       "        'manager_max_new_tokens']},\n",
       "      {'name': 'get_artifact',\n",
       "       'docstring': \"Shortcut to fetch a node's raw artifact from the ArtifactStore.\",\n",
       "       'args': ['self', 'node_id']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.model_pool': {'path': 'agents/graph/model_pool.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/model_pool.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [{'name': 'ModelProfile', 'docstring': None, 'methods': []},\n",
       "    {'name': 'ModelPool',\n",
       "     'docstring': 'Token/slot-based concurrency control.\\n- Each model has a semaphore (slots).\\n- On OOM, we record timestamp and shrink allowed tokens for a while.',\n",
       "     'methods': [{'name': 'from_llms',\n",
       "       'docstring': None,\n",
       "       'args': ['cls', 'llms', 'default_concurrency']},\n",
       "      {'name': 'register_model',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'model_name', 'profile']},\n",
       "      {'name': 'bucket', 'docstring': None, 'args': ['self', 'model_name']},\n",
       "      {'name': 'release', 'docstring': None, 'args': ['self', 'model_name']},\n",
       "      {'name': 'notify_oom',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'model_name']},\n",
       "      {'name': 'recommend_max_new_tokens',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'model_name', 'requested']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.__init__': {'path': 'agents/graph/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/__init__.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.graph.artifacts': {'path': 'agents/graph/artifacts.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/graph/artifacts.py',\n",
       "   'package': 'neurosurfer.agents.graph',\n",
       "   'classes': [{'name': 'ArtifactStore',\n",
       "     'docstring': 'Minimal artifact store for graph runs.\\n\\nCurrently in-memory dict keyed by string IDs.\\nLater you can plug in disk / DB / S3 implementations.',\n",
       "     'methods': [{'name': 'put',\n",
       "       'docstring': None,\n",
       "       'args': ['self', 'key', 'value']},\n",
       "      {'name': 'get', 'docstring': None, 'args': ['self', 'key']},\n",
       "      {'name': 'as_dict', 'docstring': None, 'args': ['self']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.agent.responses': {'path': 'agents/agent/responses.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/responses.py',\n",
       "   'package': 'neurosurfer.agents.agent',\n",
       "   'classes': [{'name': 'ToolCallResponse', 'docstring': None, 'methods': []},\n",
       "    {'name': 'StructuredResponse', 'docstring': None, 'methods': []},\n",
       "    {'name': 'AgentResponse', 'docstring': None, 'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.agent.config': {'path': 'agents/agent/config.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/config.py',\n",
       "   'package': 'neurosurfer.agents.agent',\n",
       "   'classes': [{'name': 'RouterRetryPolicy',\n",
       "     'docstring': 'Retry tuning for routing + tool execution.',\n",
       "     'methods': []},\n",
       "    {'name': 'AgentConfig',\n",
       "     'docstring': 'Top-level configuration for the Agent.',\n",
       "     'methods': []}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.agent.templates': {'path': 'agents/agent/templates.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/templates.py',\n",
       "   'package': 'neurosurfer.agents.agent',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.agent.agent': {'path': 'agents/agent/agent.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/agent.py',\n",
       "   'package': 'neurosurfer.agents.agent',\n",
       "   'classes': [{'name': 'Agent',\n",
       "     'docstring': 'Generic LLM Agent with optional tool-calling and structured outputs.\\n\\nThis Agent is responsible for:\\n  - Plain LLM calls (free-text responses).\\n  - Structured JSON outputs validated against Pydantic models.\\n  - Tool routing and execution when a `Toolkit` is provided.\\n  - JSON prompting / parsing / repair (keeps BaseChatModel slim).\\n  - Optional tracing of key steps in the agentic flow via a pluggable `Tracer`.\\n\\nParameters\\n----------\\nllm:\\n    Concrete chat model implementing `BaseChatModel`. The agent calls this\\n    for both routing and final answers.\\ntoolkit:\\n    Optional `Toolkit` to enable tool routing + execution. If provided,\\n    `run()` will attempt to route to a tool by default.\\nconfig:\\n    Agent configuration object (see `AgentConfig`), including retry and\\n    JSON repair behaviour.\\nlogger:\\n    Python logger used for diagnostic messages.\\nverbose:\\n    If True, the agent logs more detail (e.g. selected tool, errors).\\ntracer:\\n    Optional `Tracer` used to record and span steps in the agent flow.\\nlog_tracing:\\n    If True, tracer if enabled will log spans to the console per step.\\n    Only applicable if `tracer` is not None.\\n\\nTracing behaviour\\n-----------------\\nWhen tracing is enabled, spans are opened around:\\n    * `agent.run`\\n    * `agent.structured_call`\\n    * `agent.route_and_call`\\n    * `agent.route_and_call.router_llm_call`\\n    * `agent.route_and_call.tool_execute`\\n    * `agent.free_text_call`\\nTracing results are available via the `traces` attribute of the `AgentResult` returned by `run()`, `structured_call()`, `route_and_call()`, and `free_text_call()`. ',\n",
       "     'methods': [{'name': 'run',\n",
       "       'docstring': 'Run a single agent step.\\n\\nDepending on the configuration and parameters, this will:\\n  - Call the LLM directly and return a free-text answer; OR\\n  - Use structured output with a Pydantic schema; OR\\n  - Route to a tool via the toolkit and return a `ToolCallResponse`.\\n\\nParameters\\n----------\\nsystem_prompt:\\n    Optional system prompt for the LLM. If omitted, a simple default\\n    \"helpful assistant\" prompt is used.\\nuser_prompt:\\n    Main user query / instruction. If omitted, `query` is used.\\nquery:\\n    Alias for `user_prompt`, mainly for backwards compatibility.\\noutput_schema:\\n    Optional Pydantic model class. If provided and no toolkit is set,\\n    the agent will attempt a structured JSON response, validate it\\n    against this model, and return a `StructuredResponse`.\\nstream:\\n    If True, requests streaming from the underlying LLM. If None,\\n    falls back to `config.return_stream_by_default`.\\ntemperature:\\n    Sampling temperature for the LLM. If None, uses `config.temperature`.\\nmax_new_tokens:\\n    Maximum number of new tokens to generate. If None, uses\\n    `config.max_new_tokens`.\\ncontext:\\n    Additional context dictionary merged into tool inputs when\\n    executing a tool. Ignored for free-text and structured calls.\\n_route_extra_instructions:\\n    Additional routing instructions appended to the system prompt for\\n    tool selection. Mostly internal.\\nstrict_tool_call:\\n    If True, the router must select a valid tool and repair invalid\\n    inputs; free-text fallback is disabled. If None, falls back to\\n    `config.strict_tool_call`.\\n\\nReturns\\n-------\\nAgentResponse\\n    - `response`: Union[str, Generator[str, None, None], StructuredResponse, ToolCallResponse]\\n        - Free-text answer (string or streaming generator of strings),\\n        or\\n        - StructuredResponse (for Pydantic-validated outputs), or\\n        - ToolCallResponse (for tool routing mode).\\n    - `traces`: Tracing results for the run.',\n",
       "       'args': ['self',\n",
       "        'system_prompt',\n",
       "        'user_prompt',\n",
       "        'query',\n",
       "        'output_schema',\n",
       "        'stream',\n",
       "        'temperature',\n",
       "        'max_new_tokens',\n",
       "        'context',\n",
       "        '_route_extra_instructions',\n",
       "        'strict_tool_call',\n",
       "        'reset_tracer']}]}],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.agent.__init__': {'path': 'agents/agent/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/__init__.py',\n",
       "   'package': 'neurosurfer.agents.agent',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.agents.agent.schema_utils': {'path': 'agents/agent/schema_utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/agents/agent/schema_utils.py',\n",
       "   'package': 'neurosurfer.agents.agent',\n",
       "   'classes': [{'name': 'StructuredPromptOptions',\n",
       "     'docstring': None,\n",
       "     'methods': []}],\n",
       "   'functions': [{'name': 'model_to_structure_block',\n",
       "     'docstring': 'Pretty, width-aware schema shape:\\n\\nCar: {\\n  make: str\\n  model: str\\n  features: [\\n    {\\n      name: str\\n      description: str\\n      location: { name: str, description: str }  // wrapped if short; multiline if long\\n    }\\n  ]  // add as many as needed\\n}',\n",
       "     'args': ['schema_cls',\n",
       "      'title',\n",
       "      'comment_for_arrays',\n",
       "      'max_inline_chars',\n",
       "      'indent',\n",
       "      'array_comment',\n",
       "      'object_comment',\n",
       "      'trail_commas']},\n",
       "    {'name': 'build_structured_system_prompt',\n",
       "     'docstring': None,\n",
       "     'args': ['base_system_prompt',\n",
       "      'schema_cls',\n",
       "      'options',\n",
       "      'use_model_json_schema']},\n",
       "    {'name': 'maybe_unwrap_named_root',\n",
       "     'docstring': 'If model returned {\"Car\": {...}} for schema `Car`, unwrap to {...}.\\nOtherwise return the original string.',\n",
       "     'args': ['json_obj', 'schema_cls']}]},\n",
       "  'neurosurfer.cli.processes': {'path': 'cli/processes.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/processes.py',\n",
       "   'package': 'neurosurfer.cli',\n",
       "   'classes': [],\n",
       "   'functions': []},\n",
       "  'neurosurfer.cli.serve': {'path': 'cli/serve.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/serve.py',\n",
       "   'package': 'neurosurfer.cli',\n",
       "   'classes': [{'name': 'ServeOptions', 'docstring': None, 'methods': []}],\n",
       "   'functions': [{'name': 'needs_npm_install',\n",
       "     'docstring': None,\n",
       "     'args': ['ui_root', 'mode']}]},\n",
       "  'neurosurfer.cli.utils': {'path': 'cli/utils.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/utils.py',\n",
       "   'package': 'neurosurfer.cli',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'eprint', 'docstring': None, 'args': ['*args']},\n",
       "    {'name': 'which',\n",
       "     'docstring': \"Robust 'which': return resolved path if the command is in PATH.\",\n",
       "     'args': ['cmd', 'verbose']},\n",
       "    {'name': 'env_truthy', 'docstring': None, 'args': ['name', 'default']},\n",
       "    {'name': 'find_packaged_ui_dir',\n",
       "     'docstring': 'Returns neurosurfer/ui_build if bundled and contains index.html.',\n",
       "     'args': []},\n",
       "    {'name': 'has_package_json', 'docstring': None, 'args': ['path']},\n",
       "    {'name': 'looks_like_build_dir', 'docstring': None, 'args': ['path']},\n",
       "    {'name': 'detect_ui_root', 'docstring': None, 'args': ['arg']},\n",
       "    {'name': 'effective_public_host', 'docstring': None, 'args': ['host']},\n",
       "    {'name': 'open_browser_safe', 'docstring': None, 'args': ['url']},\n",
       "    {'name': 'print_ready_banner',\n",
       "     'docstring': None,\n",
       "     'args': ['backend_url', 'ui_url']}]},\n",
       "  'neurosurfer.cli.main': {'path': 'cli/main.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/main.py',\n",
       "   'package': 'neurosurfer.cli',\n",
       "   'classes': [],\n",
       "   'functions': [{'name': 'build_parser', 'docstring': None, 'args': []},\n",
       "    {'name': 'main', 'docstring': None, 'args': ['argv']}]},\n",
       "  'neurosurfer.cli.__init__': {'path': 'cli/__init__.py',\n",
       "   'abs_path': '/home/nomi/workspace/neurosurfer/neurosurfer/cli/__init__.py',\n",
       "   'package': 'neurosurfer.cli',\n",
       "   'classes': [],\n",
       "   'functions': []}},\n",
       " 'summary': {'module_count': 140, 'class_count': 158, 'function_count': 103},\n",
       " 'errors': []}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files = scan_results.results[\"python_files\"]\n",
    "module_paths = None\n",
    "code_index_results = code_index_tool(python_files=python_files, module_paths=module_paths)\n",
    "code_index_results.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3dfd2cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<neurosurfer.agents.graph.agent.GraphAgent object at 0x7188e4571190>\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:42:44\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: directory_scan\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m1.\u001b[0m\u001b[2m904s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mscan_repo\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scan_repo'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scan_repo'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: directory_scan\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'include_patterns'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32m'**'\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'exclude_patterns'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'max_depth'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m10\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scan_repo'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m987s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scan_repo'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:42:47\u001b[0m | \u001b[96mdir_scanning.py:__call__\u001b[0m | DirectoryScanTool scanning project_root=/home/nomi/workspace/neurosurfer/neurosurfer docs_root=/home/nomi/workspace/neurosurfer/docs max_depth=10\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'directory_scan'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'project_root'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m'/home/nomi/workspace/neurosurfer/neurosurfer'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'docs_root'\u001b[0m\u001b[1;32m: '\u001b[0m\u001b[1;32m/home/nomi/workspace/\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scan_repo'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m004s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'scan_repo'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m993s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mscan_repo\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:42:47\u001b[0m | \u001b[96mtoolkit.py:register_tool\u001b[0m | Registered tool: code_symbol_index\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m3.\u001b[0m\u001b[2m183s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mbuild_symbol_index\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_index'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_index'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\n",
      "        \u001b[1;32mINFO: Selected tool: code_symbol_index\u001b[0m\n",
      "        \u001b[1;32mINFO: Raw inputs: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'module_paths'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32m'neurosurfer.agents.*'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'neurosurfer.models.*'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'neurosurfer.rag.*'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'neurosurfer.server.*'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'neurosurfer.cli.*'\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'neurosurfer.tools.*'\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m}\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_index'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.router_llm_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m571s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_index'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\n",
      "\u001b[93mWARNING \u001b[0m | \u001b[90m2025-11-26 14:42:53\u001b[0m | \u001b[96mcode_symbol_index.py:__call__\u001b[0m | CodeSymbolIndexTool requires either `python_files` argument or `project_root` configured in CodeSymbolIndexConfig.\n",
      "        \u001b[1;32mINFO: Tool \u001b[0m\u001b[1;32m'code_symbol_index'\u001b[0m\u001b[1;32m Tool Return: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'modules'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'summary'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'module_count'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'class_count'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'function_count'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m0\u001b[0m\u001b[1;32m}\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m'errors'\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32m{\u001b[0m\u001b[1;32m'\u001b[0m\u001b[1;32m...\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.tool.execute\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_index'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.route_and_call.tool_execute'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m0.\u001b[0m\u001b[2m001s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'build_symbol_index'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m573s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mbuild_symbol_index\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'manager.compose_user_prompt'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m2.\u001b[0m\u001b[2m526s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mmanager\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;33mðŸ§  Thinking\u001b[0m\u001b[1;4;33m...\u001b[0m\n",
      "\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mplan_docs\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing Start!\u001b[0m\n",
      "\u001b[2m â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\n",
      "\u001b[2m     â–¶ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\n",
      "\u001b[2m     â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.llm.call\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.free_text_call'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m58.\u001b[0m\u001b[2m105s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[2m â—€ \u001b[0m\u001b[1;2m[\u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[1;2m]\u001b[0m\u001b[1;2m[\u001b[0m\u001b[2mstep.agent\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m \u001b[0m\u001b[2;33magent_id\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'plan_docs'\u001b[0m\u001b[2m \u001b[0m\u001b[2;33mlabel\u001b[0m\u001b[2m=\u001b[0m\u001b[2;32m'agent.run'\u001b[0m\u001b[2m took \u001b[0m\u001b[1;2;36m58.\u001b[0m\u001b[2m106s; \u001b[0m\u001b[2;33merror\u001b[0m\u001b[2m=\u001b[0m\u001b[2;3;91mFalse\u001b[0m\n",
      "\u001b[1;4;36m[\u001b[0m\u001b[1;4;36mplan_docs\u001b[0m\u001b[1;4;36m]\u001b[0m\u001b[1;4;36m Tracing End!\u001b[0m\n",
      "\n",
      "\u001b[1;4;32mFinal response:\u001b[0m\n",
      "```json\n",
      "{\n",
      "  \"DocPlan\": {\n",
      "    \"index.md\": {\n",
      "      \"title\": \"Neurosurfer Documentation\",\n",
      "      \"path\": \"/index.md\"\n",
      "    },\n",
      "    \"contributing.md\": {\n",
      "      \"title\": \"Contributing to Neurosurfer\",\n",
      "      \"path\": \"/contributing.md\"\n",
      "    },\n",
      "    \"getting-started.md\": {\n",
      "      \"title\": \"Getting Started\",\n",
      "      \"path\": \"/getting-started.md\"\n",
      "    },\n",
      "    \"cli.md\": {\n",
      "      \"title\": \"CLI Reference\",\n",
      "      \"path\": \"/cli.md\"\n",
      "    },\n",
      "    \"examples/index.md\": {\n",
      "      \"title\": \"Examples\",\n",
      "      \"path\": \"/examples/index.md\"\n",
      "    },\n",
      "    \"examples/models-examples.md\": {\n",
      "      \"title\": \"Model Examples\",\n",
      "      \"path\": \"/examples/models-examples.md\"\n",
      "    },\n",
      "    \"examples/custom-tools-examples.md\": {\n",
      "      \"title\": \"Custom Tools Examples\",\n",
      "      \"path\": \"/examples/custom-tools-examples.md\"\n",
      "    },\n",
      "    \"examples/server-app-example.md\": {\n",
      "      \"title\": \"Server App Example\",\n",
      "      \"path\": \"/examples/server-app-example.md\"\n",
      "    },\n",
      "    \"examples/rag-examples.md\": {\n",
      "      \"title\": \"RAG Examples\",\n",
      "      \"path\": \"/examples/rag-examples.md\"\n",
      "    },\n",
      "    \"examples/agents-examples.md\": {\n",
      "      \"title\": \"Agent Examples\",\n",
      "      \"path\": \"/examples/agents-examples.md\"\n",
      "    },\n",
      "    \"server/index.md\": {\n",
      "      \"title\": \"Server\",\n",
      "      \"path\": \"/server/index.md\"\n",
      "    },\n",
      "    \"server/neurosurferui.md\": {\n",
      "      \"title\": \"Neurosurfer UI\",\n",
      "      \"path\": \"/server/neurosurferui.md\"\n",
      "    },\n",
      "    \"server/example-app.md\": {\n",
      "      \"title\": \"Example App\",\n",
      "      \"path\": \"/server/example-app.md\"\n",
      "    },\n",
      "    \"server/backend/index.md\": {\n",
      "      \"title\": \"Backend\",\n",
      "      \"path\": \"/server/backend/index.md\"\n",
      "    },\n",
      "    \"server/backend/custom-endpoints.md\": {\n",
      "      \"title\": \"Custom Endpoints\",\n",
      "      \"path\": \"/server/backend/custom-endpoints.md\"\n",
      "    },\n",
      "    \"server/backend/lifecycle-hooks.md\": {\n",
      "      \"title\": \"Lifecycle Hooks\",\n",
      "      \"path\": \"/server/backend/lifecycle-hooks.md\"\n",
      "    },\n",
      "    \"server/backend/auth.md\": {\n",
      "      \"title\": \"Authentication\",\n",
      "      \"path\": \"/server/backend/auth.md\"\n",
      "    },\n",
      "    \"server/backend/chat-handlers.md\": {\n",
      "      \"title\": \"Chat Handlers\",\n",
      "      \"path\": \"/server/backend/chat-handlers.md\"\n",
      "    },\n",
      "    \"api-reference/configuration.md\": {\n",
      "      \"title\": \"Configuration\",\n",
      "      \"path\": \"/api-reference/configuration.md\"\n",
      "    },\n",
      "    \"api-reference/index.md\": {\n",
      "      \"title\": \"API Reference\",\n",
      "      \"path\": \"/api-reference/index.md\"\n",
      "    },\n",
      "    \"api-reference/vectorstores/index.md\": {\n",
      "      \"title\": \"Vectorstores\",\n",
      "      \"path\": \"/api-reference/vectorstores/index.md\"\n",
      "    },\n",
      "    \"api-reference/vectorstores/in_memory.md\": {\n",
      "      \"title\": \"In-Memory Vectorstore\",\n",
      "      \"path\": \"/api-reference/vectorstores/in_memory.md\"\n",
      "    },\n",
      "    \"api-reference/vectorstores/base-vectordb.md\": {\n",
      "      \"title\": \"Base VectorDB\",\n",
      "      \"path\": \"/api-reference/vectorstores/base-vectordb.md\"\n",
      "    },\n",
      "    \"api-reference/vectorstores/chroma.md\": {\n",
      "      \"title\": \"Chroma Vectorstore\",\n",
      "      \"path\": \"/api-reference/vectorstores/chroma.md\"\n",
      "    },\n",
      "    \"api-reference/models/index.md\": {\n",
      "      \"title\": \"Models\",\n",
      "      \"path\": \"/api-reference/models/index.md\"\n",
      "    },\n",
      "    \"api-reference/models/embedders/index.md\": {\n",
      "      \"title\": \"Embedders\",\n",
      "      \"path\": \"/api-reference/models/embedders/index.md\"\n",
      "    },\n",
      "    \"api-reference/models/embedders/base-embedder.md\": {\n",
      "      \"title\": \"Base Embedder\",\n",
      "      \"path\": \"/api-reference/models/embedders/base-embedder.md\"\n",
      "    },\n",
      "    \"api-reference/models/embedders/sentence-transformer.md\": {\n",
      "      \"title\": \"Sentence Transformer Embedder\",\n",
      "      \"path\": \"/api-reference/models/embedders/sentence-transformer.md\"\n",
      "    },\n",
      "    \"api-reference/models/embedders/llamacpp-embedder.md\": {\n",
      "      \"title\": \"LLaMACPP Embedder\",\n",
      "      \"path\": \"/api-reference/models/embedders/llamacpp-embedder.md\"\n",
      "    },\n",
      "    \"api-reference/models/chat-models/index.md\": {\n",
      "      \"title\": \"Chat Models\",\n",
      "      \"path\": \"/api-reference/models/chat-models/index.md\"\n",
      "    },\n",
      "    \"api-reference/models/chat-models/base-model.md\": {\n",
      "      \"title\": \"Base Model\",\n",
      "      \"path\": \"/api-reference/models/chat-models/base-model.md\"\n",
      "    },\n",
      "    \"api-reference/models/chat-models/llamacpp-model.md\": {\n",
      "      \"title\": \"LLaMACPP Model\",\n",
      "      \"path\": \"/api-reference/models/chat-models/llamacpp-model.md\"\n",
      "    },\n",
      "    \"api-reference/models/chat-models/openai-model.md\": {\n",
      "      \"title\": \"OpenAI Model\",\n",
      "      \"path\": \"/api-reference/models/chat-models/openai-model.md\"\n",
      "    },\n",
      "    \"api-reference/models/chat-models/transformers-model.md\": {\n",
      "      \"title\": \"Transformers Model\",\n",
      "      \"path\": \"/api-reference/models/chat-models/transformers-model.md\"\n",
      "    },\n",
      "    \"api-reference/models/chat-models/unsloth-model.md\": {\n",
      "      \"title\": \"Unsloth Model\",\n",
      "      \"path\": \"/api-reference/models/chat-models/unsloth-model.md\"\n",
      "    },\n",
      "    \"api-reference/tools/index.md\": {\n",
      "      \"title\": \"Tools\",\n",
      "      \"path\": \"/api-reference/tools/index.md\"\n",
      "    },\n",
      "    \"api-reference/tools/tool-spec.md\": {\n",
      "      \"title\": \"Tool Specification\",\n",
      "      \"path\": \"/api-reference/tools/tool-spec.md\"\n",
      "    },\n",
      "    \"api-reference/tools/base-tool.md\": {\n",
      "      \"title\": \"Base Tool\",\n",
      "      \"path\": \"/api-reference/tools/base-tool.md\"\n",
      "    },\n",
      "    \"api-reference/tools/toolkit.md\": {\n",
      "      \"title\": \"Toolkit\",\n",
      "      \"path\": \"/api-reference/tools/toolkit.md\"\n",
      "    },\n",
      "    \"api-reference/tools/builtin-tools/index.md\": {\n",
      "      \"title\": \"Builtin Tools\",\n",
      "      \"path\": \"/api-reference/tools/builtin-tools/index.md\"\n",
      "    },\n",
      "    \"api-reference/tools/builtin-tools/sql/index.md\": {\n",
      "      \"title\": \"SQL Tools\",\n",
      "      \"path\": \"/api-reference/tools/builtin-tools/sql/index.md\"\n",
      "    },\n",
      "    \"api-reference/tools/builtin-tools/sql/sql_executor.md\": {\n",
      "      \"title\": \"SQL Executor\",\n",
      "      \"path\": \"/api-reference/tools/builtin-tools/sql/sql_executor.md\"\n",
      "    },\n",
      "    \"api-reference/tools/builtin-tools/sql/relevant_table_schema_retriever.md\": {\n",
      "      \"title\": \"Relevant Table Schema Retriever\",\n",
      "      \"path\": \"/api-reference/tools/builtin-tools/sql/relevant_table_schema_retriever.md\"\n",
      "    },\n",
      "    \"api-reference/tools/builtin-tools/sql/sql_query_generator.md\": {\n",
      "      \"title\": \"SQL Query Generator\",\n",
      "      \"path\": \"/api-reference/tools/builtin-tools/sql/sql_query_generator.md\"\n",
      "    },\n",
      "    \"api-reference/tools/builtin-tools/sql/final_answer_formatter.md\": {\n",
      "      \"title\": \"Final Answer Formatter\",\n",
      "      \"path\": \"/api-reference/tools/builtin-tools/sql/final_answer_formatter.md\"\n",
      "    },\n",
      "    \"api-reference/tools/builtin-tools/sql/db_insights_tool.md\": {\n",
      "      \"title\": \"DB Insights Tool\",\n",
      "      \"path\": \"/api-reference/tools/builtin-tools/sql/db_insights_tool.md\"\n",
      "    },\n",
      "    \"api-reference/rag/index.md\": {\n",
      "      \"title\": \"RAG\",\n",
      "      \"path\": \"/api-reference/rag/index.md\"\n",
      "    },\n",
      "    \"api-reference/rag/ingestor.md\": {\n",
      "      \"title\": \"Ingestor\",\n",
      "      \"path\": \"/api-reference/rag/ingestor.md\"\n",
      "    },\n",
      "    \"api-reference/rag/filereader.md\": {\n",
      "      \"title\": \"File Reader\",\n",
      "      \"path\": \"/api-reference/rag/filereader.md\"\n",
      "    },\n",
      "    \"api-reference/rag/chunker.md\": {\n",
      "      \"title\": \"Chunker\",\n",
      "      \"path\": \"/api-reference/rag/chunker.md\"\n",
      "    },\n",
      "    \"api-reference/agents/index.md\": {\n",
      "      \"title\": \"Agents\",\n",
      "      \"path\": \"/api-reference/agents/index.md\"\n",
      "    },\n",
      "    \"api-reference/agents/rag-agent.md\": {\n",
      "      \"title\": \"RAG Agent\",\n",
      "      \"path\": \"/api-reference/agents/rag-agent.md\"\n",
      "    },\n",
      "    \"api-reference/agents/react-agent.md\": {\n",
      "      \"title\": \"React Agent\",\n",
      "      \"path\": \"/api-reference/agents/react-agent.md\"\n",
      "    },\n",
      "    \"api-reference/agents/sql-agent.md\": {\n",
      "      \"title\": \"SQL Agent\",\n",
      "      \"path\": \"/api-reference/agents/sql-agent.md\"\n",
      "    },\n",
      "    \"api-reference/agents/tools_router_agent.md\": {\n",
      "      \"title\": \"Tools Router Agent\",\n",
      "      \"path\": \"/api-reference/agents/tools_router_agent.md\"\n",
      "    },\n",
      "    \"api-reference/database/index.md\": {\n",
      "      \"title\": \"Database\",\n",
      "      \"path\": \"/api-reference/database/index.md\"\n",
      "    },\n",
      "    \"api-reference/database/sql_schema_store.md\": {\n",
      "      \"title\": \"SQL Schema Store\",\n",
      "      \"path\": \"/api-reference/database/sql_schema_store.md\"\n",
      "    },\n",
      "    \"api-reference/database/sql_database.md\": {\n",
      "      \"title\": \"SQL Database\",\n",
      "      \"path\": \"/api-reference/database/sql_database.md\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:43:53\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node scan_repo output to exports/scan_repo_20251126_144246.json\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:43:53\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node build_symbol_index output to exports/build_symbol_index_20251126_144250.json\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-26 14:43:53\u001b[0m | \u001b[96mexport.py:export_single_node\u001b[0m | Exported node plan_docs output to exports/plan_docs_20251126_144255.md\n"
     ]
    }
   ],
   "source": [
    "from neurosurfer.models.chat_models.base import BaseChatModel\n",
    "from neurosurfer.agents.graph import GraphAgent, ManagerConfig\n",
    "\n",
    "graph_agent = GraphAgent(\n",
    "    llm=LLM,\n",
    "    graph_yaml=\"docgen_workflow.yml\",\n",
    "    toolkit=toolkit,\n",
    "    manager_config=ManagerConfig(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=4096,\n",
    "    ),\n",
    "    manager_llm=LLM,\n",
    "    log_traces=True\n",
    ")\n",
    "\n",
    "# Run workflow\n",
    "graph_inputs = {\n",
    "    \"project_root\": \"/home/nomi/workspace/neurosurfer/neurosurfer\",\n",
    "    \"docs_root\": \"/home/nomi/workspace/neurosurfer/docs\",\n",
    "    \"include_patterns\": [\"neurosurfer.agents.*\"],\n",
    "    \"exclude_patterns\": [],\n",
    "    \"sections\": [],\n",
    "    \"doc_template\": \"\",\n",
    "    \"mode\": \"structured\",\n",
    "}\n",
    "print(graph_agent)\n",
    "results = graph_agent.run(inputs=graph_inputs)\n",
    "# result = await run_async(executor.run(inputs=graph_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9cb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE iterating generator ===\n",
      "[]\n",
      "\n",
      "=== DURING streaming ===\n",
      "yielded: token_0\n",
      "current traces: ['TRACE: token_0']\n",
      "yielded: token_1\n",
      "current traces: ['TRACE: token_0', 'TRACE: token_1']\n",
      "yielded: token_2\n",
      "current traces: ['TRACE: token_0', 'TRACE: token_1', 'TRACE: token_2']\n",
      "\n",
      "=== AFTER streaming ===\n",
      "['TRACE: token_0', 'TRACE: token_1', 'TRACE: token_2']\n"
     ]
    }
   ],
   "source": [
    "# from dataclasses import dataclass, field\n",
    "# from typing import Generator, Optional, Union, List\n",
    "\n",
    "# @dataclass\n",
    "# class TraceResult:\n",
    "#     steps: List[str] = field(default_factory=list)\n",
    "#     def add(self, msg: str):\n",
    "#         self.steps.append(msg)\n",
    "\n",
    "# class DummyTracer:\n",
    "#     def __init__(self):\n",
    "#         self.results = TraceResult()\n",
    "#     def trace(self, msg: str):\n",
    "#         self.results.add(msg)\n",
    "\n",
    "# @dataclass\n",
    "# class AgentResponse:\n",
    "#     response: Union[str, Generator[str, None, None]]\n",
    "#     traces: Optional[TraceResult] = None\n",
    "\n",
    "# class DummyAgent:\n",
    "#     def __init__(self):\n",
    "#         self.tracer = DummyTracer()\n",
    "\n",
    "#     def run(self) -> AgentResponse:\n",
    "#         def generator():\n",
    "#             for i in range(3):\n",
    "#                 msg = f\"token_{i}\"\n",
    "#                 self.tracer.trace(f\"TRACE: {msg}\")   # tracing inside generator\n",
    "#                 yield msg\n",
    "#         return AgentResponse(\n",
    "#             response=generator(),\n",
    "#             traces=self.tracer.results  # shared reference\n",
    "#         )\n",
    "\n",
    "# agent = DummyAgent()\n",
    "# res = agent.run()\n",
    "\n",
    "# print(\"=== BEFORE iterating generator ===\")\n",
    "# print(res.traces.steps)   # should be empty\n",
    "\n",
    "# print(\"\\n=== DURING streaming ===\")\n",
    "# for tok in res.response:\n",
    "#     print(\"yielded:\", tok)\n",
    "#     print(\"current traces:\", res.traces.steps)\n",
    "\n",
    "# print(\"\\n=== AFTER streaming ===\")\n",
    "# print(res.traces.steps)   # should have all traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bb4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# print(results.final['plan_docs'].replace('```json', '').replace('```', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a52404d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': [{'step_id': 1,\n",
       "   'kind': 'agent',\n",
       "   'label': 'agent.run',\n",
       "   'node_id': None,\n",
       "   'agent_id': 'scan_repo',\n",
       "   'started_at': 1764051228.8918066,\n",
       "   'duration_ms': 840,\n",
       "   'inputs': {'agent_type': 'Agent',\n",
       "    'has_toolkit': True,\n",
       "    'structured': False,\n",
       "    'stream': False,\n",
       "    'strict_tool_call': False},\n",
       "   'outputs': {},\n",
       "   'meta': {},\n",
       "   'ok': True,\n",
       "   'error': None,\n",
       "   'logs': []},\n",
       "  {'step_id': 2,\n",
       "   'kind': 'llm.call',\n",
       "   'label': 'agent.route_and_call.router_llm_call',\n",
       "   'node_id': None,\n",
       "   'agent_id': 'scan_repo',\n",
       "   'started_at': 1764051228.8921106,\n",
       "   'duration_ms': 834,\n",
       "   'inputs': {'attempt': 1,\n",
       "    'strict_tool_call': False,\n",
       "    'system_prompt_len': 1959,\n",
       "    'user_prompt_len': 342,\n",
       "    'user_prompt': 'Scan the project_root and docs_root to build a structured index of packages, modules, and existing markdown docs. Include all Python files and markdown documents, and organize them into a compact JSON object with the following keys: \"packages\", \"modules\", \"python_files\", and \"doc_files\". Use the directory_scan tool to assist with this task.',\n",
       "    'system_prompt': 'You are a stateless tool router. \\nYou may either call a tool or respond directly with a natural language message â€” whichever best fits the user query.\\n\\nIf you decide to call a tool, respond **only** with one-line valid JSON in the exact format below:\\n{\"tool\": \"<tool_name>\", \"inputs\": {<param>: <value>}}\\n\\nIf you decide to respond directly, emit your message as a plain string (not JSON).\\n\\nRules:\\n- Choose at most ONE tool per request.\\n- Use only explicit parameters defined by that tool. Do NOT invent or rename parameters.\\n- Include only required parameters unless an optional one is clearly implied.\\n- If no tool fits the request or inputs are ambiguous, output:\\n  {\"tool\": \"none\", \"inputs\": {}}\\n- Otherwise, respond in plain text when a natural language answer is more suitable.\\n\\nTOOLS CATALOG:\\nAvailable tools:\\nTool Name: `directory_scan`\\nDescription: Scan a project directory (and optional docs directory) to build a structured index of Python modules, packages, and documentation files. Useful as a first step for automated documentation generation.\\nWhen to use: Use this tool when you need an overview of the codebase and docs structure: which packages, modules, Python files, and markdown files are present, along with basic counts.\\nTool Inputs:\\n- `include_patterns`: array (optional) â€” Optional list of glob patterns to include, e.g. [\\'neurosurfer/models/**\\'].\\n- `exclude_patterns`: array (optional) â€” Optional list of glob patterns to exclude, e.g. [\\'neurosurfer/tests/**\\'].\\n- `max_depth`: integer (optional) â€” Optional maximum depth to scan. \\nTool Return: object â€” JSON object describing the project structure, with keys like:\\n- project_root: normalized absolute path\\n- docs_root: normalized absolute path (if provided & exists)\\n- python_files: list of objects {path, abs_path, module, package}\\n- doc_files: list of objects {path, abs_path}\\n- packages: list of dotted package names\\n- modules: list of dotted module names\\n- summary: basic counts\\n\\n\\n',\n",
       "    'temperature': 0.7,\n",
       "    'max_new_tokens': 512,\n",
       "    'stream': False},\n",
       "   'outputs': {'model_response': '{\"tool\": \"directory_scan\", \"inputs\": {\"include_patterns\": [\"**\"], \"exclude_patterns\": []}}',\n",
       "    'model_response_len': 90},\n",
       "   'meta': {},\n",
       "   'ok': True,\n",
       "   'error': None,\n",
       "   'logs': [{'ts': 1764051229.726261,\n",
       "     'message': 'Selected tool: directory_scan',\n",
       "     'data': {},\n",
       "     'type': 'info'},\n",
       "    {'ts': 1764051229.7267768,\n",
       "     'message': \"Raw inputs: {'include_patterns': ['**'], 'exclude_patterns': []}\",\n",
       "     'data': {},\n",
       "     'type': 'info'}]},\n",
       "  {'step_id': 3,\n",
       "   'kind': 'tool.execute',\n",
       "   'label': 'agent.route_and_call.tool_execute',\n",
       "   'node_id': None,\n",
       "   'agent_id': 'scan_repo',\n",
       "   'started_at': 1764051229.7274964,\n",
       "   'duration_ms': 4,\n",
       "   'inputs': {'tool_name': 'directory_scan',\n",
       "    'payload': {'include_patterns': ['neurosurfer.agents.*'],\n",
       "     'exclude_patterns': [],\n",
       "     'dependencies': {},\n",
       "     'project_root': '/home/nomi/workspace/neurosurfer/neurosurfer',\n",
       "     'docs_root': '/home/nomi/workspace/neurosurfer/docs',\n",
       "     'sections': [],\n",
       "     'doc_template': '',\n",
       "     'mode': 'structured'}},\n",
       "   'outputs': {'tool_return': {'project_root': '/home/nomi/workspace/neurosurfer/neurosurfer',\n",
       "     'docs_root': '/home/nomi/workspace/neurosurfer/docs',\n",
       "     'python_files': [],\n",
       "     'doc_files': [{'path': 'index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/index.md'},\n",
       "      {'path': 'contributing.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/contributing.md'},\n",
       "      {'path': 'cli.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/cli.md'},\n",
       "      {'path': 'getting-started.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/getting-started.md'},\n",
       "      {'path': 'examples/models-examples.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/examples/models-examples.md'},\n",
       "      {'path': 'examples/custom-tools-examples.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/examples/custom-tools-examples.md'},\n",
       "      {'path': 'examples/server-app-example.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/examples/server-app-example.md'},\n",
       "      {'path': 'examples/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/examples/index.md'},\n",
       "      {'path': 'examples/rag-examples.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/examples/rag-examples.md'},\n",
       "      {'path': 'examples/agents-examples.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/examples/agents-examples.md'},\n",
       "      {'path': 'server/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/index.md'},\n",
       "      {'path': 'server/neurosurferui.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/neurosurferui.md'},\n",
       "      {'path': 'server/example-app.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/example-app.md'},\n",
       "      {'path': 'server/backend/custom-endpoints.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/backend/custom-endpoints.md'},\n",
       "      {'path': 'server/backend/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/backend/index.md'},\n",
       "      {'path': 'server/backend/lifecycle-hooks.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/backend/lifecycle-hooks.md'},\n",
       "      {'path': 'server/backend/auth.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/backend/auth.md'},\n",
       "      {'path': 'server/backend/chat-handlers.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/server/backend/chat-handlers.md'},\n",
       "      {'path': 'api-reference/configuration.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/configuration.md'},\n",
       "      {'path': 'api-reference/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/index.md'},\n",
       "      {'path': 'api-reference/vectorstores/in_memory.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/vectorstores/in_memory.md'},\n",
       "      {'path': 'api-reference/vectorstores/base-vectordb.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/vectorstores/base-vectordb.md'},\n",
       "      {'path': 'api-reference/vectorstores/chroma.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/vectorstores/chroma.md'},\n",
       "      {'path': 'api-reference/vectorstores/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/vectorstores/index.md'},\n",
       "      {'path': 'api-reference/models/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/index.md'},\n",
       "      {'path': 'api-reference/models/embedders/sentence-transformer.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/embedders/sentence-transformer.md'},\n",
       "      {'path': 'api-reference/models/embedders/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/embedders/index.md'},\n",
       "      {'path': 'api-reference/models/embedders/base-embedder.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/embedders/base-embedder.md'},\n",
       "      {'path': 'api-reference/models/embedders/llamacpp-embedder.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/embedders/llamacpp-embedder.md'},\n",
       "      {'path': 'api-reference/models/chat-models/base-model.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/chat-models/base-model.md'},\n",
       "      {'path': 'api-reference/models/chat-models/llamacpp-model.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/chat-models/llamacpp-model.md'},\n",
       "      {'path': 'api-reference/models/chat-models/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/chat-models/index.md'},\n",
       "      {'path': 'api-reference/models/chat-models/openai-model.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/chat-models/openai-model.md'},\n",
       "      {'path': 'api-reference/models/chat-models/transformers-model.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/chat-models/transformers-model.md'},\n",
       "      {'path': 'api-reference/models/chat-models/unsloth-model.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/models/chat-models/unsloth-model.md'},\n",
       "      {'path': 'api-reference/tools/tool-spec.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/tool-spec.md'},\n",
       "      {'path': 'api-reference/tools/base-tool.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/base-tool.md'},\n",
       "      {'path': 'api-reference/tools/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/index.md'},\n",
       "      {'path': 'api-reference/tools/toolkit.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/toolkit.md'},\n",
       "      {'path': 'api-reference/tools/builtin-tools/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/builtin-tools/index.md'},\n",
       "      {'path': 'api-reference/tools/builtin-tools/sql/db_insights_tool.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/builtin-tools/sql/db_insights_tool.md'},\n",
       "      {'path': 'api-reference/tools/builtin-tools/sql/sql_executor.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/builtin-tools/sql/sql_executor.md'},\n",
       "      {'path': 'api-reference/tools/builtin-tools/sql/relevant_table_schema_retriever.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/builtin-tools/sql/relevant_table_schema_retriever.md'},\n",
       "      {'path': 'api-reference/tools/builtin-tools/sql/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/builtin-tools/sql/index.md'},\n",
       "      {'path': 'api-reference/tools/builtin-tools/sql/final_answer_formatter.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/builtin-tools/sql/final_answer_formatter.md'},\n",
       "      {'path': 'api-reference/tools/builtin-tools/sql/sql_query_generator.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/tools/builtin-tools/sql/sql_query_generator.md'},\n",
       "      {'path': 'api-reference/rag/ingestor.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/rag/ingestor.md'},\n",
       "      {'path': 'api-reference/rag/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/rag/index.md'},\n",
       "      {'path': 'api-reference/rag/filereader.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/rag/filereader.md'},\n",
       "      {'path': 'api-reference/rag/chunker.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/rag/chunker.md'},\n",
       "      {'path': 'api-reference/agents/rag-agent.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/agents/rag-agent.md'},\n",
       "      {'path': 'api-reference/agents/react-agent.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/agents/react-agent.md'},\n",
       "      {'path': 'api-reference/agents/sql-agent.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/agents/sql-agent.md'},\n",
       "      {'path': 'api-reference/agents/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/agents/index.md'},\n",
       "      {'path': 'api-reference/agents/tools_router_agent.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/agents/tools_router_agent.md'},\n",
       "      {'path': 'api-reference/database/sql_schema_store.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/database/sql_schema_store.md'},\n",
       "      {'path': 'api-reference/database/sql_database.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/database/sql_database.md'},\n",
       "      {'path': 'api-reference/database/index.md',\n",
       "       'abs_path': '/home/nomi/workspace/neurosurfer/docs/api-reference/database/index.md'}],\n",
       "     'packages': ['neurosurfer',\n",
       "      'neurosurfer.agents',\n",
       "      'neurosurfer.agents.agent',\n",
       "      'neurosurfer.agents.graph',\n",
       "      'neurosurfer.agents.rag',\n",
       "      'neurosurfer.agents.react',\n",
       "      'neurosurfer.cli',\n",
       "      'neurosurfer.db',\n",
       "      'neurosurfer.models.chat_models',\n",
       "      'neurosurfer.models.embedders',\n",
       "      'neurosurfer.server',\n",
       "      'neurosurfer.server.api',\n",
       "      'neurosurfer.server.db',\n",
       "      'neurosurfer.server.schemas',\n",
       "      'neurosurfer.server.services.rag',\n",
       "      'neurosurfer.tools',\n",
       "      'neurosurfer.tools.common',\n",
       "      'neurosurfer.tools.sql',\n",
       "      'neurosurfer.tools.websearch',\n",
       "      'neurosurfer.tools.websearch.engines',\n",
       "      'neurosurfer.tracing',\n",
       "      'neurosurfer.utils',\n",
       "      'neurosurfer.vectorstores'],\n",
       "     'modules': [],\n",
       "     'summary': {'python_file_count': 0,\n",
       "      'doc_file_count': 58,\n",
       "      'package_count': 23,\n",
       "      'module_count': 0}},\n",
       "    'extras': {}},\n",
       "   'meta': {},\n",
       "   'ok': True,\n",
       "   'error': None,\n",
       "   'logs': [{'ts': 1764051229.7315056,\n",
       "     'message': \"Tool 'directory_scan' Tool Return: {'project_root': '/home/nomi/workspace/neurosurfer/neurosurfer', 'docs_root': '/home/nomi/workspace/...\",\n",
       "     'data': {},\n",
       "     'type': 'info'}]}],\n",
       " 'meta': {'agent_type': 'generic_agent',\n",
       "  'agent_config': {'allow_input_pruning': True,\n",
       "   'repair_with_llm': True,\n",
       "   'strict_tool_call': False,\n",
       "   'temperature': 0.7,\n",
       "   'max_new_tokens': 512,\n",
       "   'return_stream_by_default': False,\n",
       "   'retry': {'max_route_retries': 2,\n",
       "    'max_tool_retries': 1,\n",
       "    'backoff_sec': 0.7},\n",
       "   'strict_json': True,\n",
       "   'max_json_repair_attempts': 1},\n",
       "  'model': '/home/nomi/workspace/Model_Weights/Qwen3-8B-unsloth-bnb-4bit',\n",
       "  'toolkit': True,\n",
       "  'verbose': True,\n",
       "  'log_steps': True}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.nodes['scan_repo'].traces.model_dump()\n",
    "# results.nodes['scan_repo'].traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7f9e61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan the project_root and docs_root to build a structured index of packages, modules, and existing markdown docs. Focus on Python files and documentation in the specified directories, using the include_patterns and exclude_patterns provided. Output a compact JSON object with the keys \"packages\", \"modules\", \"python_files\", and \"doc_files\".\n"
     ]
    }
   ],
   "source": [
    "print(results.nodes['scan_repo'].traces.steps[1].inputs['user_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd2c59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a795f88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseChatModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     34\u001b[39m     strict_json: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m                  \u001b[38;5;66;03m# enforce RFC 8259 JSON\u001b[39;00m\n\u001b[32m     35\u001b[39m     max_repair_attempts: \u001b[38;5;28mint\u001b[39m = \u001b[32m1\u001b[39m              \u001b[38;5;66;03m# for malformed JSON repairs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNodeBudget\u001b[39;00m(\u001b[43mBaseChatModel\u001b[49m):\n\u001b[32m     40\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    Budget / LLM-related overrides per node.\u001b[39;00m\n\u001b[32m     42\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m \u001b[33;03m        - return_stream_by_default -> AgentConfig.return_stream_by_default\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     49\u001b[39m     max_new_tokens: Optional[\u001b[38;5;28mint\u001b[39m] = Field(\n\u001b[32m     50\u001b[39m         default=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     51\u001b[39m         description=\u001b[33m\"\u001b[39m\u001b[33mOverride AgentConfig.max_new_tokens for this node only.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m     )\n",
      "\u001b[31mNameError\u001b[39m: name 'BaseChatModel' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass\n",
    "class RouterRetryPolicy:\n",
    "    \"\"\"Retry tuning for routing + tool execution.\"\"\"\n",
    "    max_route_retries: int = 2\n",
    "    max_tool_retries: int = 1\n",
    "    backoff_sec: float = 0.7  # linear backoff\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"\n",
    "    Top-level configuration for the Agent.\n",
    "    \"\"\"\n",
    "    # Routing:\n",
    "    allow_input_pruning: bool = True    # drop unknown inputs not in ToolSpec\n",
    "    repair_with_llm: bool = True        # ask LLM to repair invalid routing/inputs\n",
    "    strict_tool_call: bool = False      # router must output JSON; else can answer in plain text\n",
    "    # synonyms: Dict[str, Dict[str, str]] = field(default_factory=dict)  # field -> {from: to}\n",
    "\n",
    "    # LLM defaults:\n",
    "    temperature: float = 0.7\n",
    "    max_new_tokens: int = 512\n",
    "    return_stream_by_default: bool = False\n",
    "\n",
    "    # Retries:\n",
    "    retry: RouterRetryPolicy = field(default_factory=RouterRetryPolicy)\n",
    "\n",
    "    # Structured-output options:\n",
    "    strict_json: bool = True                  # enforce RFC 8259 JSON\n",
    "    max_repair_attempts: int = 1              # for malformed JSON repairs\n",
    "\n",
    "\n",
    "\n",
    "class NodeBudget(BaseChatModel):\n",
    "    \"\"\"\n",
    "    Budget / LLM-related overrides per node.\n",
    "\n",
    "    These map directly to AgentConfig fields:\n",
    "        - temperature      -> AgentConfig.temperature\n",
    "        - max_new_tokens   -> AgentConfig.max_new_tokens\n",
    "        - return_stream_by_default -> AgentConfig.return_stream_by_default\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.max_new_tokens for this node only.\",\n",
    "    )\n",
    "    temperature: Optional[float] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.temperature for this node only.\",\n",
    "    )\n",
    "    return_stream_by_default: Optional[bool] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.return_stream_by_default for this node only.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class NodePolicy(BaseChatModel):\n",
    "    \"\"\"\n",
    "    Per-node policy that can override some AgentConfig settings and add\n",
    "    node-level execution constraints (e.g., timeout).\n",
    "\n",
    "    YAML example:\n",
    "\n",
    "        nodes:\n",
    "          - id: research\n",
    "            policy:\n",
    "              retries: 1\n",
    "              timeout_s: 30\n",
    "              budget:\n",
    "                max_new_tokens: 180\n",
    "                temperature: 0.2\n",
    "              allow_input_pruning: false\n",
    "              repair_with_llm: true\n",
    "              strict_tool_call: true\n",
    "    \"\"\"\n",
    "\n",
    "    retries: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Override AgentConfig.retry.max_route_retries for this node.\",\n",
    "    )\n",
    "    timeout_s: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"Soft timeout for this node in seconds. Execution isn't forcibly \"\n",
    "            \"cancelled but the node will be marked as errored if exceeded.\"\n",
    "        ),\n",
    "    )\n",
    "    budget: Optional[NodeBudget] = None\n",
    "\n",
    "    # Direct AgentConfig-like overrides\n",
    "    allow_input_pruning: Optional[bool] = None\n",
    "    repair_with_llm: Optional[bool] = None\n",
    "    strict_tool_call: Optional[bool] = None\n",
    "    strict_json: Optional[bool] = None\n",
    "    max_repair_attempts: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        extra = \"ignore\"  # ignore unknown keys under 'policy'\n",
    "\n",
    "c = AgentConfig()\n",
    "\n",
    "p = NodePolicy(budget=NodeBudget(temperature=1.2))\n",
    "\n",
    "print(c)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93052a6d",
   "metadata": {},
   "source": [
    "### Python API version (no YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926be727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: True\n",
      "Answer:\n",
      " The calculator result for your request is ${compute.text}. This means that after performing the calculation based on your input, the final answer is ${compute.text}. Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from graph import Graph, Node, NodePolicy, GraphConfig, GraphExecutor\n",
    "from neurosurfer.tools import Toolkit\n",
    "from neurosurfer.models.chat_models.openai import OpenAIModel\n",
    "\n",
    "# Reuse your existing toolkit + model\n",
    "llm = LLM  # already created in your environment\n",
    "tk = toolkit\n",
    "\n",
    "graph = Graph(\n",
    "    name=\"calc_and_explain\",\n",
    "    config=GraphConfig(max_concurrency=2),\n",
    "    inputs_schema={\"prompt\": str},\n",
    "    nodes=[\n",
    "        Node(\n",
    "            id=\"rewrite\",\n",
    "            fn=\"general_query_assistant\",  # adjust name if needed\n",
    "            inputs={\n",
    "                # swap \"query\" -> \"prompt\" if your tool expects \"prompt\"\n",
    "                \"query\": (\n",
    "                    \"You will receive a user request. Extract a SINGLE pure arithmetic expression that can be \"\n",
    "                    \"evaluated by a calculator (e.g., '(42 * 7) - 5^2' or '0.035 * 12000').\\n\"\n",
    "                    \"- Do NOT include explanations.\\n\"\n",
    "                    \"- Return ONLY the expression as plain text.\\n\\n\"\n",
    "                    \"User request:\\n${inputs.prompt}\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"num1\", \"num2\", \"operation\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 128, \"temperature\": 0.1},\n",
    "            ),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"compute\",\n",
    "            fn=\"calculator\",\n",
    "            inputs={\"num1\": \"${rewrite.num1}\", \"num2\": \"${rewrite.num2}\", \"operation\": \"${rewrite.operation}\"},\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(retries=0, timeout_s=15),\n",
    "        ),\n",
    "        Node(\n",
    "            id=\"explain\",\n",
    "            fn=\"general_query_assistant\",\n",
    "            inputs={\n",
    "                \"query\": (\n",
    "                    \"Original request: ${inputs.prompt}\\n\"\n",
    "                    \"Calculator result: ${compute.text}\\n\\n\"\n",
    "                    \"Write a brief, user-friendly explanation of the result (one short paragraph).\"\n",
    "                )\n",
    "            },\n",
    "            outputs=[\"text\"],\n",
    "            policy=NodePolicy(\n",
    "                retries=1,\n",
    "                timeout_s=30,\n",
    "                budget={\"max_new_tokens\": 180, \"temperature\": 0.2},\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    outputs={\"answer\": \"${explain.text}\"},\n",
    ")\n",
    "\n",
    "executor = GraphExecutor(llm=llm, toolkit=tk, max_concurrency=2)\n",
    "\n",
    "result = await run_async(\n",
    "    executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}, stream=True)\n",
    ")\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(\"Answer:\\n\", result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e25a8",
   "metadata": {},
   "source": [
    "### Planner-based path (using the YAML as a skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, tempfile, pathlib\n",
    "from graph import PlannerAgent, FlowLoader, GraphExecutor\n",
    "\n",
    "# 1) Write the YAML to a temp file (only for this demo)\n",
    "yaml_text = r\"\"\"\n",
    "name: calc_and_explain\n",
    "inputs:\n",
    "  prompt: str\n",
    "config:\n",
    "  max_concurrency: 2\n",
    "nodes:\n",
    "  - id: rewrite\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        You will receive a user request. Extract a SINGLE pure arithmetic expression that can be\n",
    "        evaluated by a calculator (e.g., \"(42 * 7) - 5^2\" or \"0.035 * 12000\").\n",
    "        - Do NOT include explanations.\n",
    "        - Return ONLY the expression as plain text.\n",
    "\n",
    "        User request:\n",
    "        ${inputs.prompt}\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 128, temperature: 0.1 } }\n",
    "\n",
    "  - id: compute\n",
    "    kind: task\n",
    "    fn: calculator\n",
    "    inputs: { expression: ${rewrite.text} }\n",
    "    outputs: [\"text\"]\n",
    "\n",
    "  - id: explain\n",
    "    kind: task\n",
    "    fn: general_query_assistant\n",
    "    inputs:\n",
    "      query: |\n",
    "        Original request: ${inputs.prompt}\n",
    "        Calculator result: ${compute.text}\n",
    "\n",
    "        Write a brief, user-friendly explanation of the result (one short paragraph).\n",
    "    outputs: [\"text\"]\n",
    "    policy: { retries: 1, timeout_s: 30, budget: { max_new_tokens: 180, temperature: 0.2 } }\n",
    "\n",
    "outputs: { answer: ${explain.text} }\n",
    "\"\"\".strip()\n",
    "\n",
    "tmp = pathlib.Path(tempfile.gettempdir()) / \"calc_and_explain.yml\"\n",
    "tmp.write_text(yaml_text)\n",
    "\n",
    "# 2) Use the planner with a skeleton (so it returns your YAML-based Graph)\n",
    "planner = PlannerAgent(llm=LLM)  # LLM not used when skeleton is set\n",
    "graph = planner.plan_from_query(query=\"Compute 3.5% of 12000 and explain\", skeleton=str(tmp))\n",
    "\n",
    "# 3) Execute\n",
    "executor = GraphExecutor(llm=LLM, toolkit=toolkit, max_concurrency=2)\n",
    "result = asyncio.run(executor.run(graph, inputs={\"prompt\": \"Compute 3.5% of 12000 and explain\"}))\n",
    "\n",
    "print(\"OK:\", result.ok)\n",
    "print(result.outputs[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225587f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f9ca96",
   "metadata": {},
   "source": [
    "Test ToolsRouterAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d83d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: calculator\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:32\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'num1': 20.0, 'num2': 90.0, 'operation': 'multiply'}\n",
      "1800.0"
     ]
    }
   ],
   "source": [
    "query = \"Perform the calculation 20 * 90\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6635c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Using tool: general_query_assistant\n",
      "\u001b[92mINFO    \u001b[0m | \u001b[90m2025-11-06 11:08:33\u001b[0m | \u001b[96mtools_router_agent.py:run\u001b[0m | [router] Raw inputs: {'query': 'Tell me a light-hearted joke!'}\n",
      "Why don't skeletons fight each other? They don't have the guts!None"
     ]
    }
   ],
   "source": [
    "query = \"Tell me a light-hearted joke!\"\n",
    "\n",
    "for chunk in tools_router_agent.run(query, temperature=0.7, max_new_tokens=4000):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafe29f",
   "metadata": {},
   "source": [
    "## ReactAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aa87f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[ðŸ§ ] Chain of Thoughts...\n",
      "Thought: I will first calculate 300 - 300 using the calculator tool, and then I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"calculator\",\n",
      "  \"inputs\": {\n",
      "    \"num1\": 300,\n",
      "    \"num2\": 300,\n",
      "    \"operation\": \"subtract\"\n",
      "  },\n",
      "  \"final_answer\": false\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>ðŸ”§<span style=\"font-weight: bold\">]</span> Tool: calculator\n",
       "<span style=\"font-weight: bold\">[</span>ðŸ“¤<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'num1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'operation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'subtract'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0mðŸ”§\u001b[1m]\u001b[0m Tool: calculator\n",
       "\u001b[1m[\u001b[0mðŸ“¤\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'num1'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'num2'\u001b[0m: \u001b[1;36m300\u001b[0m, \u001b[32m'operation'\u001b[0m: \u001b[32m'subtract'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[ðŸ§ ] Chain of Thoughts...\n",
      "Thought: The result of the calculation is 0. Now, I will use the general_query_assistant tool to find a light-hearted joke about the result.\n",
      "\n",
      "Action: {\n",
      "  \"tool\": \"general_query_assistant\",\n",
      "  \"inputs\": {\n",
      "    \"query\": \"Tell me a light-hearted joke about the number 0.\"\n",
      "  },\n",
      "  \"final_answer\": true\n",
      "}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>ðŸ”§<span style=\"font-weight: bold\">]</span> Tool: general_query_assistant\n",
       "<span style=\"font-weight: bold\">[</span>ðŸ“¤<span style=\"font-weight: bold\">]</span> Inputs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tell me a light-hearted joke about the number 0.'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0mðŸ”§\u001b[1m]\u001b[0m Tool: general_query_assistant\n",
       "\u001b[1m[\u001b[0mðŸ“¤\u001b[1m]\u001b[0m Inputs: \u001b[1m{\u001b[0m\u001b[32m'query'\u001b[0m: \u001b[32m'Tell me a light-hearted joke about the number 0.'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the number 0 break up with the number 8?  \n",
      "Because it found someone more \"8\" (8) than a zero!"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Observation:</span> Why did the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> break up with the number <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>?  \n",
       "Because it found someone more <span style=\"color: #008000; text-decoration-color: #008000\">\"8\"</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span> than a zero!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mObservation:\u001b[0m Why did the number \u001b[1;36m0\u001b[0m break up with the number \u001b[1;36m8\u001b[0m?  \n",
       "Because it found someone more \u001b[32m\"8\"\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m than a zero!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[ðŸ§ ] Chain of Thoughts...\n",
      "Thought: The calculation result is 0, and the joke provided is ready. The final answer is complete.\n",
      "\n",
      "Final Answer: The result of 300 - 300 is 0. Here's a light-hearted joke about it: Why did the number 0 break up with the number 8? Because it found someone more \"8\" (8) than a zero!"
     ]
    }
   ],
   "source": [
    "from neurosurfer.agents.react import ReActAgent, ReActConfig\n",
    "\n",
    "react_agent = ReActAgent(\n",
    "    toolkit=toolkit,\n",
    "    llm=LLM,\n",
    "    specific_instructions=\"Always be concise in your answers. Break the task into steps if needed.\",\n",
    "    config=ReActConfig(\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=4096,\n",
    "        allow_input_pruning=True,\n",
    "        repair_with_llm=True,\n",
    "        skip_special_tokens=True,\n",
    "        verbose=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(react_agent._system_prompt())\n",
    "TASK = \"\"\"Calculate 300 - 300. Then tell me a light-hearted joke about that result.\"\"\"\n",
    "\n",
    "for chunk in react_agent.run(TASK):\n",
    "    print(chunk, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41580e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c7a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766512d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad2c2b-4a95-4ac0-9727-4c746e97a629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ea014-d67c-4af9-b2f6-1a8d80d63b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
